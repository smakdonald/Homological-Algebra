<?xml version='1.0' encoding='utf-8'?>

<pretext xml:lang="en-US" xmlns:xi="http://www.w3.org/2001/XInclude">

  <docinfo>

    <!-- the other option is "long" which will produce an -->
    <!-- entire front matter section with more headings   -->
    <author-biographies length="short" />

    <!--
    <brandlogo url="http://abstract.pugetsound.edu" source="images/cover_aata_2014.png" />
    -->

    <!--
    <covers front="images/original-front-cover-aata.pdf"
            back="images/plain-back-cover-aata.pdf"/>
    -->

    <!-- Prefix to enhance Sage notebook contents -->
    <!--
    <initialism>AATA</initialism>
    -->

    <macros>
        <!-- Operators     -->
        \def\ann{\operatorname{ann}}
        \newcommand{\Ass}{\operatorname{Ass}}
        \def\Aut{\operatorname{Aut}}
        \def\can{{\mathrm {can}}}
        \def\char{\operatorname{char}}
        \def\cp{\operatorname{CharPoly}}
        \def\codim{\operatorname{codim}} 
        \def\coker{\operatorname{coker}}
        \DeclareMathOperator*{\colim}{colim} 
        \def\cont{\operatorname{cont}} 
        \def\diam{\operatorname{diam}} 
        \def\dm{\operatorname{dim}} 
        \DeclareMathOperator{\edim}{embdim} 
        \def\End{\operatorname{End}} 
        \def\eval{\operatorname{eval}} 
        \def\Ext{\operatorname{Ext}} 
        \def\Frac{\operatorname{Frac}}
        \def\Fun{\operatorname{Fun}}
        \def\Gal{\operatorname{Gal}}
        \def\gcd{\operatorname{gcd}}
        \newcommand{\GL}{\operatorname{GL}} 
        \newcommand{\ht}{\operatorname{height}} 
        \def\Hom{\operatorname{Hom}} 
        \def\id{\operatorname{id}} 
        \def\im{\operatorname{im}} 
        \def\Inn{\operatorname{Inn}}
        \def\ker{\operatorname{ker}}
        \def\lcm{\operatorname{lcm}} 
        \def\Mat{\operatorname{Mat}}
        \newcommand{\Min}{\operatorname{Min}}
        \def\mp{\operatorname{MinPoly}}
        \def\mSpec{\operatorname{mSpec}}
        \def\MSpec{\operatorname{MSpec}}
        \def\null{\operatorname{Nul}}
        \DeclareMathOperator{\ns}{nullspace}
        \newcommand{\opp}{\operatorname{opp}}
        \def\Orb{\operatorname{Orb}} 
        \def\Out{\operatorname{Out}}
        \def\Perm{\operatorname{Perm}}
        \def\ptstab{\operatorname{PtStab}} 
        \def\rad{\operatorname{rad}}
        \DeclareMathOperator{\range}{range}
        \def\rank{\operatorname{rank}}
        \def\res{\operatorname{res}}
        \def\setstab{\operatorname{SetStab}}
        \def\sign{{\operatorname{sign}}}
        \newcommand{\SL}{\operatorname{SL}}
        \def\Span{\operatorname{Span}}
        \def\Spec{\operatorname{Spec}}
        \def\Stab{\operatorname{Stab}} 
        \DeclareMathOperator{\Supp}{Supp}
        \def\Syl{\operatorname{Syl}}
        \def\Tor{\operatorname{Tor}}
        \def\trace{\operatorname{trace}}
        \def\uSpec{\operatorname{\underline{Spec}}}
        <!-- Categories     -->
        \newcommand{\Ob}{\mathrm{Ob}}
        \newcommand{\Set}{\mathbf{Set}}
        \newcommand{\Grp}{\mathbf{Grp}}
        \newcommand{\Ab}{\mathbf{Ab}}
        \newcommand{\Sgrp}{\mathbf{Sgrp}}
        \newcommand{\Ring}{\mathbf{Ring}} 
        \newcommand{\Fld}{\mathbf{Fld}}
        \newcommand{\cRing}{\mathbf{cRing}}
        \newcommand{\Mod}{-\mathbf{Mod}}
        \newcommand{\mod}{-\mathbf{mod}} 
        \newcommand{\Cx}[1]{#1-\mathbf{Comp}} 
        \newcommand{\vs}[1]{#1-\mathbf{vect}}
        \newcommand{\Vs}[1]{#1-\mathbf{Vect}}
        \newcommand{\vsp}[1]{#1-\mathbf{vect}^+} 
        \newcommand{\Top}{\mathbf{Top}} 
        \newcommand{\Setp}{\mathbf{Set}_*} 
        \newcommand{\Alg}[1]{#1-\mathbf{Alg}} 
        \newcommand{\cAlg}[1]{#1-\mathbf{cAlg}} 
        \newcommand{\PO}{\mathbf{PO}}
        \newcommand{\Cont}{\mathrm{Cont}}
        \newcommand{\MaT}[1]{\mathbf{Mat}_{#1}}
        \newcommand{\Rep}[2]{\mathbf{Rep}_{#1}(#2)}
        <!-- Greek     -->
        \def\l{\lambda}
        \def\lx{\lambda_x}
        \newcommand{\a}{\alpha}
        \def\b{\beta}
        \def\d{\delta}
        \def\e{\varepsilon}
        \def\g{\gamma}
        \def\t{\theta}
        \def\s{\sigma}
        \def\z{\zeta}
        \def\vp{\varphi}
        <!-- Letters     -->
        <!-- MathBB     -->
        \newcommand{\A}{\mathbb{A}}
        \newcommand{\B}{\mathbb{B}}
        \newcommand{\C}{\mathbb{C}}
        \newcommand{\D}{\mathbb{D}}
        \newcommand{\E}{\mathbb{E}}
        \newcommand{\F}{\mathbb{F}}
        \newcommand{\G}{\mathbb{G}}
        \newcommand{\H}{\mathbb{H}}
        \newcommand{\I}{\mathbb{I}}
        \newcommand{\J}{\mathbb{J}}
        \newcommand{\K}{\mathbb{K}}
        \newcommand{\L}{\mathbb{L}} 
        \newcommand{\M}{\mathbb{M}}
        \newcommand{\N}{\mathbb{N}}
        \newcommand{\O}{\mathbb{O}}
        \newcommand{\P}{\mathbb{P}}
        \newcommand{\Q}{\mathbb{Q}} 
        \newcommand{\R}{\mathbb{R}} 
        \newcommand{\S}{\mathbb{S}}
        \newcommand{\T}{\mathbb{T}}
        \newcommand{\U}{\mathbb{U}}
        \newcommand{\V}{\mathbb{V}}
        \newcommand{\W}{\mathbb{W}}
        \newcommand{\X}{\mathbb{X}}
        \newcommand{\Y}{\mathbb{Y}}
        \newcommand{\Z}{\mathbb{Z}} 
        \newcommand{\ON}{\mathbb{ON}}
        <!-- MathCal     -->
        \def\cA{\mathcal A} 
        \def\cB{\mathcal B} 
        \def\cC{\mathcal C} 
        \def\cD{\mathcal D} 
        \def\cE{\mathcal E} 
        \def\cF{\mathcal F} 
        \def\cG{\mathcal G} 
        \def\cH{\mathcal H} 
        \def\cI{\mathcal I} 
        \def\cJ{\mathcal J} 
        \def\cK{\mathcal K} 
        \def\cL{\mathcal L}
        \def\cM{\mathcal M} 
        \def\cN{\mathcal N} 
        \def\cO{\mathcal O} 
        \def\cP{\mathcal P} 
        \def\cQ{\mathcal Q} 
        \def\cR{\mathcal R} 
        \def\cS{\mathcal S} 
        \def\cT{\mathcal T} 
        \def\cU{\mathcal U} 
        \def\cV{\mathcal V} 
        \def\cW{\mathcal W} 
        \def\cX{\mathcal X} 
        \def\cY{\mathcal Y} 
        \def\cZ{\mathcal Z} 
        <!-- MathFrak     -->
        \newcommand{\fa}{{\mathfrak a}} 
        \newcommand{\fb}{{\mathfrak b}} 
        \newcommand{\fc}{{\mathfrak c}} 
        \newcommand{\fd}{{\mathfrak d}} 
        \newcommand{\fe}{{\mathfrak e}}
        \newcommand{\fm}{{\mathfrak m}} 
        \newcommand{\fp}{{\mathfrak p}} 
        \newcommand{\fq}{{\mathfrak q}} 
        \newcommand{\fK}{{\mathfrak K}} 
        \newcommand{\fR}{{\mathfrak R}} 
        <!-- MathScr     -->
        \def\sA{\mathscr A} 
        \def\sB{\mathscr B} 
        \def\sC{\mathscr C} 
        \def\sD{\mathscr D} 
        \def\sE{\mathscr E} 
        \def\sF{\mathscr F} 
        \def\sG{\mathscr G} 
        \def\sH{\mathscr H} 
        \def\sI{\mathscr I} 
        \def\sJ{\mathscr J} 
        \def\sK{\mathscr K} 
        \def\sL{\mathscr L}
        \def\sM{\mathscr M}
        \def\sN{\mathscr N}
        \def\sO{\mathscr O}
        \def\sP{\mathscr P}
        \def\sQ{\mathscr Q}
        \def\sR{\mathscr R}
        \def\sS{\mathscr S}
        \def\sT{\mathscr T}
        \def\sU{\mathscr U}
        \def\sV{\mathscr V}
        \def\sW{\mathscr W}
        \def\sX{\mathscr X}
        \def\sY{\mathscr Y}
        \def\sZ{\mathscr Z}
        <!-- Tildes     -->
        \def\tS{\tilde{S}}
        <!-- Algebra     -->
        \def\sdp{\rtimes}
        \newcommand{\tensor}{\otimes} 
        \newcommand{\igen}[1]{\langle #1 \rangle} 
        \def\nsg{\unlhd} 
        \def\kval{{k-\mathrm{valued}}} 
        \def\kalg{{k-\mathrm{alg}}}
        \newcommand\GG[2]{\Gal(#1/#2)}
        <!-- Matrices     -->
        \newcommand{\MF}[3]{\Mat_{#1\times #2}(#3)}
        \newcommand{\vectwo}[2]{\begin{bmatrix} #1 \\ #2 \end{bmatrix}} 
        \newcommand{\vecthree}[3]{\begin{bmatrix} #1 \\ #2 \\ #3\end{bmatrix}} 
        \def\ob{{\mathfrak{ob}} }
        <!-- Misc     -->
        \def\qed{\square}
        \def\sse{\subseteq}
        \def\ss{\subset} 
        \def\ssne{\subsetneq}
        \def\sm{\setminus}
        \def\inv{^{-1}} 
        \newcommand{\es}{\emptyset} 
        \newcommand{\Zm}[1]{\Z/({#1})} 
        \def\ov#1{\overline{#1}} 
        \def\xdots{x_1, \dots, x_n} 
        \def\adots{a_1, \dots, a_n} 
        \def\bdots{b_1, \dots, b_n} 
        \def\udots{u_1, \dots, u_n} 
        \newcommand{\leg}[2]{\left(\frac{{#1}}{{#2}}\right)} 
        \def\th{^{th}} 
        \def\htpy{\simeq_{\mathrm{htpc}}} 
        <!-- Math Text     -->
        \def\textand{ \, \text{and} \, } 
        \def\textor{ \, \text{or} \, } 
        \def\textfor{ \, \text{for} \, } 
        \def\textfa{ \, \text{for all} \, } 
        \def\textst{ \, \text{such that} \, } 
        \def\textin{ \, \text{in} \, } 
        \def\fg{ \, \text{finitely generated} \, }
        \newcommand{\op}{\mathrm{op}}
        <!-- Arrows     -->
        \newcommand{\xra}[1]{\xrightarrow{#1}} 
        \newcommand{\xora}[1]{\xtwoheadrightarrow{#1}} 
        \newcommand{\xira}[1]{\xhookrightarrow{#1}} 
        \newcommand{\xla}[1]{\xleftarrow{#1}} 
        \def\lra{\longrightarrow}
        \def\into{\hookrightarrow}
        \def\onto{\twoheadrightarrow}
        <!-- Vectors     -->
        \newcommand{\vv}[1]{\mathbf{#1}}
        \newcommand{\lm}[2]{{#1}\,\l + {#2}\,\mu} 
        \renewcommand{\v}{\vv{v}}
        \renewcommand{\u}{\vv{u}}
        \newcommand{\w}{\vv{w}}
        \newcommand{\x}{\vv{x}}
        \renewcommand{\k}{\vv{k}}
        \newcommand{\0}{\vv{0}}
        \newcommand{\1}{\vv{1}}
        \newcommand{\vecs}[2]{#1_1,#1_2,\dots,#1_{#2}}
        \newcommand{\us}[1][n]{\vecs{\u}{#1}}
        \newcommand{\vs}[1][n]{\vecs{\v}{#1}}
        \newcommand{\ws}[1][n]{\vecs{\w}{#1}}
        \newcommand{\vps}[1][n']{\vecs{\v'}{#1}}
        \newcommand{\ls}[1][n]{\vecs{\l}{#1}}
        \newcommand{\mus}[1][n]{\vecs{\mu}{#1}} 
        \newcommand{\lps}[1][n]{\vecs{\l'}{#1}}
        \def\td{\tilde{\delta}}
        \def\oo{\overline{\omega}}
        \def\ctJ{\tilde{\mathcal J}}
        \def\tPhi{\tilde{\Phi}}
        \def\te{\tilde{e}}
        \def\M{\operatorname{M}}
        \newcommand{\homotopic}{\simeq}
        \newcommand{\homeq}{\cong}
        \newcommand{\iso}{\approx}
        \newcommand{\dual}{\vee} 
        \DeclarePairedDelimiter{\abs}{|}{|}
        \newcommand{\bv}{{\bar{v}}}
        \newcommand{\bu}{{\bar{u}}}
        \newcommand{\bw}{{\bar{w}}}
        \newcommand{\by}{{\bar{y}}}
        \newcommand{\ba}{{\bar{a}}}
        \newcommand{\bb}{{\bar{b}}}
        \newcommand{\bx}{{\bar{x}}}
        \DeclarePairedDelimiterX\setof[2]{\{}{\}}{#1\,|\,#2}
        \newcommand{\vx}{\underline{x}}
        \renewcommand{mod}[1]{\text{(mod }{#1})}
        \newcommand{\Slv}[3]{\sum_{{#2}=1}^{{#3}} {#1}_{{#2}} \v_{{#2}}}
    </macros>

    <!-- this is the default, but supresses a warning -->
    <cross-references text="type-global" />

    <!-- tikz package and libraries for images -->
    <latex-image-preamble>
      \usepackage{tikz}
      \usetikzlibrary{backgrounds}
      \usetikzlibrary{snakes}
      \usepackage{tkz-graph}
      \usepackage{tkz-euclide}
      \usetikzlibrary{patterns}
      \usetikzlibrary{positioning}
      \usetikzlibrary{matrix,arrows}
      \usetikzlibrary{calc}
      \usetikzlibrary{shapes}
      \usetikzlibrary{through,intersections,decorations,shadows,fadings}
      
      \usepackage{pgfplots}
    </latex-image-preamble>

    <rename element="inlineexercise">Exercise</rename>
    <rename element="outcomes">Summary</rename>

  </docinfo>

  <book xml:id="book-homological"><title>Homological Algebra</title>

    <frontmatter xml:id="frontmatter">

      <titlepage>
        <author>
          <personname>Sam Macdonald</personname>
          <department>Department of Mathematics</department>
          <institution>University of Nebraska -- Lincoln</institution>
        </author>
        <date>
          <today />
        </date>
      </titlepage>

      <colophon>
        <website>
          <name>
            <c>smakdonald.github</c>
          </name>
          <address>https://smakdonald.github.io/index.html</address>
        </website>

        <copyright>
          <year>2020<ndash />2023</year>
          <holder>Sam Macdonald</holder>
          <shortlicense> 
            This work is licensed under the Creative Commons Attribution-ShareAlike 4.0 International License. To view a copy of this license, visit <url href="http://creativecommons.org/licenses/by-sa/4.0/" visual="creativecommons.org/licenses/by-sa/4.0"> CreativeCommons.org</url>
          </shortlicense>
        </copyright>
      </colophon>

    </frontmatter>

    <part xml:id="part-homalg"><title>Homological Algebra</title>

      <chapter xml:id="ch-intro"><title>Where are we going?</title>

        <p>
          Homological algebra first appeared in the study of topological spaces. 
          Roughly speaking, homology is a way of associating a sequence of abelian groups (or modules, or other more sophisticated algebraic objects) to another object, for example a topological space. 
          The homology of a topological space encodes topological information about the space in algebraic language - this is what algebraic topology is all about.
        </p>
    
        <p>
          More formally, we will study complexes and their homology from a more abstract perspective. 
          While algebraic topologists are often concerned with complexes of abelian groups, we will work a bit more generally with complexes of <m>R</m>-modules. 
          The basic assumptions and notation about rings and modules we will use in this class can be found in Appendix A. 
          As an appetizer, we begin with some basic homological algebra definitions.
        </p>

        <definition xml:id="def-chain-complex"><title>Chain Complex</title>
          <statement>
            <p>
              A chain complex of <m>R</m>-modules <m>\left(C_{\bullet}, \partial_{\bullet}\right)</m>, also referred to simply as a complex, is a sequence of <m>R</m>-modules <m>C_{i}</m> and <m>R</m>-module homomorphisms
              <me>
                \cdots \longrightarrow C_{n+1} \stackrel{\partial_{n+1}}{\longrightarrow} C_{n} \stackrel{\partial_{n}}{\longrightarrow} C_{n-1} \longrightarrow \cdots
              </me>
              such that <m>\partial_{n} \partial_{n+1}=0</m> for all <m>n</m>. 
              We refer to <m>C_{n}</m> as the module in homological degree <m>n</m>. 
              The maps <m>\partial_{n}</m> are the differentials of our complex. 
              We may sometimes omit the differentials <m>\partial_{n}</m> and simply refer to the complex <m>C_{\bullet}</m> or even <m>C</m>; 
              we may also sometimes refer to <m>\partial_{\bullet}</m> as the differential of <m>C_{\bullet}</m>.
            </p>
          </statement>
        </definition>

        <p>
          In some contexts, it is important to make a distinction between chain complexes and co-chain complexes, where the arrows go the opposite way: a co-chain complex would look like
          <me>
            \cdots \longrightarrow C_{n-1} \stackrel{\partial_{n}}{\longrightarrow} C_{n} \stackrel{\partial_{n+1}}{\longrightarrow} C_{n+1} \longrightarrow \cdots.
          </me>
        </p>
    
        <p>
          We will not need to make such a distinction, so we will call both of these complexes and most often follow the convention in the definition above. 
          We will say a complex <m>C</m> is bounded above if <m>C_{n}=0</m> for all <m>n \gg 0</m>, and bounded below if <m>C_{n}=0</m> for all <m>n \ll 0</m>. 
          A bounded complex is one that is both bounded above and below. 
          If a complex is bounded, we may sometimes simply write it as a finite complex, say
          <me>
            C_{n} \stackrel{\partial_{n}}{\longrightarrow} C_{n-1} \longrightarrow \cdots \longrightarrow C_{m}.
          </me>
        </p>

        <remark>
          <p>
            The condition that <m>\partial_{n} \partial_{n+1}=0</m> for all <m>n</m> implies that im <m>\partial_{n+1} \subseteq \operatorname{ker} \partial_{n}</m>.
          </p>
        </remark>

        <definition xml:id="def-ses"><title>Exact Sequences</title>
          <statement>
            <p>
              The complex <m>\left(C_{\bullet}, \partial_{\bullet}\right)</m> is exact at <m>n</m> if im <m>\partial_{n+1}=\operatorname{ker} \partial_{n}</m>. 
              An exact sequence is a complex that is exact everywhere. 
              More precisely, an exact sequence of <m>R</m>-modules is a sequence
              <me>
                \cdots \stackrel{f_{n-1}}{\longrightarrow} M_{n} \stackrel{f_{n}}{\longrightarrow} M_{n+1} \stackrel{f_{n+1}}{\longrightarrow} \cdots
              </me>
              of <m>R</m>-modules and <m>R</m>-module homomorphisms such that <m>\operatorname{im} f_{n}=\operatorname{ker} f_{n+1}</m> for all <m>n</m>. 
              An exact sequence of the form
              <me>
                0 \longrightarrow A \longrightarrow B \longrightarrow C \longrightarrow 0
              </me>
              is a short exact sequence, sometimes written ses.
            </p>
          </statement>
        </definition>
    
        <remark>
          <p>
            The sequence
            <me>
              0 \longrightarrow M \stackrel{f}{\longrightarrow} N
            </me>
            is exact if and only if <m>f</m> is injective. 
            Similarly,
            <me>
              M \stackrel{f}{\longrightarrow} N \longrightarrow 0
            </me>
            is exact if and only if <m>f</m> is surjective. 
            So
            <me>
              0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0
            </me>
            is a short exact sequence if and only if
            <ul>
              <li>
                <p>
                  <m>f</m> is injective
                </p>
              </li>
      
              <li>
                <p>
                  <m>g</m> is surjective
                </p>
              </li>
        
              <li>
                <p>
                  <m>\operatorname{im} f=\operatorname{ker} g</m>.
                </p>
              </li>
            </ul>
          </p>
        </remark>
    
        <p>
          When this is indeed a short exact sequence, we can identify <m>A</m> with its image <m>f(A)</m>, and <m>A=\operatorname{ker} g</m>. 
          Moreover, since <m>g</m> is surjective, by the First Isomorphism Theorem we conclude that <m>C \cong B / f(A)</m>, so we might abuse notation and identify <m>C</m> with <m>B / A</m>.
        </p>

        <convention>
          <p>
            We write <m>A \rightarrow B</m> to denote a surjective map, and <m>A \hookrightarrow B</m> to denote an injective map.
          </p>
        </convention>

        <definition xml:id="def-cokernel"><title>Cokernel</title>
          <statement>
            <p>
              The cokernel of a map of <m>R</m>-modules <m>A \stackrel{f}{\rightarrow} B</m> is the module
              <me>
                \text { coker } f:=B / \operatorname{im}(f).
              </me>
            </p>
          </statement>
        </definition>

        <remark>
          <p>
            We can rephrase Remark 0.4 in a fancier language: if
            <me>
              0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0
            </me>
            is a short exact sequence, then <m>A=\operatorname{ker} g</m> and <m>C=\operatorname{coker} f</m>.
          </p>
        </remark>

        <example>
          <p>
            Let <m>\pi</m> be the canonical projection <m>\mathbb{Z} \longrightarrow \mathbb{Z} / 2 \mathbb{Z}</m>. 
            The following is a short exact sequence:
            <me>
              0 \longrightarrow \mathbb{Z} \stackrel{2}{\longrightarrow} \mathbb{Z} \stackrel{\pi}{\longrightarrow} \mathbb{Z} / 2 \mathbb{Z} \longrightarrow 0
            </me>
          </p>
        </example>
    
        <p>
          We will most often be interested in complexes of <m>R</m>-modules, where the abelian groups that show up are all modules over the same ring <m>R</m>.
        </p>

        <example>
          <p>
            Let <m>R=k[x]</m> be a polynomial ring over the field <m>k</m>. 
            The following is a short exact sequence:
            <me>
              0 \longrightarrow R \stackrel{\cdot x}{\longrightarrow} R \stackrel{\pi}{\longrightarrow} R /(x) \longrightarrow 0 \text {. }
            </me>
          </p>
      
          <p>
            The first map is multiplication by <m>x</m>, and the second map is the canonical projection.
          </p>
        </example>

        <example>
          <p>
            Given an ideal <m>I</m> in a ring <m>R</m>, the inclusion map <m>\iota: I \rightarrow R</m> and the canonical projection <m>\pi: R \rightarrow R / I</m> give us the following short exact sequence:
            <me>
              0 \longrightarrow I \stackrel{\iota}{\longrightarrow} R \stackrel{\pi}{\longrightarrow} R / I \longrightarrow 0
            </me>
          </p>
        </example>

        <example>
          <p>
            Let <m>R=k[x] /\left(x^{2}\right)</m>. 
            The following complex is exact:
          </p>
      
          <p>
            <me>
              \cdots \longrightarrow R \stackrel{\cdot x}{\longrightarrow} R \stackrel{\cdot x}{\longrightarrow} R \longrightarrow \cdots
            </me>
          </p>
      
          <p>
            Indeed, the image and the kernel of multiplication by <m>x</m> are both <m>(x)</m>.
          </p>
        </example>
    
        <p>
          Sometimes we can show that certain modules vanish or compute them explicitly when they do not vanish by seeing that they fit in some naturally constructed exact sequence involving other modules we understand better. 
          We will discuss this in more detail when we talk about long exact sequences.
        </p>

        <remark>
          <p>
            The complex <m>0 \longrightarrow M \stackrel{f}{\longrightarrow} N \longrightarrow 0</m> is exact if and only if <m>f</m> is an isomorphism.
          </p>
        </remark>

        <remark>
          <p>
            The complex <m>0 \longrightarrow M \longrightarrow 0</m> is exact if and only if <m>M=0</m>.
          </p>
        </remark>
    
        <p>
          Historically, chain complexes first appeared in topology. 
          To study a topological space, one constructs a particular chain complex that arises naturally from information from the space, and then calculates its homology, which ends up encoding important topological information in the form of a sequence of abelian groups.
        </p>

        <definition xml:id="def-homology"><title>Homology</title>
          <statement>
            <p>
              The homology of the complex <m>\left(C_{\bullet}, \partial_{\bullet}\right)</m> is the sequence of <m>R</m>-modules
              <me>
                \mathrm{H}_{n}\left(C_{\bullet}\right)=\mathrm{H}_{n}(C):=\frac{\operatorname{ker} \partial_{n}}{\operatorname{im} \partial_{n+1}} .
              </me>
            </p>
        
            <p>
              The <m>n</m>th homology of <m>\left(C_{\bullet}, \partial_{\bullet}\right)</m> is <m>\mathrm{H}_{n}(C)</m>. 
              The submodules <m>Z_{n}\left(C_{\bullet}\right)=Z_{n}(C):=\operatorname{ker} \partial_{n} \subseteq C_{n}</m> are called cycles, while the submodules <m>B_{n}\left(C_{\bullet}\right)=B_{n}(C):=\operatorname{im} \partial_{n+1} \subseteq C_{n}</m> are called boundaries. 
              One sometimes uses the word boundary to refer an element of <m>B_{n}(C)</m> (an <m>n</m>-boundary), and the word cycle to refer to an element of <m>Z_{n}(C)</m> (an <m>n</m>-cycle).
            </p>
          </statement>
        </definition>
    
        <p>
          The homology of a complex measures how far our complex is from being exact at each point. 
          Again, we can talk about the cohomology of a cochain complex instead, which we write as <m>\mathrm{H}^{n}(C)</m>; we will for now not worry about the distinction.
        </p>

        <remark>
          <p>
            Note that <m>\left(C_{\bullet}, \partial_{\bullet}\right)</m> is exact at <m>n</m> if and only if <m>\mathrm{H}_{n}\left(C_{\bullet}\right)=0</m>. 
          </p>
        </remark>

        <example>
          <p>
            Let <m>R=k[x] /\left(x^{3}\right)</m>. 
            Consider the following complex:
            <me>
              F_{\bullet}=\cdots \longrightarrow R \stackrel{\cdot x^{2}}{\longrightarrow} R \stackrel{\cdot x^{2}}{\longrightarrow} R \longrightarrow \cdots .
            </me>
            The image of multiplication by <m>x^{2}</m> is <m>\left(x^{2}\right)</m>, while the the kernel of multiplication by <m>x^{2}</m> is <m>(x) \supseteq\left(x^{2}\right)</m>. 
            For all <m>n</m>,
            <me>
              \mathrm{H}_{n}\left(F_{\bullet}\right)=(x) /\left(x^{2}\right) \cong R /(x)
            </me>
          </p>
        </example>

        <example>
          <p>
            Let <m>\mathbb{Z} \stackrel{\pi}{\longrightarrow} \mathbb{Z} / 2 \mathbb{Z}</m> be the canonical projection map. 
            Then
          </p>
          <image source="2023_08_28_614593e69373955f3addg-07.jpg"/>
          <p>
            is a complex of abelian groups, since the image of multiplication by 4 is <m>4 \mathbb{Z}</m>, and that is certainly contained in <m>\operatorname{ker} \pi=2 \mathbb{Z}</m>. 
            The homology of <m>C</m> is
            <me>
              \begin{array}{ll}
              \mathrm{H}_{n}(C)=0 &amp; \text { for } n \geqslant 3 \\
              \mathrm{H}_{2}(C)=\frac{\operatorname{ker}(\mathbb{Z} \stackrel{4}{\rightarrow} \mathbb{Z})}{\operatorname{im}(0 \longrightarrow \mathbb{Z})}=\frac{0}{0}=0 &amp; \\
              \mathrm{H}_{1}(C)=\frac{\operatorname{ker}(\mathbb{Z} \stackrel{\pi}{\rightarrow} \mathbb{Z} / 2 \mathbb{Z})}{\operatorname{im}(\mathbb{Z} \stackrel{4}{\rightarrow} \mathbb{Z})}=\frac{2 \mathbb{Z}}{4 \mathbb{Z}} \cong \mathbb{Z} / 2 \mathbb{Z} &amp; \\
              \mathrm{H}_{0}(C)=\frac{\operatorname{ker}(\mathbb{Z} / 2 \mathbb{Z} \longrightarrow 0)}{\operatorname{im}(\mathbb{Z} \longrightarrow \mathbb{Z} / 2 \mathbb{Z})}=\frac{\mathbb{Z} / 2 \mathbb{Z}}{\mathbb{Z} / 2 \mathbb{Z}}=0 &amp; \text { for } n&lt;0 \\
              \mathrm{H}_{n}(C)=0 &amp;
              \end{array}
            </me>
          </p>
      
          <p>
            Notice that our complex is exact at <m>2</m> and <m>0</m>. 
            The exactness at <m>2</m> says that the map <m>\mathbb{Z} \stackrel{4}{\rightarrow} \mathbb{Z}</m> is injective, while exactness at <m>0</m> says that <m>\pi</m> is surjective.
          </p>
        </example>
    
        <p>
          Before we can continue any further into the world of homological algebra, we will need some categorical language. 
          We will take a short break to introduce category theory, and then armed with that knowledge we will be ready to study homological algebra.
        </p>

      </chapter>

      <chapter xml:id="ch-categories"><title>Categories for the Working Homological Algebraist</title>

        <introduction>
          <p>
            Most fields in modern mathematics follow the same basic recipe: there is a main type of object one wants to study - groups, rings, modules, topological spaces, etc - and a natural notion of arrows between these - group homomorphisms, ring homomorphisms, module homomorphisms, continuous maps, etc. 
            The objects are often sets with some extra structure, and the arrows are often maps between the objects that preserve whatever that extra structure is. 
            Category theory is born of this realization, by abstracting the basic notions that make math and studying them all at the same time. 
            How many times have we felt a sense of déjà vu when learning about a new field of math? Category theory unifies all those ideas we have seen over and over in different contexts.
          </p>

          <p>
            Category theory is an entire field of mathematics in its own right. 
            As such, there is a lot to say about category theory, and unfortunately it doesn't all fit in the little time we have to cover it in this course. 
            You are strongly encouraged to learn more about category theory, for example from [ML98] or [Rie17].
          </p>
      
          <p>
            Before we go any further, note that there is a long and fun story about why we use the word collection when describing the objects in a category. 
            Not all collections are allowed to be sets, an issue that was first discovered by Russel with his famous Russel's Paradox. 
            <fn>The collection of all sets that don't contain themselves cannot be a set. Do you see why? </fn>
            Russel exposed the fact that one has to be careful with how we formalize set theory. 
            We follow the ZFC (Zermelo-Fraenkel with choice, short for the Zermelo-Fraenkel axioms plus the Axiom of Choice) axiomatization of set theory, and while we will not discuss the details of this formalization here, you are encouraged to read more on the subject.
          </p>
        </introduction>

        <section xml:id="sec-categories"><title>Categories</title>

          <subsection xml:id="subsec-cat"><title>Definition and First Examples</title>

            <blockquote>
              <p>
                <q>
                  We'll only use as much category theory as is necessary. Famous last words...
                </q>
              </p>
              <attribution>Roman Abramovich</attribution>
            </blockquote>
          
            <p>
              A category consists of a collection of objects and arrows or morphisms between those objects. 
              While these are often sets and some kind of functions between them, beware that this will not always be the case. 
              We will use the words morphism and arrows interchangeably, though arrow has the advantage of reminding us we are not necessarily talking about functions.
            </p>

            <definition xml:id="def-category"><title>Category</title>
              <statement>
                <p>
                  A <em>category</em> <m>\mathscr{C}</m> consists of three different pieces of data:
                  <ul>
                    <li>
                      <p>
                        a collection of <em>objects</em>, <m>\mathbf{ob}(\mathscr{C}),</m>
                      </p>
                    </li>

                    <li>
                      <p>
                        for each two objects, say <m>A</m> and <m>B</m>, a collection <m>\operatorname{Hom}_{\mathscr{C}}(A, B)</m> of <em>arrows</em> or <em>morphisms</em> from <m>A</m> to <m>B</m>, and
                      </p>
                    </li>
          
                    <li>
                      <p>
                        for each three objects <m>A, B</m>, and <m>C</m>, a <em>composition</em>
                      </p>
                  
                      <p>
                        <me>
                          \begin{gathered}
                          \operatorname{Hom}_{\mathscr{C}}(A, B) \times \operatorname{Hom}_{\mathscr{C}}(B, C) \longrightarrow \operatorname{Hom}_{\mathscr{C}}(A, C) . \\
                          (f, g) \longmapsto g \circ f
                          \end{gathered}
                        </me>
                      </p>
                    </li>
                  </ul>
                  </p>
          
                <p>
                  We will often drop the <m>\circ</m> and write simply <m>gf</m> for <m>g \circ f</m>.
                </p>
          
                <p>
                  These ingredients satisfy the following axioms:
                  <ol>
                    <li>
                      <p>
                        The <m>\operatorname{Hom}_{\mathscr{C}}(A, B)</m> are all disjoint. 
                        In particular, if <m>f</m> is an arrow in <m>\mathscr{C}</m>, we can talk about its <em>source</em> <m>A</m> and its <em>target</em> <m>B</m> as the objects such that <m>f \in \operatorname{Hom}_{\mathscr{C}}(A, B)</m>.
                      </p>
                    </li>
            
                    <li>
                      <p>
                        For each object <m>A</m>, there is an <em>identity arrow</em> <m>1_{A} \in \operatorname{Hom}_{\mathscr{C}}(A, A)</m> such that <m>1_{A} \circ f=f</m> and <m>g \circ 1_{A}=g</m> for all <m>f \in \operatorname{Hom}_{\mathscr{C}}(B, A)</m> and all <m>g \in \operatorname{Hom}_{\mathscr{C}}(A, B)</m>.
                      </p>
                    </li>
            
                    <li>
                      <p>
                        Composition is <em>associative</em>: <m>f \circ(g \circ h)=(f \circ g) \circ h</m> for all appropriately chosen arrows.
                      </p>
                    </li>
                  </ol>
                </p>
              </statement>
            </definition>

            <convention>
              <p>
                We sometimes write <m>f: A \rightarrow B</m> or <m>A \stackrel{f}{\rightarrow} B</m> for an arrow <m>f \in \operatorname{Hom}(A, B)</m>.
              </p>
            </convention>

            <exploration xml:id="exp-unique-id-morphism"><title>Unique Identity Morphism</title>
              <p>
                Prove that every element in a category has a unique identity morphism.
              </p>
            </exploration>

            <p>
              Here are some categories you have likely encountered before:
            </p>

            <example xml:id="ex-categories"><title>Categories</title>
              <p>
                <ol>
                  <li>
                    <p>
                      The category <m>\Set</m> with objects all sets and arrows all functions between sets.
                    </p>
                  </li>
            
                  <li>
                    <p>
                      The category <m>\Grp</m> whose objects are the collection of all groups, and whose arrows are all the homomorphisms of groups.
                      The identity arrows are the identity homomorphisms.
                    </p>
                  </li>
            
                  <li>
                    <p>
                      The category <m>\mathbf{Ab}</m> with objects all abelian groups, and arrows the homomorphisms of abelian groups. 
                      The identity arrows are the identity homomorphisms.
                    </p>
                  </li>
            
                  <li>
                    <p>
                      The category <m>\Ring</m> of rings and ring homomorphisms. 
                      Contrary to what you may expect, this is not nearly as important as the next one.
                    </p>
                  </li>
            
                  <li>
                    <p>
                      The category <m>R</m><m>\mod</m> of modules over a fixed <m>\operatorname{ring} R</m> and with <m>R</m>-module homomorphisms. 
                      Sometimes one writes <m>R</m><m>\Mod</m> for this category, and reserve <m>R</m><m>\mod</m> for the category of finitely generated <m>R</m>-modules with <m>R</m><m>\Mod</m>ule homomorphisms. 
                      When <m>R=k</m> is a field, the objects in the category <m>k</m>-Mod are <m>k</m>-vector spaces, and the arrows are linear transformations; 
                      we may instead refer to this category as Vect-<m>k</m>.
                    </p>
                  </li>
            
                  <li>
                    <p>
                      The category Top of topological spaces and continuous functions. 
                      One may consider many variations of the categories above. 
                      Here are some variations on vector spaces:
                    </p>
                  </li>
                </ol>
              </p>
            </example>

            <example xml:id="ex-more-categories"><title>More Categories!</title>
              <p>
                Let <m>k</m> be a field.
                <ol>
                  <li>
                    <p>
                      The collection of finite dimensional <m>k</m>-vector spaces with all linear transformations is a category.
                    </p>
                  </li>
            
                  <li>
                    <p>
                      The collection of all <m>n</m>-dimensional <m>k</m>-vector spaces with all linear transformations is a category.
                    </p>
                  </li>
            
                  <li>
                    <p>
                      The collection of all <m>k</m>-vector spaces (or <m>n</m>-dimensional vector spaces) with linear isomorphisms is a category.
                    </p>
                  </li>
            
                  <li>
                    <p>
                      The collection of all <m>k</m>-vector spaces (or <m>n</m>-dimensional vector spaces) with nonzero linear transformations is not a category, since it is not closed under composition.
                    </p>
                  </li>
            
                  <li>
                    <p>
                      The collection of all <m>n</m>-dimensional vector spaces with linear transformations of determinant 0 is not a category, since it does not have identity maps.
                    </p>
                  </li>
                </ol>
              </p>
            </example>

            <p>
              Here is an important variation of Set:
            </p>

            <example xml:id="ex-pointed-set"><title>Pointed Set Category</title>
              <p>
                There is a category Set* of pointed sets, where the objects are pairs <m>(X, x)</m> of sets <m>X</m> and points <m>x \in X</m>, and where for two pointed sets <m>(X, x)</m> and <m>(Y, y)</m>, the morphisms from <m>(X, x)</m> to <m>(Y, y)</m> are functions <m>f: X \rightarrow Y</m> such that <m>f(x)=y</m>, with the usual composition of functions.
              </p>
            </example>

            <p>
              While the collections of objects and arrows might not actually be sets, sometimes they are.
            </p>

            <definition xml:id="def-locally-small"><title>Locally Small</title>
              <statement>
                <p>
                  A category <m>\mathscr{C}</m> is <em>locally small</em> if for all objects <m>A</m> and <m>B</m> in <m>\mathscr{C}, \operatorname{Hom}_{\mathscr{C}}(A, B)</m> is a set. 
                  A category <m>\mathscr{C}</m> is <em>small</em> if it is locally small and the collection of all objects in <m>\mathscr{C}</m> is a set.
                </p>
              </statement>
            </definition>
        
            <p>
              In fact, one can define a small category as one where the collection of all arrows is a set. 
              It follows immediately that the collection of all objects is also a set, since it must be a subset of the set of arrows - for each object, there is an identity arrow.
            </p>
        
            <p>
              Many important categories are at least locally small. 
              For example, Set is locally small but not small. 
              In a locally small category, we can now refer to its Hom-sets.
            </p>
        
            <p>
              Categories where the objects are sets with some extra structure and the arrows are some kind of functions between the objects are called concrete. 
              Not all categories are concrete.
            </p>

            <example xml:id="ex-poset-category"><title>Poset Category</title>
              <p>
                Given a partially ordered set <m>(X, \leqslant)</m>, we can regard <m>X</m> itself as a category: 
                the objects are the elements of <m>X</m>, and for each <m>x</m> and <m>y</m> in <m>X, \operatorname{Hom}_{X}(x, y)</m> is either a singleton if <m>x \leqslant y</m> or empty if <m>x \neq y</m>. 
                There is only one possible way to define composition, and the transitive property of <m>\leqslant</m> guarantees that the composition of arrows is indeed well-defined: 
                if there is an arrow <m>i \rightarrow j</m> and an arrow <m>j \rightarrow k</m>, then <m>i \leqslant j</m> and <m>j \leqslant k</m>, so <m>i \leqslant k</m> and thus there is a unique arrow <m>i \rightarrow k</m>. 
                This category is locally small, since all nonempty Hom-sets are in fact singletons. 
                It is in fact small, since the objects are by construction the set <m>X</m>.
              </p>
            </example>

            <example xml:id="poset-categories-2"><title><m>\mathbf{n}</m> Category</title>
              <p>
                For each positive integer <m>n</m>, the category <m>\mathbf{n}</m> has <m>n</m> objects <m>0,1, \ldots, n-1</m> and <m>\operatorname{Hom}(i, j)</m> is either empty if <m>i&gt;j</m> or a singleton if <m>i \leqslant j</m>. 
                As <xref ref="ex-poset-category"/>, composition is defined in the only way possible, and things work out. 
                This is the poset category for the poset <m>(\{0,1, \ldots, n-1\}, \leqslant)</m> with the usual <m>\leqslant</m>.
              </p>
            </example>

            <example xml:id="ex-mat-category"><title>Matrix Category</title>
              <p>
                Fix a field <m>k</m>. 
                We define a category Mat-<m>k</m> with objects all positive integers, and given two positive integers <m>a</m> and <m>b</m>, the <m>\operatorname{Hom}</m>-set <m>\operatorname{Hom}(a, b)</m> consists of all <m>b \times a</m> matrices with entries in <m>k</m>. 
                The composition rule is given by product of matrices: given <m>A \in \operatorname{Hom}(a, b)</m> and <m>B \in \operatorname{Hom}(b, c)</m>, the composition <m>B \circ A</m> is the matrix <m>B A \in \operatorname{Hom}(a, c)</m>. 
                For each object <m>a</m>, its identity arrow is given by the <m>a \times a</m> identity matrix.
              </p>
            </example>

            <example xml:id="ex-directed-graph-category"><title>Directed Graph Category</title>
              <p>
              Let <m>G</m> be a directed graph. 
              We can construct a category from <m>G</m> as follows: the objects are the vertices of <m>G</m>, and the arrows are directed paths in the graph <m>G</m>. 
              In this category, composition of arrows corresponds to concatenation of paths. 
              For each object <m>A</m>, the identity arrow corresponds to the empty path from <m>A</m> to <m>A</m>.
              </p>
            </example>

            <remark>
              <p>
                A locally small category with just one element is completely determined by its unique Hom-set; 
                it thus consists of a set <m>S</m> with an associative operation that has an identity element, which in this class is what we call a semigroup. 
                <fn>Some authors prefer the term monoid.</fn>
              </p>
            </remark>
        
            

          </subsection>

          <subsection xml:id="subsec-diagrams-arrows"><title>Diagrams and Morphisms</title>

            <blockquote>
              <p>
                <q>
                  Death is very, very terminal.
                </q>
              </p>
              <attribution>David Lange</attribution>
            </blockquote>

            <p>
              A key insight we get from category theory is that many important concepts can be understood through diagrams. 
              Homological algebra is in many ways the study of commutative diagrams. 
              One way to formalize what a diagram is involves talking about functors, which we will discuss in Section 1.2; here is a more down to earth definition.
            </p>

            <definition xml:id="def-diagram"><title>Diagram</title>
              <statement>
                <p>
                  A <em>diagram</em> in a category <m>\mathscr{C}</m> is a directed multigraph whose vertices are objects in <m>\mathrm{C}</m> and whose arrows/edges are morphisms in <m>\mathscr{C}</m>. 
                  A commutative diagram in <m>\mathscr{C}</m> is a diagram in which for each pair of vertices <m>A</m> and <m>B</m>, any two paths from <m>A</m> to <m>B</m> compose to the same morphism.
                </p>
              </statement>
            </definition>

            <example xml:id="ex-commutative-diagram"><title>Commutative Diagram</title>
              <p>
                The diagram
              </p>
              <image source="2023_08_28_614593e69373955f3addg-11.jpg"/>
              <p>
                <em>commutes</em> if and only if <m>g f=v u</m>.
              </p>
            </example>
        
            <p>
              There are some special types of arrows we will want to consider.
            </p>

            <definition xml:id="def-inverses"><title>Morphism Inverses</title>
              <statement>
                <p>
                  Let <m>\mathscr{C}</m> be any category.
                  <ul>
                    <li>
                      <p>
                        An arrow <m>f \in \operatorname{Hom}_{\mathscr{C}}(A, B)</m> is <em>left invertible</em> if there exists <m>g \in \operatorname{Hom}_{\mathscr{C}}(B, A)</m> such that <m>g f=1_{A}</m>. 
                        In this case, we say that <m>g</m> is the left inverse of <m>f</m>. 
                        So <m>g</m> is a left inverse of <m>f</m> if the diagram
                      </p>
                      <image source="2023_08_28_614593e69373955f3addg-11(1).jpg"/>
                      <p>
                        commutes.
                      </p>
                    </li>

                    <li>
                      <p>
                        An arrow <m>f \in \operatorname{Hom}_{\mathscr{C}}(A, B)</m> is <em>right invertible</em> if there exists <m>g \in \operatorname{Hom}_{\mathscr{C}}(B, A)</m> such that <m>f g=1_{B}</m>. 
                        In this case, we say that <m>g</m> is the right inverse of <m>f</m>. So <m>g</m> is a right inverse of <m>f</m> if the diagram
                      </p>
                      <image source="2023_08_28_614593e69373955f3addg-12.jpg"/>
                      <p>
                        commutes.
                      </p>
                    </li>
                
                    <li>
                      <p>
                        An arrow <m>f \in \operatorname{Hom}_{\mathscr{C}}(A, B)</m> is an <em>isomorphism</em> if there exists <m>g \in \operatorname{Hom}_{\mathscr{C}}(B, A)</m> such that <m>g f=1_{A}</m> and <m>f g=1_{B}</m>. 
                        Unsurprisingly, such an arrow <m>g</m> is called the inverse of <m>f</m>.
                      </p>
                    </li>
                  </ul>
                </p>
              </statement>
            </definition>

            <definition xml:id="def-mono-epi"><title>Monic and Epic</title>
              <statement>
                <p>
                  <ul>
                    <li>
                      <p>
                        An arrow <m>f \in \operatorname{Hom}(B, C)</m> is <em>monic</em>, a <em>monomorphism</em>, or a <em>mono</em> if for all arrows
                      </p>

                      <p>
                        <me>A \stackrel{g_{1}}{\underset{g_{2}}{\longrightarrow}} B \stackrel{f}{\longrightarrow} C</me>
                      </p>
                  
                      <p>
                        if <m>f g_{1}=f g_{2}</m> then <m>g_{1}=g_{2}</m>.
                      </p>
                    </li>
            
                    <li>
                      <p>
                        Similarly, an arrow <m>f \in \operatorname{Hom}(A, B)</m> is an <em>epi</em> or an <em>epimorphism</em> if for all arrows
                        <me>
                          A \stackrel{f}{\longrightarrow} B \underset{g_{2}}{\stackrel{g_{1}}{\longrightarrow}} C
                        </me>
                        if <m>g_{1} f=g_{2} f</m> then <m>g_{1}=g_{2}</m>.
                      </p>
                    </li>
                  </ul>
                </p>
              </statement>
            </definition>
        
            <p>
              Here are some examples:
            </p>

            <exploration xml:id="exp-mono-epi-set"><title>Monos and Epis in Set</title>
              <p>
                Show that in <m>\Set</m>, the monos coincide with the injective functions and the epis coincide with the surjective functions.
              </p>
            </exploration>

            <example xml:id="ex-isomorphisms"><title>Isomorphisms</title>
              <p>
                <ol>
                  <li>
                    <p>
                      In <m>\Grp</m>, <m>\Ring</m>, and R<m>\Mod</m> the isomorphisms are the morphisms that are bijective functions.
                    </p>
                  </li>

                  <li>
                    <p>
                      In contrast, in <m>\Top</m> the isomorphisms are the homeomorphisms, which are the bijective continuous functions with continuous inverses. 
                      These are not the same thing as just the bijective continuous functions.
                    </p>
                  </li>
                </ol>
              </p>
            </example>

            <exploration xml:id="exp-iso-mono-epi"><title>Isomorphisms Mono and Epi</title>
              <p>
                Show that in any category, every isomorphism is both epi and mono.
              </p>
            </exploration>

            <exploration xml:id="exp-epi-not-surj"><title>Epi and Surjective not the Same</title>
              <p>
                Show that the usual inclusion <m>\mathbb{Z} \longrightarrow \mathbb{Q}</m> is an epi in the category <m>\Ring</m>.
              </p>
            </exploration>
        
            <p>
              This should feel weird: it says being epi and being surjective are not the same thing. 
              Similarly, being monic and being injective are not the same thing.
            </p>

            <exploration xml:id="exp-mono-not-inj"><title>Mono and Injective not the Same</title>
              <p>
                Show that the canonical projection <m>\mathbb{Q} \longrightarrow \mathbb{Q} / \mathbb{Z}</m> is a mono in the category of divisible abelian groups.
                <fn>An abelian group <m>A</m> is divisible if for every <m>a \in A</m> and every positive integer <m>n</m> there exists <m>b \in A</m> such that <m>n b=a</m>.</fn>
              </p>
            </exploration>

            <exploration xml:id="exp-mono-epi-poset"><title>Monic and Epic in Poset Category</title>
              <p>
                Show that given any poset <m>P</m>, in the poset category of <m>P</m> every morphism is both monic and epic, but no nonidentity morphism has a left or right inverse.
              </p>
            </exploration>

            <p>
              There are some special types of objects we will want to consider.
            </p>

            <definition xml:id="def-initial-terminal"><title>Initial and Terminal Objects</title>
              <statement>
                <p>
                  Let <m>\mathscr{C}</m> be a category. 
                  An <em>initial object</em> in <m>\mathscr{C}</m> is an object <m>i</m> such that for every object <m>x</m> in <m>\mathscr{C}, \operatorname{Hom}_{\mathscr{C}}(i, x)</m> is a singleton, meaning there exists a unique arrow <m>i \longrightarrow x</m>. 
                  A <em>terminal object</em> in <m>\mathscr{C}</m> is an object <m>t</m> such that for every object <m>x</m> in <m>\mathscr{C}, \operatorname{Hom}_{\mathscr{C}}(x, t)</m> is a singleton, meaning there exists a unique arrow <m>x \longrightarrow t</m>. 
                  A <em>zero object</em> in <m>\mathscr{C}</m> is an object that is both initial and terminal.
                </p>
              </statement>
            </definition>

            <exploration xml:id="exp-unique-initial-terminal"><title>Uniqueness of Initial and Terminal Objects</title>
              <p>
                Initial objects are unique up to unique isomorphism. 
                Terminal objects are unique up to unique isomorphism.
              </p>
            </exploration>

            <p>
              So we can talk about the initial object, the terminal object, and the zero object, if they exist.
            </p>

            <example xml:id="ex-initial-terminal"><title>Initial and Terminal Objects</title>
              <p>
                <ol>
                  <li>
                    <p>
                      The empty set is initial in Set. 
                      Any singleton is terminal. 
                      Since the empty set and a singleton are not isomorphic in Set, there is no zero object in Set.
                    </p>
                  </li>

                  <li>
                    <p>
                      The <m>0</m> module is the zero object in <m>R</m><m>\Mod</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      The trivial group <m>\{e\}</m> is the zero object in <m>\Grp</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      In the category of rings, <m>\mathbb{Z}</m> is the initial object, but there is no terminal object unless we allow the <m>0</m> ring.
                    </p>
                  </li>

                  <li>
                    <p>
                      There are neither initial nor terminal objects in the category of fields.
                    </p>
                  </li>
                </ol>
              </p>
            </example>

          </subsection>

          <subsection xml:id="subsec-sub-dual"><title>Opposite and Subcategories</title>

            <blockquote>
              <p>
                <q>
                  The life of this world is nothing but the harmony of opposites.
                </q>
              </p>
              <attribution>Rumi</attribution>
            </blockquote>
      
            <p>
              We will now continue to follow a familiar pattern and define the related concepts one can guess should be defined.
            </p>

            <definition xml:id="def-subcategory"><title>Subcategory</title>
              <statement>
                <p>
                  A <em>subcategory</em> <m>\mathscr{C}</m> of a category <m>\mathscr{D}</m> consists of a subcollection of the objects of <m>\mathscr{D}</m> and a subcollection of the morphisms of <m>\mathscr{D}</m> such that the following hold:
                  <ul>
                    <li>
                      <p>
                        For every object <m>C</m> in <m>\mathscr{C}</m>, the arrow <m>1_{C} \in \operatorname{Hom}_{\mathscr{D}}(C, C)</m> is an arrow in <m>\mathscr{C}</m>.
                      </p>
                    </li>
              
                    <li>
                      <p>
                        For every arrow in <m>\mathscr{C}</m>, its source and target in <m>\mathscr{D}</m> are objects in <m>\mathscr{C}</m>.
                      </p>
                    </li>
              
                    <li>
                      <p>
                        For every pair of arrows <m>f</m> and <m>g</m> in <m>\mathscr{C}</m> such that <m>f g</m> is an arrow that makes sense in <m>\mathscr{D}</m>, <m>f g</m> is an arrow in <m>\mathscr{C}</m>.
                      </p>
                    </li>
                  </ul>
                </p>
              </statement>
            </definition>
        
            <p>
              In particular, <m>\mathscr{C}</m> is a category in its own right.
            </p>

            <example xml:id="ex-subcategories"><title>Subcategories</title>
              <p>
                The category of finitely generated <m>R</m>-modules with <m>R</m>-module homomorphisms is a subcategory of <m>R</m><m>\Mod</m>.
              </p>
            </example>
            
            <definition xml:id="def-full-subcategory"><title>Full Subcategory</title>
              <statement>
                <p>
                  A subcategory <m>\mathscr{C}</m> of <m>\mathscr{D}</m> is a <em>full subcategory</em> if <m>\mathscr{C}</m> includes all of the arrows in <m>\mathscr{D}</m> between any two objects in <m>\mathscr{C}</m>.
                </p>
              </statement>
            </definition>

            <example xml:id="ex-full-subcategories"><title>Full Subcategories</title>
              <p>
                <ol>
                  <li>
                    <p>
                      The category <m>\mathbf{Ab}</m> of abelian groups is a full subcategory of <m>\Grp</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      Since every group is a set, and every homomorphism is a function, <m>\Grp</m> is a subcategory of <m>\Set</m>. 
                      However, not every function between two groups is a group homomorphism, so <m>\Grp</m> is not a full subcategory of <m>\Set</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      The category whose objects are all sets and with arrows all bijections is a subcategory of <m>\Set</m> that is not full.
                    </p>
                  </li>
                </ol>
              </p>
            </example>
        
            <p>
              Here is another way of constructing a new category out of an old one.
            </p>

            <definition xml:id="def-opposite-category"><title>Opposite Category</title>
              <statement>
                <p>
                  Let <m>\mathscr{C}</m> be a category. 
                  The <em>opposite category</em> of <m>\mathscr{C}</m>, denoted <m>\mathscr{C}^{op}</m>, is a category whose objects are the objects of <m>\mathscr{C}</m>, and such that each arrow <m>f \in \operatorname{Hom}_{\mathscr{C} \text { op }}(A, B)</m> is the same as some arrow in <m>\operatorname{Hom}_{\mathscr{C}}(B, A)</m>. 
                  The composition <m>f g</m> of two morphisms <m>f</m> and <m>g</m> in <m>\mathscr{C}^{\text {op }}</m> is defined as the composition <m>g f</m> in <m>\mathscr{C}</m>.
                </p>
              </statement>
            </definition>
        
            <p>
              Many objects and concepts one might want to describe are obtained from existing ones by flipping the arrows. 
              Opposite categories give us the formal framework to talk about such things. 
              We will often want to refer to dual notions, which will essentially mean considering the same notion in a category <m>\mathscr{C}</m> and in the opposite category <m>\mathscr{C}^{\mathrm{op}}</m>; 
              in practice, this means we should flip all the arrows involved.
              We will see examples of this later on.
            </p>
        
            <p>
              The dual category construction gives us a formal framework to talk about dual notions. 
              We will often make a statement in a category <m>\mathscr{C}</m> and make comments about the dual statement; 
              in practice, this corresponds to simply switching the way all arrows go. 
              Here are some examples of dual notions and statements:
            </p>
        
            <table><title></title>
              <tabular>
              <row header="yes">
                <cell halign="center">source</cell>
                <cell halign="center">target</cell>
              </row>
              <row class="odd">
                <cell halign="center">epi</cell>
                <cell halign="center">mono</cell>
              </row>
              <row class="even">
                <cell halign="center"><m>g</m> is a right inverse for <m>f</m></cell>
                <cell halign="center"><m>g</m> is a left inverse for <m>f</m></cell>
              </row>
              <row class="odd">
                <cell halign="center"><m>f</m> is invertible</cell>
                <cell halign="center"><m>f</m> is invertible</cell>
              </row>
              <row class="even">
                <cell halign="center">initial objects</cell>
                <cell halign="center">terminal objects</cell>
              </row>
              <row class="odd">
                <cell halign="center">homology</cell>
                <cell halign="center">cohomology</cell>
              </row>
              </tabular>
            </table>
        
            <p>
              Note that the dual of the dual is the original statement; 
              we can make this more formal by saying that <m>\left(\mathscr{C}^{\mathrm{op}}\right)^{\text {op }}=\mathscr{C}</m>. 
              Sometimes we can easily prove a statement by dualizing; however, this is not always straightforward, and one needs to carefully dualize all portions of the statement in question. 
              Nevertheless, Sanders MacLane, one of the fathers of category theory, wrote that "If any statement about a category is deducible from the axioms for a category, the dual statement is likely deducible".
              One of the upshots of duality is that any theorem in category theory must simultaneously prove two theorems: the original statement and its dual. 
              But for this to hold, we need proofs that use the abstraction of a purely categorical proof.
            </p>
        
            <p>
              Opposite categories are more interesting than they might appear at first; 
              there is more than just flipping all the arrows. 
              For example, consider the opposite category of Set. 
              For any nonempty set <m>X</m>, there is a unique morphism in Set (a function) <m>i: \emptyset \rightarrow X</m>, but there are no functions <m>X \rightarrow \emptyset</m>, so <m>i^{\text {op }}: \emptyset \rightarrow X</m> is not a function. 
              Thus thinking about Set <m>{ }^{\text {op }}</m> is a bit difficult. 
              One can show that this is the category of complete atomic Boolean algebras - but we won't concern ourselves with what that means.
            </p>

          </subsection>
          
        </section>

        <section xml:id="sec-functors"><title>Functors</title>

          <subsection xml:id="subsec-functors"><title>Functor? Damn Near Killed 'er!</title>
            
            <p>
              Many mathematical constructions are functorial, in the sense that they behave well with respect to morphisms. 
              In the formalism of category theory, this means that we can think of a functorial construction as a functor.
            </p>

            <definition xml:id="def-functor"><title>Functor</title>
              <statement>
                <p>
                  Let <m>\mathscr{C}</m> and <m>\mathscr{D}</m> be categories. 
                  A covariant functor <m>F: \mathscr{C} \longrightarrow \mathscr{D}</m> is a mapping that assigns to each object <m>A</m> in <m>\mathscr{C}</m> an object <m>F(A)</m> in <m>\mathscr{D}</m>, and to each arrow <m>f \in \operatorname{Hom}_{\mathscr{C}}(A, B)</m> an arrow <m>F(f) \in \operatorname{Hom}_{\mathscr{D}}(F(A), F(B))</m>, such that
                  <ul>
                    <li>
                      <p>
                        <m>F</m> preserves the composition of maps, meaning <m>F(f g)=F(f) F(g)</m> for all arrows <m>f</m> and <m>g</m> in <m>\mathscr{C}</m>, and
                      </p>
                    </li>
          
                    <li>
                      <p>
                        <m>F</m> preserves the identity arrows, meaning <m>F\left(1_{A}\right)=1_{F(A)}</m> for all objects <m>A</m> in <m>\mathscr{C}</m>.
                      </p>
                    </li>
                  </ul>
                </p>
            
                <p>
                  A <em>contravariant functor</em> <m>F: \mathscr{C} \longrightarrow \mathscr{D}</m> is a mapping that assigns to each object <m>A</m> in <m>\mathscr{C}</m> an object <m>F(A)</m> in <m>\mathscr{D}</m>, and to each arrow <m>f \in \operatorname{Hom}_{\mathscr{C}}(A, B)</m> an arrow <m>F(f) \in \operatorname{Hom}_{\mathscr{D}}(F(B), F(A))</m>, such that
                  <ul>
                    <li>
                      <p>
                        <m>F</m> preserves the composition of maps, meaning <m>F(f g)=F(g) F(f)</m> for all composable arrows <m>f</m> and <m>g</m> in <m>\mathscr{C}</m>, and
                      </p>
                    </li>
          
                    <li>
                      <p>
                        <m>F</m> preserves the identity arrows, meaning <m>F\left(1_{A}\right)=1_{F(A)}</m> for all objects <m>A</m> in <m>\mathscr{C}</m>.
                      </p>
                    </li>
                  </ul>
                </p>
              </statement>
            </definition>
      
            <p>
              So a contravariant functor is a functor that flips all the arrows. 
              We can also describe a contravariant functor as a covariant functor from <m>\mathscr{C}</m> to the opposite category of <m>\mathscr{D}</m>, <m>\mathscr{D}{ }^{\text {op }}</m>.
            </p>

            <remark>
              <p>
                A contravariant functor <m>F: \mathscr{C} \longrightarrow \mathscr{D}</m> can be thought of as a covariant functor <m>\mathscr{C}^{\text {op }} \longrightarrow \mathscr{D}</m>, or also as a covariant functor <m>\mathscr{C} \longrightarrow \mathscr{D}^{\text {op }}</m>. 
                If using one of these conventions, one needs to be careful, however, when composing functors, so that the respective sources and targets match up correctly.
                While we haven't specially discussed how one composes functors, it should be clear that applying a functor <m>F: \mathscr{C} \longrightarrow \mathscr{D}</m> and <m>G: \mathscr{D} \longrightarrow \mathscr{E}</m> is the same as applying a functor <m>\mathscr{C} \longrightarrow \mathscr{D}</m>, which we can write as <m>G F</m>.
              </p>
        
              <p>
                For example, if <m>F: \mathscr{C} \longrightarrow \mathscr{D}</m> and <m>G: \mathscr{D} \longrightarrow \mathscr{E}</m> are both contravariant functors, the composition <m>G F: \mathscr{C} \longrightarrow \mathscr{E}</m> is a covariant functor, since
              </p>
              <image source="2023_08_28_614593e69373955f3addg-15.jpg"/>
              <p>
                So we could think of <m>F</m> as a covariant functor <m>\mathscr{C} \longrightarrow \mathscr{D}^{\text {op }}</m> and <m>G</m> as a covariant functor <m>\mathscr{D}^{\text {op }} \longrightarrow \mathscr{E}</m>. 
                Similarly, if <m>F: \mathscr{C} \longrightarrow \mathscr{D}</m> is a covariant functor and <m>G: \mathscr{D} \longrightarrow \mathscr{E}</m> is a contravariant functor, <m>G F: \mathscr{C} \longrightarrow \mathscr{E}</m> is a contravariant functor. 
                In this case, we can think of <m>G</m> as a covariant functor <m>\mathscr{D} \longrightarrow \mathscr{E}^{\mathrm{op}}</m>, so that <m>G F</m> is now a covariant functor <m>\mathscr{C} \longrightarrow \mathscr{E}^{\mathrm{op}}</m>.
              </p>
            </remark>

            <exploration>
              <p>
                Show that functors preserve isomorphisms.
              </p>
            </exploration>
      
            <remark>
              <p>
                Any functor sends isos to isos, since it preserves compositions and identities.
              </p>
            </remark>

            <p>
              Here are some examples of functors you may have encountered before.
            </p>

            <example>
              <p>
                <ol>
                  <li>
                    <p>
                      Many categories one may think about are concrete categories, where the objects are sets with some extra structure, and the arrows are functions between those sets that preserved that extra structure. 
                      The <em>forgetful functor</em> from such a category to <m>\Set</m> is the functor that, just as the name says, forgets that extra structure, and sees only the underlying sets and functions of sets. 
                      For example, the forgetful functor <m>\mathbf{G r} \longrightarrow</m> <m>\Set</m> sends each group to its underlying set, and each group homomorphism to the corresponding function of sets.

                    </p>
                  </li>

                  <li>
                    <p>
                      The <em>identity functor</em> <m>1_{\mathscr{C}}</m> on any category <m>\mathscr{C}</m> does what the name suggests: it sends each object to itself and each arrow to itself.
                    </p>
                  </li>

                  <li>
                    <p>
                      Given a group <m>G</m>, the subgroup <m>[G, G]</m> of <m>G</m> generated by the set of commutators
                      <me>
                        \left\{g h g^{-1} h^{-1} \mid g, h \in G\right\}
                      </me>
                      is a normal subgroup, and the quotient <m>G^{\text {ab }}:=G /[G, G]</m> is called the abelianization of <m>G</m>. 
                      The group <m>G^{\text {ab }}</m> is abelian. 
                      Given a group homomorphism <m>f: G \rightarrow H, f</m> automatically takes commutators to commutators, so it induces a homomorphism <m>\tilde{f}: G^{\mathrm{ab}} \rightarrow H^{\mathrm{ab}}</m>. 
                      More precisely, abelianization gives a covariant functor from <m>\Grp</m> to <m>\Ab</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      The <em>unit group functor</em> <m>-^{*}</m> : <m>\Ring</m> <m>\rightarrow</m> <m>\Grp</m> sends a ring <m>R</m> to its group of units <m>R^{*}</m>. 
                      To see this is indeed a functor, we should check it behaves well on morphisms; 
                      and indeed if <m>f: R \rightarrow S</m> is a ring homomorphism, and <m>u \in R^{*}</m> is a unit in <m>R</m>, then
                      <me>
                        f(u) f\left(u^{-1}\right)=f\left(u u^{-1}\right)=f\left(1_{R}\right)=1_{S},
                      </me>
                      so <m>f(u)</m> is a unit in <m>S</m>. 
                      Thus <m>f</m> induces a function <m>R^{*} \rightarrow S^{*}</m> given by restriction of <m>f</m> to <m>R^{*}</m>, which must therefore be a group homomorphism since <m>f</m> preserves products.
                    </p>
                  </li>

                  <li>
                    <p>
                      Fix a field <m>k</m>. 
                      Given a vector space <m>V</m>, the collection <m>V^{*}</m> of linear transformations from <m>V</m> to <m>k</m> is again a <m>k</m>-vector space, the <em>dual vector space</em> of <m>V</m>. If <m>\varphi: W \rightarrow V</m> is a linear transformation and <m>\ell: V \rightarrow K</m> is an element of <m>V^{*}</m>, then <m>\ell \circ \varphi: W \rightarrow k</m> is in <m>W^{*}</m>. 
                      Doing this for all elements <m>\ell \in V^{*}</m> gives a function <m>\varphi^{*}: V^{*} \rightarrow W^{*}</m>, and one can show that <m>\varphi^{*}</m> is a linear transformation. 
                      The assignment that sends each vector space <m>V</m> to its dual vector space <m>V^{*}</m> and each linear transformation <m>\varphi</m> to <m>\varphi^{*}</m> is a contravariant functor on Vect- <m>k</m>.

                    </p>
                  </li>

                  <li>
                    <p>
                      Localization is a functor. 
                      Let <m>R</m> be a ring and <m>W</m> be a multiplicatively closed set in <m>R</m>. 
                      There is localization at <m>W</m> induces a a functor <m>R</m><m>\mod</m> <m>\longrightarrow W^{-1} R</m><m>\mod</m> that sends each <m>R</m>-module <m>M</m> to <m>W^{-1} M</m>, and each <m>R</m>-module homomorphism <m>\alpha: M \longrightarrow N</m> to the <m>R</m>-module homomorphism <m>W^{-1} \alpha: W^{-1} M \longrightarrow W^{-1} N</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </example>
      
            <remark>
              <p>
                If we apply a covariant functor to a diagram, then we get a diagram of the same shape: 
              </p>
                <image source='2023_08_28_614593e69373955f3addg-16.jpg'/>
                <p>
                However, if we apply a contravariant functor to the same diagram, we get a similar diagram but with the arrows reversed:
              </p> 
              <image source='2023_08_28_614593e69373955f3addg-17.jpg'/>
            </remark>

            <definition xml:id="def-cat-cat"><title>Category of Small Categories</title>
              <statement>
                <p>
                  The category Cat has objects all small categories and arrows all functors between them.
                </p>
              </statement>
            </definition>

          </subsection>

          <subsection xml:id="subsec-funcor-props"><title>Properties of Functors</title>
    
            <p>
              If we think about functors as functions between categories, it's natural to consider what would be the appropriate versions of the notions of injective or surjective.
            </p>

            <definition xml:id="def-functor-properties">
              <statement>
                <p>
                  A covariant functor <m>F: \mathscr{C} \longrightarrow \mathscr{D}</m> between locally small categories is
                </p>
          
                <p>
                  <ul>
                    <li>
                      <p>
                        <em>faithful</em> if all the functions of sets
                      </p>

                      <p>
                        <me>
                          \begin{gathered}
                          \operatorname{Hom}_{\mathscr{C}}(A, B) \longrightarrow \operatorname{Hom}_{\mathscr{D}}(F(A), F(B)) \\
                          f \longmapsto F(f)
                          \end{gathered}
                        </me>
                      </p>

                      <p>
                        are injective.
                      </p>
                    </li>
              
                  
                    <li>
                      <p>
                        <em>full</em> if all the functions of sets
                      </p>

                      <p>
                        <me>
                          \begin{gathered}
                          \operatorname{Hom}_{\mathscr{C}}(A, B) \longrightarrow \operatorname{Hom}_{\mathscr{D}}(F(A), F(B)) \\
                          f \longmapsto F(f)
                          \end{gathered}
                        </me>
                      </p>

                      <p>
                        are surjective.
                      </p>
                    </li>
              
                    
                    <li>
                      <p>
                        <em>fully faithful</em> if it is full and faithful.
                      </p>
                    </li>
              
                    <li>
                      <p>
                        <em>essentially surjective</em> if every object <m>d</m> in <m>\mathscr{D}</m> is isomorphic to <m>F c</m> for <m>c</m> in <m>\mathscr{C}</m>.
                      </p>
                    </li>
            
                    <li>
                        <p>
                        an <em>embedding</em> if it is fully faithful and injective on objects.
                      </p>
                    </li>
                  </ul>
                </p>
              </statement>
            </definition>

            <example>
              <p>
                The forgetful functor <m>R</m><m>\mod</m> <m>\longrightarrow</m> <m>\Set</m> is faithful since any two maps of <m>R</m>-modules with the same source and target coincide if and only if they are the same function of sets. 
                This functor is not full, since there not every functions between the underlying sets of two <m>R</m>-modules is an <m>R</m>-module homomorphism.
              </p>
            </example>

            <remark>
              <p>
                A fully faithful functor is not necessarily injective on objects, but it is injective on objects up to isomorphism.
              </p>
            </remark>

            <remark>
              <p>
                A subcategory <m>\mathscr{C}</m> of <m>\mathscr{D}</m> is full if the inclusion functor <m>\mathscr{C} \longrightarrow \mathscr{D}</m> is full.
              </p>
            </remark>

            <example>
              <p>
                <ol>
                  <li>
                    <p>
                      The category <m>\mathbf{A b}</m> of abelian groups is a full subcategory of <m>\Grp</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      The category whose objects are all sets and with arrows all bijections is a subcategory of <m>\Set</m> that is not full. 
                    </p>
                  </li>
                </ol>
              </p>
            </example>

            <p>
              To close this section, here are the two of the most important functors we will discuss this semester:
            </p>

            <definition xml:id="def-represent-functor"><title><m>\Hom</m> Functors</title>
              <statement>
                <p>
                  Let <m>\mathscr{C}</m> be a locally small category. 
                  An object <m>A</m> in <m>\mathscr{C}</m> induces two <m>\Hom</m> functors:
                  <ul>
                    <li>
                      <p>
                        The covariant functor <m>\operatorname{Hom}_{\mathscr{C}}(A,-): \mathscr{C} \longrightarrow</m> Set is defined as follows:
                      </p>
                      <image source="2023_08_28_614593e69373955f3addg-18(1).jpg"/>
                      <p>
                        We may refer to this functor as the covariant functor represented by <m>A</m>. 
                        Given an arrow <m>f</m> in <m>\mathscr{C}</m>, we write <m>f_{*}:=\operatorname{Hom}_{\mathscr{C}}(A, f)</m>. 
                        It is easier to see what <m>f_{*}</m> does through the following commutative diagram:
                        <me>
                          f_{*}=\operatorname{Hom}_{\mathscr{C}}(A, f):
                        </me>
                      </p>
                      <image source="2023_08_28_614593e69373955f3addg-18(3).jpg"/>
                    </li>
                  
                    <li>
                      <p>
                        The contravariant functor <m>\operatorname{Hom}_{\mathscr{C}}(-, B): \mathscr{C} \longrightarrow\Set</m> is defined as follows:
                      </p>
                      <image source="2023_08_28_614593e69373955f3addg-18(2).jpg"/>
                      <p>
                        We may refer to this functor as the contravariant functor represented by <m>B</m>. 
                        Given an arrow <m>f</m> in <m>\mathscr{C}</m>, we write <m>f^{*}:=\operatorname{Hom}_{\mathscr{C}}(A,-)</m>. 
                        It is easier to see what <m>f^{*}</m> does through the following commutative diagram:
                        <me>
                          f^{*}=\operatorname{Hom}_{\mathscr{C}}(f, B):
                        </me>
                      </p>
                      <image source="2023_08_28_614593e69373955f3addg-18.jpg"/>
                    </li>
                  </ul>
                </p>
              </statement>
            </definition>

            <exploration>
              <p>
                Check that <m>\operatorname{Hom}(A,-)</m> and <m>\operatorname{Hom}(-, B)</m> are indeed functors.
              </p>
            </exploration>
      
            <p>
              We will be particularly interested in the Hom-functors in the category <m>R</m><m>\mod</m>, which we will study in detail in a later chapter.
            </p>

          </subsection>

        </section>

        <section xml:id="sec-natural-transformations"><title>Natural Transformations</title>

          <subsection xml:id="subsec-natural"><title>Natural Transformations</title>
            
            <definition xml:id="def-natural-transformation">
              <statement>
                <p>
                  Let <m>F</m> and <m>G</m> be covariant functors <m>\mathscr{C} \longrightarrow \mathscr{D}</m>. 
                  A natural transformation between <m>F</m> and <m>G</m> is a mapping that to each object <m>A</m> in <m>\mathscr{C}</m> assigns an arrow <m>\eta_{A} \in \operatorname{Hom}_{\mathscr{D}}(F(A), G(A))</m> such that for all <m>f \in \operatorname{Hom}_{\mathscr{C}}(A, B)</m>, the diagram
                </p>
                <image source="2023_08_28_614593e69373955f3addg-19(1).jpg"/>
                <p>
                  commutes. 
                  A natural isomorphism is a natural transformation <m>\eta</m> where each <m>\eta_{A}</m> is an isomorphism. 
                  We sometimes write
                </p>
                <image source="2023_08_28_614593e69373955f3addg-19(2).jpg"/>
                <p>
                  or simply <m>\eta: F \Longrightarrow G</m>.
                </p>

                <p>
                  Let <m>F</m> and <m>G</m> be contravariant functors <m>\mathscr{C} \longrightarrow \mathscr{D}</m>. 
                  A natural transformation between <m>F</m> and <m>G</m> is a mapping that to each object <m>A</m> in <m>\mathscr{C}</m> assigns an arrow <m>\eta_{A} \in \operatorname{Hom}_{\mathscr{D}}(F(A), G(A))</m> such that for all <m>f \in \operatorname{Hom}_{\mathscr{C}}(A, B)</m>, the diagram
                </p>
                <image source="2023_08_28_614593e69373955f3addg-19.jpg"/>
                <p>
                  commutes.
                </p>
              </statement>
            </definition>

            <p>
              Often, when studying a particular topic, we sometimes say a certain map is natural to mean that there is actually a natural transformation behind it.
            </p>

            <example>
              <p>
                Recall the abelianization functor we discussed in Example 1.26. 
                The abelianization comes equipped with a natural projection map <m>\pi_{G}: G \longrightarrow G^{\text {ab }}</m>, the usual quotient map from <m>G</m> to a normal subgroup. 
                Here we mean natural in two different ways: both that this is common sense map to consider, and that this is in fact coming from a natural transformation. 
                What's happening behind the scenes is that abelianization is a functor <m>ab: \Grp\longrightarrow \Grp</m>. 
                On objects, the abelianizations functor is defined as <m>G \mapsto G^{\text {ab }}</m>. 
                Given an arrow, meaning a group homomorphism <m>G \stackrel{f}{\rightarrow} H</m>, one can check that <m>[G, G]</m> is contained in the kernel of <m>\pi_{H} f</m>, so <m>\pi_{H} f</m> factors through <m>G^{\text {ab }}</m>, and there exists a group homomorphism <m>f^{\mathrm{ab}}</m> making the following diagram commute:
              </p>
              <image source="2023_08_28_614593e69373955f3addg-19(3).jpg"/>
              <p>
                So the abelianization functor takes the arrow <m>f</m> to <m>f^{\text {ab }}</m>. 
                The commutativity of the diagram above says that <m>\pi_{-}</m>is a natural transformation between the identity functor on <m>\Grp</m> and the abelianization functor, which we can write more compactly as
                <me>
                  \operatorname{Grp} \underset{\frac{\mathrm{id}}{\Downarrow \pi}}{\stackrel{\mathrm{ab}}{\longrightarrow}} \operatorname{Grp}.
                </me>
              </p>
            </example>

            <definition xml:id="def-functor-category"><title>Functor Category</title>
              <statement>
                <p>
                  Let <m>F, G: \mathscr{C} \longrightarrow \mathscr{D}</m> be two functors between the categories <m>\mathscr{C}</m> and <m>\mathscr{D}</m>. 
                  We write
                  <me>
                    \operatorname{Nat}(F, G)=\{\text { natural transformations } F \longrightarrow G\}.
                  </me>
                </p>
          
                <p>
                  Given two categories <m>\mathscr{C}</m> and <m>\mathscr{D}</m>, one can build a functor category
                  <fn>Yes, the madness is neverending.</fn>
                  with objects all covariant functors <m>\mathscr{C} \longrightarrow \mathscr{D}</m>, and arrows the corresponding natural transformations. 
                  This category is denoted <m>\mathscr{D}^{\mathscr{C}}</m>. 
                  Sometimes one writes <m>\operatorname{Hom}(F, G)</m> for <m>\operatorname{Nat}(F, G)</m>, but we will avoid that, as it might make things even more confusing.
                </p>
              </statement>
            </definition>
      
            <p>
              For the functor category to truly be a category, though, we need to know how to compose natural transformations.
            </p>

            <remark>
              <p>
                Consider natural transformations
              </p>
              <image source="2023_08_28_614593e69373955f3addg-20(3).jpg"/>
              <p>
                and
              </p>
              <image source="2023_08_28_614593e69373955f3addg-20(1).jpg"/>
              <p>
                We can compose them for form a new natural transformation
              </p>
              <image source="2023_08_28_614593e69373955f3addg-20.jpg"/>
              <p>
                We should think of this composition as happening vertically. 
                For each object <m>C</m> in <m>\mathscr{C}, \eta \varphi</m> sends <m>C</m> to the arrow <m>F(A) \stackrel{\varphi_{A}}{\longrightarrow} G(A) \stackrel{\eta_{A}}{\longrightarrow} H(A)</m>. 
                This makes the diagram
              </p>
              <image source="2023_08_28_614593e69373955f3addg-20(2).jpg"/>
              <p>
                commute.
              </p>
            </remark>

            <exploration>
              <p>
                Show that a natural transformation <m>\eta: \mathscr{C} \Longrightarrow \mathscr{D}</m> is a natural isomorphism if and only if there exists a natural transformation <m>\mu: \mathscr{D} \Longrightarrow \mathscr{C}</m> such that <m>\eta \circ \mu</m> is the identity natural isomorphism on <m>G</m> and <m>\mu \circ \eta</m> is the identity natural isomorphism on <m>F</m>.
              </p>
            </exploration>

            <definition xml:id="def-equivalent-categories">
              <statement>
                <p>
                  Two categories <m>\mathscr{C}</m> and <m>\mathscr{D}</m> are equivalent if there exist functors <m>F: \mathscr{C} \rightarrow \mathscr{D}</m> and <m>G: \mathscr{D} \rightarrow \mathscr{C}</m> and two natural isomorphisms <m>\alpha: G F \Longrightarrow 1_{\mathscr{C}}</m> and <m>\beta: F G \Longrightarrow 1_{\mathscr{D}}</m>. 
                  We say that a functor <m>F: \mathscr{C} \rightarrow \mathscr{D}</m> is an equivalence of categories if there exists a functor <m>G</m> and natural isomorphisms <m>\alpha</m> and <m>\beta</m> as above.
              </p>
              </statement>
            </definition>

            <p>
              If one assumes the Axiom of Choice, this is the right notion of isomorphism of two categories (though not in the categorical sense!); better said, two categories that are equivalent are essentially the same. 
              Note that this does not mean that there is a bijection between the objects of <m>\mathscr{C}</m> and the objects of <m>\mathscr{D}</m>. 
              In fact, one can show that a functor is an equivalence of categories if and only if it is fully faithful and essentially surjective - though this fact requires the Axiom of Choice!
            </p>

            <exploration>
              <p>
                Let <m>\mathscr{C}</m> be the category with one object <m>C</m> and a unique arrow <m>1_{C}</m>. Let <m>\mathscr{D}</m> be the category with two objects <m>D_{1}</m> and <m>D_{2}</m> and four arrows: 
                the identities <m>1_{D_{i}}</m> and two isomorphisms <m>\alpha: D_{1} \rightarrow D_{2}</m> and <m>\beta: D_{2} \rightarrow D_{1}</m>. 
                Let <m>\mathscr{E}</m> be the category with two objects <m>E_{1}</m> and <m>E_{2}</m> and only two arrows, <m>1_{E_{1}}</m> and <m>1_{E_{2}}</m>.
                <ol>
                  <li>
                    <p>
                      Show that <m>\mathscr{C}</m> and <m>\mathscr{D}</m> are equivalent categories.
                    </p>
                  </li>

                  <li>
                    <p>
                      Show that <m>\mathscr{C}</m> and <m>\mathscr{E}</m> are not equivalent categories.
                    </p>
                  </li>
                </ol>
              </p>
            </exploration>

          </subsection>

          <subsection xml:id="subsec-yoneda"><title>The Yoneda Lemma</title>
            
            <p>
              Even though this is only a short introduction to category theory, we would be remiss not to mention the <xref text="title" ref="thm-yoneda"/>, arguably the most important statement in category theory.
            </p>

            <theorem xml:id="thm-yoneda"><title>Yoneda Lemma</title>
              <statement>
                <p>
                  Let <m>\mathscr{C}</m> be a locally small category, and fix an object <m>A</m> in <m>\mathscr{C}</m>. 
                  Let <m>F: \mathscr{C} \longrightarrow</m> Set be a covariant functor. 
                  Then there is a bijection
                  <me>\operatorname{Nat}\left(\operatorname{Hom}_{\mathscr{C}}(A,-), F\right) \stackrel{\gamma}{\longrightarrow} F(A)</me>
                  Moreover, this correspondence is natural in both <m>A</m> and <m>F</m>.
                </p>
              </statement>

              <proof>
                <p>
                  Let <m>\varphi</m> be a natural transformation in <m>\operatorname{Nat}\left(\operatorname{Hom}_{\mathscr{C}}(A,-), F\right)</m>. 
                  The proof of the Yoneda Lemma is essentially the following diagram:
                </p>
                <image source="2023_08_28_614593e69373955f3addg-21.jpg"/>
                <p>
                  Our bijection will be defined by <m>\gamma(\varphi):=\varphi_{A}\left(1_{A}\right)</m>. 
                  We should first check that this makes sense: 
                  arrows in Set are just functions between sets, and so <m>\varphi_{A}</m> is a function of sets <m>\operatorname{Hom}_{\mathscr{C}}(A, A) \longrightarrow F(A)</m>. 
                  Also, <m>\operatorname{Hom}_{\mathscr{C}}(A, A)</m> is a set that contains at least the element <m>1_{A}</m>, and <m>\varphi_{A}\left(1_{A}\right)</m> is some element in the set <m>F(A)</m>.
                </p>
          
                <p>
                  Given any fixed <m>f \in \operatorname{Hom}_{\mathscr{C}}(A, X)</m>, the fact that <m>\varphi</m> is a natural transformation translates into the outer commutative diagram. 
                  In particular, the maps of sets <m>F(f) \varphi_{A}</m> and <m>\varphi_{X} \operatorname{Hom}_{\mathscr{C}}(A, f)</m> coincide, and must in particular take <m>1_{A}</m> to the same element in <m>F(X)</m>. 
                  This is the commutativity of the inner diagram, with <m>u:=\varphi_{A}\left(1_{A}\right)</m>.
                </p>
          
                <p>
                  The commutativity of the diagram above says that <m>\varphi</m> is completely determined by <m>\varphi_{A}\left(1_{A}\right)</m>, since for any other object <m>X</m> in <m>\mathscr{C}</m> and any arrow <m>f \in \operatorname{Hom}_{\mathscr{C}}(A, X)</m>, we necessarily have <m>\varphi_{X}(f)=F(f) \varphi_{A}\left(1_{A}\right)</m>. 
                  In particular, our map <m>\gamma(\varphi)=\varphi_{A}\left(1_{A}\right)</m> is injective. 
                  Moreover, note that each choice of <m>u \in F(A)</m> gives rise to a different natural transformation <m>\varphi</m> by setting <m>\varphi_{X}(f)=F(f) u</m>. 
                  So our map <m>\gamma</m> is indeed a bijection.
                </p>
          
                <p>
                  We now have two naturality statements to prove. 
                  Naturality in the functor means that given a natural isomorphism <m>\eta: F \longrightarrow G</m>, the diagram
                </p>
                <image source="2023_08_28_614593e69373955f3addg-22.jpg"/>
                <p>
                  commutes. 
                  Given a natural transformation <m>\varphi</m> between <m>\operatorname{Hom}_{\mathscr{C}}(A,-)</m> and <m>F</m>,
                  <me>
                    \begin{array}{rlr}
                    \eta_{A} \circ \gamma_{F}(\varphi) &amp; =\eta_{A}\left(\varphi_{A}\left(1_{A}\right)\right) &amp; \text { by definition of } \gamma \\
                    &amp; =(\eta \circ \varphi)_{A}\left(1_{A}\right) &amp; \text { by definition of composition of natural transformations } \\
                    &amp; =\gamma_{G}(\eta \circ \varphi) &amp; \text { by definition of } \gamma \\
                    &amp; =\gamma_{G} \circ \eta_{*}(\varphi) &amp; \text { by definition of } \eta_{*}
                    \end{array}
                  </me>
                  so commutativity does hold. 
                  Naturality on the object means that given an arrow <m>f: A \longrightarrow B</m>, the diagram
                </p>
                <image source="2023_08_28_614593e69373955f3addg-22(1).jpg"/>
                <p>
                  commutes. 
                  Given a natural transformation <m>\varphi</m> between <m>\operatorname{Hom}_{\mathscr{C}}(A,-)</m> and <m>F</m>,
                  <me>
                    F(f) \circ \gamma_{A}(\varphi)=F(f)\left(\varphi_{A}\left(1_{A}\right)\right)
                  </me>
                  while
                  <me>
                    \gamma_{B} \circ\left(f^{*}\right)^{*}(\varphi)=\gamma_{B}\left(\varphi \circ f^{*}\right)=\left(\varphi \circ f^{*}\right)_{B}\left(1_{B}\right)
                  </me>
                  Now notice that
                  <me>
                    \begin{array}{r}
                    \operatorname{Hom}_{\mathscr{C}}(B, B) \stackrel{f^{*}}{\longrightarrow} \operatorname{Hom}_{\mathscr{C}}(A, B) \stackrel{\varphi_{B}}{\longrightarrow} F(B) . \\
                    1_{B} \longmapsto f \longmapsto \varphi_{B}(f)
                    \end{array}
                  </me>
                </p>

                <p>
                  Let's look back at the big commutative diagram we started our proof with: it says in particular that <m>\varphi_{B}(f)=F(f)\left(\varphi_{A}\left(1_{A}\right)\right)</m>. 
                  So commutativity does hold, and we are done. 
                </p>
              </proof>
            </theorem>

            <p>
              One can naturally (pun intended) define the notion of functor category of contravariant functors, and then prove the corresponding <xref text="title" ref="thm-yoneda"/>, which will instead use the contravariant Hom functor.
            </p>

            <exploration><title>Contravariant version of the Yoneda Lemma</title>
              <p>
                Let <m>\mathscr{C}</m> be a locally small category, and fix an object <m>B</m> in <m>\mathscr{C}</m>. Let <m>F: \mathscr{C} \longrightarrow</m> Set be a contravariant functor. 
                Then there is a bijection
                <me>
                  \text { Nat }\left(\operatorname{Hom}_{\mathscr{C}}(-, B), F\right) \stackrel{\gamma}{\longrightarrow} F(B).
                </me>
              </p>
            </exploration>

            <p>
              In a way, the <xref text="title" ref="thm-yoneda"/> says that to give a natural transformation between the functors <m>\operatorname{Hom}_{\mathscr{C}}(A,-)</m> and <m>F</m> is choosing an element in <m>F(A)</m>.
            </p>

            <remark>
              <p>
                Notice that the <xref text="title" ref="thm-yoneda"/> says in particular that the collection of all natural transformations from <m>\operatorname{Hom}_{\mathscr{C}}(A,-)</m> to <m>F</m> is a set. 
                This wasn't clear a priori, since the collection of objects in <m>\mathscr{C}</m> is not necessarily a set.
              </p>
            </remark>

            <remark>
              <p>
                If we apply the <xref text="title" ref="thm-yoneda"/> to the case when <m>F</m> itself is also a Hom functor, say <m>F=\operatorname{Hom}_{\mathscr{C}}(B,-)</m>, the <xref text="title" ref="thm-yoneda"/> says that there is a bijection between <m>\operatorname{Nat}\left(\operatorname{Hom}_{\mathscr{C}}(A,-), \operatorname{Hom}_{\mathscr{C}}(B,-)\right)</m> and <m>\operatorname{Hom}_{\mathscr{C}}(B, A)</m>. 
                In particular, each arrow in <m>\mathscr{C}</m> determines a natural transformation between Hom functors.
              </p>
            </remark>
      
            <p>
              One of the consequences of the <xref text="title" ref="thm-yoneda"/> is the Yoneda Embedding, which roughly says that every locally small category can be embedded into the category of contravariant functors from <m>\mathscr{C}</m> to Set. 
              In particular, the Yoneda embedding says that natural transformations between representable functors correspond to arrows between the representing objects.
            </p>

            <theorem xml:id="thm-yondea-embedding"><title>Yoneda Embedding</title>
              <statement>
                <p>
                  Let <m>\mathscr{C}</m> be a locally small category. The covariant functor
                </p>
                <image source="2023_08_28_614593e69373955f3addg-23(1).jpg"/>
                <p>
                  from <m>\mathscr{C}</m> to the category of contravariant functors <m>\mathscr{C} \longrightarrow</m> Set is an embedding. 
                  Moreover, the contravariant functor 
                </p>
                <image source='2023_08_28_614593e69373955f3addg-23.jpg'/>
                <p>
                  from the category <m>\mathscr{C}</m> to the category of covariant functors <m>\mathscr{C} \longrightarrow</m> Set is also an embedding.
                </p>
              </statement>

              <proof>
                <p>
                  First, note that our functors are injective on objects because the Hom-sets in our category are all disjoint. 
                  We need to check that given objects <m>A</m> and <m>B</m> in <m>\mathscr{C}</m>, we have bijections
                  <me>
                    \operatorname{Hom}_{\mathscr{C}}(A, B) \cong \operatorname{Nat}\left(\operatorname{Hom}_{\mathscr{C}}(-, A), \operatorname{Hom}_{\mathscr{C}}(-, B)\right)
                  </me>
                  and
                  <me>
                    \operatorname{Hom}_{\mathscr{C} \text { op }}(A, B) \cong \operatorname{Nat}\left(\operatorname{Hom}_{\mathscr{C}}(A,-) \operatorname{Hom}_{\mathscr{C}}(B,-)\right).
                  </me>
                </p>
          
                <p>
                  We will do the details for the first one, and leave the second as an exercise.
                </p>
          
                <p>
                  First, let us take a sanity check and confirm that indeed our proposed functors take arrows <m>f: A \longrightarrow B</m> in <m>\mathscr{C}</m> to natural transformations between <m>\operatorname{Hom}_{\mathscr{C}}(-, A)</m> and <m>\operatorname{Hom}_{\mathscr{C}}(-, B)</m>. 
                  This is essentially the content of Remark 1.43, but let's carefully check the details. 
                  The <xref text="title" ref="thm-yoneda"/> applied here tells us that each natural transformation <m>\varphi</m> between <m>\mathrm{Hom}_{\mathscr{C}}(-, A)</m> and <m>F=\operatorname{Hom}_{\mathscr{C}}(-, B)</m> corresponds to an element <m>u \in \operatorname{Hom}_{\mathscr{C}}(A, B)</m>, which we obtain by taking <m>u:=\varphi_{A}\left(1_{A}\right)</m>. 
                  As we discussed in the proof of the <xref text="title" ref="thm-yoneda"/>, we can recover <m>\varphi</m> from <m>u</m> by taking the natural transformation <m>\varphi</m> that for each object <m>X</m> in <m>\mathscr{C}</m> has <m>\varphi_{X}: \operatorname{Hom}_{\mathscr{C}}(X, A) \longrightarrow \operatorname{Hom}_{\mathscr{C}}(X, B)</m> given by <m>\varphi_{X}(f)=\operatorname{Hom}_{\mathscr{C}}(f, B)(u)=f_{*}(u)</m>.
                </p>
          
                <p>
                  We can see that different arrows <m>f</m> give rise to different natural transformations by applying the resulting natural transformation <m>f_{;} *</m> to the identity arrow <m>1_{A}</m>, which takes it to <m>f</m>. 
                  Moreover, the <xref text="title" ref="thm-yoneda"/> tells us that every natural transformation <m>\varphi</m> between <m>\operatorname{Hom}_{\mathscr{C}}(-, A)</m> and <m>\operatorname{Hom}_{\mathscr{C}}(-, B)</m> is the image of some <m>u</m>, as described above.
                </p>
              </proof>
            </theorem>
      
            <p>
              The functors that are naturally isomorphic to some Hom functor are important.
            </p>

            <definition xml:id="def-representable-functor">
              <statement>
                <p>
                  A covariant functor <m>F: \mathscr{C} \longrightarrow</m> Set is representable if there exists an object <m>A</m> in <m>\mathscr{C}</m> such that <m>F</m> is naturally isomorphic to <m>\operatorname{Hom}_{\mathscr{C}}(A,-)</m>. 
                  A contravariant functor <m>F: \mathscr{C} \longrightarrow</m> Set is representable if there exists an object <m>B</m> in <m>\mathscr{C}</m> such that <m>F</m> is naturally isomorphic to <m>\operatorname{Hom}_{\mathscr{C}}(-, B)</m>.
                </p>
              </statement>
            </definition>

            <example>
              <p>
                We claim that the identity functor Set <m>\longrightarrow</m> Set is representable. 
                Let 1 be a singleton set. 
                Given any set <m>X</m>, there is a bijection between elements <m>x \in X</m> and functions <m>\mathbf{1} \longrightarrow X</m> sending the one element in <m>\mathbf{1}</m> to each <m>x</m>. 
                Moreover, given any other set <m>Y</m>, and a function <m>f: X \longrightarrow Y</m>, our bijections make the following diagram commute:
              </p>
              <image source="2023_08_28_614593e69373955f3addg-24.jpg"/>
              <p>
                This data gives a natural isomorphism between the identity functor and <m>\operatorname{Hom}_{\text {Set }}(\mathbf{1},-)</m>.
              </p>
            </example>

            <p>
              A representable functor encodes a universal property of the object that represents it. 
              For example, in Example 1.46, mapping out of the singleton set is the same as choosing an element <m>x</m> in a set <m>X</m>. 
              We have all seen constructions that are at first a bit messy but that end up satisfying some nice universal property that makes everything work out. 
              At the end of the day, a universal property allows us to ignore the messy details and focus on the universal property, which usually says everything we need to know about the construction. 
              And as you may have already realized, universal properties are everywhere. 
              Before we give a formal definition, we want to discuss some important examples.
            </p>

          </subsection>
          
        </section>
        
      </chapter>

      <chapter xml:id="ch-chain-complexes"><title>The Category of Chain Complexes</title>

        <section xml:id="sec-compelx-maps"><title>Maps of Complexes</title>

          <p>
            Unsurprisingly, we can form a category of complexes, but to do that we need the right definition of maps between complexes. 
            We also take this section as a chance to set up some definitions we will need later. 
            One thing to keep in mind as we build our basic definitions: we also want homology to be functorial.
          </p>

          <definition xml:id="def-2.1">
            <statement>
              <p>
                Let <m>\left(F_{\bullet}, \partial_{\bullet}^{F}\right)</m> and <m>\left(G_{\bullet}, \partial_{\bullet}^{G}\right)</m> be complexes. 
                A map of complexes or a chain map, which we write as <m>h:\left(F_{\bullet}, \partial_{\bullet}^{F}\right) \longrightarrow\left(G_{\bullet}, \partial_{\bullet}^{G}\right)</m> or simply <m>h: F \longrightarrow G</m>, is a sequence of homomorphisms of <m>R</m>-modules <m>h_{n}: F_{n} \longrightarrow G_{n}</m> such that the following diagram commutes:
              </p>
              <image source="2023_10_23_e2d6a27704be928b3deeg-051.jpg"/>
              <p>
                This means that <m>h_{n} \partial_{n+1}^{F}=\partial_{n+1}^{G} h_{n+1}</m> for all <m>n</m>.
              </p>
            </statement>
          </definition>

          <p>
            Note that throughout, whenever we call a function <m>f: M \rightarrow N</m> between <m>R</m>-modules <m>M</m> and <m>N</m> a map, we really mean to say it is a homomorphism of <m>R</m>-modules.
          </p>

          <example>
            <p>
              Example 2.2. 
              The zero and the identity maps of complexes <m>\left(F_{\bullet}, \partial_{\bullet}\right) \longrightarrow\left(F_{\bullet}, \partial_{\bullet}\right)</m> are exactly what they sound like: the zero map <m>0_{F_{\bullet}}</m> is 0 in every homological degree, and the identity map <m>1_{F_{\bullet}}</m> is the identity in every homological degree.
            </p>
          </example>
    
          <p>
            This is the notion of morphism we would want to form a category of chain complexes.
          </p>

          <definition xml:id="def-2.3">
            <statement>
              <p>
                Let <m>R</m> be a ring. 
                The category of chain complexes of <m>R</m>-modules, denoted <m>\mathrm{Ch}(R</m>-mod <m>)</m> or simply <m>\mathrm{Ch}(R)</m>, is the category with objects all chain complexes of <m>R</m>-modules and arrows all maps of complexes of <m>R</m>-modules.
                When <m>R=\mathbb{Z}</m>, we write <m>\mathrm{Ch}(\mathrm{Ab})</m> for <m>\mathrm{Ch}(\mathbb{Z})</m>, the category of chain complexes of abelian groups.
              </p>
            </statement>
          </definition>
    
          <p>
            Note that the identity maps defined above are precisely the identity arrows in the category of chain complexes.
          </p>

          <exercise>
            <p>
              Exercise 25. Show that the isomorphisms in the category <m>\mathrm{Ch}(R)</m> are precisely the maps of complexes
            </p>
            
            <image source="2023_10_23_e2d6a27704be928b3deeg-052.jpg"/>
                  
            <p>
              such that <m>h_{n}</m> is an isomorphism for all <m>n</m>.
            </p>
          </exercise>
    
          <p>
            This is a good notion of map of complexes: it induces homomorphisms in homology, which in particular allows us to say that homology is a functor.
          </p>

          <lemma xml:id="lem-2.4">
            <statement>
              <p>
                Let <m>h:\left(F_{\bullet}, \partial_{\bullet}^{F}\right) \longrightarrow\left(G_{\bullet}, \partial_{\bullet}^{G}\right)</m> be a map of complexes. For all <m>n, h_{n}</m> restricts to homomorphisms <m>B_{n}(h): B_{n}\left(F_{\bullet}\right) \longrightarrow B_{n}\left(G_{\bullet}\right)</m> and <m>Z_{n}(h): Z_{n}\left(F_{\bullet}\right) \longrightarrow Z_{n}\left(G_{\bullet}\right)</m>. As a consequence, <m>h</m> induces homomorphisms on homology <m>\mathrm{H}_{n}(h): \mathrm{H}_{n}\left(F_{\bullet}\right) \longrightarrow \mathrm{H}_{n}\left(G_{\bullet}\right)</m>.
              </p>
            </statement>

            <proof>
              <p>
                Since <m>h_{n} \partial_{n+1}^{F}=\partial_{n+1}^{G} h_{n+1}</m>, any element <m>a \in B_{n}\left(F_{\bullet}\right)</m>, say <m>a=\partial_{n+1}^{F}(b)</m>, is taken to
                <me>
                  h_{n}(a)=h_{n} \partial_{n+1}^{F}(b)=\partial_{n+1}^{G} h_{n+1}(b) \in \operatorname{im} \partial_{n+1}^{G}=B_{n}\left(G_{\bullet}\right)
                </me>
              </p>
        
              <p>
                Similarly, if <m>a \in Z_{n}\left(F_{\bullet}\right)=\operatorname{ker} \partial_{n}^{F}</m>, then   
                <me>
                  \partial_{n} h_{n}(a)=h_{n-1} \partial_{n}^{F}(a)=0
                </me>
                so <m>h_{n}(a) \in \operatorname{ker} \partial_{n}^{G}=Z_{n}\left(G_{\bullet}\right)</m>. 
                Finally, the restriction of <m>h_{n}</m> to <m>Z_{n}\left(F_{\bullet}\right) \longrightarrow Z_{n}\left(G_{\bullet}\right)</m> sends <m>B_{n}\left(F_{\bullet}\right)</m> into <m>B_{n}\left(G_{\bullet}\right)</m>, and thus it induces a well-defined homomorphism on the quotients <m>\mathrm{H}_{n}\left(F_{\bullet}\right) \longrightarrow \mathrm{H}_{n}\left(G_{\bullet}\right)</m>.
              </p>
            </proof>
          </lemma>

          <definition xml:id="def-2.5">
            <statement>
              <p>
                Let <m>h:\left(F_{\bullet}, \partial_{\bullet}^{F}\right) \longrightarrow\left(G_{\bullet}, \partial_{\bullet}^{G}\right)</m> be a map of complexes. We call the map
                <me>
                  \begin{aligned}
                  \mathrm{H}_{n}(h): &amp; \mathrm{H}_{n}\left(F_{\bullet}\right) \longrightarrow \mathrm{H}_{n}\left(G_{\bullet}\right) \\
                  &amp; a+B_{n}(F) \longmapsto h_{n}(a)+B_{n}(G)
                  \end{aligned}
                </me>
                the induced map in homology, and sometimes denote it by <m>h_{*}</m>.
              </p>
            </statement>
          </definition>
    
          <p>
            One can show that <m>\mathrm{H}_{n}</m> preserves compositions, and that moreover, the map in homology induced by the identity is the identity. 
            Thus taking <m>n</m>th homology is a functor
            <me>
              \mathrm{H}_{n}: \mathrm{Ch}(R) \longrightarrow R \text {-Mod }
            </me>
            which takes each map of complexes <m>h: F_{\bullet}, \longrightarrow G_{\bullet}</m> to the <m>R</m>-module homomorphism
            <me>
              \mathrm{H}_{n}(h): \mathrm{H}_{n}\left(F_{\bullet}\right) \longrightarrow \mathrm{H}_{n}\left(G_{\bullet}\right)
            </me>
          </p>

          <definition xml:id="def-2.6">
            <statement>
              <p>
                A map of chain complexes <m>h</m> is a quasi-isomorphism if it induces an isomorphism in homology, meaning <m>\mathrm{H}_{n}(h)</m> is an isomorphism of <m>R</m>-modules for all <m>n</m>. 
                If there exists a quasi-isomorphism between two complexes <m>C</m> and <m>D</m>, we say that <m>C</m> and <m>D</m> are quasi-isomorphic, and write <m>C \simeq D</m>.
              </p>
            </statement>
          </definition>

          <remark>
            <p>
              Remark 2.7. 
              Note that saying that if <m>f</m> is a quasi-isomorphism between <m>F</m> and <m>G</m> is a stronger statement that the fact that <m>\mathrm{H}_{n}(F) \cong \mathrm{H}_{n}(G)</m> for all <m>n</m>: 
              it also says that there are isomorphisms <m>\mathrm{H}_{n}(F) \cong \mathrm{H}_{n}(G)</m> that are all induced by <m>f</m>.
            </p>
          </remark>

          <p>
            Not all quasi-isomorphisms are isomorphisms, as the following example shows:
          </p>

          <exercise>
            <p>
              Exercise 26. 
              Let <m>\pi</m> denote the projection map from <m>\mathbb{Z}</m> to <m>\mathbb{Z} / 2 \mathbb{Z}</m>. 
              The chain map
            </p>
            <image source="2023_10_23_e2d6a27704be928b3deeg-053.jpg"/>
            <p>
              is a quasi-isomorphism.
            </p>
          </exercise>
    
          <definition xml:id="def-2.8">
            <statement>
              <p>
                Let <m>f, g: F \longrightarrow G</m> be maps complexes. 
                A homotopy, sometimes referred to as a chain homotopy, between <m>f</m> and <m>g</m> is a sequence of maps <m>h_{n}: F_{n} \longrightarrow G_{n+1}</m>
              </p>
              <image source="2023_10_23_e2d6a27704be928b3deeg-053(1).jpg"/>
              <p>
                such that
                <me>
                  \partial_{n+1} h_{n}+h_{n-1} \partial_{n}=f_{n}-g_{n}
                </me>
                for all <m>n</m>. 
                If there exists a homotopy between <m>f</m> and <m>g</m>, we say that <m>f</m> and <m>g</m> are homotopic or that they have the same homotopy type. 
                We write <m>f \simeq g</m> to say that <m>f</m> and <m>g</m> are homotopic. 
                If <m>f</m> is homotopic to the zero map, we say <m>f</m> is nullhomotopic, and write <m>f \simeq 0</m>. 
                This should not be confused with the notation <m>C \simeq D</m> on complexes.
              </p>
            </statement>
          </definition>

          <exercise>
            <p>
              Exercise 27. 
              Homotopy is an equivalence relation.
            </p>
          </exercise>
        
          <p>
            The equivalence classes under homotopy are called homotopy classes. 
            Homotopy is an interesting equivalence relation because homotopic maps induce the same map on homology.
          </p>

          <lemma xml:id="lem-2.9">
            <statement>
              <p>
                Let <m>f, g:\left(F_{\bullet}, \partial_{\bullet}^{F}\right) \longrightarrow\left(G_{\bullet}, \partial_{\bullet}^{G}\right)</m> be maps of complexes. 
                If <m>f</m> is homotopic to <m>g</m>, then <m>\mathrm{H}_{n}(f)=\mathrm{H}_{n}(g)</m> for all <m>n</m>. 
                In particular, every nullhomotopic map induces the zero map in homology.
              </p>
            </statement>

            <proof>
              <p>
                Let <m>f, g:\left(F_{\bullet}, \partial_{\bullet}^{F}\right) \longrightarrow\left(G_{\bullet}, \partial_{\bullet}^{G}\right)</m> be homotopic maps of complexes, and let <m>h</m> be a homotopy between <m>f</m> and <m>g</m>. We claim that the map of complexes <m>f-g</m> (defined in the obvious way) sends cycles to boundaries. If <m>a \in Z_{n}\left(F_{\bullet}\right)</m>, then
                <me>
                  (f-g)_{n}(a)=\partial_{n+1} h_{n}(a)+h_{n-1} \underbrace{\partial_{n}(a)}_{0}=\partial_{n+1}\left(h_{n}(a)\right) \in B_{n}\left(G_{\bullet}\right)
                </me>
                The map on homology induced by <m>f-g</m> must then be the 0 map, so <m>f</m> and <m>g</m> induce the same map on homology. Here we are implicitly using the fact that <m>\mathrm{H}_{n}(f+h)=\mathrm{H}_{n}(f)+\mathrm{H}_{n}(g)</m>, which we leave as an exercise to be further explored in Remark 3.4.
              </p>
            </proof>
          </lemma>
    
          <p>
            Notice, however, that the converse is false: the induced map in homology can be the zero map (for all homological degrees) even if the original map of complexes is not nullhomotopic.
          </p>

          <exercise>
            <p>
              Exercise 28. Consider the following map of complexes:
            </p>
            <image source="2023_10_23_e2d6a27704be928b3deeg-054(1).jpg"/>
            
            <p>
              Show that this map is not nullhomotopic, but that the induced map in homology is zero.
            </p>
          </exercise>

          <definition xml:id="def-2.10">
            <statement>
              <p>
                If <m>f:\left(F_{\bullet}, \partial_{\bullet}^{F}\right) \longrightarrow\left(G_{\bullet}, \partial_{\bullet}^{G}\right)</m> and <m>g:\left(G_{\bullet}, \partial_{\bullet}^{G}\right) \longrightarrow\left(F_{\bullet}, \partial_{\bullet}^{F}\right)</m> are maps of complexes such that <m>f g</m> is homotopic to the identity map on <m>\left(G_{\bullet}, \partial_{\bullet}^{G}\right)</m> and <m>g f</m> is homotopic to the identity chain map on <m>\left(F_{\bullet}, \partial_{\bullet}^{F}\right)</m>, we say that <m>f</m> and <m>g</m> are homotopy equivalences and <m>\left(F_{\bullet}, \partial_{\bullet}^{F}\right)</m> and <m>\left(G_{\bullet}, \partial_{\bullet}^{G}\right)</m> are homotopy equivalent.
              </p>
            </statement>
          </definition>

          <corollary xml:id="cor-2.11">
            <statement>
              <p>
                Homotopy equivalences are quasi-isomorphisms.
              </p>
            </statement>

            <proof>
              <p>
                If <m>f:\left(F_{\bullet}, \partial_{\bullet}^{F}\right) \longrightarrow\left(G_{\bullet}, \partial_{\bullet}^{G}\right)</m> and <m>g:\left(G_{\bullet}, \partial_{\bullet}^{G}\right) \longrightarrow\left(F_{\bullet}, \partial_{\bullet}^{F}\right)</m> are such that <m>f g</m> is homotopic to <m>1_{G_{\bullet}}</m> and <m>g f</m> is homotopic to <m>1_{F_{\bullet}}</m>, then by Lemma 2.9 the map <m>f g</m> induces the identity map on homology. 
                So for all <m>n</m> we have
                <me>
                  \mathrm{H}_{n}(f) \mathrm{H}_{n}(g)=\mathrm{H}_{n}(f g)=\mathrm{H}_{n}(1)=1.
                </me>
                Therefore, <m>\mathrm{H}_{n}(f)</m> and <m>\mathrm{H}_{n}(g)</m> must both be isomorphisms.
              </p>
            </proof>
          </corollary>
    
          <p>
            The converse is false.
          </p>

          <exercise>
            <p>
              Exercise 29. Let <m>\pi</m> denote the projection map from <m>\mathbb{Z}</m> to <m>\mathbb{Z} / 2 \mathbb{Z}</m>. The chain map
            </p>
            <image source="2023_10_23_e2d6a27704be928b3deeg-054.jpg"/>
            <p>
              is a quasi-isomorphism but not a homotopy equivalence.
            </p>
          </exercise>

          <remark>
            <p>
              Remark 2.12. 
              The relation <m>F \simeq G</m>, meaning "there is a quasi-isomorphism from <m>F</m> to <m>G</m> ", is not symmetric: in Exercise 29, there is no quasi-isomorphism going in the opposite direction of the one given.
            </p>
          </remark>
    
          <p>
            Now that we know about maps between complexes, it's time to point out that we can also talk about complexes of complexes and exact sequences of complexes. 
            While we will later formalize this a little better when we discover that <m>\mathrm{Ch}(R)</m> is an abelian category, let's for now give quick definitions that we can use.
          </p>

          <definition xml:id="def-2.13">
            <statement>
              <p>
                Given complexes <m>B</m> and <m>C, B</m> is a subcomplex of <m>C</m> if <m>B_{n}</m> is a submodule of <m>C_{n}</m> for all <m>n</m>, and the inclusion maps <m>\iota_{n}: B_{n} \subseteq C_{n}</m> define a map of complexes <m>\iota: B \longrightarrow C</m>. 
                Given a subcomplex <m>B</m> of <m>C</m>, the quotient of <m>C</m> by <m>B</m> is the complex <m>C / B</m> that has <m>C_{n} / B_{n}</m> in homological degree <m>n</m>, with differential induced by the differential on <m>C_{n}</m>.
              </p>
            </statement>
          </definition>

          <exercise>
            <p>
              Exercise 30. 
              If <m>B</m> is a subcomplex of <m>C</m>, then the differential <m>d</m> on <m>C</m> satisfies <m>d_{n}\left(B_{n}\right) \subseteq B_{n-1}</m>. 
              Therefore, <m>d_{n}</m> induces a map of <m>R</m>-modules <m>C_{n} / B_{n} \longrightarrow C_{n-1} / B_{n-1}</m> for all <m>n</m>, so that our definition of the differential on <m>C / B</m> actually makes sense.
            </p>
          </exercise>
    
          <p>
            We can also talk about kernels and cokernels of maps of complexes.
          </p>

          <definition xml:id="def-2.14">
            <statement>
              <p>
                Given any map of complexes <m>f: B_{\bullet} \longrightarrow C_{\bullet}</m>, the kernel of <m>f</m> is the subcomplex <m>\ker f</m> of <m>B_{\bullet}</m> that we can assemble from the the kernels <m>\ker f_{n}</m>. 
                More precisely, <m>\operatorname{ker} f</m> is the complex
                <me>
                  \cdots \longrightarrow \operatorname{ker} f_{n+1} \longrightarrow \operatorname{ker} f_{n} \longrightarrow \operatorname{ker} f_{n-1} \longrightarrow \cdots
                </me>
                where the differentials are simply the corresponding restrictions of the differentials on <m>B_{\bullet}</m>. Similarly, the image of <m>f</m> is the subcomplex of <m>C</m>.
                <me>
                  \cdots \longrightarrow \operatorname{im} f_{n+1} \longrightarrow \operatorname{im} f_{n} \longrightarrow \operatorname{im} f_{n-1} \longrightarrow \cdots
                </me>
                where the differentials are given by restriction of the corresponding differentials in <m>C_{\bullet}</m>. 
                The cokernel of <m>f</m> is the quotient complex <m>C_{\bullet} / \operatorname{im} f</m>.
              </p>
            </statement>
          </definition>

          <p>
            Again, there are some details to check.
          </p>

          <exercise>
            <p>
              Exercise 31. 
              Show that the kernel, image, and cokernel of a complex map are indeed complexes.
            </p>
          </exercise>

          <definition xml:id="def-2.15">
            <statement>
              <p>
                A complex in <m>\mathrm{Ch}(R)</m> is a sequence of complexes of <m>R</m>-modules <m>C_{n}</m> and chain maps <m>d_{n}: C_{n} \longrightarrow C_{n-1}</m> between them
                <me>
                  \cdots \longrightarrow C_{n+1} \stackrel{d_{n+1}}{\longrightarrow} C_{n} \stackrel{d_{n}}{\longrightarrow} C_{n-1} \longrightarrow \cdots
                </me>
                such that <m>d_{n} d_{n+1}=0</m> for all <m>n</m>. A complex of complexes is a diagram of the form
              </p>
              <image source="2023_10_23_e2d6a27704be928b3deeg-055.jpg"/>
              <p>
                where <m>C_{i, j}</m> is the module in homological degree <m>j</m> in the complex <m>C_{i}</m>. 
                The <m>n</m>th column corresponds to the complex <m>C_{n}</m>, and every row is also a complex. 
                The vertical maps are the differentials on each individual complex; 
                the horizontal maps are the differentials on the complex of complexes.
              </p>
            </statement>
          </definition>
    
          <p>
            Given a complex <m>C</m> in <m>\operatorname{Ch}(R)</m>, we can talk about cycles and boundaries, which are a sequence of subcomplexes of the complexes in <m>C</m>, and thus its homology. 
            Such a complex is exact if <m>\operatorname{im} d_{n+1}=\operatorname{ker} d_{n}</m> for all <m>n</m>.
          </p>

          <definition xml:id="def-2.16">
            <statement>
              <p>
                Definition 2.16. A short exact sequence of complexes is an exact complex in <m>\mathrm{Ch}(R)</m> of the form
                <me>
                  0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0 .
                </me>
                Equivalently, a short exact sequence of complexes is a commutative diagram
              </p>
              <image source="2023_10_23_e2d6a27704be928b3deeg-056.jpg"/>
              <p>
                where the rows are exact and the columns are complexes.
              </p>
            </statement>
          </definition>
        </section>

        <section xml:id="sec-ses"><title>Short Exact Sequences</title>

          <p>
            In this section, we will discuss short exact sequences of modules in a bit more detail. 
            We note, however, that everything we will discuss here can be extended for short exact sequences of complexes, and that the generalization is not too difficult: one just needs to replace modules with complexes and maps of modules by maps of complexes.
          </p>

          <example>
            <p>
              Example 2.17. Fix a ring <m>R</m>, and let <m>A</m> and <m>C</m> be <m>R</m>-modules. 
              Consider the inclusion <m>i: A \rightarrow A \oplus C</m> of <m>A</m> into the first component of the direct sum, and the projection map <m>\pi: A \oplus C \rightarrow C</m> onto the second component of the product. 
              These two maps fit into a short exact sequence
              <me>
                0 \longrightarrow A \stackrel{i}{\longrightarrow} A \oplus C \stackrel{p}{\longrightarrow} C \longrightarrow 0
              </me>
              These are sometimes called trivial short exact sequences.
            </p>
          </example>
      
          <p>
            On the one hand, the short exact sequences that look like this one are very important; 
            on the other hand, not all short exact sequences are of this type.
          </p>

          <definition xml:id="def-2.18">
            <statement>
              <p>
                Definition 2.18. We say that a short exact sequence
                <me>
                  0 \longrightarrow A \longrightarrow B \longrightarrow C \longrightarrow 0
                </me>
                splits or is a split short exact sequence if it is isomorphic to
                <me>
                  0 \longrightarrow A \stackrel{i}{\longrightarrow} A \oplus C \stackrel{p}{\longrightarrow} C \longrightarrow 0
                </me>
                where <m>i</m> is the inclusion of the first component and <m>p</m> is the projection onto the second component.
              </p>
            </statement>
          </definition>

          <lemma xml:id="lem-2.19"><title>Splitting Lemma</title>
            <statement>
              <p>
                Lemma 2.19. Consider the short exact sequence
                <me>
                  0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0
                </me>
                of <m>R</m>-modules. 
                The following are equivalent:
                <ol>
                  <li>
                    <p>
                      There exists a homomorphism of <m>R</m>-modules <m>q: B \longrightarrow A</m> such that <m>q f=\operatorname{id}_{A}</m>.
                    </p>
                  </li>
      
                  <li>
                    <p>
                      There exists a homomorphism of <m>R</m>-modules <m>r: C \longrightarrow B</m> such that <m>g r=\operatorname{id}_{C}</m>.
                    </p>
                  </li>
      
                  <li>
                    <p>
                      The short exact sequence splits.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>

            <proof>
              <p>
                First, we will show that c implies a and b. If the sequence splits, then consider an isomorphism of complexes
              </p>
              <image source="2023_10_23_e2d6a27704be928b3deeg-057.jpg"/>
              <p>
                meaning that the diagram commutes and <m>a, b</m>, and <m>c</m> are isomorphisms of <m>R</m>-modules, <m>i</m> is the inclusion in the first component, and <m>p</m> is the projection onto the second component. 
                Let <m>\pi: A \oplus C \longrightarrow A</m> be the projection onto the first component, and <m>j: C \longrightarrow A \oplus C</m> be the inclusion onto the first component. 
                Now consider the maps <m>q:=a^{-1} \pi b</m> and <m>r:=b^{-1} j c</m>. 
                Then
                <me>
                  \begin{array}{rlr}
                  q f &amp; =a^{-1} \pi b f &amp; \\
                  &amp; =a^{-1} \pi i a &amp; \text { by commutativity } \\
                  &amp; =a^{-1} a &amp; \text { because } \pi i=\mathrm{id}_{A} \\
                  &amp; =1_{A} &amp;
                  \end{array}
                </me>
                and
                <me>
                  \begin{aligned}
                  g r &amp; =g b^{-1} j c &amp; &amp; \\
                  &amp; =c^{-1}(c g) b^{-1} j c &amp; &amp; \text { multiplying by } c^{-1} c=1_{C} \\
                  &amp; =c^{-1}(p b) b^{-1} j c &amp; &amp; \text { by commutativity } \\
                  &amp; =c^{-1} p j c &amp; &amp; \text { because } b b^{-1}=1_{B} \\
                  &amp; =c^{-1} c &amp; &amp; \text { because } p j=\mathrm{id}_{C} \\
                  &amp; =1_{C} . &amp; &amp;
                  \end{aligned}
                </me>
                Therefore, c implies a and b.
              </p>
          
              <p>
                Now suppose that a holds, and let's show that the sequence splits. 
                First, we need to show that <m>B \cong A \oplus C</m>. 
                Every <m>b \in B</m> can be written as
                <me>
                  b=(b-f q(b))+f q(b)
                </me>
                where <m>f q(b) \in \operatorname{im} f \cong A</m>, and
                <me>
                  q(b-f q(b))=q(b)-\underbrace{q f}_{\operatorname{id}_{A}}(q(b))=q(b)-q(b)=0
                </me>
                so <m>b-f q(b) \in \operatorname{ker} q</m>. 
                This shows that <m>B=\operatorname{im} f+\operatorname{ker} q</m>. 
                Moreover, if <m>f(a) \in \operatorname{ker} q</m>, then <m>a=q f(a)=0</m>, so <m>\operatorname{im} f \cap \operatorname{ker} q=0</m>, and <m>B=\operatorname{im} f \oplus \operatorname{ker} q</m>. 
                Now when we restrict <m>g</m> to <m>\operatorname{ker} q, g</m> becomes injective. 
                We claim it is also surjective, and thus an isomorphism. 
                Indeed, for any <m>c \in C</m> we can pick <m>b \in B</m> such that <m>g(b)=c</m>, since <m>g</m> is surjective, and we showed that we can write <m>b=f(a)+k</m> for some <m>k \in \operatorname{ker} q</m>. 
                Then
                <me>
                  g(k)=\underbrace{g f}_{0}(a)+g(k)=g(b)=c.
                </me>
                Finally, note that <m>\operatorname{im} f \cong A</m>, so we conclude that <m>B \cong A \oplus C</m>, via the isomorphism <m>\varphi</m> given by
                <me>
                  \begin{aligned}
                  &amp; B \longrightarrow \operatorname{im} f \oplus \operatorname{ker} q \longrightarrow A \oplus C \\
                  &amp; b \longmapsto(f q(b), b-f q(b)) \longmapsto(q(b), g(b)) .
                  \end{aligned}
                </me>
                Since <m>g f=0</m> and <m>q f=\operatorname{id}_{A}, \varphi f(a)=(q f(a), 0)=(a, 0)</m>, so <m>\varphi f=i</m>, where <m>i: A \longrightarrow A \oplus C</m> is the inclusion on the first factor. 
                If <m>p: A \oplus C \longrightarrow C</m> denotes the projection onto the second factor, <m>p \varphi=g</m>. 
                Together, these two facts say that the following is a map of complexes:
              </p>
              <image source="2023_10_23_e2d6a27704be928b3deeg-058.jpg"/>
              <p>
                Since <m>\varphi</m> is an isomorphism, so is our map of complexes, and thus our original sequence is a split exact sequence. 
                This shows that a implies <m>c</m>.
              </p>
          
              <p>
                Now assume b holds. 
                Every <m>b \in B</m> can be written as
                <me>
                  b=(b-r g(b))+r g(b)
                </me>
                where <m>r g(b) \in \operatorname{im} r</m> and
                <me>
                  g(b-r g(b))=g(b)-\underbrace{g r}_{\mathrm{id}_{C}}(g(b))=g(b)-g(b)=0
                </me>
                so <m>b-r g(b) \in \operatorname{ker} g</m>. 
                This shows that <m>B=\operatorname{ker} g+\operatorname{im} r</m>. 
                Moreover, if <m>r(c) \in \operatorname{ker} g</m>, then
                <me>
                  c=\operatorname{id}_{C}(c)=g r(c)=0
                </me>
                Therefore, <m>B=\operatorname{ker} g \oplus \operatorname{im} r</m>. 
                Now <m>r</m> is injective, since <m>r(c)=0 \Longrightarrow c=g r(c)=0</m>, and thus <m>\operatorname{im} r \cong C</m>. 
                Since <m>\operatorname{ker} g=\operatorname{im} f \cong A</m>, we conclude that <m>B \cong A \oplus C</m>, via the isomorphism
                <me>
                  \begin{aligned}
                  &amp; A \oplus C \stackrel{\psi}{\longrightarrow} B \\
                  &amp; (a, c) \longmapsto f(a)+r(c) .
                  \end{aligned}
                </me>
                Finally, let <m>i: A \longrightarrow A \oplus C</m> denote the inclusion of the first factor, and <m>p: A \oplus C \longrightarrow C</m> denote the projection onto the second factor. 
                By construction, <m>\psi i=f</m>. 
                Moreover,
                <me>
                  g \psi(a, c)=\underbrace{g f}_{0}(a)+\underbrace{g r}_{\mathrm{id}_{C}}(c)=c
                </me>
                so <m>g \psi=p</m>. 
                Together, these say that the diagram
              </p>
              <image source="2023_10_23_e2d6a27704be928b3deeg-059.jpg"/>
              <p>
                commutes, and must then be an isomorphism of short exact sequences.
              </p>
            </proof>
          </lemma>
      
          <definition xml:id="def-2.20">
            <statement>
              <p>
                Given a split short exact sequence
                <me>
                  0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0
                </me>
                maps <m>q</m> and <m>r</m> satisfying the conditions of the Splitting Lemma are called splittings.
              </p>
            </statement>
          </definition>

          <remark>
            <p>
              Remark 2.21. In the split short exact sequence
              <me>
                0 \longrightarrow A \stackrel{i}{\longrightarrow} A \oplus C \stackrel{p}{\longrightarrow} C \longrightarrow 0
              </me>
              the canonical projection <m>q: A \oplus C \rightarrow A</m> and the usual inclusion <m>r: C \rightarrow A \oplus C</m> are splittings.
            </p>
          </remark>

          <exercise>
            <p>
              Exercise 32. 
              Let <m>k</m> be a field. 
              Show that every short exact sequence of <m>k</m>-vector spaces splits.
            </p>
          </exercise>
      
          <p>
            The Rank-Nulity Theorem can be recast in this setting as a consequence of the fact that every short exact sequence of <m>k</m>-vector spaces splits.
          </p>

          <exercise>
            <p>
              Exercise 33. 
              Prove the Rank-Nulity Theorem using Exercise 32: show that given any linear transformation <m>T: V \rightarrow W</m> of <m>k</m>-vector spaces,
              <me>
                \operatorname{dim}(\operatorname{im} T)+\operatorname{dim}(\operatorname{ker} T)=\operatorname{dim} V
              </me>
            </p>
          </exercise>

          <p>
            But over a general ring, not every short exact sequence splits.
          </p>

          <example>
            <p>
              Example 2.22. The short exact sequence
              <me>
                0 \longrightarrow \mathbb{Z} \stackrel{2}{\longrightarrow} \mathbb{Z} \longrightarrow \mathbb{Z} / 2 \longrightarrow 0
              </me>
              is not split. 
              Indeed, <m>\mathbb{Z}</m> does not have any 2 -torsion elements, so it is not isomorphic to <m>\mathbb{Z} \oplus \mathbb{Z} / 2</m>.
            </p>
            <p>
              An alternative explanation is that there is no splitting to the inclusion <m>\mathbb{Z} \stackrel{2}{\longrightarrow} \mathbb{Z}</m>. 
              On the one hand, every <m>\mathbb{Z}</m>-module map is given by multiplication by a fixed integer <m>n</m>, so a splitting <m>f: \mathbb{Z} \longrightarrow \mathbb{Z}</m> would be of the form <m>f(a)=n a</m> for some fixed <m>n</m>. 
              On the other hand, our proposed splitting <m>f</m> must send 2 to 1 , but there is no integer solution <m>n</m> to <m>2 n=f(2)=1</m>.
            </p>
          </example>

          <p>
            More surprisingly, a short exact sequence of the form
            <me>
              0 \longrightarrow A \stackrel{f}{\longrightarrow} A \oplus C \stackrel{g}{\longrightarrow} C \longrightarrow 0
            </me>
            is not necessarily split, not unless <m>f</m> is the inclusion of the first component and <m>g</m> is the projection onto the second component, as the next example will show.
          </p>

          <example>
            <p>
              Example 2.23. Consider the short exact sequence
              <me>
                0 \longrightarrow \mathbb{Z} /(2) \stackrel{f}{\longrightarrow} \mathbb{Z} /(4) \stackrel{g}{\longrightarrow} \mathbb{Z} /(2) \longrightarrow 0
              </me>
              where <m>f</m> is the inclusion of the subgroup generated by 2, so <m>f(1+(2))=2+(4)</m>, and <m>g</m> is the quotient onto that subgroup, meaning <m>g(1)=1</m>. 
              This is not a split short exact sequence, because <m>\mathbb{Z} /(4) \nsucceq \mathbb{Z} /(2) \oplus \mathbb{Z} /(2)</m>. 
              Now let
              <me>
                M:=\bigoplus_{\mathbb{N}}(\mathbb{Z} /(2) \oplus \mathbb{Z} /(4))
              </me>
              be the direct sum of infinitely many copies of <m>\mathbb{Z} /(2) \oplus \mathbb{Z} /(4)</m>. 
              Then
              <me>
                \mathbb{Z} /(2) \oplus M \cong M \cong M \oplus \mathbb{Z} /(4)
              </me>
              and the sequence
              <me>
                0 \longrightarrow \mathbb{Z} /(2) \stackrel{h}{\longrightarrow} \mathbb{Z} /(4) \oplus M \stackrel{t}{\longrightarrow} \mathbb{Z} /(2) \oplus M \longrightarrow 0
              </me>
              with <m>h(a)=(f(a), 0)</m> and <m>t(a, m)=(g(a), m)</m> is still exact. 
              The middle term is indeed isomorphic to the direct sum of the other two:
              <me>
                \mathbb{Z} /(4) \oplus M \cong M \cong(M \oplus \mathbb{Z} /(2)) \oplus \mathbb{Z} /(2)
              </me>
              And yet this is not a split exact sequence: 
              if we had a splitting <m>q: \mathbb{Z} /(4) \oplus M \longrightarrow \mathbb{Z} /(2)</m> of <m>h</m>, then its restriction to the first factor would give us a splitting <m>\mathbb{Z} /(4) \longrightarrow \mathbb{Z} /(2)</m> of <m>f</m>, which we know cannot exist, since
              <me>
                0 \longrightarrow \mathbb{Z} /(2) \stackrel{f}{\longrightarrow} \mathbb{Z} /(4) \stackrel{g}{\longrightarrow} \mathbb{Z} /(2) \longrightarrow 0
              </me>
              does not split.
            </p>
          </example>
      
          <p>
            Given splittings <m>q</m> and <m>r</m> for a short exact sequence as in Lemma 2.19, we can quickly show that our short exact sequence splits using the Five Lemma. 
            To prove the Five Lemma, one needs to use diagram chasing. 
            Diagram chasing is a common technique in homological algebra, which essentially consists of tracing elements around in the diagram. 
            We will see some examples of diagram chasing in the next section.
          </p>

          <exercise>
            <p>
              Exercise 34 (The Five Lemma). Consider the following commutative diagram of <m>R</m>-modules with exact rows:
            </p>
            <image source="2023_10_23_e2d6a27704be928b3deeg-060.jpg"/>
            <p>
              Show that if <m>a, b, d</m>, and <m>e</m> are isomorphisms, then <m>c</m> is an isomorphism.
            </p>
          </exercise>

          <remark>
            <p>
              Remark 2.24. Given a short exact sequence, suppose we have <m>R</m>-module homomorphisms <m>q</m> and <m>r</m>
            </p>

            <image source="2023_10_23_e2d6a27704be928b3deeg-061.jpg"/>
          
            <p>
              such that <m>q f=\operatorname{id}_{A}</m> and <m>r g=\operatorname{id}_{C}</m>. 
              Then we get an induced map
              <me>
                \begin{aligned}
                &amp; B \stackrel{\varphi}{\longrightarrow} A \oplus C \\
                &amp; b \longmapsto(q(b), g(b))
                \end{aligned}
              </me>
              such that the diagram
            </p>
            <image source="2023_10_23_e2d6a27704be928b3deeg-061(1).jpg"/>
            <p>
              commutes. 
              The Five Lemma guarantees that <m>\varphi</m> must be an isomorphism, so our diagram is an isomorphism of short exact sequences.
            </p>
          </remark>
    
          <p>
            There are many ways in which <m>R</m>-Mod behaves better than the category of groups, and this is one of them.
          </p>

          <remark>
            <p>
              Remark 2.25. 
              The Splitting Lemma does not hold if we replace <m>R</m>-modules with the category Grp of groups. 
              For example, consider the symmetric group on 3 elements <m>S_{3}</m> and the inclusion <m>A_{3} \hookrightarrow S_{3}</m> of the alternating group in <m>S_{3}</m>. 
              Notice that <m>A_{3}</m> is precisely the kernel of the sign map
              <me>
                \operatorname{sign}: S_{3} \longrightarrow \mathbb{Z} / 2
              </me>
              which sends even permutations to 0 and odd permutations to 1 . Therefore,
              <me>
                0 \longrightarrow A_{3} \longrightarrow S_{3} \longrightarrow \mathbb{Z} / 2 \longrightarrow 0
              </me>
              is a short exact sequence.
              When writing exact sequences of nonabelian groups such as this one, one sometimes uses <m>\{e\}</m> for instead of 0, to indicate that trivial group. 
              So our short exact sequence is
              <me>
                \{e\} \longrightarrow A_{3} \longrightarrow S_{3} \longrightarrow \mathbb{Z} / 2 \longrightarrow\{e\}
              </me>
            </p>
        
            <p>
              Moreover, this exact sequence is not split, since <m>S_{3}</m> is not abelian but <m>A_{3} \oplus \mathbb{Z} / 2</m> is, and thus <m>S_{3} \neq A_{3} \oplus \mathbb{Z} / 2</m>. 
              However, any group homomorphism <m>u: \mathbb{Z} / 2 \rightarrow S_{3}</m> defined by sending the generator to any two cycle is a splitting for our short exact sequence, meaning signo <m>u=\mathrm{id}_{\mathbb{Z} / 2}</m>.
            </p>
        
            <p>
              Funny enough, there is no splitting for the inclusion <m>A_{3} \subseteq S_{3}</m>, since there are no nontrivial homomorphisms <m>S_{3} \rightarrow A_{3}: A_{3}</m> has no elements of order 2, so a group homomorphism <m>S_{3} \rightarrow A_{3}</m> must send every 2-cycle in <m>S_{3}</m> must be sent to the identity, but 2-cycles generate <m>S_{3}</m>.
            </p>
          </remark>
      
          <p>
            We will return to the topic of split short exact sequences when we talk about projective and injective modules.
          </p>
      
          <exercise>
            <p>
              Exercise 35. 
              Fix a ring <m>R</m>. Show that if <m>F</m> is a free <m>R</m>-module, then every short exact sequence of <m>R</m>-modules
              <me>
                0 \longrightarrow A \longrightarrow B \longrightarrow F \longrightarrow 0
              </me>
              splits.
            </p>
          </exercise>

        </section>

        <section xml:id="sec-les"><title>Long Exact Sequences</title>

          <p>
            A long exact sequence is just what it sounds like: an exact sequence that is, well, long. 
            Usually, we use the term long exact sequence to refer to any exact sequence, especially if it is not a short exact sequence. 
            So in particular, a long exact sequence does not literally have to be that long.
          </p>
    
          <p>
            Long exact sequences arise naturally in various ways, and are often induced by some short exact sequence. 
            The first long exact sequence one encounters is the long exact sequence on homology. 
            All other long exact sequences are, in some way, a special case of this one. 
            The main tool we need to build it is the Snake Lemma.
          </p>

          <theorem xml:id="thm-2.26"><title>Snake Lemma</title>
            <statement>
              <p>
                Consider the commutative diagram of <m>R</m>-modules
              </p>
              <image source="2023_10_23_e2d6a27704be928b3deeg-062.jpg"/>
              <p>
                If the rows of the diagram are exact, then there exists an exact sequence
                <me>
                  \operatorname{ker} f \longrightarrow \operatorname{ker} g \longrightarrow \operatorname{ker} h \stackrel{\partial}{\longrightarrow} \operatorname{coker} f \longrightarrow \operatorname{coker} g \longrightarrow \text { coker } h
                </me>
                Given <m>c^{\prime} \in \operatorname{ker} h</m>, pick <m>b^{\prime} \in B^{\prime}</m> such that <m>p^{\prime}\left(b^{\prime}\right)=c^{\prime}</m>, and <m>a \in A</m> such that <m>i(a)=g\left(b^{\prime}\right)</m>. 
                Then
                <me>
                  \partial\left(c^{\prime}\right)=a+\operatorname{im} f \in \operatorname{coker} f
                </me>
                The picture to keep in mind (and which explains the name of the lemma) is the following:
              </p>
              <image source="2023_10_23_e2d6a27704be928b3deeg-062(1).jpg"/>
            </statement>

            <proof>
              <p>
                If <m>a^{\prime} \in \operatorname{ker} f</m>, then
              </p>
        
              <p>
                <me>
                  g\left(i^{\prime}\left(a^{\prime}\right)\right)=i f\left(a^{\prime}\right)=0
                </me>
              </p>
        
              <p>
                by commutativity, so <m>i^{\prime}\left(a^{\prime}\right) \in \operatorname{ker} g</m>. 
                Similarly, if <m>b^{\prime} \in \operatorname{ker} g</m> then <m>p^{\prime}\left(b^{\prime}\right) \in \operatorname{ker}(g)</m>. 
                So
              </p>
        
              <p>
                <me>A^{\prime} \stackrel{i^{\prime}}{\longrightarrow} B^{\prime} \stackrel{p^{\prime}}{\longrightarrow} C^{\prime} \quad \text { restrict to maps } \quad \operatorname{ker} f \stackrel{i^{\prime}}{\longrightarrow} \operatorname{ker} g \stackrel{p^{\prime}}{\longrightarrow} \operatorname{ker} h \text {. }</me>
              </p>
        
              <p>
                We claim that the sequence obtained by restriction
              </p>
        
              <p>
                <me>\operatorname{ker} f \stackrel{i^{\prime}}{\longrightarrow} \operatorname{ker} g \stackrel{p^{\prime}}{\longrightarrow} \operatorname{ker} h</me>
              </p>
        
              <p>
                is exact. 
                On the one hand, we already know that the original maps satisfy <m>p^{\prime} i^{\prime}=0</m>, so their restrictions must satisfy this as well, guaranteeing that
              </p>
        
              <p>
                <me>i^{\prime}(\operatorname{ker} f) \subseteq \operatorname{ker}\left(\operatorname{ker} g \stackrel{p^{\prime}}{\rightarrow} \operatorname{ker} h\right)</me>
              </p>
        
              <p>
                On the other and, if <m>b^{\prime} \in \operatorname{ker} g</m> is such that <m>p^{\prime}\left(b^{\prime}\right)=0</m>, then by exactness of the original sequence there exists <m>a^{\prime} \in A^{\prime}</m> such that <m>i^{\prime}\left(a^{\prime}\right)=b^{\prime}</m>; 
                we only need to check that we can choose such <m>a^{\prime}</m> satisfying <m>a^{\prime} \in \operatorname{ker} f</m>. 
                An indeed, by commutativity, any <m>a^{\prime}</m> with <m>i^{\prime}\left(a^{\prime}\right)=b^{\prime}</m> satisfies
              </p>
        
              <p>
                <me>i f\left(a^{\prime}\right)=g i^{\prime}\left(a^{\prime}\right)=g\left(b^{\prime}\right)=0 \text {, }</me>
              </p>
        
              <p>
                and since <m>i</m> is injective, we must have <m>f\left(a^{\prime}\right)=0</m>. 
                So we have shown that the following is an exact sequence:
              </p>
        
              <p>
                <me>\operatorname{ker} f \stackrel{i^{\prime}}{\longrightarrow} \operatorname{ker} g \stackrel{p^{\prime}}{\longrightarrow} \operatorname{ker} h</me>
              </p>
        
              <p>
                Similarly, if <m>a \in \operatorname{im} f</m>, the commutativity of the diagram guarantees that <m>i(a) \in \operatorname{im} g</m>, and if <m>b \in \operatorname{im} g</m>, then <m>p(b) \in \operatorname{im} h</m>. 
                So the maps <m>A \stackrel{i}{\longrightarrow} B \stackrel{p}{\longrightarrow} C</m> restrict to maps
              </p>
        
              <p>
                <me>\operatorname{im} f \stackrel{i}{\longrightarrow} \operatorname{im} g \stackrel{p}{\longrightarrow} \operatorname{im} h</me>
              </p>
        
              <p>
                which then induce maps
              </p>
        
              <p>
                <me>\text { coker } f \longrightarrow \text { coker } g \longrightarrow \text { coker } h \text {. }</me>
              </p>
        
              <p>
                To make the notation less heavy, we denote the induced maps on the quotients by <m>i</m> and <m>p</m>. 
                Again, the fact that <m>p i=0</m> automatically gives us that the restrictions satisfy
              </p>
        
              <p>
                <me>\operatorname{im}(\operatorname{coker} f \rightarrow \operatorname{coker} g) \subseteq \operatorname{ker}(\operatorname{coker} g \rightarrow \operatorname{coker} h)</me>
              </p>
        
              <p>
                so we only need to check equality. 
                Consider <m>b+\operatorname{im} g</m> such that <m>p(b+\operatorname{im} g)=0</m>, meaning that <m>p(b)=0</m>, meaning that <m>p(b) \in \operatorname{im} h</m>. 
                Let <m>c^{\prime} \in C</m> be such that <m>h\left(c^{\prime}\right)=p(b)</m>. Since <m>p^{\prime}</m> is surjective, there exists <m>b^{\prime} \in B^{\prime}</m> such that <m>p^{\prime}\left(b^{\prime}\right)=c^{\prime}</m>, and by commutativity,
              </p>
        
              <p>
                <me>p g\left(b^{\prime}\right)=h p^{\prime}\left(b^{\prime}\right)=h\left(c^{\prime}\right)=p(b) \text {. }</me>
              </p>
        
              <p>
                Then <m>b-g\left(b^{\prime}\right) \in \operatorname{ker} p=\operatorname{im} i</m>. 
                Let <m>a \in A</m> be such that <m>i(a)=b-g\left(b^{\prime}\right)</m>. 
                Now in coker <m>g</m> we have
              </p>
        
              <p>
                <me>
                  \begin{aligned}
                  b+\operatorname{im} g &amp; =b-g\left(b^{\prime}\right)+\operatorname{im} g \\
                  &amp; =i(a)+\operatorname{im} g \\
                  &amp; =i(a+\operatorname{im} f)
                  \end{aligned}
                </me>
              </p>
        
              <p>
                This concludes the proof of exactness of <m>\operatorname{ker} f \longrightarrow \operatorname{ker} g \longrightarrow \operatorname{ker} h \quad</m> and <m>\quad</m> coker <m>f \longrightarrow \operatorname{coker} g \longrightarrow\coker h</m>.
              </p>
        
              <p>
                We still need to show the parts of the statement related to the connecting homomorphism <m>\partial</m>. 
                Our definition of <m>\partial</m> can be visualized as follows:
              </p>
        
      
              <image source="2023_10_23_e2d6a27704be928b3deeg-064(1).jpg"/>
        
        
              <p>
                Let's recap the process in words. 
                First, we fix <m>c^{\prime} \in \operatorname{ker} h \subseteq C^{\prime}</m>. 
                Since <m>p^{\prime}</m> is surjective, we can always pick <m>b^{\prime} \in B^{\prime}</m> such that <m>p^{\prime}\left(b^{\prime}\right)=c^{\prime}</m>. 
                Since <m>c^{\prime} \in</m> ker <m>h</m>, by commutativity we have
              </p>
        
              <p>
                <me>p g\left(b^{\prime}\right)=h p^{\prime}\left(b^{\prime}\right)=h\left(c^{\prime}\right)=0,</me>
              </p>
        
              <p>
                so <m>g\left(b^{\prime}\right) \in \operatorname{ker} p=\operatorname{im} i</m>. 
                Therefore, there exists <m>a \in A</m> such that <m>i(a)=g\left(b^{\prime}\right)</m>. 
                In fact, since <m>i</m> is injective, there exists a unique <m>a \in A</m> such that <m>i(a)=g\left(b^{\prime}\right)</m>. 
                Our definition of <m>\partial\left(c^{\prime}\right)</m> sets
              </p>
        
              <p>
                <me>\partial\left(c^{\prime}\right)=a+\operatorname{im} f \in \operatorname{coker} f .</me>
              </p>
        
              <p>
                The fact that <m>\partial</m> is a homomorphism of <m>R</m>-modules follows from the fact that all the maps involved are homomorphisms of <m>R</m>-modules: 
                given <m>c_{1}^{\prime}, c_{2}^{\prime} \in \operatorname{ker} h</m>, and <m>b_{1}^{\prime}, b_{2}^{\prime} \in B^{\prime}, a_{1}, a_{2} \in A</m> such that
              </p>
        
              <p>
                <me>p^{\prime}\left(b_{1}^{\prime}\right)=c_{1}^{\prime}, \quad p^{\prime}\left(b_{2}^{\prime}\right)=c_{2}^{\prime}, \quad i\left(a_{1}\right)=g\left(b_{1}^{\prime}\right), \quad i\left(a_{2}\right)=g\left(b_{2}^{\prime}\right),</me>
              </p>
        
              <p>
                we have
              </p>
        
              <p>
                <me>i\left(a_{1}+a_{2}\right)=i\left(a_{1}\right)+i\left(a_{2}\right)=g\left(b_{1}^{\prime}\right)+g\left(b_{2}^{\prime}\right)=g\left(b_{1}^{\prime}+b_{2}^{\prime}\right) \text {, }</me>
              </p>
        
              <p>
                So
              </p>
        
              <p>
                <me>\partial\left(c_{1}^{\prime}\right)=a_{1}+\operatorname{im} f, \quad \partial\left(c_{2}^{\prime}\right)=a_{2}+\operatorname{im} f, \quad \text { and } \quad \partial\left(c_{1}^{\prime}+c_{2}^{\prime}\right)=\left(a_{1}+a_{2}\right)+\operatorname{im} f</me>
              </p>
        
              <p>
                Therefore, <m>\partial\left(c_{1}^{\prime}\right)+\partial\left(c_{2}^{\prime}\right)=\partial\left(c_{1}^{\prime}+c_{2}^{\prime}\right)</m>. 
                Similarly, given any <m>r \in R</m>,
              </p>
        
              <p>
                <m>r\left(a_{1}+\operatorname{im} f\right)=r a_{1}+\operatorname{im} f, \quad i\left(r a_{1}\right)=r i\left(a_{1}\right)=r g\left(b_{1}^{\prime}\right)=g\left(r b_{1}^{\prime}\right), \quad</m> and <m>\quad p^{\prime}\left(r b_{1}\right)=r p^{\prime}\left(b_{1}\right)=r c_{1}</m>,
              </p>
        
              <p>
                so <m>\partial\left(r c_{1}\right)=r\left(a_{1}+\operatorname{im} f\right)=r \partial\left(c_{1}\right)</m>. We now need to show the following:
              </p>
        
      
              <image source="2023_10_23_e2d6a27704be928b3deeg-064.jpg"/>
              
        
              <p>
                Points 2) and 3) together say that the sequence
              </p>
        
              <p>
                <m>\operatorname{ker} g \longrightarrow \operatorname{ker} h \stackrel{\partial}{\longrightarrow} \operatorname{coker} f \longrightarrow \operatorname{coker} g</m>
              </p>
        
              <p>
                is exact, and this will complete the proof.
              </p>
        
              <p>
                First, let's show that <m>\partial(0)</m> is well-defined. 
                Ultimately, our definition of <m>\partial</m> only involves one choice, when we pick <m>b^{\prime} \in B^{\prime}</m> such that <m>p^{\prime}\left(b^{\prime}\right)=0</m>; 
                we need to show that <m>\partial(0)</m> does not depend on the choice of <m>b^{\prime}</m>. 
                Given <m>b^{\prime} \in B^{\prime}</m> such that <m>p^{\prime}\left(b^{\prime}\right)=0</m>, by exactness we have <m>b^{\prime} \in \operatorname{ker} p^{\prime}=\operatorname{im} i^{\prime}</m>. 
                Therefore, there exists <m>a^{\prime} \in A^{\prime}</m> such that <m>i^{\prime}\left(a^{\prime}\right)=b^{\prime}</m>. 
                Notice that <m>a:=f\left(a^{\prime}\right) \in A</m> is such that
              </p>
        
              <p>
                <me>i(a)=i f\left(a^{\prime}\right)=g i^{\prime}\left(a^{\prime}\right)=g\left(b^{\prime}\right) .</me>
              </p>
        
              <p>
                Thus our definition says that <m>\partial(0)=a+\operatorname{im} f \in \operatorname{coker} f</m>. 
                Since <m>a=f\left(a^{\prime}\right) \in \operatorname{im} f</m>, we conclude that <m>a+\operatorname{im} f=0</m>, so <m>\partial(0)=0</m> for any choice of <m>b^{\prime}</m>.
              </p>
        
              <p>
                Now consider any <m>c^{\prime} \in \operatorname{ker} h</m>. 
                Again, to show <m>\partial</m> is well-defined, we need only to show it does not depend on the choice of <m>b^{\prime}</m> such that <m>p^{\prime}\left(b^{\prime}\right)=c^{\prime}</m>. 
                Consider <m>b_{1}^{\prime}, b_{2}^{\prime} \in B^{\prime}</m> such that
              </p>
        
              <p>
                <me>p^{\prime}\left(b_{1}^{\prime}\right)=p^{\prime}\left(b_{2}^{\prime}\right)=c^{\prime},</me>
              </p>
        
              <p>
                and <m>a_{1}, a_{2} \in A</m> such that
              </p>
        
              <p>
                <me>i\left(a_{1}\right)=g\left(b_{1}^{\prime}\right) \quad \text { and } \quad i\left(a_{2}\right)=g\left(b_{2}^{\prime}\right) \text {. }</me>
              </p>
        
              <p>
                Note that
              </p>
        
              <p>
                <me>i\left(a_{1}-a_{2}\right)=g\left(b_{1}^{\prime}-b_{2}^{\prime}\right)</me>
              </p>
        
              <p>
                and since
              </p>
        
              <p>
                <me>p^{\prime}\left(b_{1}^{\prime}-b_{2}^{\prime}\right)=c^{\prime}-c^{\prime}=0</me>
              </p>
        
              <p>
                we must have
              </p>
        
              <p>
                <me>a_{1}-a_{2}+\operatorname{im} f=\partial(0)=0</me>
              </p>
        
              <p>
                Thus
              </p>
        
              <p>
                <me>a_{1}+\operatorname{im} f=a_{2}+\operatorname{im} f,</me>
              </p>
        
              <p>
                and this concludes our proof that <m>\partial</m> is well-defined.
              </p>
        
              <p>
                Now we show 2): that <m>p^{\prime}(\operatorname{ker} g)=\operatorname{ker} \partial</m>.
              </p>
        
              <p>
                If <m>b^{\prime} \in \operatorname{ker} g</m>, then the only <m>a \in A</m> such that <m>i(a)=g\left(b^{\prime}\right)=0</m> is <m>a=0</m>. 
                Therefore, <m>\partial\left(p^{\prime}\left(b^{\prime}\right)\right)=0</m>, so <m>p^{\prime}(\operatorname{ker} g) \subseteq \operatorname{ker} \partial</m>. 
                On the other hand, let <m>c^{\prime} \in \operatorname{ker} h</m> be such that <m>\partial\left(c^{\prime}\right)=0</m>. 
                That means that for any <m>b^{\prime} \in B^{\prime}</m> such that <m>p^{\prime}\left(b^{\prime}\right)=c^{\prime}</m> we must have <m>g\left(b^{\prime}\right)=i(a)</m> for some <m>a \in \operatorname{im} f</m>. Let <m>a^{\prime} \in A^{\prime}</m> be such that <m>f\left(a^{\prime}\right)=a</m>. 
                Then
              </p>
        
              <p>
                <me>g i^{\prime}\left(a^{\prime}\right)=i f\left(a^{\prime}\right)=i(a)=g\left(b^{\prime}\right)</me>
              </p>
        
              <p>
                so <m>b^{\prime}-i^{\prime}\left(a^{\prime}\right) \in \operatorname{ker} g</m>. 
                Since <m>p^{\prime} i^{\prime}=0</m>,
              </p>
        
              <p>
                <me>c^{\prime}=p^{\prime}\left(b^{\prime}\right)=p^{\prime}\left(b^{\prime}-i^{\prime}\left(a^{\prime}\right)\right) \in p^{\prime}(\operatorname{ker} g) .</me>
              </p>
        
              <p>
                We conclude that <m>\operatorname{ker} \partial=p^{\prime}(\operatorname{ker} g)</m>, and this shows 2<m>)</m>.
              </p>
        
              <p>
                Now we show 3 ), that is, <m>\operatorname{im} \partial=\operatorname{ker}(\operatorname{coker} f \stackrel{i}{\rightarrow} \operatorname{coker} g)</m>.
              </p>
        
              <p>
                Let <m>a \in A</m> be such that <m>i(a+\operatorname{im} f)=0</m>. 
                In <m>B</m>, this says that <m>i(a) \in \operatorname{im} g</m>, so we can choose <m>b^{\prime} \in B^{\prime}</m> such that <m>g\left(b^{\prime}\right)=i(a)</m>. 
                Using commutativity and the fact that <m>p i=0</m>, we have
              </p>
        
              <p>
                <me>h p^{\prime}\left(b^{\prime}\right)=p g\left(b^{\prime}\right)=p i(a)=0 \quad \text { so } \quad p^{\prime}\left(b^{\prime}\right) \in \operatorname{ker} h \text {. }</me>
              </p>
        
              <p>
                This shows that <m>a+\operatorname{im} f=\partial\left(p^{\prime}\left(b^{\prime}\right)\right)</m>, and thus <m>\operatorname{ker}(\operatorname{coker} f \stackrel{i}{\rightarrow} \operatorname{coker} g) \subseteq \operatorname{im} \partial</m>.
                Finally, if <m>p^{\prime}\left(b^{\prime}\right)=c^{\prime}</m> and <m>i(a)=g\left(b^{\prime}\right)</m>, then
              </p>
        
              <p>
                <me>i \partial\left(c^{\prime}\right)=i(a+\operatorname{im} f)=g\left(b^{\prime}\right)+\operatorname{im} g=0, \quad \text { so } \quad \operatorname{im} \partial \subseteq \operatorname{ker}(\operatorname{coker} f \stackrel{i}{\rightarrow} \operatorname{coker} g)</me>
              </p>
            </proof>
          </theorem>

          <definition xml:id="def-2.27">
            <statement>
              <p>
                The map <m>\partial</m> in the Snake Lemma is the connecting homomorphism.
              </p>
            </statement>
          </definition>

          <p>
            The proof of the Snake Lemma is what we call a diagram chase, for reasons that may be obvious by now: 
            we followed the diagram in the natural way, and everything worked out in the end. 
            The Five Lemma is another classical example of a diagram chase.
          </p>
    
          <p>
            Now that we have the Snake Lemma, we can construct the long exact sequence in homology:
          </p>

          <theorem xml:id="thm-2.28"><title>Long exact sequence in homology</title>
            <statement>
              <p>
                Given a short exact sequence in <m>\mathrm{Ch}(R)</m>
              </p>
        
              <p>
                <me>0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0</me>
              </p>
        
              <p>
                there are connecting homomorphisms <m>\partial: \mathrm{H}_{n}(C) \longrightarrow \mathrm{H}_{n-1}(A)</m> such that
              </p>
        
              <p>
                <me>\cdots \longrightarrow \mathrm{H}_{n+1}(C) \stackrel{\partial}{\longrightarrow} \mathrm{H}_{n}(A) \stackrel{f}{\longrightarrow} \mathrm{H}_{n}(B) \stackrel{g}{\longrightarrow} \mathrm{H}_{n}(C) \stackrel{\partial}{\longrightarrow} \mathrm{H}_{n-1}(A) \longrightarrow \cdots</me>
              </p>
        
              <p>
                is an exact sequence.
              </p>
            </statement>

            <proof>
              <p>
                For each <m>n</m>, we have short exact sequences
              </p>
        
              <p>
                <me>0 \longrightarrow A_{n} \longrightarrow B_{n} \longrightarrow C_{n} \longrightarrow 0</me>
              </p>
        
              <p>
                The condition that <m>f</m> and <m>g</m> are maps of complexes implies, by Lemma 2.4, that <m>f</m> and <m>g</m> take cycles to cycles, so we get exact sequences
              </p>
        
              <p>
                <me>0 \longrightarrow Z_{n}(A) \longrightarrow Z_{n}(B) \longrightarrow Z_{n}(C)</me>
              </p>
        
              <p>
                Again by Lemma 2.4, the condition that <m>f</m> and <m>g</m> are maps of complexes also implies that <m>f</m> and <m>g</m> both take boundaries to boundaries, so that we get exact sequences
              </p>
        
              <p>
                <me>A_{n} / \mathrm{im} d_{n+1}^{A} \longrightarrow B_{n} / \operatorname{im} d_{n+1}^{B} \longrightarrow C_{n} / \mathrm{im} d_{n+1}^{C} \longrightarrow 0</me>
              </p>
        
              <p>
                Let <m>F</m> be any complex. The boundary maps on <m>F</m> induce maps <m>F_{n} \longrightarrow Z_{n-1}(F)</m> that send <m>\operatorname{im} d_{n+1}</m> to 0 , so we get induced maps <m>F_{n} / \operatorname{im} d_{n+1} \longrightarrow Z_{n-1}(F)</m>. Applying this general fact to <m>A, B</m>, and <m>C</m>, and putting all this together, we have a commutative diagram with exact rows
              </p>
      
              <image source="2023_10_23_e2d6a27704be928b3deeg-066.jpg"/>
              
              <p>
                For any complex <m>F</m>,
              </p>
        
              <p>
                <me>\operatorname{ker}\left(F_{n} / \operatorname{im} d_{n+1}^{F} \stackrel{d_{n}^{F}}{\longrightarrow} Z_{n-1}(F)\right)=\mathrm{H}_{n}(F)</me>
              </p>
        
              <p>
                and
              </p>
        
              <p>
                <me>\operatorname{coker}\left(F_{n} / \operatorname{im} d_{n+1}^{F} \stackrel{d_{n}^{F}}{\longrightarrow} Z_{n-1}(F)\right)=Z_{n-1}(F) / \operatorname{im} d_{n}^{F}=\mathrm{H}_{n-1}(F)</me>
              </p>
        
              <p>
                The Snake Lemma now gives us exact sequences
              </p>
        
              <p>
                <me>\mathrm{H}_{n}(A) \longrightarrow \mathrm{H}_{n}(B) \longrightarrow \mathrm{H}_{n}(C) \stackrel{\partial}{\longrightarrow} \mathrm{H}_{n-1}(A) \longrightarrow \mathrm{H}_{n-1}(B) \longrightarrow \mathrm{H}_{n-1}(C)</me>
              </p>
        
              <p>
                Finally, we glue all these together to obtain the long exact sequence in homology.
              </p>
            </proof>
          </theorem>

          <remark>
            <p>
              Remark 2.29. It's helpful to carefully consider how to compute the connecting homomorphisms in the long exact sequence in homology, which we can easily put together from the proof of the Snake Lemma. Suppose that <m>c \in Z_{n+1}(C)=\operatorname{ker} d_{n+1}^{C}</m>. When we view <m>c</m> as an element in <m>C_{n+1}</m>, we can find <m>b \in B_{n+1}</m> such that <m>g_{n+1}(b)=c</m>, since <m>g_{n+1}</m> is surjective by assumption. Since <m>g</m> is a map of complexes, we have
            </p>
      
            <p>
              <me>g_{n} d_{n+1}^{B}(b)=d_{n+1}^{C} g_{n+1}(b)=d_{n+1}^{C}(c)=0</me>
            </p>
      
            <p>
              so <m>d_{n+1}^{B}(b) \in \operatorname{ker} g_{n}</m>. In fact, note that <m>d_{n+1}^{B}(b) \in \mathbb{Z}_{n}(B)</m>, so
            </p>
      
            <p>
              <me>b \in \operatorname{ker}\left(Z_{n}(B) \stackrel{g_{n}}{\rightarrow} Z_{n}(C)\right)=\operatorname{im}\left(Z_{n}(A) \rightarrow Z_{n}(B)\right)</me>
            </p>
      
            <p>
              Thus there exists <m>a \in Z_{n}(A)</m> such that <m>f_{n}(a)=d_{n+1}^{B}(b)</m>. Finally,
            </p>
      
            <p>
              <me>\partial\left(c+\operatorname{im} d_{n+2}\right)=a+\operatorname{im} d_{n+1}^{A} .</me>
            </p>
      
            <p>
              So in summary, the recipe goes as follows: given <m>c+\operatorname{im} d_{n+2} \in H_{n+1}(C)</m>, we find <m>b \in B_{n+1}</m> such that <m>g_{n+1}(b)=c</m> and <m>a \in Z_{n}(A)</m> such that <m>f_{n}(a)=d_{n+1}^{B}(b)</m>, and
            </p>
      
            <p>
              <me>\partial(c)=a+\operatorname{im} d_{n+1}^{A} .</me>
            </p>
          </remark>
    
          <p>
            We will soon see that long exact sequences appear everywhere, and that they are very helpful. 
            Before we see more examples, we want to highlight a connection between long and short exact sequences.
          </p>

          <remark>
            <p>
              Remark 2.30. Suppose that
            </p>
      
            <p>
              <me>\cdots \longrightarrow C_{n+1} \stackrel{f_{n+1}}{\longrightarrow} C_{n} \stackrel{f_{n}}{\longrightarrow} \cdots</me>
            </p>
      
            <p>
              is a long exact sequence. This long exact sequence breaks into the short exact sequences
            </p>
      
            <p>
              <me>0 \longrightarrow \operatorname{ker} f_{n} \stackrel{i}{\longrightarrow} C_{n} \stackrel{\pi}{\longrightarrow} \operatorname{coker} f_{n+1} \longrightarrow 0</me>
            </p>
      
            <p>
              The first map <m>i</m> is simply the inclusion of the submodule ker <m>f_{n}</m> into <m>C_{n}</m>, while the second map <m>\pi</m> is the canonical projection onto the quotient. While it is clear that <m>i</m> is injective and <m>\pi</m> is surjective, exactness at the middle is less obvious. This follows from the exactness of the original complex, which gives <m>\operatorname{im} i=\operatorname{ker} f_{n}=\operatorname{im} f_{n+1}=\operatorname{ker} \pi</m>.
            </p>
          </remark>
    
          <p>
            The long exact sequence in homology is natural.
          </p>

          <theorem xml:id="thm-2.31"><title>Naturality of the long exact sequence in homology</title>
            <statement>
              <p>
                Any commutative diagram in <m>\mathrm{Ch}(R)</m>
              </p>
        
      
              <image source="2023_10_23_e2d6a27704be928b3deeg-067(1).jpg"/>
              
        
              <p>
                with exact rows induces a commutative diagram with exact rows
              </p>
        
        
              <image source="2023_10_23_e2d6a27704be928b3deeg-067.jpg"/>
            </statement>

            <proof>
              <p>
                Proof. The rows of the resulting diagram are the long exact sequences in homology induced by each row of the original diagram, as in Theorem 2.28. So the content of the theorem is that the maps induced in homology by <m>f, g</m>, and <m>h</m> make the diagram commute. The commutativity of
              </p>
        
      
              <image source="2023_10_23_e2d6a27704be928b3deeg-068(2).jpg"/>
              
        
              <p>
                follows from the fact that <m>\mathrm{H}_{n}</m> is a functor, so we only need to check commutativity of the square
              </p>
        
        
            <image source="2023_10_23_e2d6a27704be928b3deeg-068(1).jpg"/>
              
        
              <p>
                that involves the connecting homomorphisms <m>\partial</m> and <m>\partial^{\prime}</m>. Consider the following commutative diagram:
              </p>
        
        
              <image source="2023_10_23_e2d6a27704be928b3deeg-068(3).jpg"/>
              
        
              <p>
                Given <m>c \in \operatorname{ker}\left(d_{n}: C_{n} \longrightarrow C_{n-1}\right)</m>, we need to check that <m>f_{n-1}(\partial(c))=\partial^{\prime} h_{n}(c)</m> in <m>\mathrm{H}_{n-1}\left(A^{\prime}\right)</m>. To compute <m>\partial(c)</m>, we find a lift <m>b \in B_{n}</m> such that <m>p_{n}(b)=c</m>, and <m>a \in A_{n-1}</m> with <m>i_{n-1}(a)=d_{n}(b)</m>, and set <m>\partial(c)=a+\operatorname{im} d_{n} \in \mathrm{H}_{n-1}(A)</m>. So <m>f_{n-1} \partial(c)=f_{n-1}(a)+\operatorname{im} d_{n}</m>. On the other hand, to compute <m>\partial^{\prime} h_{n}(c)</m>, we start by finding <m>b^{\prime} \in B_{n}^{\prime}</m> such that <m>p_{n}^{\prime}\left(b^{\prime}\right)=h_{n}(c)</m>. By commutativity of the right back square
              </p>
        
        
              <image source="2023_10_23_e2d6a27704be928b3deeg-068.jpg"/>
              
        
              <p>
                we can choose <m>b^{\prime}=g_{n}(b)</m>, since
              </p>
        
              <p>
                <me>p_{n}^{\prime}\left(b^{\prime}\right)=p_{n}^{\prime} g_{n}(b)=h_{n} p_{n}(b)=h_{n}(c)</me>
              </p>
        
              <p>
                Next we take <m>a^{\prime} \in A_{n-1}^{\prime}</m> such that <m>i_{n-1}^{\prime}\left(a^{\prime}\right)=d_{n}\left(b^{\prime}\right)</m>, and set <m>\partial^{\prime}(h(c))=a^{\prime}+\operatorname{im} d_{n} \in \mathrm{H}_{n-1}\left(A^{\prime}\right)</m>.
              </p>
        
              <p>
                By commutativity of the middle square
              </p>
        
        
              <image source="2023_10_23_e2d6a27704be928b3deeg-069.jpg"/>
              
              <p>
                we have
              </p>
        
              <p>
                <me>d_{n}\left(b^{\prime}\right)=d_{n} g_{n}(b)=g_{n-1} d_{n}(b) .</me>
              </p>
        
              <p>
                By our choice of <m>a</m>, we have
              </p>
        
              <p>
                <me>d_{n}\left(b^{\prime}\right)=g_{n-1} d_{n}(b)=g_{n-1} i_{n-1}(a)</me>
              </p>
        
              <p>
                and by commutativity of the front left square
              </p>
        
      
              <image source="2023_10_23_e2d6a27704be928b3deeg-069(1).jpg"/>
        
              <p>
                we have
              </p>
        
              <p>
                <me>i_{n-1}^{\prime} f_{n-1}(a)=g_{n-1} i_{n-1}(a)=d_{n}\left(b^{\prime}\right)</me>
              </p>
        
              <p>
                So we can take <m>a^{\prime}=f_{n-1}(a)</m>. Finally, this means <m>\partial^{\prime}\left(h_{n}(c)\right)=f_{n-1}(a)+\operatorname{im} d_{n-1}</m>, as we wanted to prove.
              </p>
            </proof>
          </theorem>

          <remark>
            <p>
              Remark 2.32. Let
            </p>
      
            <p>
              <me>0 \longrightarrow A \stackrel{i}{\longrightarrow} B \stackrel{p}{\longrightarrow} C \longrightarrow 0</me>
            </p>
      
            <p>
              be a short exact sequence in <m>\operatorname{Ch}(R)</m>. We can think of Theorem 2.31 as saying that the induced maps on homology <m>i_{*}: \mathrm{H}_{n}(A) \longrightarrow \mathrm{H}_{n}(B)</m> and <m>p_{*}: \mathrm{H}_{n}(B) \longrightarrow \mathrm{H}_{n}(C)</m> and the connecting homomorphism <m>\partial: \mathrm{H}_{n}(C) \longrightarrow \mathrm{H}_{n-1}(A)</m> are all natural transformations. More precisely, consider the category SES of short exact sequences of <m>R</m>-modules, which is a full subcategory of <m>\mathrm{Ch}(R)</m>. Homology gives us functors SES <m>\longrightarrow R</m>-Mod that given a short exact sequence
            </p>
      
            <p>
              <me>0 \longrightarrow A \stackrel{i}{\longrightarrow} B \stackrel{p}{\longrightarrow} C \longrightarrow 0</me>
            </p>
      
            <p>
              return the <m>R</m>-modules <m>\mathrm{H}_{n}(A), \mathrm{H}_{n}(B)</m>, or <m>\mathrm{H}_{n}(C)</m> ). A map between two short exact sequences then induces <m>R</m>-module homomorphisms between the corresponding homologies. With this framework, Theorem 2.31 says that <m>i_{*}: \mathrm{H}_{n}(A) \longrightarrow \mathrm{H}_{n}(B)</m>, and <m>p_{*}: \mathrm{H}_{n}(B) \longrightarrow \mathrm{H}_{n}(C)</m> and the connecting homomorphism <m>\partial: \mathrm{H}_{n}(C) \longrightarrow \mathrm{H}_{n-1}(A)</m> are all natural transformations between the corresponding homology functors.
            </p>
          </remark>

        </section>
        
      </chapter>

      <chapter xml:id="ch-rmod"><title><m>R</m>-Mod</title>

        <section xml:id="sec-hom"><title><m>\Hom</m></title>

          <subsection xml:id="subsec-hom"><title>Introducing <m>\Hom</m></title>

            <p>
              From now on, let's fix a ring <m>R</m>. 
              Recall that whenever we say an <m>R</m>-module <m>M</m>, we mean a left <m>R</m>-module; any general facts about left modules can be naturally converted into statements about right <m>R</m>-modules, under small appropriate corrections. 
              When <m>M</m> is commutative, left and right module structures agree, so the distinction is not relevant.
            </p>
      
            <p>
              Our goal is to get to know the category <m>R</m>-Mod, which as we are about to discover is a very nice category. 
              One of the many nice things about <m>R</m>-Mod is that the Hom-sets have an extra structure. 
              (Roughly speaking, a locally small category where the Hom-sets are objects in some other category is called an enriched category).
            </p>
      
            <p>
              To make the notation less heavy, we write <m>\operatorname{Hom}_{R}(M, N)</m> instead of <m>\operatorname{Hom}_{R-\operatorname{Mod}}(M, N)</m> for the Hom-set between <m>M</m> and <m>N</m> in <m>R</m>-Mod. 
              The arrows in <m>\operatorname{Hom}_{R}(M, N)</m> are all the <m>R</m>-module homomorphisms from <m>M</m> to <m>N</m>. 
              This is a locally small category, meaning that the Hom-sets are actual sets, but more even is true: 
              the Hom-sets are actually abelian groups, and when <m>R</m> is commutative, they are even <m>R</m>-modules.
            </p>
      
            <p>
              Given <m>f, g \in \operatorname{Hom}_{R}(M, N), f+g</m> is the <m>R</m>-module homomorphism defined by
              <me>
                (f+g)(m):=f(m)+g(m)
              </me>
              When <m>R</m> is a commutative ring, given <m>r \in R</m> and <m>f \in \operatorname{Hom}_{R}(M, N), r \cdot f</m> is the <m>R</m>-module homomorphism defined by
            </p>
      
            <p>
              <me>
                (r \cdot f)(m):=f(r m)
              </me>
            </p>

            <exercise xml:id="exe-36">
              <p>
                Let <m>M</m> and <m>N</m> be <m>R</m>-modules. 
                Then <m>\operatorname{Hom}_{R}(M, N)</m> is an abelian group under the sum defined above.
              </p>
            </exercise>

            <exercise xml:id="exe-37">
              <p>
                Let <m>M</m> and <m>N</m> be <m>R</m>-modules over a commutative <m>\operatorname{ring} R</m>. 
                Then <m>\operatorname{Hom}_{R}(M, N)</m> is an <m>R</m>-module.
              </p>
            </exercise>
            
            <remark xml:id="rem-3.1">
              <p>
                The main reason we need commutativity for <m>\operatorname{Hom}_{R}(M, N)</m> to be a module is that given any <m>r \in R</m> and <m>f \in \operatorname{Hom}_{R}(M, N)</m>, we need <m>r f</m> to be an <m>R</m>-module homomorphism, so in particular for any <m>a \in M</m> and any <m>s \in R</m> we need
                <me>
                  (r f)(s a)=s(r f)(a)
                </me>
                So
                <me>
                  (r s) f(a)=r f(s a)=(r f)(s a)=s(r f)(a)=s(r f(a))=(s r) f(a).
                </me>
                This holds whenever <m>r s=s r</m>, but not in general.
              </p>
            </remark>
      
            <p>
              Some Hom-sets can easily be identified with other well-understood modules.
            </p>

            <exercise xml:id="exe-38">
              <p>
                Let <m>R</m> be a commutative ring. 
                Let <m>M</m> be an <m>R</m>-module, and <m>I</m> an ideal in <m>R</m>. 
                Then we have the following isomorphisms of <m>R</m>-modules:
                <ol>
                  <li>
                    <p>
                      <m>\operatorname{Hom}_{R}(R, M) \cong M</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>\operatorname{Hom}_{R}\left(R^{n}, M\right) \cong M^{n}</m> for any <m>n \geqslant 1</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>\operatorname{Hom}_{R}(R / I, M) \cong\left(0:_{M} I\right):=\{m \in M \mid I m=0\}</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </exercise>

          </subsection>

          <subsection xml:id="subsec-additive-functors"><title>Additive Functors</title>
            
            <p>
              Since <m>R</m>-Mod is a locally small category, we saw in Definition 1.34 that there are two Hom-functors from <m>R</m>-Mod to Set, the covariant functor <m>\operatorname{Hom}_{R}(M,-): R</m>-Mod <m>\longrightarrow</m> Set and the contravariant functor <m>\operatorname{Hom}_{R}(-, N): R</m>-Mod <m>\longrightarrow</m> Set. 
              In light of <xref ref="exe-37"/>, we can upgrade these functors to land in <m>\mathbf{A b}</m>, or in <m>R</m>-Mod when <m>R</m> is commutative, not just in Set. 
              Note that while there are two Hom-functors, we will sometimes refer to the Hom functor when talking about properties that are common to both of them.
            </p>
      
            <p>
              A functor that lands in <m>\mathbb{R}-\bmod</m>, or <m>\mathbf{A b}</m> in particular, can have some additional good properties.
            </p>

            <definition xml:id="def-3.2"><title>Additive Functor</title>
              <statement>
                <p>
                  Let <m>R</m> and <m>S</m> be rings. 
                  A functor <m>T: R</m>-Mod <m>\longrightarrow S</m>-Mod is an <em>additive functor</em> if
                  <me>T(f+g)=T(f)+T(g)</me>
                  for all <m>f, g \in \operatorname{Hom}_{R}(M, N)</m>.
                </p>
              </statement>
            </definition>

            <p>
              Note that to say that <m>T</m> is a covariant additive functor is to say that for all <m>A</m> and <m>B</m>, the map
              <me>
                \begin{gathered}
                \operatorname{Hom}(A, B) \longrightarrow \operatorname{Hom}(T(A), T(B)) \\
                f \longmapsto T(f)
                \end{gathered}
              </me>
              induced by <m>T</m> is a homomorphism of abelian groups. 
              Similarly, a contravariant additive functor <m>T</m> is one such that
              <me>
                \begin{gathered}
                \operatorname{Hom}(A, B) \longrightarrow \operatorname{Hom}(T(B), T(A)) \\
                f \longmapsto T(f)
                \end{gathered}
              </me>
              is a homomorphism of abelian groups.
              Notice moreover that this definition makes sense more generally in any category <m>\mathscr{C}</m> whose objects have an abelian group structure.
            </p>

            <exercise xml:id="exe-39"><title><m>\Hom</m> is Additive</title>
              <p>
                Show that <m>\operatorname{Hom}_{R}(M,-)</m> and <m>\operatorname{Hom}_{R}(-, N)</m> are both additive functors.
              </p>
            </exercise>
      
            <p>
              Note that in <xref ref="exe-39"/> we were purposely vague about where <m>\operatorname{Hom}_{R}(M,-)</m> and <m>\operatorname{Hom}_{R}(-, N)</m> land: 
              these are additive functors whether we consider them as functors with target <m>\mathbf{A b}</m> or target <m>R</m>-Mod, when appropriate.
            </p>
      
            <p>
              Additive functors have many nice properties.
            </p>

            <lemma xml:id="lem-3.3"><title>Properties of Additive Functors</title>
              <statement>
                <p>
                  Let <m>T: R-</m> Mod <m>\longrightarrow S</m>-Mod be an additive functor.
                  <ol>
                    <li>
                      <p>
                        Let 0 denote the 0-map between any two <m>R</m>-modules <m>M</m> and <m>N</m>. Then <m>T(0)=0</m> is the <m>0-\operatorname{map} T(M) \rightarrow T(N)</m>.
                      </p>
                    </li>

                    <li>
                      <p>
                        Let 0 denote the zero <m>R</m>-module. Then <m>T(0)=0</m> is the zero <m>S</m>-module.
                      </p>
                    </li>
                  </ol>
                </p>
              </statement>

              <proof>
                <p>
                  <ol>
                    <li>
                      <p>
                        As a function defined on each fixed <m>\operatorname{Hom}_{R}(M, N), T</m> is a group homomorphism, so it must send <m>0</m> to <m>0</m>.
                      </p>
                    </li>

                    <li>
                      <p>
                        An <m>R</m>-module <m>M</m> is the zero module if and only if the zero and identity maps on <m>M</m> coincide. 
                        Let <m>N</m> be the image of the zero <m>R</m>-module via <m>T</m>. 
                        On the one hand, any functor must send identity maps to identity maps, so the identity map on the zero module must be sent to the identity on <m>N</m>. 
                        On the other hand, we have shown that the zero map must be sent to the zero map on <m>N</m>, so the zero and identity maps on <m>N</m> must coincide, so <m>N=0</m>.
                      </p>
                    </li>
                  </ol>
                </p>
              </proof>
            </lemma>

            <remark xml:id="rem-3.4">
              <p>
                Note that the category of chain complexes also has a similar structure to <m>R</m>-Mod: 
                given two maps of complexes <m>f, g: C \rightarrow D</m>, we define a map of complexes <m>f+g</m> : <m>C \rightarrow D</m> given by
                <me>(f+g)_{n}:=f_{n}+g_{n}</me>
                It is routine to check that this again gives a map of complexes, and that this operation gives the <m>\Hom</m>-sets in <m>\operatorname{Ch}(R)</m> the structure of an abelian group. 
                In fact, this abelian group structure can be upgraded to an <m>R</m>-module structure when <m>R</m> is commutative, by setting
                <me>(r f)_{n}:=r f_{n}</me>
                for all <m>r \in R</m>. 
                This allows us to talk about additive functors to and from the category <m>\operatorname{Ch}(R)</m>, and there is a version of <xref ref="lem-3.3"/> in <m>\mathrm{Ch}(R)</m>.
              </p>
            </remark>

            <exercise xml:id="exe-40"><title>Homology is Additive</title>
              <p>
                Show that homology is an additive functor.
              </p>
            </exercise>
      
            <p>
              Most functors between categories or modules or chain complexes are additive. 
              In fact, we will spend the rest of this chapter studying three very important additive functors: the two <m>\Hom</m> functors, and a third functor we have yet to define.
            </p>

            <exercise xml:id="exe-41"><title>Additive Functors Preserve Direct Sums</title>
              <p>
                Let <m>R</m> and <m>S</m> be rings and let <m>T: R</m>-Mod <m>\longrightarrow S</m>-Mod be an additive functor. 
                Show that for all <m>R</m>-modules <m>A</m> and <m>B</m>,
                <me>T(A \oplus B) \cong T(A) \oplus T(B)</me>
              </p>
            </exercise>
      
            <p>
              <m>\Hom</m> satisfies a stronger version of this property.
            </p>

            <theorem xml:id="thm-3.5">
              <statement>
                <p>
                  For all <m>R</m>-modules <m>M, N, M_{i}, N_{i}</m>, there are isomorphisms of abelian groups
                  <me>\operatorname{Hom}_{R}\left(M, \prod_{i} N_{i}\right) \cong \prod_{i} \operatorname{Hom}_{R}\left(M, N_{i}\right) \text { and } \operatorname{Hom}_{R}\left(\bigoplus_{i} M_{i}, N\right) \cong \prod_{i} \operatorname{Hom}_{R}\left(M_{i}, N\right)</me>
                  Moreover, when <m>R</m> is commutative, these are in fact isomorphisms of <m>R</m>-modules.
                </p>
          
                <p>
                  In particular,
                  <me>\operatorname{Hom}_{R}(A \oplus B, C) \cong \operatorname{Hom}_{R}(A, C) \oplus \operatorname{Hom}_{R}(B, C)</me>
                  and
                  <me>\operatorname{Hom}_{R}(A, B \oplus C) \cong \operatorname{Hom}_{R}(A, B) \oplus \operatorname{Hom}_{R}(A, C) .</me>
                </p>
              </statement>

              <proof>
                <p>
                  For each <m>i</m>, let <m>\pi_{i}: \prod_{j} N_{j} \longrightarrow N_{i}</m> be the canonical projection map. 
                  Consider the map
                  <me>
                    \begin{gathered}
                    \operatorname{Hom}_{R}\left(M, \prod_{i} N_{i}\right) \stackrel{\alpha}{\longrightarrow} \prod_{i} \operatorname{Hom}_{R}\left(M, N_{i}\right) \\
                    f \longmapsto\left(\pi_{i} f\right)
                    \end{gathered}
                  </me>
                  We claim this map is the desired isomorphism. 
                  We leave it as an exercise to show that <m>\alpha</m> is a homomorphism of abelian groups, and a homomorphism of <m>R</m>-modules when <m>R</m> is commutative; 
                  we focus on proving that <m>\alpha</m> is a bijection. 
                  First, take <m>\left(f_{i}\right)_{i} \in \prod_{i} \operatorname{Hom}_{R}\left(M, N_{i}\right)</m>. 
                  Define a map
                  <me>
                    \begin{aligned}
                    &amp; M \stackrel{\psi}{\longrightarrow} \prod_{i} N_{i} \\
                    &amp; m \longmapsto\left(f_{i}(m)\right)
                    \end{aligned}
                  </me>
                  This makes the diagram
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-073.jpg"/>
                <p>
                  commute, so that <m>\alpha(\psi)=\left(\pi_{i} \psi\right)_{i}=\left(f_{i}\right)</m>. 
                  This shows that <m>\alpha</m> us surjective.
                  Now let us show that <m>\alpha</m> is injective. 
                  Suppose <m>f \in \operatorname{Hom}_{R}\left(M, \prod_{i} N_{i}\right)</m> is such that <m>\alpha(f)=0</m>. 
                  For each <m>m \in M</m>, let <m>f(m)=\left(n_{i}\right)_{i}</m>, so <m>\pi_{i} f(m)=n_{i}</m>. 
                  By assumption, <m>\left(\pi_{i} f(m)\right)=0</m>, which means that <m>\pi_{i} \alpha=0</m> for all <m>i</m>, and thus <m>n_{i}=0</m> for all <m>i</m>. 
                  So <m>f=0</m>. 
                  We conclude that <m>\alpha</m> is an isomorphism.
                </p>
          
                <p>
                  Now consider the map
                  <me>
                    \begin{gathered}
                    \operatorname{Hom}_{R}\left(\bigoplus_{i} M_{i}, N\right) \stackrel{\beta}{\longrightarrow} \prod_{i} \operatorname{Hom}_{R}\left(M_{i}, N\right) \\
                    f \longmapsto\left(f \iota_{i}\right)
                    \end{gathered}
                  </me>
                  where <m>\iota_{j}: M_{j} \longrightarrow \bigoplus_{i} M_{i}</m> is the inclusion of the <m>j</m> th factor. 
                  We leave it as an exercise to prove that <m>\beta</m> is a homomorphism of abelian groups, and that whenever <m>R</m> is commutative, <m>\beta</m> is in fact a homomorphism of <m>R</m>-modules.
                </p>
          
                <p>
                  Given <m>\left(f_{i}\right)_{i} \in \prod_{i} \operatorname{Hom}_{R}\left(M_{i}, N\right)</m>, let
                </p>
        
                <image source="2023_10_23_e2d6a27704be928b3deeg-074.jpg"/>
                  
                <p>
                  Then <m>\beta(\psi)=\left(\psi \iota_{i}\right)_{i}</m>, so for each <m>i</m> and each <m>m_{i} \in M_{i}, \psi \iota_{i}\left(m_{i}\right)=f_{i}\left(m_{i}\right)</m>, and <m>\beta(\psi)=\left(f_{i}\right)_{i}</m>. 
                  This shows that <m>\beta</m> is surjective.
                </p>
          
                <p>
                  Now assume <m>\beta(f)=0</m>, which implies that <m>f \iota_{i}</m> is the zero map for each <m>i</m>. 
                  Consider any <m>\left(m_{i}\right)_{i} \in \bigoplus_{i} M_{i}</m>. 
                  For each <m>i, f \iota_{i}\left(m_{i}\right)=0</m>. 
                  On the other hand, <m>\left(m_{i}\right)_{i}=\sum_{i} \iota_{i}\left(m_{i}\right)</m>, so <m>f\left(\left(m_{i}\right)_{i}\right)=\sum_{i} \iota_{i}\left(m_{i}\right)=0</m>. 
                  We conclude that <m>f=0</m>, and <m>\beta</m> is injective.
                </p>
              </proof>
            </theorem>
          
            <p>
              These two properties, however, are consequences of <xref ref="exe-39"/> and <xref ref="exe-41"/>: 
              <m>\Hom</m> is additive, and additive functors preserve finite direct sums.
            </p>

            <exercise xml:id="exe-42">
              <p>
                Show that the isomorphisms in <xref ref="thm-3.5"/> are natural on both components. 
                More precisely, given any other family of <m>R</m>-modules <m>L_{i}</m> such that for each <m>i</m> there exists <m>j</m>, a map <m>\sigma_{i j}</m> there exist <m>R</m>-module maps making the following diagrams commute: 
              </p>
              <image source='2023_10_23_e2d6a27704be928b3deeg-074(1).jpg'/>
              <p>
                In fact, one can show that more generally, <m>\Hom</m> behaves well with limits and colimits.
              </p>
            </exercise>

            <exercise xml:id="exe-43">
              <p>
                Let <m>R</m> be any ring and consider <m>R</m>-modules <m>A</m> and <m>\left\{M_{i}\right\}</m>.
                <ol>
                  <li>
                    <p>
                      For any inverse system <m>\left\{M_{i}\right\}</m>, there is a natural isomorphism
                      <me>\operatorname{Hom}_{R}\left(A, \lim _{i} M_{i}\right) \cong \lim _{i} \operatorname{Hom}_{R}\left(A, M_{i}\right)</me>
                    </p>
                  </li>

                  <li>
                    <p>
                      For any direct system <m>\left\{M_{i}\right\}</m> or <m>R</m>-modules, there is a natural isomorphism
                      <me>\operatorname{Hom}_{R}\left(\operatorname{colim}_{i} M_{i}, A\right) \cong \lim _{i} \operatorname{Hom}_{R}\left(M_{i}, B\right)</me>
                    </p>
                  </li>
                </ol>
                Moreover, when <m>R</m> is commutative, these are isomorphisms of modules.
              </p>
            </exercise>

          </subsection>

          <subsection xml:id="subsec-exact-functors"><title>Exact Functors</title>

            <p>
              Another important property of <m>\Hom</m> is how it interacts with exact sequences. 
              First, an important note about general additive functors:
            </p>

            <remark xml:id="rem-3.6">
              <p>
                Let <m>F: R</m>-Mod <m>\rightarrow S</m>-Mod be an additive functor. 
                Thanks to <xref ref="lem-3.3"/>, if <m>g f=0</m>, then
                <me>F(g f)=F(g) F(f)=F(0)=0.</me>
                Thus <m>F</m> must send complexes to complexes, and in fact, <m>F</m> induces a functor <m>\operatorname{Ch}(R) \rightarrow \operatorname{Ch}(S)</m>, which we also call <m>F</m>. 
                Now if <m>h</m> is a homotopy between two maps of complexes, <m>F</m> must preserve the identities
                <me>\delta_{n+1} h_{n}+h_{n-1} \delta_{n}=f_{n}-g_{n}</me>
                for all <m>n</m>, so <m>F(h)</m> is a homotopy between <m>F(f)</m> and <m>F(g)</m>.
              </p>
            </remark>
    
            <p>
              While additive functors send complexes to complexes, they don't have to preserve exactness. 
              Functors that do preserve exactness are very special.
            </p>

            <definition xml:id="def-3.7"><title>Exact Functors</title>
              <statement>
                <p>
                  An additive functor <m>T: R</m>-Mod <m>\longrightarrow S</m>-Mod is an <em>exact functor</em> if it preserves short exact sequences. 
                  When <m>T</m> is covariant, this means that every short exact sequence
                  <me>0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0</me>
                  is taken to the short exact sequence
                  <me>0 \longrightarrow T(A) \stackrel{T(f)}{\longrightarrow} T(B) \stackrel{T(g)}{\longrightarrow} T(C) \longrightarrow 0</me>
                </p>
          
                <p>
                  When <m>T</m> is contravariant, this means that any short exact sequence
                  <me>0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0</me>
                  is taken to the short exact sequence
                  <me>0 \longrightarrow T(C) \stackrel{T(g)}{\longrightarrow} T(B) \stackrel{T(f)}{\longrightarrow} T(A) \longrightarrow 0</me>
                </p>
              </statement>
            </definition>

            <exercise xml:id="exe-44"><title>Functors are Exact iff They Commute with Homology</title>
              <p>
                Show that an additive functor <m>T</m> is exact if it commutes with homology, that is, for all complexes <m>C</m> and all <m>n</m>,
                <me>\mathrm{H}_{n}(T(C))=T\left(\mathrm{H}_{n}(C)\right)</me>
              </p>
            </exercise>
      
            <p>
              As we will soon see, most functors are not exact. 
              However, many functors of interest preserve some exactness.
            </p>

            <definition xml:id="def-3.8"><title>Left and Right Exact Functors</title>
              <statement>
                <p>
                  A covariant additive functor <m>T: R</m>-Mod <m>\longrightarrow S</m>-Mod is left exact if it takes every exact sequence
                  <me>0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C</me>
                  of <m>R</m>-modules to the exact sequence
                  <me>0 \longrightarrow T(A) \stackrel{T(f)}{\longrightarrow} T(B) \stackrel{T(g)}{\longrightarrow} T(C)</me>
                  of <m>S</m>-modules, and right exact if it takes every exact sequence of <m>R</m>-modules
                  <me>A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0</me>
                  to the exact sequence of <m>S</m>-modules
                  <me>T(A) \stackrel{T(f)}{\longrightarrow} T(B) \stackrel{T(g)}{\longrightarrow} T(C) \longrightarrow 0 .</me>
                </p>
              </statement>
            </definition>

            <definition xml:id="def-3.9"><title>Left and Right Exact Functors</title>
              <statement>
                <p>
                  A contravariant additive functor <m>T: R</m>-Mod <m>\longrightarrow S</m>-Mod is left exact if it takes every exact sequence
                  <me>A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0</me>
                  of <m>R</m>-modules to the exact sequence
                  <me>0 \longrightarrow T(C) \stackrel{T(g)}{\longrightarrow} T(B) \stackrel{T(f)}{\longrightarrow} T(A)</me>
                  of <m>S</m>-modules, and right exact if it takes every exact sequence of <m>R</m>-modules
                  <me>0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C</me>
                  to the exact sequence of <m>S</m>-modules
                  <me>T(C) \stackrel{T(g)}{\longrightarrow} T(B) \stackrel{T(f)}{\longrightarrow} T(A) \longrightarrow 0 .</me>
                </p>
              </statement>
            </definition>

            <exercise xml:id="exe-45"><title>Exactness and SESs</title>
              <p>
                The definitions above all stay unchanged if for each condition we start with a short exact sequence. 
                For example, a covariant additive functor <m>T</m> is left exact if and only if for every short exact sequence
                <me>0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0</me>
                of <m>R</m>-modules,
                <me>0 \longrightarrow T(A) \stackrel{T(f)}{\longrightarrow} T(B) \stackrel{T(g)}{\longrightarrow} T(C)</me>
                is exact.
              </p>
            </exercise>

            <remark xml:id="rem-3.10">
              <p>
                Left exact covariant functors take kernels to kernels, while right exact covariant functors take cokernels to cokernels: 
                the kernel of <m>f</m> fits in an exact sequence
                <me>0 \longrightarrow \operatorname{ker} f \longrightarrow A \stackrel{f}{\longrightarrow} B</me>
                and applying a left exact functor <m>F</m> gives us an exact sequence
                <me>0 \longrightarrow F(\operatorname{ker} f) \longrightarrow F(A) \stackrel{F(f)}{\longrightarrow} F(B)</me>
                Exactness tells us that <m>F(\operatorname{ker} f)</m> is the kernel of <m>F(f)</m>. 
              </p>
                
              <p>
                Similarly, the cokernel of <m>f</m> fits into an exact sequence
                <me>A \stackrel{f}{\longrightarrow} B \longrightarrow \operatorname{coker} f \longrightarrow 0</me>
                which any right exact functor <m>G</m> will take to an exact sequence
                <me>G(A) \stackrel{G(f)}{\longrightarrow} G(B) \longrightarrow G(\operatorname{coker} f) \longrightarrow 0</me>
                Exactness says that <m>G(\operatorname{coker} f)</m> is the cokernel of <m>G(f)</m>.
              </p>
        
              <p>
                Similarly, left exact contravariant functors take cokernels to kernels, and right exact contravariant functors take kernels to cokernels. 
                A left exact contravariant functor <m>F</m> will take the exact sequence
                <me>A \stackrel{f}{\longrightarrow} B \longrightarrow \operatorname{coker} f \longrightarrow 0</me>
                to an exact sequence
                <me>0 \longrightarrow F(\operatorname{coker} f) \longrightarrow F(B) \stackrel{F(f)}{\longrightarrow} F(A)</me>
                and exactness tells us that <m>F(\operatorname{coker} f)</m> is the kernel of <m>F(f)</m>.
              </p>
        
              <p>
                A right exact contravariant functor <m>G</m> will take the exact sequence
                <me>0 \longrightarrow \operatorname{ker} f \longrightarrow A \stackrel{f}{\longrightarrow} B</me>
                to the exact sequence
                <me>G(B) \stackrel{G(f)}{\longrightarrow} G(A) \longrightarrow G(\operatorname{ker} f) \longrightarrow 0</me>
                and exactness says that <m>G(\operatorname{ker} f)</m> is the cokernel of <m>G(f)</m>.
              </p>
            </remark>
      
            <p>
              Exactness is preserved by natural isomorphisms.
            </p>

            <remark xml:id="rem-3.11">
              <p>
                Suppose that <m>F, G: R</m>-Mod <m>\longrightarrow S</m>-Mod are naturally isomorphic additive functors. 
                We claim that <m>F</m> is exact if and only if <m>G</m> is exact. 
                Let's prove it in the case when <m>F</m> and <m>G</m> are covariant. 
                Given any short exact sequence
                <me>0 \longrightarrow A \longrightarrow B \longrightarrow C \longrightarrow 0</me>
                applying each of our functors yields complexes of <m>R</m>-modules which may or may not be exact. 
                Our natural isomorphism gives us an isomorphism of complexes
              </p>

              <image source="2023_10_23_e2d6a27704be928b3deeg-077.jpg"/>

              <p>
                Isomorphisms of complexes induce isomorphisms in homology, so the top sequence is exact if and only if the bottom sequence is exact. 
                Thus <m>F</m> preserves the short exact sequence if and only if <m>G</m> does.
              </p>
        
              <p>
                A similar argument shows that <m>F</m> is left (respectively, right) exact if and only if <m>G</m> is left (respectively, right) exact; we leave the details as an exercise.
              </p>
            </remark>
      
            <p>
              However, an additive functor does not have to be left exact nor right exact. 
              There are even some functors that preserve exactness in the middle.
            </p>

            <example xml:id="ex-3.12"><title>Homology is Exact in the Middle</title>
              <p>
                The homology functor is exact in the middle: given a short exact sequence
                <me>0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0</me>
                the exactness of the long exact sequence in homology says in particular that
                <me>\mathrm{H}_{n}(A) \stackrel{\mathrm{H}_{n}(f)}{\longrightarrow} \mathrm{H}_{n}(B) \stackrel{\mathrm{H}_{n}(g)}{\longrightarrow} \mathrm{H}_{n}(C)</me>
                is exact for all <m>n</m>. On the other hand, we claim that the homology functor is neither left exact nor right exact. More precisely, <m>\mathrm{H}_{n}(f)</m> might fail to be injective and <m>\mathrm{H}_{n}(g)</m> might fail to be surjective. Finding a counterexample amounts to finding a short exact sequence of complexes such that the connecting homomorphism in the long exact sequence in homology is not the zero map.
              </p>
        
              <p>
                For example, consider the following complexes and maps of complexes:
              </p>
        
              <image source="2023_10_23_e2d6a27704be928b3deeg-078.jpg"/>
                
              <p>
                Applying <m>\mathrm{H}_{0}</m> gives us
                <me>
                  \begin{gathered}
                  \mathrm{H}_{0}(A) \stackrel{\mathrm{H}_{0}(f)}{\longrightarrow} \mathrm{H}_{0}(B) \\
                  \mathbb{Z} \stackrel{0}{\longrightarrow} 0
                  \end{gathered}
                </me>
                which is not injective, so
                <me>0 \longrightarrow \mathrm{H}_{0}(A) \stackrel{\mathrm{H}_{0}(f)}{\longrightarrow} \mathrm{H}_{0}(B) \stackrel{\mathrm{H}_{0}(g)}{\longrightarrow} \mathrm{H}_{0}(C)</me>
                is not exact. 
                Similarly, applying <m>\mathrm{H}_{1}</m> gives
                <me>
                  \begin{gathered}
                  \mathrm{H}_{1}(B) \stackrel{\mathrm{H}_{1}(g)}{\longrightarrow} \mathrm{H}_{1}(C) \\
                  0 \stackrel{0}{\longrightarrow} \mathbb{Z}
                  \end{gathered}
                </me>
                which is not surjective, so
                <me>\mathrm{H}_{1}(A) \stackrel{\mathrm{H}_{1}(f)}{\longrightarrow} \mathrm{H}_{1}(B) \stackrel{\mathrm{H}_{1}(g)}{\longrightarrow} \mathrm{H}_{1}(C) \longrightarrow 0</me>
                is not exact. 
                Thus homology is neither left exact nor right exact, though it is exact in the middle.
              </p>
            </example>
      
            <p>
              But in general, an additive functor might fail to preserve exactness even in the middle.
            </p>

            <example xml:id="ex-3.13">
              <p>
                Fix a prime <m>p</m> and consider the functor <m>F: \mathbf{A b} \rightarrow \mathbf{A b}</m> which on objects is defined by
                <me>F(M)=\operatorname{Hom}_{\mathbb{Z}}\left(\mathbb{Z} / p, M / p^{2} M\right)</me>
                given a homomorphism of abelian groups <m>f: M \rightarrow N</m>, we get an induced homomorphism of abelian groups
                <me>
                  \begin{gathered}
                  M / p^{2} M \stackrel{\bar{f}}{\longrightarrow} N / p^{2} N \\
                  m+p^{2} M \longmapsto f(m)+p^{2} N
                  \end{gathered}
                </me>
                and <m>F(f)=\bar{f} \circ-</m> is postcomposition with <m>\bar{f}</m>. 
                Consider the short exact sequence
                <me>0 \longrightarrow \mathbb{Z} / p^{2} \stackrel{f}{\longrightarrow} \mathbb{Z} / p^{3} \stackrel{g}{\longrightarrow} \mathbb{Z} / p \longrightarrow 0</me>
                where <m>f</m> is the multiplication by <m>p</m> map, which sends <m>1 \mapsto p</m>, and <m>g</m> is the canonical quotient map by the subgroup generated by <m>p</m>.
              </p>
        
              <p>
                Note that
                <me>F\left(\mathbb{Z} / p^{2}\right)=\operatorname{Hom}_{\mathbb{Z}}\left(\mathbb{Z} / p, \mathbb{Z} / p^{2}\right)</me>
                is the submodule of <m>\mathbb{Z} / p^{2}</m> of elements killed by <m>p</m>, which is generated by the class of <m>p</m>, so <m>F\left(\mathbb{Z} / p^{2}\right)=\mathbb{Z} / p</m>. 
                Moreover,
                <me>\frac{\mathbb{Z} / p^{3}}{p^{2} \mathbb{Z} / p^{3}} \cong \mathbb{Z} / p^{2}</me>
                so <m>F\left(\mathbb{Z} / p^{3}\right)</m> is the the submodule of <m>\mathbb{Z} / p^{2}</m> of elements killed by <m>p</m>, which is generated by <m>p</m> and isomorphic to <m>\mathbb{Z} / p</m>, so <m>F\left(\mathbb{Z} / p^{3}\right)=\mathbb{Z} / p</m>.
                Now
                <me>F(f): \mathbb{Z} / p \rightarrow \mathbb{Z} / p</me>
                is the map induced by multiplication by <m>p</m>, so it is the zero map. 
                The map
                <me>\bar{g}: \mathbb{Z} / p^{2} \rightarrow \mathbb{Z} / p</me>
                is the canonical quotient by the subgroup generated by <m>p</m>; 
                any element in
                <me>F\left(Z / p^{3}\right)=\operatorname{Hom}_{\mathbb{Z}}\left(\mathbb{Z} / p, \mathbb{Z} / p^{2}\right)</me>
                corresponds to choosing an element of order <m>p</m>, and thus in the subgroup generated by <m>p</m>, so applying <m>\bar{g}</m> always results in <m>0</m>. 
                We conclude that <m>F(g)=0</m>. 
                Finally, this shows that applying <m>F</m> to the original short exact sequence gives us the complex
                <me>0 \longrightarrow \mathbb{Z} / p \stackrel{0}{\longrightarrow} \mathbb{Z} / p \stackrel{0}{\longrightarrow} \mathbb{Z} / p \longrightarrow 0</me>
                which is not exact anywhere.
              </p>
            </example>
      
            <p>
              One amazing fact, however, is that even if a functor is not exact, it must always preserve split short exact sequences.
            </p>

            <exercise xml:id="exe-46"><title>Additive Functors Preserve Split Exact Sequences</title>
              <p>
                Show that additive functors preserve split short exact sequences.
              </p>
            </exercise>

          </subsection>

          <subsection xml:id="subsec-hom-left"><title><m>\Hom</m> is Left Exact</title>
            
            <p>
              We are now ready for our first important example of a left exact functor: 
              <m>\Hom</m> is left exact.
            </p>

            <theorem xml:id="thm-3.14"><title><m>\Hom</m> is Left Exact</title>
              <statement>
                <p>
                  Let <m>M</m> be an R-module.
                  <ol>
                    <li>
                      <p>
                        The covariant functor <m>\operatorname{Hom}_{R}(M,-)</m> is left exact: 
                        for every exact sequence
                        <me>0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C</me>
                        of <m>R</m>-modules, the sequence
                        <me>0 \longrightarrow \operatorname{Hom}_{R}(M, A) \stackrel{\operatorname{Hom}_{R}(M, f)}{\longrightarrow} \operatorname{Hom}_{R}(M, B) \stackrel{\operatorname{Hom}_{R}(M, g)}{\longrightarrow} \operatorname{Hom}_{R}(M, C)</me>
                        is exact.
                      </p>
                    </li>

                    <li>
                      <p>
                        The contravariant functor <m>\operatorname{Hom}_{R}(-, M)</m> is left exact: for every exact sequence
                        <me>A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0</me>
                        of <m>R</m>-modules, the sequence
                        <me>0 \longrightarrow \operatorname{Hom}_{R}(C, M) \stackrel{\operatorname{Hom}_{R}(g, M)}{\longrightarrow} \operatorname{Hom}_{R}(B, M) \stackrel{\operatorname{Hom}_{R}(f, M)}{\longrightarrow} \operatorname{Hom}_{R}(A, M)</me>
                        is exact.
                      </p>
                    </li>
                  </ol>
                </p>
              </statement>

              <proof>
                <p>
                  To make the notation less heavy, we will write
                  <me>f_{*}:=\operatorname{Hom}_{R}(M, f) \quad \text { and } \quad g_{*}:=\operatorname{Hom}_{R}(M, g)</me>
                  and similarly
                  <me>f^{*}:=\operatorname{Hom}_{R}(f, M) \quad \text { and } \quad g^{*}:=\operatorname{Hom}_{R}(g, M) \text {. }</me>
                </p>
          
                <p>
                  Since additive functors send complexes to complexes, as outlined in <xref ref="rem-3.6"/>, we at least know that
                  <me>0 \longrightarrow \operatorname{Hom}_{R}(M, A) \stackrel{\operatorname{Hom}_{R}(M, f)}{\longrightarrow} \operatorname{Hom}_{R}(M, B) \stackrel{\operatorname{Hom}_{R}(M, g)}{\longrightarrow} \operatorname{Hom}_{R}(M, C)</me>
                  and
                  <me>0 \longrightarrow \operatorname{Hom}_{R}(C, M) \stackrel{\operatorname{Hom}_{R}(g, M)}{\longrightarrow} \operatorname{Hom}_{R}(B, M) \stackrel{\operatorname{Hom}_{R}(f, M)}{\longrightarrow} \operatorname{Hom}_{R}(A, M)</me>
                  are functors, so in particular
                  <me>g_{*} f_{*}=0 \Longrightarrow \operatorname{im} f_{*} \subseteq \operatorname{ker} g_{*}</me>
                  and
                  <me>f^{*} g^{*}=0 \Longrightarrow \operatorname{im} g^{*} \subseteq \operatorname{ker} f^{*}</me>
                </p>
          
                <p>
                  <ol>
                    <li>
                      <p>
                        We have two things to show:
                        <ol>
                          <li><title><m>\underline{f_{*} \text { is injective: }}</m></title>
                            <p>
                              Suppose that <m>h \in \operatorname{Hom}_{R}(M, A)</m> is such that <m>f_{*}(h)=0</m>. 
                              By definition, this means that <m>f h=0</m>. 
                              But <m>f</m> is injective, so for any <m>m \in M</m>
                              <me>f h(m)=0 \Longrightarrow h(m)=0 \text {. }</me>
                              We conclude that <m>h=0</m>, and <m>f_{*}</m> is injective.
                            </p>
                          </li>

                          <li><title><m>\underline{\operatorname{ker} g_{*} \subseteq \operatorname{im} f_{*}:}</m></title>
                            <p>
                              Let <m>h \in \operatorname{Hom}_{R}(M, B)</m> be in the kernel of <m>g_{*}</m>. 
                              Then <m>g h=g_{*}(h)=0</m>, so for each <m>m \in M</m>, <m>g h(m)=0</m>. 
                              Then <m>h(m) \in \operatorname{ker} g=\operatorname{im} f</m>, so there exists <m>a \in A</m> such that <m>f(a)=h(m)</m>. 
                              Since <m>f</m> is injective, this element <m>a</m> is unique for each <m>m \in M</m>. So setting <m>k(m):=a</m> gives us a well-defined function <m>k: M \longrightarrow A</m>. 
                            </p>

                            <p>
                              We claim that <m>k</m> is in fact an <m>R</m>-module homomorphism. 
                              To see that, notice that if <m>k\left(m_{1}\right)=a_{1}</m> and <m>k\left(m_{2}\right)=a_{2}</m>, then
                              <me>f\left(a_{1}+a_{2}\right)=f\left(a_{1}\right)+f\left(a_{2}\right)=h\left(m_{1}\right)+h\left(m_{2}\right)=h\left(m_{1}+m_{2}\right)</me>
                              so that <m>k\left(m_{1}+m_{2}\right)=a_{1}+a_{2}=k\left(m_{1}\right)+k\left(m_{2}\right)</m>. 
                            </p>
                            
                            <p>
                              Similarly, given any <m>r \in R</m>,
                              <me>f\left(r a_{1}\right)=r f\left(a_{1}\right)=r h\left(m_{1}\right)=h\left(r m_{1}\right)</me>
                              so <m>k\left(r m_{1}\right)=r a_{1}=r k\left(m_{1}\right)</m>. 
                              Finally, this element <m>k \in \operatorname{Hom}_{R}(M, A)</m> satisfies
                              <me>f_{*}(k)(m)=f(k(m))=h(m)</me>
                              for all <m>m \in M</m>, so <m>f_{*}(k)=h</m> and <m>h \in \operatorname{im} f_{*}</m>.
                            </p>
                          </li>
                        </ol>
                      </p>
                    </li>

                    <li>
                      <p>
                        Again, we have two things to show:
                        <ol>
                          <li><title><m>g^{*}</m> is injective:</title>
                            <p>
                              If <m>g^{*}(h)=0</m> for some <m>h \in \operatorname{Hom}_{R}(C, M)</m>, then <m>h g=g^{*}(h)=0</m>. 
                              Consider any <m>c \in C</m>. 
                              Since <m>g</m> is surjective, there exists <m>b \in B</m> such that <m>g(b)=c</m>. 
                              Then <m>h(c)=h g(b)=0</m>, so <m>h=0</m>.
                            </p>
                          </li>

                          <li><title><m>\underline{\operatorname{ker} f^{*} \subseteq \operatorname{im} g^{*}:}</m></title>
                            <p>
                              Let <m>h \in \operatorname{Hom}_{R}(B, M)</m> be in <m>\ker f^{*}</m>, so that <m>h f=0</m>. 
                              Given any <m>c \in C</m>, there exists <m>b \in B</m> such that <m>g(b)=c</m>, since <m>g</m> is surjective. 
                              Let <m>k: C \longrightarrow M</m> be the function defined by <m>k(c):=h(b)</m> for some <m>b</m> with <m>g(b)=c</m>. 
                              This function is well-defined, since whenever <m>g\left(b^{\prime}\right)=g(b)=c, b-b^{\prime} \in \operatorname{ker} g=\operatorname{im} f</m>, say <m>b-b^{\prime}=f(a)</m>, and thus <m>h\left(b-b^{\prime}\right)=h(f(a))=0</m>. 
                              Moreover, we claim that <m>k</m> is indeed a homomorphism of <m>R</m>-modules. 
                              If <m>c_{1}, c_{2} \in C</m>, and <m>g\left(b_{1}\right)=c_{1}, g\left(b_{2}\right)=c_{2}</m>, then <m>g\left(b_{1}+b_{2}\right)=c_{1}+c_{2}</m>, so
                              <me>k\left(c_{1}+c_{2}\right)=h\left(b_{1}+b_{2}\right)=h\left(b_{1}\right)+h\left(b_{2}\right)=k\left(b_{1}\right)+k\left(b_{2}\right)</me>
                            </p>
                      
                            <p>
                              Finally, this element <m>k \in \operatorname{Hom}_{R}(C, M)</m> is such that <m>g^{*}(k)</m> satisfies
                              <me>\left(g_{*}(k)\right)(b)=k(g(b))=h(b)</me>
                              for all <m>b \in B</m>, so <m>g^{*}(k)=h</m>, and <m>h \in \operatorname{im} g^{*}</m>.
                            </p>
                          </li>
                        </ol>
                      </p>
                    </li>
                  </ol>
                </p>
                <p>
                  So <m>\operatorname{Hom}_{R}(M,-)</m> preserves kernels, and <m>\operatorname{Hom}_{R}(-, N)</m> sends cokernels to kernels.
                </p>
              </proof>
            </theorem>

            <p>
              However, <m>\Hom</m> is not right exact in general.
            </p>

            <example xml:id="ex-3.15">
              <p>
                Consider the short exact sequence of abelian groups
                <me>0 \longrightarrow \mathbb{Z} \longrightarrow \mathbb{Q} \longrightarrow \mathbb{Q} / \mathbb{Z} \longrightarrow 0</me>
                where the first map is the inclusion of <m>\mathbb{Z}</m> into <m>\mathbb{Q}</m>, and the second map is the canonical projection. 
                The elements in the abelian group <m>\mathbb{Q} / \mathbb{Z}</m> are cosets of the form <m>\frac{p}{q}+\mathbb{Z}</m>, where <m>\frac{p}{q} \in \mathbb{Q}</m>, and whenever <m>\frac{p}{q} \in \mathbb{Z}, \frac{p}{q}+\mathbb{Z}=0</m>. 
                While <xref ref="thm-3.14"/> says that
                <me>0 \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} / 2, \mathbb{Z}) \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} / 2, \mathbb{Q}) \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} / 2, \mathbb{Q} / \mathbb{Z})</me>
                is exact, we claim that this cannot be extended to a short exact sequence, since the map <m>\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} / 2, \mathbb{Q}) \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} / 2, \mathbb{Q} / \mathbb{Z})</m> is not surjective.
                On the one hand, there are no nontrivial homomorphisms from <m>\mathbb{Z} / 2</m> to either <m>\mathbb{Z}</m> nor <m>\mathbb{Q}</m>, since there are no elements in <m>\mathbb{Z}</m> nor <m>\mathbb{Q}</m> of order <m>2</m>. 
                This shows that
                <me>\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} / 2, \mathbb{Q}) \cong 0.</me>
              </p>
        
              <p>
                On the other hand, <m>\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} / 2, \mathbb{Q} / \mathbb{Z})</m> is nonzero: 
                to give a homomorphism of abelian groups <m>\mathbb{Z} / 2 \rightarrow \mathbb{Q} / Z Z</m> is to choose an element in <m>\mathbb{Q} / \mathbb{Z}</m> of order <m>2</m>. 
                Since <m>\frac{1}{2}+\mathbb{Z}</m> is an element of order 2 in <m>\mathbb{Q} / \mathbb{Z}</m>, the map sending <m>1</m> in <m>\mathbb{Z} / 2</m> to <m>\frac{1}{2}+\mathbb{Z}</m> in <m>\mathbb{Z} / \mathbb{Q}</m> is nonzero. 
                So after applying <m>\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} / 2,-)</m>, we get the exact sequence
                <me>0 \longrightarrow 0 \longrightarrow 0 \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} / 2, \mathbb{Q} / \mathbb{Z})</me>
                So this shows that <m>\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} / 2,-)</m> is not an exact functor, only left exact.
              </p>
            </example>

            <p>
              Similarly, we can show that <m>\operatorname{Hom}_{\mathbb{Z}}(-, \mathbb{Z})</m> is not exact:
            </p>

            <example xml:id="ex-3.16">
              <p>
                Let's apply <m>\operatorname{Hom}_{\mathbb{Z}}(-, \mathbb{Z})</m> to the short exact sequence
                <me>0 \longrightarrow \mathbb{Z} \longrightarrow \mathbb{Q} \longrightarrow \mathbb{Q} / \mathbb{Z} \longrightarrow 0</me>
                This time, <xref ref="thm-3.14"/> says that
                <me>0 \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Q} / \mathbb{Z}, \mathbb{Z}) \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Q}, \mathbb{Z}) \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}, \mathbb{Z})</me>
                is exact. 
                We claim that the last map is not surjective.
                First, we claim that <m>\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Q}, \mathbb{Z})=0</m>. 
                Indeed, if <m>f: \mathbb{Q} \longrightarrow \mathbb{Z}</m> is a homomorphism of abelian groups, then for all <m>n \geqslant 1</m> we have
                <me>f(1)=n f\left(\frac{1}{n}\right)</me>
                So <m>f(1)</m> is an integer that is divisible by every integer, which is impossible unless <m>f(1)=0</m>. 
                We conclude that <m>f=0</m>, and thus <m>\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Q}, \mathbb{Z}) \cong 0</m>. 
                So our exact sequence above is actually
                <me>0 \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Q} / \mathbb{Z}, \mathbb{Z}) \longrightarrow 0 \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}, \mathbb{Z})</me>
                By <xref ref="exe-38"/>, <m>\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}, \mathbb{Z}) \cong \mathbb{Z} \neq 0</m>, so the last map in our sequence can't possibly be surjective, so our sequence is not a short exact sequence.
              </p>
        
              <p>
                The other fun consequence is that <m>\operatorname{since} \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Q}, \mathbb{Z})=0</m> and we have an exact sequence
                <me>0 \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Q} / \mathbb{Z}, \mathbb{Z}) \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Q}, \mathbb{Z})=0</me>
                we can now conclude that
                <me>\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Q} / \mathbb{Z}, \mathbb{Z})=0</me>
              </p>
            </example>

            <p>
              The last observation is a common trick: once we know we have an exact sequence involving certain modules we do not know, we can sometimes calculate them exactly by studying the other modules and maps in the exact sequence.
            </p>
      
            <p>
              We can use the left exactness of Hom to compute some modules of interest:
            </p>

            <example xml:id="exe-3.17">
              <p>
                Let <m>R</m> be a commutative ring and <m>M</m> be a finitely presented <m>R</m>-module. 
                This means that <m>M</m> has a presentation with finitely many generators and relations, which translates into an exact sequence of the form
                <me>R^{m} \stackrel{f}{\longrightarrow} R^{n} \longrightarrow M \longrightarrow 0</me>
              </p>
        
              <p>
                Since <m>R^{m}</m> and <m>R^{n}</m> are free modules, we can think of the map <m>f</m> as multiplication by a matrix <m>A</m> with <m>n</m> rows and <m>m</m> columns, after we fix a basis for <m>R^{n}</m> and <m>R^{m}</m>. 
                Applying <m>\operatorname{Hom}_{R}(-, R)</m> to the exact sequence above, we get an exact sequence
                <me>0 \longrightarrow \operatorname{Hom}_{R}(M, R) \longrightarrow \operatorname{Hom}_{R}\left(R^{n}, R\right) \stackrel{f^{*}}{\longrightarrow} \operatorname{Hom}\left(R^{m}, R\right)</me>
                By <xref ref="exe-38"/>, <m>\operatorname{Hom}_{R}\left(R^{n}, R\right) \cong R^{n}</m> and <m>\operatorname{Hom}_{R}\left(R^{m}, R\right) \cong R^{m}</m>. 
                Moreover, we claim that <m>f^{*}</m> is multiplication by the transpose of <m>A</m>.
              </p>
        
              <p>
                First, note that given a basis <m>\left\{e_{1}, \ldots, e_{n}\right\}</m> for <m>R^{n}</m>, we get a dual basis <m>\left\{e_{1}^{*}, \ldots, e_{n}^{*}\right\}</m> for <m>\operatorname{Hom}_{R}\left(R^{n}, R\right)</m>, where
                <me>e_{i}^{*}\left(e_{j}\right)= \begin{cases}1 &amp; \text { if } i=j \\ 0 &amp; \text { otherwise }\end{cases}</me>
              </p>
        
              <p>
                Similarly, we have a dual basis <m>\left\{e_{1}^{*}, \ldots, e_{m}^{*}\right\}</m> for <m>\operatorname{Hom}_{R}\left(R^{m}, R\right) \cong R^{m}</m>; 
                we might as well assume that we picked the canonical basis in both cases, so that we can use similar notation on both.
              </p>
        
              <p>
                Now the map <m>f^{*}</m> is also given by multiplication by a matrix, now having <m>m</m> rows and <m>n</m> columns. 
                To calculate its <m>j\th</m> column, we need to calculate <m>f^{*}\left(e_{j}^{*}\right)</m>, which is given by precomposition with <m>f</m>, so <m>f^{*}\left(e_{j}^{*}\right)=e_{j}^{*} A</m>; 
                this reads off the <m>j</m> th row of <m>A</m>. Thus <m>f^{*}</m> is indeed multiplication by <m>A^{T}</m>, and we have an exact sequence
                <me>0 \longrightarrow \operatorname{Hom}_{R}(M, R) \longrightarrow R^{n} \stackrel{A^{T}}{\longrightarrow} R^{m}</me>
              </p>
        
              <p>
                In particular, we have shown that <m>\operatorname{Hom}_{R}(M, R)</m> is the kernel of multiplication by <m>A^{T}</m>.
              </p>
            </example>

          </subsection>
          
        </section>

        <section xml:id="sec-tensor"><title>Tensor Products</title>

          <subsection xml:id="subsec-biadditive"><title>Biadditive Maps and First Properties</title>
            
            <definition xml:id="def-3.18">
              <statement>
                <p>
                  Definition 3.18. Fix a ring <m>R</m>, and consider:
                </p>
          
                <p><ul>
                  <li>
                        <p>
                  a right <m>R</m>-module <m>M</m>,
                </p>
                  </li>
          
                  <li>
                        <p>
                  a left <m>R</m>-module <m>N</m>,
                </p>
                  </li>
          
                  <li>
                        <p>
                  an abelian group <m>L</m>.
                </p>
                  </li>
          
                </ul></p>
          
                <p>
                  A function <m>f: M \times N \longrightarrow L</m> is <m>R</m>-biadditive if for all <m>m, m^{\prime} \in M</m>, all <m>n, n^{\prime} \in N</m>, and all <m>r \in R</m> we have
                </p>
          
                <p><ul>
                  <li>
                        <p>
                  <m>f\left(m+m^{\prime}, n\right)=f(m, n)+f\left(m^{\prime}, n\right)</m>
                </p>
                  </li>
          
                  <li>
                        <p>
                  <m>f\left(m, n+n^{\prime}\right)=f(m, n)+f\left(m, n^{\prime}\right)</m>
                </p>
                  </li>
          
                  <li>
                        <p>
                  <m>f(m r, n)=f(m, r n)</m>.
                </p>
                  </li>
          
                </ul></p>
          
                <p>
                  When <m>R</m> is a commutative ring, suppose that <m>L</m> is also an <m>R</m>-module. We say that a function <m>f: M \times N \longrightarrow L</m> is <m>R</m>-bilinear if for all <m>m, m^{\prime} \in M</m>, all <m>n, n^{\prime} \in N</m>, and all <m>r \in R</m> we have
                </p>
          
                <p><ul>
                  <li>
                        <p>
                  <m>f\left(m+m^{\prime}, n\right)=f(m, n)+f\left(m^{\prime}, n\right)</m>
                </p>
                  </li>
          
                  <li>
                        <p>
                  <m>f\left(m, n+n^{\prime}\right)=f(m, n)+f\left(m, n^{\prime}\right)</m>
                </p>
                  </li>
          
                  <li>
                        <p>
                  <m>f(r m, n)=f(m, r n)=r f(m, n)</m>.
                </p>
                  </li>
          
                </ul></p>
              </statement>
            </definition>
      
            <p>
              Note that an <m>R</m>-bilinear function is an <m>R</m>-biadditive function that satisfies
            </p>
      
            <p>
              <me>f(r m, n)=f(m, r n)=r f(m, n)</me>
            </p>

            <example>
              <p>
                Example 3.19. The product on <m>R</m> is an <m>R</m>-biadditive function <m>R \times R \longrightarrow R</m>. The first two rules follow from distributivity of multiplication over the sum; the final rule is a consequence of the associativity of multiplication.
              </p>
        
              <p>
                When <m>R</m> is commutative, this is an <m>R</m>-bilinear function.
              </p>
            </example>

            <definition xml:id="def-3.20">
              <statement>
                <p>
                  Definition 3.20. Let <m>M</m> be a right <m>R</m>-module and let <m>N</m> be a left <m>R</m>-module. The tensor product of <m>M</m> and <m>N</m> is an abelian group <m>M \otimes_{R} N</m> together with an <m>R</m>-biadditive function <m>\tau: M \times N \longrightarrow M \otimes_{R} N</m> with the following universal property: for every abelian group <m>A</m> and every <m>R</m>-biadditive map <m>f: M \times N \longrightarrow A</m>, there exists a unique group homomorphism <m>\tilde{f}: M \otimes_{R} N \longrightarrow A</m> such that the following diagram commutes:
                </p>
          
        
                <image source="2023_10_23_e2d6a27704be928b3deeg-084.jpg"/>
              </statement>
            </definition>  
      
            <p>
              We will now show that tensor products exist and are unique up to isomorphism; in particular, we can talk about the tensor product of <m>M</m> and <m>N</m>.
            </p>

            <lemma xml:id="lem-3.21">
              <statement>
                <p>
                  Lemma 3.21. Let <m>R</m> be any ring, <m>M</m> be a right <m>R</m>-module, and <m>N</m> a left <m>R</m>-module. The tensor product of <m>M</m> and <m>N</m> is unique up to unique isomorphism. More precisely, if <m>M \times N \stackrel{\tau_{1}}{\rightarrow} T_{1}</m> and <m>M \times N \stackrel{\tau_{2}}{\rightarrow} T_{2}</m> are two tensor products, then there exists a unique isomorphism <m>T_{1} \stackrel{i}{\rightarrow} T_{2}</m> such that
                </p>
          
        
                <image source="2023_10_23_e2d6a27704be928b3deeg-085(1).jpg"/>
              </statement>

              <proof>
                <p>
                  Proof. First, note that the universal property of the tensor product implies that there exists a unique <m>\varphi</m> such that
                </p>
          
        
                <image source="2023_10_23_e2d6a27704be928b3deeg-085.jpg"/>
                  
          
                <p>
                  commutes. Since the identity map <m>T_{i} \longrightarrow T_{i}</m> is such a map, it must be the only such map.
                </p>
          
                <p>
                  Similarly, there are unique maps <m>\varphi_{1}: T_{1} \longrightarrow T_{2}</m> and <m>\varphi_{2}: T_{2} \longrightarrow T_{1}</m> such that 
                </p>
                <image source='2023_10_23_e2d6a27704be928b3deeg-085(2).jpg'/>
                <p>
                  both commute. Stacking these up, we get commutative diagrams 
                </p>
        
                <image source='2023_10_23_e2d6a27704be928b3deeg-085(4).jpg'/>
        
                <p>
                  Note that the identity maps on <m>T_{1}</m> and <m>T_{2}</m> are homomorphisms <m>T_{1} \rightarrow T_{1}</m> and <m>T_{2} \rightarrow T_{2}</m> that would make each of these triangles commute: 
                </p>
                <image source='2023_10_23_e2d6a27704be928b3deeg-085(3).jpg'/>
                <p>
                  By uniqueness, <m>\varphi_{2} \varphi_{1}</m> must be the identity on <m>T_{1}</m> and <m>\varphi_{1} \varphi_{2}</m> must be the identity on <m>T_{2}</m>. In particular, <m>T_{1}</m> and <m>T_{2}</m> are isomorphic, and the isomorphisms <m>\varphi_{1}</m> and <m>\varphi_{2}</m> are unique.
                </p>
              </proof>
            </lemma>
      
            <theorem xml:id="thm-3.22">
              <statement>
                <p>
                  Theorem 3.22. Given any right <m>R</m>-modules <m>M</m> and any left <m>R</m>-module <m>N</m>, their tensor product <m>M \otimes_{R} N</m> exists, and it is given by the abelian group <m>M \otimes_{R} N</m> defined as follows:
                </p>
          
                <p><ul>
                  <li>
                        <p>
                  Generators: For each pair of elements <m>m \in M</m> and <m>n \in N</m>, we have a generator <m>m \otimes n</m>.
                </p>
                  </li>
          
                  <li>
                        <p>
                  Relations: the generators of <m>m \otimes n</m> satisfy the following relations, where <m>m, m^{\prime} \in M</m>, <m>n, n^{\prime} \in N</m>, and <m>r \in R</m> :
                </p>
                  </li>
          
                </ul></p>
          
                <p>
                  <me>\begin{aligned}
          m \otimes\left(n+n^{\prime}\right) &amp; =m \otimes n+m \otimes n^{\prime} \\
          \left(m+m^{\prime}\right) \otimes n &amp; =m \otimes n+m \otimes n^{\prime} \\
          (m r) \otimes n &amp; =m \otimes(r n) .
          \end{aligned}</me>
                </p>
              </statement>

              <proof>
                <p>
                  Proof. Let <m>F</m> be the free abelian group on the set <m>M \times N</m>. In what follows, we identify a pair <m>(m, n) \in M \times N</m> with the corresponding basis element for <m>F</m>. Let <m>S</m> be the subgroup of <m>F</m> generated by
                </p>
          
                <p>
                  <me>\left.S=\left(\begin{array}{c|c}
          \left(m, n+n^{\prime}\right)-(m, n)-\left(m, n^{\prime}\right) &amp; m, m^{\prime} \in M \\
          \left(m+m^{\prime}, n\right)-(m, n)-\left(m^{\prime}, n\right) &amp; n, n^{\prime} \in N \\
          (m r, n)-(m, r n) &amp; r \in R
          \end{array}\right\}\right)</me>
                </p>
          
                <p>
                  Let <m>M \otimes_{R} N:=F / S</m>, and let <m>m \otimes n</m> denote the class of <m>(m, n)</m> in the quotient. We claim that this abelian group <m>M \otimes_{R} N</m> is a tensor product for <m>M</m> and <m>N</m>, together with the map
                </p>
          
                <p>
                  <me>\begin{gathered}
          M \times N \stackrel{\tau}{\longrightarrow} M \otimes N \\
          (m, n) \longmapsto M \otimes n
          \end{gathered}</me>
                </p>
          
                <p>
                  Notice <m>\tau</m> is the restriction of the quotient map <m>F \longrightarrow F / S</m> to the basis elements of <m>F</m>. Moreover, by construction of <m>M \otimes_{R} N</m>, the following identities hold:
                </p>
          
                <p>
                  <me>\begin{array}{r}
          m \otimes\left(n+n^{\prime}\right)=m \otimes n+m \otimes n^{\prime} \\
          \left(m+m^{\prime}\right) \otimes n=m \otimes n+m \otimes n^{\prime} \\
          (m r) \otimes n=m \otimes(r n)
          \end{array}</me>
                </p>
          
                <p>
                  Together, these make <m>\tau</m> an <m>R</m>-biadditive map. The map <m>M \times N \longrightarrow F</m> that sends each pair <m>(m, n)</m> to the corresponding basis element is <m>R</m>-bilinear by construction. Moreover, there is a natural quotient map <m>F \longrightarrow M \otimes_{R} N</m>, and these maps make the diagram
                </p>
          
        
                <image source="2023_10_23_e2d6a27704be928b3deeg-086.jpg"/>
                  
          
                <p>
                  commute.
                </p>
          
                <p>
                  Now suppose that <m>A</m> is any other abelian group, and let <m>M \times N \stackrel{f}{\rightarrow} A</m> by any <m>R</m>-biadditive map. Since <m>F</m> is the free <m>R</m>-module on <m>M \times N, f</m> induces a homomorphism of abelian groups <m>\varphi: F \longrightarrow A</m> such that <m>f i=\varphi</m>, meaning <m>f(m, n)=\varphi(m, n)</m> for all <m>m \in M</m> and all <m>n \in N</m>.
                </p>
          
                <p>
                  Finally, the fact that <m>f</m> is bilinear implies that <m>S \subseteq \operatorname{ker} \varphi</m>. Therefore, <m>\varphi</m> induces a group homomorphism on <m>F / S=M \otimes_{R} N</m>. All this fits in the following commutative diagram:
                </p>
          
        
                <image source="2023_10_23_e2d6a27704be928b3deeg-087.jpg"/>
                  
          
                <p>
                  Finally, this map <m>\tilde{f}</m> we constructed satisfies <m>\tilde{f}(n \otimes n)=f(m, n)</m>, and since <m>M \otimes_{R} N</m> is generated by such elements, <m>\tilde{f}</m> is completely determined by the images of <m>m \otimes n</m>, and thus unique.
                </p>
              </proof>
            </theorem>
      
            <p>
              The construction in Theorem 3.22 gives us generators <m>m \otimes n</m> for <m>M \otimes_{R} N</m>. These are usually called simple tensors. So any element in <m>M \otimes_{R} N</m> is of the form
            </p>
      
            <p>
              <me>\sum_{i=1}^{k} m_{i} \otimes n_{i}</me>
            </p>
      
            <p>
              Such expressions are not unique. For a cheap example, consider the relations we used to construct <m>M \otimes_{R} N</m> from the abelian group on <m>M \times N</m>, which gives us nontrivial ways to write the 0 element in <m>M \otimes_{R} N</m> :
            </p>
      
            <p>
              <me>
                \begin{array}{r}
                0=m \otimes\left(n+n^{\prime}\right)-m \otimes n-m \otimes n^{\prime} \\
                0=\left(m+m^{\prime}\right) \otimes n-m \otimes n-m \otimes n^{\prime} \\
                0=(m r) \otimes n-m \otimes(r n) .
                \end{array}
              </me>
            </p>
      
            <p>
              This makes things unexpectedly tricky. For starters, the tensor product of two nonzero modules might be zero nevertheless. Also, whenever we try to define some <m>R</m>-module homomorphism from <m>M \otimes_{R} N</m> into some other <m>R</m>-module, we must carefully check that our map is well-defined, which is in principle not an easy task. Therefore, the easiest way to define some <m>R</m>-module homomorphism from <m>M \otimes_{R} N</m> is to give some <m>R</m>-bilinear map from <m>M \times N</m> into our desired <m>R</m>-module.
            </p>
      
            <p>
              In summary: the tensor product <m>M \otimes_{R} N</m> of <m>M</m> and <m>N</m> is generated by the simple tensors <m>m \otimes n</m>, but it's important to remember (though we're all bound to forget once or twice) that not all elements in <m>M \otimes_{R} N</m> are simple tensors. Moreover, even if <m>M</m> and <m>N</m> are nonzero, <m>M \otimes_{R} N</m> could very well be zero.
            </p>

            <remark>
              <p>
                Remark 3.23. Two group homomorphisms <m>M \otimes_{R} N \longrightarrow L</m> coincide if and only if they agree on simple tensors, since these are generators for <m>M \otimes_{R} N</m>.
              </p>
            </remark>

            <remark>
              <p>
                Remark 3.24. In any tensor product <m>M \otimes_{R} N</m>, the simple tensor <m>0 \otimes 0</m> is the zero element, and
              </p>
        
              <p>
                <me>m \otimes 0=0=0 \otimes n</me>
              </p>
        
              <p>
                for all <m>m \in M</m> and <m>n \in N</m>.
              </p>
            </remark>

          </subsection>

          <subsection xml:id="subsec-tensor-elements"><title>Elements in Tensor Products</title>
          
            <p>
              Let's see some examples of how tensor products can be zero.
            </p>

            <example>
              <p>
                Example 3.25. We claim that <m>\mathbb{Z} / 2 \otimes_{\mathbb{Z}} \mathbb{Q}=0</m>, despite the fact that both of these <m>\mathbb{Z}</m>-modules are nonzero. To see that, simply note that given any <m>a \in \mathbb{Z} / 2</m> and any <m>p \in \mathbb{Q}</m>,
              </p>
        
              <p>
                <me>a \otimes p=a \otimes \frac{2 p}{2}=(2 a) \otimes \frac{p}{2}=0 \otimes \frac{p}{2}=0</me>
              </p>
        
              <p>
                Since <m>\mathbb{Z} / 2 \otimes_{\mathbb{Z}} \mathbb{Q}</m> is generated by simple tensors, which are all 0 , we conclude that <m>\mathbb{Z} / 2 \otimes_{\mathbb{Z}} \mathbb{Q}=0</m>.
              </p>
            </example>

            <example>
              <p>
                Example 3.26. Consider the abelian group <m>\mathbb{Q} / \mathbb{Z}</m>. Again, this is very much nonzero, and yet we claim that <m>\mathbb{Q} / \mathbb{Z} \otimes_{\mathbb{Z}} \mathbb{Q} / \mathbb{Z}=0</m>. For any simple tensor,
              </p>
        
              <p>
                <me>
                  \begin{aligned}
                  \left(\frac{p}{q}+\mathbb{Z}\right) \otimes\left(\frac{a}{b}+\mathbb{Z}\right)=\left(\frac{b p}{b q}+\mathbb{Z}\right) \otimes\left(\frac{a}{b}+\mathbb{Z}\right) &amp; =\left(\frac{p}{b q}+\mathbb{Z}\right) \otimes b\left(\frac{a}{b}+\mathbb{Z}\right) \\
                  &amp; =\left(\frac{p}{b q}+\mathbb{Z}\right) \otimes 0=0 \otimes 0=0
                  \end{aligned}
                </me>
              </p>
            </example>

            <example>
              <p>
                Example 3.27. Let <m>p</m> and <m>q</m> be distinct prime integers. Then <m>p</m> has inverse modulo <m>q</m>, say <m>a p \equiv 1 \bmod q</m>, and <m>q</m> has an inverse modulo <m>p</m>, say <m>b q \equiv 1 \bmod p</m>. Given any simple tensor <m>n \otimes m</m> in <m>\mathbb{Z} / p \otimes_{\mathbb{Z}} \mathbb{Z} / q</m>
              </p>
        
              <p>
                <me>n \otimes m=((b q) n) \otimes((a p) m)=(p b n) \otimes(q a m)=0 \otimes 0</me>
              </p>
        
              <p>
                Since all simple tensors are 0 and <m>\mathbb{Z} / p \otimes_{\mathbb{Z}} \mathbb{Z} / q</m> is generated by simple tensors, we conclude that <m>\mathbb{Z} / p \otimes_{\mathbb{Z}} \mathbb{Z} / q=0</m>.
              </p>
            </example>
      
            <p>
              More generally, the following holds:
            </p>

            <exercise>
              <p>
                Exercise 47. Show that if <m>d=\operatorname{gcd}(m, n)</m>, then <m>\mathbb{Z} / n \otimes_{\mathbb{Z}} \mathbb{Z} / m \cong \mathbb{Z} / d</m>.
              </p>
            </exercise>
      
            <p>
              Of course not all tensor products are zero. A good method for showing that a particular element <m>m</m> in a module <m>M</m> is nonzero is to give a homomorphism from <m>M</m> sending <m>m</m> to some nonzero element. We apply this technique to tensor products: to show that a particular element <m>x</m> in <m>M \otimes_{R} N</m> is nonzero, we construct a homomorphism from <m>M \otimes_{R} N</m> that takes <m>x</m> no some nonzero element. This is typically easier for simple tensors: we need an <m>R</m>-biadditive map out of <m>M \times N</m> that sends the corresponding pair to a nonzero element.
            </p>

            <example>
              <p>
                Example 3.28. Consider the abelian group <m>2 \mathbb{Z} \otimes_{\mathbb{Z}} \mathbb{Z} / 2</m>. The map
              </p>
        
              <p>
                <me>
                  \begin{array}{r}
                  2 \mathbb{Z} \times \mathbb{Z} / 2 \longrightarrow \mathbb{Z} / 2 \\
                  (a, b) \longmapsto \frac{a b}{2}
                  \end{array}
                </me>
              </p>
        
              <p>
                is <m>\mathbb{Z}</m>-bilinear, and thus it induces a homomorphism <m>2 \mathbb{Z} \otimes_{\mathbb{Z}} \mathbb{Z} / 2 \longrightarrow \mathbb{Z} / 2</m>. Via this map, <m>2 \otimes 1 \mapsto 1 \neq 0</m>, so <m>2 \otimes 1</m> is nonzero in <m>2 \mathbb{Z} \otimes_{\mathbb{Z}} \mathbb{Z} / 2</m>, and <m>2 \mathbb{Z} \otimes_{\mathbb{Z}} \mathbb{Z} / 2 \neq 0</m>.
              </p>
            </example>
      
            <p>
              Moreover, not all elements in a tensor product are simple tensors.
            </p>

            <exercise>
              <p>
                Exercise 48. Let <m>R=\mathbb{Z}[x]</m> and consider the ideal <m>I=(2, x)</m>. Show that in <m>I \otimes_{R} I</m>, the element <m>2 \otimes 2+x \otimes x</m> is not a simple tensor.
              </p>
            </exercise>

          </subsection>

          <subsection xml:id="subsec-tensor-module"><title>Bimodules and When Tensor Products are Modules</title>
    
            <p>
              We can sometimes give <m>M \otimes_{R} N</m> the structure of an <m>R</m>-module.
            </p>

            <remark>
              <p>
                Remark 3.29. Let <m>R</m> be a commutative ring, and let <m>M</m> and <m>N</m> be <m>R</m>-modules. We can give <m>M \otimes_{R} N</m> the structure of an <m>R</m>-module, as follows: given <m>r \in R</m> and a simple tensor <m>m \otimes n</m>,
              </p>
        
              <p>
                <me>r(m \otimes n)=(r m) \otimes n=m \otimes(r n)</me>
              </p>
        
              <p>
                We can then extend this linearly to all other elements of <m>M \otimes_{R} N</m>. We leave it as an exercise to check that this does indeed make the abelian group <m>M \otimes_{R} N</m> into an <m>R</m>-module.
              </p>
            </remark>
      
            <p>
              Alternatively, over a commutative ring we can define the tensor product as follows:
            </p>

            <definition xml:id="def-3.30">
              <statement>
                <p>
                  Definition 3.30. Let <m>R</m> be a commutative ring and <m>M</m> and <m>N</m> be <m>R</m>-modules. The tensor product of <m>M</m> and <m>N</m> is an <m>R</m>-module <m>M \otimes_{R} N</m> together with an <m>R</m>-bilinear map <m>\tau: M \times N \longrightarrow</m> <m>M \otimes_{R} N</m> with the following universal property: for every <m>R</m>-module <m>A</m> and every <m>R</m>-bilinear map <m>f: M \times N \longrightarrow A</m> there exists a unique <m>R</m>-module homomorphism <m>\tilde{f}: M \otimes_{R} N \longrightarrow A</m> such that the following diagram commutes:
                </p>
          
        
                <image source="2023_10_23_e2d6a27704be928b3deeg-089(1).jpg"/>
              </statement>
            </definition>
      
            <p>
              One can now check that if we take the abelian group <m>M \otimes_{R} N</m>, which is the unique abelian group which satisfies the universal property of the tensor product (as defined for a general ring <m>R</m> ), and endow it with the <m>R</m>-module structure defined in Remark 3.29, the resulting <m>R</m>-module satisfies the universal property in Definition 3.30, and the argument we gave in Lemma 3.21 can be repurposed to show that this is the unique <m>R</m>-module satisfying this universal property.
            </p>

            <remark>
              <p>
                Remark 3.31. We can express the universal property of the tensor product in the framework of Definition 1.87. For simplicity, assume that <m>R</m> is a commutative ring. Consider the functor <m>\operatorname{Bilin}(M \times N,-): R</m>-Mod <m>\longrightarrow</m> Set that sends an <m>R</m>-module <m>A</m> to the set of <m>R</m>-bilinear maps <m>M \times N \longrightarrow A</m>, and a map of <m>R</m>-modules <m>f A \longrightarrow B</m> to the function of sets induced by post-composition of functions. The universal property of the tensor product is encoded in the representable functor <m>\operatorname{Bilin}(M \times N,-): R</m>-Mod <m>\longrightarrow</m> Set together with the bilinear map <m>\tau \in \operatorname{Bilin}\left(M \times N, M \otimes_{R} N\right)</m>. Indeed, this says that <m>\tau</m> induces a natural isomorphism between <m>\operatorname{Hom}_{R}\left(M \otimes_{R} N,-\right)</m> and <m>\operatorname{Bilin}(M \times N,-)</m> by sending each <m>R</m>-module <m>A</m> to the bijection
              </p>
        
              <p>
                <me>
                  \begin{aligned}
                  \operatorname{Hom}_{R}\left(M \otimes_{R} N, A\right) &amp; \longrightarrow \operatorname{Bilin}(M \times N, A) \\
                  f &amp; \longmapsto \operatorname{Bilin}(M \times N, f) \tau=f_{*}(\tau)=f \tau
                  \end{aligned}
                </me>
              </p>
        
              <p>
                The fact that this is a bijection says that for every <m>R</m>-bilinear map <m>g</m> there exists a unique <m>R</m>-module homomorphism <m>f</m> such that
              </p>
        
      
              <image source="2023_10_23_e2d6a27704be928b3deeg-089.jpg"/>
                
        
              <p>
                commutes. So this is indeed the universal property we described before.
              </p>
            </remark>
      
            <p>
              More generally, <m>M \otimes_{R} N</m> has a module structure when one of <m>M</m> or <m>N</m> is a bimodule.
            </p>

            <definition xml:id="def-3.32">
              <statement>
                <p>
                  Definition 3.32. Fix rings <m>R</m> and <m>S</m>. An <m>(R, S)</m>-bimodule is an abelian group <m>M</m> together with a left <m>R</m>-module structure and a right <m>S</m>-module structure such that for all <m>r \in R, s \in S</m>, and <m>m \in M</m>,
                </p>
          
                <p>
                  <me>(r m) s=r(m s)</me>
                </p>
          
                <p>
                  One sometimes writes <m>{ }_{R} M_{S}</m> to indicate <m>M</m> is an <m>(R, S)</m>-bimodule. An <m>R</m>-bimodule is an <m>(R, R)</m>-bimodule.
                </p>
              </statement>
            </definition>

            <example>
              <p>Example 3.33.</p>
      
              <p>
                a) Let <m>\mathrm{M}_{m, n}(R)</m> denote the ring of <m>m \times n</m> matrices with entries in a ring <m>R</m>. We can also view <m>\mathrm{M}_{m, n}(R)</m> as an <m>\left(\mathrm{M}_{m, m}, \mathrm{M}_{n, n}\right)</m>-bimodule via left and right multiplication of matrices.
              </p>
          
              <p>
                b) Any two-sided ideal <m>I</m> of a ring <m>R</m> is an <m>R</m>-bimodule.
              </p>
          
              <p>
                c) Let <m>R</m> be a commutative ring and let <m>M</m> be any left <m>R</m>-module. Then <m>M</m> is also a right <m>R</m>-module under the same module structure, by setting
              </p>
          
              <p>
                <me>m \cdot r:=r m \text {. }</me>
              </p>
          
              <p>
                Moreover, <m>M</m> is also an <m>R</m>-bimodule using both of these structures at once.
              </p>
          
              <p>
                d) Let <m>f: R \rightarrow S</m> be a ring homomorphism. We can view <m>S</m> as an <m>(R, S)</m>-bimodule via
              </p>
          
              <p>
                <me>t \cdot s \cdot r:=t s f(r)</me>
              </p>
          
              <p>
                for <m>t, s \in S</m> and <m>r \in R</m>, where the right hand side is just multiplication in <m>s</m>. Similarly, <m>S</m> can be viewed as an <m>(S, R)</m>-bimodule and as an <m>(R, R)</m>-bimodule.
              </p>
          
              <p>
                e) Let <m>R</m> be a commutative ring of prime characteristic <m>p&gt;0</m>, meaning that <m>R</m> contains a copy of <m>\mathbb{F}_{p}</m>, or equivalently, that
              </p>
          
              <p>
                <me>\underbrace{1+\cdots+1}_{p \text { times }}=0</me>
              </p>
          
              <p>
                Then <m>R</m> is an <m>R</m>-bimodule with the left module structure given by the Frobenius map
              </p>
          
              <p>
                <me>\begin{aligned}
          &amp; R \stackrel{F}{\longrightarrow} R \\
          &amp; r \longmapsto r^{p}
          \end{aligned}</me>
              </p>
          
              <p>
                and right module structure given by the usual multiplication on <m>R</m>. More precisely, given <m>r, s, t \in R</m>,
              </p>
          
              <p>
                <me>r \cdot s \cdot t:=r^{p} s t</me>
              </p>
          
              <p>
                where the right hand side is just multiplication in <m>R</m>.
              </p>
            </example>

            <exercise>
              <p>
                Exercise 49. Let <m>M</m> be an <m>(S, R)</m>-bimodule and <m>N</m> a left <m>R</m>-module. Consider <m>M \times N</m> as a left <m>S</m>-module via
              </p>
          
              <p>
                <me>s(m, n)=(s m, n) \text {. }</me>
              </p>
          
              <p>
                Then <m>M \otimes_{R} N</m> is a left <m>S</m>-module via
              </p>
          
              <p>
                <me>s\left(\sum_{i} m_{i} \otimes n_{i}\right)=\left(s m_{i}\right) \otimes n_{i}</me>
              </p>
          
              <p>
                The map
              </p>
          
              <p>
                <me>\begin{gathered}
          M \times N \longrightarrow M \otimes_{R} N \\
          (m, n) \longrightarrow m \otimes n
          \end{gathered}</me>
              </p>
          
              <p>
                is left <m>S</m>-linear, and for any left <m>S</m>-module <m>A</m> and left <m>S</m>-linear <m>R</m>-biadditive map <m>b: M \times N \rightarrow A</m>, there is a unique left <m>S</m>-linear map <m>\alpha: M \otimes_{R} N \rightarrow A</m> such that <m>\alpha(m \otimes n)=b(m, n)</m>.
              </p>
          
              <p>
                Similarly, for a left <m>R</m>-module <m>M</m> and an <m>(R, S)</m>-bimodule <m>N, M \times N</m> is a right <m>S</m>-module via
              </p>
          
              <p>
                <me>(m, n) s=(m, n s)</me>
              </p>
          
              <p>
                Then <m>M \otimes_{R} N</m> is a right <m>S</m>-module via
              </p>
          
              <p>
                <me>\left(\sum_{i} m_{i} \otimes n_{i}\right) s=m_{i} \otimes\left(n_{i} s\right)</me>
              </p>
          
              <p>
                and the map
              </p>
          
              <p>
                <me>\begin{gathered}
          M \times N \longrightarrow M \otimes_{R} N \\
          (m, n) \longrightarrow m \otimes n
          \end{gathered}</me>
              </p>
          
              <p>
                is right <m>S</m>-linear, and for any <m>S</m>-module <m>A</m> and right <m>S</m>-linear <m>R</m>-biadditive map <m>b: M \times N \rightarrow A</m>, there is a unique right <m>S</m>-linear map <m>\alpha: M \otimes_{R} N \rightarrow A</m> such that <m>\alpha(m \otimes n)=b(m, n)</m>.
              </p>
            </exercise>   

          </subsection>

          <subsection xml:id="subsec-tensor-functor"><title>The Tensor Product Functor</title>
      
            <p>
              We can also take tensor products of maps.
            </p>

            <lemma xml:id="lem-3.34">
              <statement>
                <p>
                  Lemma 3.34. Let <m>R</m> be a ring, <m>f: A \rightarrow C</m> be a homomorphism of right <m>R</m>-modules, and <m>g: B \rightarrow D</m> be a homomorphism of left <m>R</m>-modules. There exists a unique homomorphism of abelian groups <m>f \otimes g: A \otimes_{R} B \longrightarrow C \otimes_{R} D</m> such that
                </p>
            
                <p>
                  <me>(f \otimes g)(a \otimes b)=f(a) \otimes g(b)</me>
                </p>
            
                <p>
                  for all <m>a \in A</m> and <m>b \in B</m>. When <m>R</m> is commutative, this map <m>f \otimes g</m> is a homomorphism of <m>R</m>-modules. Moreover, if <m>A</m> and <m>B</m> are <m>(S, R)</m>-bimodules and <m>f</m> is left <m>S</m>-linear, then <m>f \otimes g</m> is also a homomorphism of left <m>S</m>-modules, and if <m>C</m> and <m>D</m> are <m>(R, S)</m>-bimodules and <m>g</m> is right <m>S</m>-linear, then <m>f \otimes g</m> is also a homomorphism of right <m>S</m>-modules.
                </p>
              </statement>

              <proof>
                <p>
                  Proof sketch. The function
                </p>
            
                <p>
                  <me>\begin{aligned}
            A \times B &amp; \longrightarrow C \otimes_{R} D \\
            (a, b) &amp; \longmapsto f(a) \otimes g(b)
            \end{aligned}</me>
                </p>
            
                <p>
                  is <m>R</m>-biadditive, and <m>R</m>-bilinear when <m>R</m> is commutative, and right or left <m>S</m>-linear in the bimodule case, so the universal property of tensor products in each case gives the desired homomorphism and its uniqueness.
                </p>
              </proof>
            </lemma>

            <lemma xml:id="lem-3.35">
              <statement>
                <p>
                  Lemma 3.35. Given <m>R</m>-module maps <m>A_{1} \stackrel{f_{1}}{\longrightarrow} A_{2} \stackrel{f_{2}}{\longrightarrow} A_{3}</m> and <m>B_{1} \stackrel{b_{1}}{\longrightarrow} B_{2} \stackrel{g_{2}}{\longrightarrow} B_{3}</m>, the composition of <m>f_{1} \otimes g_{1}</m> satisfies <m>f_{2} \otimes g_{2}</m>
                </p>
            
                <p>
                  <me>\left(f_{2} \otimes g_{2}\right) \circ\left(f_{1} \otimes g_{1}\right)=\left(f_{2} f_{1}\right) \otimes\left(g_{2} g_{1}\right)</me>
                </p>
              </statement>
            </lemma>

            <proof>
              <p>
                Proof. It's sufficient to check that these maps agree on simple tensors, and indeed they both take <m>a \otimes b</m> to <m>\left(f_{2} f_{1}(a)\right) \otimes\left(g_{2} g_{1}(b)\right)</m>.
              </p>
            </proof>
        
            <p>
              We are particularly interested in tensor products because of the tensor functor.
            </p>

            <theorem xml:id="thm-3.36">
              <statement>
                <p>
                  Theorem 3.36. Let <m>M</m> be a right <m>R</m>-module. There is an additive covariant functor
                </p>
            
                <p>
                  <me>M \otimes_{R}-: R-\operatorname{Mod} \longrightarrow \mathbf{A b}</me>
                </p>
            
                <p>
                  that takes each <m>R</m>-module <m>N</m> to <m>M \otimes_{R} N</m>, and each <m>R</m>-module homomorphism <m>f: A \longrightarrow B</m> to the homomorphism of abelian groups <m>1_{M} \otimes f: M \otimes_{R} A \longrightarrow M \otimes_{R} B</m>.
                </p>
            
                <p>
                  When <m>R</m> is commutative, we can view <m>M \otimes_{R}-</m> as an additive functor <m>R-\boldsymbol{M o d} \rightarrow R</m>-Mod.
                </p>
              </statement>

              <proof>
                <p>
                  Proof. Let <m>T:=M \otimes_{R}-</m>. First, note that <m>T</m> preserves identities, meaning <m>T\left(1_{N}\right)=1_{T(N)}</m>, since the identity map on <m>M \otimes_{R} N</m> agrees with <m>T\left(1_{N}\right)=1_{M} \otimes 1_{N}</m> on simple tensors. Moreover, <m>T</m> preserves compositions, since by Lemma 3.35 we have
                </p>
            
                <p>
                  <me>T(f) T(g)=(1 \otimes f)(1 \otimes g)=1 \otimes(f g)=T(f g)</me>
                </p>
            
                <p>
                  Therefore, <m>T</m> is a functor. To check that it is an additive functor, we need to prove that <m>T(f+g)=T(f)+T(g)</m> for all <m>f, g \in \operatorname{Hom}_{R}(A, B)</m>. It is sufficient to check that the maps <m>T(f+g)=1 \otimes(f+g)</m> and <m>T(f)+T(g)=1 \otimes f+1 \otimes g</m> agree on simple tensors. Indeed,
                </p>
            
                <p>
                  <me>\begin{aligned}
            T(f+g)(a \otimes b) &amp; =(1 \otimes(f+g))(a \otimes b) \\
            &amp; =a \otimes(f+g)(b) \\
            &amp; =a \otimes f(b)+g(b) \\
            &amp; =a \otimes f(b)+a \otimes g(b) \\
            &amp; =(1 \otimes f)(a \otimes b)+(1 \otimes g)(a \otimes b) \\
            &amp; =T(f)(a \otimes b)+T(g)(a \otimes b) .
            \end{aligned}</me>
                </p>
            
                <p>
                  We conclude that <m>T(f+g)=T(f)+T(g)</m>.
                </p>
              </proof>
            </theorem>
            
            <definition xml:id="def-3.37">
              <statement>
                <p>
                  Definition 3.37. Given a ring <m>R</m> and a right <m>R</m>-module <m>M</m>, the functor <m>M \otimes_{R}-</m> is the tensor product functor.
                </p>
              </statement>
            </definition>
            
            <p>
              Note that we were purposely vague on the target of the tensor product functor: when <m>R</m> is commutative, we get both a functor <m>R</m>-Mod <m>\rightarrow \mathrm{Ab}</m> and a functor <m>R</m>-Mod <m>\rightarrow R</m>-Mod. The two functors are essentially the same: the tensor product functor <m>R-\mathbf{M o d} \rightarrow \mathbf{A b}</m> is the composition of functor <m>R</m>-Mod <m>\rightarrow R</m>-Mod followed by the forgetful functor <m>R</m>-Mod <m>\rightarrow \mathbf{A b}</m>.
            </p>
        
            <p>
              We can similarly define the tensor product functor <m>-\otimes_{R} N</m>; when <m>R</m> is commutative, it turns out that the two constructions are essentially the same.
            </p>

            <lemma xml:id="lem-3.38">
              <statement>
                <p>
                  Lemma 3.38 (Commutativity of tensor products). Let <m>R</m> be a commutative ring. There is a natural isomorphism <m>M \otimes_{R}-\cong-\otimes_{R} N</m>. In particular, for all <m>R</m>-modules <m>M</m> and <m>N</m> we have
                </p>
            
                <p>
                  <me>M \otimes_{R} N \cong N \otimes_{R} M</me>
                </p>
              </statement>

              <proof>
                <p>
                  Proof. One can check (exercise!) that the map <m>M \times N \longrightarrow N \otimes_{R} M</m> given by <m>(m, n) \mapsto n \otimes m</m> is <m>R</m>-biadditive, and <m>R</m>-bilinear if <m>R</m> is commutative. The universal property of the tensor product <m>M \otimes_{R} N</m> gives us a homomorphism <m>\varphi</m> of abelian groups or <m>R</m>-modules, depending on the case, such that the diagram
                </p>
            
            
                <image source="2023_10_23_e2d6a27704be928b3deeg-093(1).jpg"/>
                  
            
                <p>
                  commutes. Similarly, we get a map <m>\psi</m> and a commutative diagram
                </p>
            
            
                <image source="2023_10_23_e2d6a27704be928b3deeg-093(3).jpg"/>
                  
            
                <p>
                  Then <m>\varphi \psi</m> agrees with the identity on <m>N \otimes_{R} M</m> on simple tensors, so it is the identity. Similarly, <m>\psi \varphi</m> is the identity on <m>M \otimes_{R} N</m>, and these are the desired isomorphisms.
                </p>
            
                <p>
                  The statement about naturality is more precisely the following: for every <m>R</m>-module maps <m>f: M_{1} \longrightarrow M_{2}</m> and <m>g: N_{1} \longrightarrow N_{2}</m>, our isomorphisms <m>M_{1} \otimes_{R} N_{1} \cong N_{1} \otimes_{R} M_{1}</m> and <m>M_{2} \otimes_{R} N_{2} \cong N_{2} \otimes_{R} M_{2}</m> make the diagram
                </p>
            
            
                <image source="2023_10_23_e2d6a27704be928b3deeg-093.jpg"/>
                  
            
                <p>
                  commute. To check this, it's sufficient to check commutativity on simple tensors, and indeed
                </p>
            
            
                <image source="2023_10_23_e2d6a27704be928b3deeg-093(2).jpg"/>
              </proof>
            </lemma>

            <lemma xml:id="lem-3.39">
              <statement>
                <p>
                  Lemma 3.39 (Associativity of tensors). Given a right <m>R</m>-module <m>A</m>, an <m>(R, S)</m>-bimodule <m>B</m>, and a left <m>S</m>-module <m>C</m>,
                </p>
            
                <p>
                  <me>\left(A \otimes_{R} B\right) \otimes_{S} C \cong A \otimes_{R}\left(B \otimes_{S} C\right)</me>
                </p>
              </statement>

              <proof>
                <p>
                  Proof. Fix <m>c \in C</m>. The map
                </p>
            
                <p>
                  <me>\begin{gathered}
            A \times B \longrightarrow A \otimes_{R}\left(B \otimes_{R} C\right) \\
            (a, b) \longmapsto a \otimes(b \otimes c)
            \end{gathered}</me>
                </p>
            
                <p>
                  is <m>R</m>-biadditive, so it induces a homomorphism of abelian groups
                </p>
            
                <p>
                  <me>\varphi_{c}: A \otimes_{R} B \longrightarrow A \otimes_{R}\left(B \otimes_{R} C\right)</me>
                </p>
            
                <p>
                  This map is in fact a homomorphism of <m>R</m>-modules when <m>R</m> is commutative. Moreover,
                </p>
            
                <p>
                  <me>\begin{gathered}
            \left(A \otimes_{R} B\right) \times C \longrightarrow A \otimes_{R}\left(B \otimes_{R} C\right) \\
            (a \otimes b, c) \longmapsto a \otimes(b \otimes c)
            \end{gathered}</me>
                </p>
            
                <p>
                  is also <m>R</m>-biadditive, and it induces a homomorphism that sends <m>(a \otimes b) \otimes c</m> to <m>a \otimes(b \otimes c)</m>. Similarly, we can define a homomorphism
                </p>
            
                <p>
                  <me>\begin{gathered}
            A \otimes_{R}\left(B \otimes_{R} C\right) \longrightarrow\left(A \otimes_{R} B\right) \otimes_{R} C \\
            a \otimes(b \otimes c) \longmapsto(a \otimes b) \otimes c .
            \end{gathered}</me>
                </p>
            
                <p>
                  The composition of these two homomorphisms in either order is the identity on simple tensors, and thus they are both isomorphisms.
                </p>
              </proof>
            </lemma>

            <lemma xml:id="lem-3.40">
              <statement>
                <p>
                  Lemma 3.40. Let <m>R</m> be any ring. There is a natural isomorphism between <m>R \otimes_{R}-</m> and the identity functor on <m>R</m>-Mod. In particular, for every left <m>R</m>-module <m>M</m> there is an isomorphism of <m>R</m>-modules
                </p>
            
                <p>
                  <me>R \otimes_{R} M \cong M</me>
                </p>
              </statement>

              <proof>
                <p>
                  Proof. First, note that <m>R</m> is an <m>R</m>-bimodule, so <m>R \otimes_{R} M</m> is a left <m>R</m>-module. The map
                </p>
            
                <p>
                  <me>\begin{aligned}
            R \times M &amp; \longrightarrow M \\
            (r, m) &amp; \longmapsto r m
            \end{aligned}</me>
                </p>
            
                <p>
                  is <m>R</m>-biadditive (by the distributive laws), <m>R</m>-bilinear (by associativity of the action on a module), and <m>R</m>-linear, so it induces a homomorphism of <m>R</m>-modules <m>R \otimes_{R} M \stackrel{\varphi_{M}}{\longrightarrow} M</m>. By definition, <m>\varphi_{M}</m> is surjective. Moreover, the map
                </p>
            
                <p>
                  <me>\begin{aligned}
            &amp; M \stackrel{f_{M}}{\longmapsto} R \otimes_{R} M \\
            &amp; m \longmapsto 1 \otimes m
            \end{aligned}</me>
                </p>
            
                <p>
                  is a homomorphism of <m>R</m>-modules, since
                </p>
            
                <p>
                  <me>f_{M}(a+b)=1 \otimes(a+b)=1 \otimes a+1 \otimes b \text { and } f_{M}(r a)=1 \otimes(r a)=r(1 \otimes a)=r f_{M}(a)</me>
                </p>
            
                <p>
                  For every <m>m \in M, \varphi_{M} f_{M}(m)=\varphi_{M}(1 \otimes m)=1 m=m</m>, and for every simple tensor, <m>f_{M} \varphi_{M}(r \otimes m)=f_{M}(r m)=1 \otimes(r m)=r \otimes m</m>. This shows that <m>\varphi_{M}</m> is an isomorphism.
                </p>
            
                <p>
                  Finally, given any <m>f \in \operatorname{Hom}_{R}(M, N)</m>, since <m>f</m> is <m>R</m>-linear we conclude that the diagram
                </p>
            
                <image source="2023_10_23_e2d6a27704be928b3deeg-095.jpg"/>
                  
                <p>
                  commutes, so our isomorphism is natural.
                </p>
              </proof>
            </lemma>

            <p>
              Similarly to the Hom functor, tensor behaves well with respect to arbitrary direct sums.
            </p>

            <theorem xml:id="thm-3.41">
              <statement>
                <p>
                  Theorem 3.41. Let <m>M</m> be a right <m>R</m>-module, and let <m>\left\{N_{i}\right\}_{i \in I}</m> be an arbitrary family of left <m>R</m>-modules. Then the map
                </p>
            
                <p>
                  <me>\begin{gathered}
            M \otimes_{R}\left(\bigoplus_{i \in I} N_{i}\right) \cong \underset{i \in I}{\rightrightarrows} \bigoplus_{i \in I} M \otimes_{R} N_{i} \\
            m \otimes\left(a_{i}\right)_{i} \longmapsto \\
            \longrightarrow\left(m \otimes a_{i}\right)
            \end{gathered}</me>
                </p>
            
                <p>
                  is an isomorphism of abelian groups in general, of <m>R</m>-modules in the commutative case, of <m>S</m> modules if each <m>N_{i}</m> is an <m>(S, R)</m>-bimodule, and of right <m>S</m>-modules if <m>N</m> is an <m>(R, S)</m>-bimodule. Moreover, this isomorphism is natural: given two families of left <m>R</m>-modules <m>\left\{A_{i}\right\}_{i \in I}</m> and <m>\left\{B_{j}\right\}_{j \in J}</m>, and left <m>R</m>-module homomorphisms <m>\sigma_{i j}: A_{i} \longrightarrow B_{j}</m>, the <m>R</m>-module homomorphisms
                </p>
            
                <p>
                  <me>\begin{aligned}
            &amp; \bigoplus_{i \in I} A_{i} \stackrel{\sigma}{\longrightarrow} \bigoplus_{j \in J} B_{j} \quad \text { and } \quad \tilde{\sigma}=\bigoplus_{i \in I} \sigma_{i j}: \bigoplus_{i \in I} M \otimes_{R} A_{i} \longrightarrow \bigoplus_{j \in J} M \otimes_{R} B_{j} \\
            &amp; \left(a_{i}\right)_{i \in I} \longmapsto\left(\sigma_{i j}\left(a_{i}\right)\right)_{j \in J}
            \end{aligned}</me>
                </p>
            
                <p>
                  give a commutative diagram
                </p>
            
                <p>
                  <me>\begin{aligned}
            M \otimes_{R}\left(\bigoplus_{i \in I} A_{i}\right) &amp; \cong \bigoplus_{i \in I} M \otimes_{R} A_{i} \\
            1 \otimes \sigma &amp; \downarrow \\
            M \otimes_{R}\left(\bigoplus_{j \in J} B_{j}\right) &amp; \stackrel{\sim}{\longleftarrow} \bigoplus_{j \in J} M \otimes_{R} B_{j} .
            \end{aligned}</me>
                </p>
              </statement>

              <proof>
                <p>
                  Proof. First, note that the function
                </p>
            
                <p>
                  <me>\begin{gathered}
            M \times\left(\bigoplus_{i \in I} A_{i}\right) \longrightarrow \bigoplus_{i \in I}\left(M \otimes_{R} A_{i}\right) \\
            \left(m,\left(a_{i}\right)_{i}\right) \longmapsto\left(m \otimes a_{i}\right)
            \end{gathered}</me>
                </p>
            
                <p>
                  is <m>R</m>-bilinear, so it induces a homomorphism
                </p>
            
                <p>
                  <me>M \otimes_{R}\left(\bigoplus_{i \in I} A_{i}\right) \stackrel{\tau}{\longrightarrow} \bigoplus_{i \in I}\left(M \otimes_{R} A_{i}\right)</me>
                </p>
            
                <p>
                  For each <m>k \in I</m>, let <m>\iota_{k}</m> denote the inclusion map <m>A_{k} \subseteq \bigoplus_{i} A_{i}</m>. The universal property of the coproduct (which in the case of <m>R</m>-modules, means the direct sum) gives an <m>R</m>-module homomorphism
                </p>
            
                <p>
                  <me>\begin{array}{r}
            \bigoplus_{i \in I}\left(M \otimes_{R} A_{i}\right) \stackrel{\lambda}{\longrightarrow} M \otimes_{R} \bigoplus_{i \in I}\left(A_{i}\right) \\
            \left(m \otimes a_{i}\right)_{i} \longmapsto m \otimes \sum_{i} \iota_{i}\left(a_{i}\right)
            \end{array}</me>
                </p>
            
                <p>
                  which we obtain by assembling the <m>R</m>-module homomorphisms <m>1 \otimes \iota_{i}</m>. It is routine to check that <m>\lambda</m> is the inverse of <m>\tau</m>, which must then be an isomorphism. Finally, we can check naturality by checking commutativity of the square above, element by element:
                </p>
            
            
                <image source="2023_10_23_e2d6a27704be928b3deeg-096.jpg"/>
              </proof>
            </theorem>

            <remark>
              <p>
                Remark 3.42. By commutativity of the tensor product, we also get natural isomorphisms
              </p>
          
              <p>
                <me>\left(\bigoplus_{i \in I} N_{i}\right) \otimes_{R} M \stackrel{\cong}{\longrightarrow} \bigoplus_{i \in I} N_{i} \otimes_{R} M</me>
              </p>
            </remark>
            
            <p>
              The following follows as a corollary of Lemma 3.40 and Theorem 3.41:
            </p>

            <exercise>
              <p>
                Exercise 50. Show that if <m>F</m> and <m>G</m> are free <m>R</m>-modules on bases <m>\left\{e_{\lambda}\right\}_{\lambda \in \Lambda}</m> and <m>\left\{e_{\gamma}\right\}_{\gamma \in \Gamma}</m>, respectively, then <m>F \otimes_{R} G</m> is the free <m>R</m>-module on basis
              </p>
          
              <p>
                <me>\left\{e_{\lambda} \otimes e_{\gamma} \mid \lambda \in \Lambda, \gamma \in \Gamma\right\}</me>
              </p>
          
              <p>
                In particular,
              </p>
          
              <p>
                <me>R^{n} \otimes R^{m} \cong R^{n m}</me>
              </p>
            </exercise>

            <example>
              <p>
                Example 3.43. Let <m>R</m> be any ring and consider <m>R^{2} \otimes_{R} R^{2}</m>. Let <m>e_{1}=(1,0) \in R^{2}</m> and <m>e_{2}=(0,1) \in R^{2}</m>. We claim that the element <m>e_{1} \otimes e_{2}+e_{2} \otimes e_{1}</m> is not a simple tensor. Suppose, by contradiction, that there exist <m>v, y \in R^{2}</m> such that
              </p>
          
              <p>
                <me>e_{1} \otimes e_{2}+e_{2} \otimes e_{1}=v \otimes w</me>
              </p>
          
              <p>
                Since <m>\left\{e_{1}, e_{2}\right\}</m> is a basis for the free module <m>R^{2}</m>, we can write
              </p>
          
              <p>
                <me>v=v_{1} e_{1}+v_{2} e_{2} \quad \text { and } \quad w=w_{1} e_{1}+w_{2} e_{2}</me>
              </p>
          
              <p>
                Substituting above, we see that
              </p>
          
              <p>
                <me>\begin{aligned}
          v \otimes w &amp; =\left(v_{1} e_{1}+v_{2} e_{2}\right) \otimes\left(w_{1} e_{1}+w_{2} e_{2}\right) \\
          &amp; =v_{1} w_{1} e_{1} \otimes e_{1}+v_{1} w_{2} e_{1} \otimes e_{2}+v_{2} w_{1} e_{2} \otimes e_{1}+v_{2} w_{2} e_{2} \otimes e_{2}
          \end{aligned}</me>
              </p>
          
              <p>
                But by Exercise 50, <m>\left\{e_{1} \otimes e_{1}, e_{1} \otimes e_{2}, e_{2} \otimes e_{1}, e_{2} \otimes e_{2}\right\}</m> is a basis for the free <m>R</m>-module <m>R^{2} \otimes R^{2} \cong R^{4}</m>, so we can now compare coefficients: since
              </p>
          
              <p>
                <me>e_{1} \otimes e_{2}+e_{2} \otimes e_{1}=v_{1} w_{1} e_{1} \otimes e_{1}+v_{1} w_{2} e_{1} \otimes e_{2}+v_{2} w_{1} e_{2} \otimes e_{1}+v_{2} w_{2} e_{2} \otimes e_{2}</me>
              </p>
          
              <p>
                we must have
              </p>
          
              <p>
                <me>\left\{\begin{array} { l } 
          { v _ { 1 } w _ { 1 } = 1 } \\
          { v _ { 1 } w _ { 2 } = 0 } \\
          { v _ { 2 } w _ { 1 } = 0 } \\
          { v _ { 2 } w _ { 2 } = 1 }
          \end{array} \Longrightarrow \left\{\begin{array}{l}
          v_{1} \text { and } w_{1} \text { are units } \\
          v_{1} w_{2}=0 \\
          v_{2} w_{1}=0 \\
          v_{2} \text { and } w_{2} \text { are units }
          \end{array}\right.\right.</me>
              </p>
          
              <p>
                But since <m>v_{1}</m> is a unit and <m>v_{1} w_{2}=0</m>, we must have <m>w_{2}=0</m>; similarly, since <m>v_{2}</m> is a unit and <m>v_{2} w_{1}=0</m>, we must have <m>w_{1}=0</m>. But we have both <m>w_{1}=w_{2}=0</m> and that <m>w_{1}, w_{2}</m> are units, which is a contradiction. We conclude that <m>e_{1} \otimes e_{2}+e_{2} \otimes e_{1}</m> is not a simple tensor.
              </p>
            </example>
        
            <p>
              One of the reasons tensor products are useful is that we can use tensor products to extend module structures to ring extensions.
            </p>

            <remark>
              <p>
                Remark 3.44. Let <m>f: R \rightarrow S</m> be a ring homomorphism. Since <m>S</m> is an <m>(S, R)</m>-bimodule, the abelian group <m>S \otimes_{R} M</m> has a left <m>S</m>-module structure for every left <m>R</m>-module <m>M</m>. Thus <m>S \otimes_{R}</m> - determines a functor from <m>R</m>-modules to <m>S</m>-modules.
              </p>
            </remark>

            <definition xml:id="def-3.45">
              <statement>
                <p>
                  Definition 3.45. Let <m>f: R \rightarrow S</m> be a ring homomorphism. The extension of scalars from <m>R</m> to <m>S</m> is the functor <m>S \otimes_{R}-: R</m>-Mod <m>\longrightarrow S</m>-mod: for each <m>R</m>-module <m>M</m>, we get an <m>S</m>-module <m>S \otimes_{R} M</m> with
                </p>
            
                <p>
                  <me>s \cdot\left(\sum_{i} s_{i} \otimes m_{i}\right):=\sum_{i}\left(s s_{i}\right) \otimes m_{i}</me>
                </p>
            
                <p>
                  and for each <m>R</m>-module homomorphism <m>f: M \rightarrow N</m> we get the <m>S</m>-module homomorphism <m>1 \otimes_{R} f: S \otimes_{R} M \longrightarrow S \otimes_{R} N</m>.
                </p>
              </statement>
            </definition>
        
            <p>
              This functor is closely related to restriction of scalars: we will soon show that restriction and extension of scalars are adjoint functors.
            </p>

            <definition xml:id="def-3.46">
              <statement>
                <p>
                  Definition 3.46. Let <m>f: R \rightarrow S</m> be a ring homomorphism. The restriction of scalars functor from <m>S</m> to <m>R</m> is the functor <m>f^{*}: S</m>-mod <m>\longrightarrow R</m>-Mod that takes each <m>S</m>-module <m>M</m> to the <m>R</m>-module <m>f^{*} M</m> with underlying abelian group <m>M</m> and <m>R</m>-module structure
                </p>
            
                <p>
                  <me>r \cdot m:=f(r) m</me>
                </p>
            
                <p>
                  induced by <m>f</m>. Moreover, for each <m>S</m>-module homomorphism <m>g: M \longrightarrow N</m> we get the <m>R</m> module homomorphism <m>f^{*}(g): f^{*}(M) \longrightarrow f^{*}(N)</m> defined by <m>f^{*}(g)(m):=g(n)</m>.
                </p>
              </statement>
            </definition>

            <exercise>
              <p>
                Exercise 51. Check that restriction of scalars as defined above is indeed a functor.
              </p>
            </exercise>

          </subsection>

          <subsection xml:id="subsec-tensor-right-exact"><title>Tensor is Right Exact</title>
            
            <p>
              Tensor is right exact.
            </p>

            <theorem xml:id="thm-3.47">
              <statement>
                <p>
                  Theorem 3.47. Let <m>M</m> be a right <m>R</m>-module. The functor <m>M \otimes_{R}-</m> is right exact, meaning that for every exact sequence
                </p>
            
                <p>
                  <me>A \stackrel{i}{\longrightarrow} B \stackrel{p}{\longrightarrow} C \longrightarrow 0</me>
                </p>
            
                <p>
                  the sequence
                </p>
            
                <p>
                  <me>M \otimes_{R} A \stackrel{1 \otimes i}{\longrightarrow} M \otimes_{R} B \stackrel{1 \otimes p}{\longrightarrow} M \otimes_{R} C \longrightarrow 0</me>
                </p>
            
                <p>
                  is exact.
                </p>
              </statement>

              <proof>
                <p>
                  Proof. Since additive functors send complexes to complexes, <m>(1 \otimes p)(1 \otimes i)=0</m>. We have two more things to show:
                </p>
                <image source='2023_10_23_e2d6a27704be928b3deeg-098.jpg'/>
                <p>
                  we can find <m>b_{1}, \ldots, b_{n} \in B</m> such that <m>p\left(b_{i}\right)=c_{i}</m>. Therefore,
                </p>
            
                <p>
                  <m>(1 \otimes p)\left(m_{1} \otimes b_{1}+\cdots+m_{n} \otimes b_{n}\right)=m_{1} \otimes p\left(b_{1}\right)+\cdots+m_{n} \otimes p\left(b_{n}\right)=m_{1} \otimes c_{1}+\cdots+m_{n} \otimes c_{n}</m>.
                </p>
            
                <p>
                  <m>\operatorname{ker}(1 \otimes p)=\operatorname{im}(1 \otimes i)</m> : Let <m>I=\operatorname{im}(1 \otimes i)</m>. We have already shown that <m>I \subseteq \operatorname{ker}(1 \otimes p)</m>, so <m>\overline{1 \otimes p \text { induces a map } q}:\left(M \otimes_{R} B\right) / I \longrightarrow M \otimes_{R} C</m>. Let <m>\pi: M \otimes_{R} B \longrightarrow\left(M \otimes_{R} B\right) / I</m> be the canonical projection. By definition, <m>q \pi=1 \otimes p</m>.
                </p>
            
                <p>
                  Consider the map
                </p>
            
                <p>
                  <me>\begin{gathered}
            M \times C \stackrel{f}{\longrightarrow}\left(M \otimes_{R} B\right) / I \\
            (m, c) \longmapsto m \otimes b
            \end{gathered}</me>
                </p>
            
                <p>
                  where <m>b</m> is such that <m>p(b)=c</m>. First, we should check this map <m>f</m> is well-defined. To see that, suppose that <m>b^{\prime} \in B</m> is another element with <m>p\left(b^{\prime}\right)=c</m>, so that <m>p\left(b-b^{\prime}\right)=0</m>. Then <m>b-b^{\prime} \in \operatorname{ker} p=\operatorname{im} i</m>, so <m>m \otimes\left(b-b^{\prime}\right) \in \operatorname{im}(1 \otimes i) \subseteq I</m>. Therefore, <m>m \otimes b=m \otimes b^{\prime}</m> modulo <m>I</m>, and <m>f</m> is well-defined.
                </p>
            
                <p>
                  Moreover, one can check (exercise!) that <m>f</m> is <m>R</m>-biadditive, so it induces a homomorphism of <m>R</m>-modules <m>M \otimes_{R} C \longrightarrow\left(M \otimes_{R} B\right) / I</m>, which we will denote by <m>\hat{f}</m>. We will show that <m>\hat{f}</m> is a left inverse of <m>q</m>, so <m>q</m> is injective. And indeed, given <m>m_{i} \in M</m> and <m>b_{i} \in B</m>, we have
                </p>
            
                <p>
                  <me>\hat{f} q\left(\sum_{i=1}^{n} m_{i} \otimes b_{i}\right)=f\left(\sum_{i=1}^{n} m_{i} \otimes p\left(b_{i}\right)\right)=\sum_{i=1}^{n} f\left(m_{i} \otimes p\left(b_{i}\right)\right)=\sum_{i=1}^{n} m_{i} \otimes b_{i}</me>
                </p>
            
                <p>
                  We conclude that <m>q</m> is injective, and thus
                </p>
            
                <p>
                  <me>\operatorname{ker}(1 \otimes p)=\operatorname{ker}(q \pi)=\operatorname{ker} \pi=I=\operatorname{im}(1 \otimes i)</me>
                </p>
              </proof>
            </theorem>

            <p>
              However, tensor is not exact.
            </p>

            <example>
              <p>
                Example 3.48. Consider the short exact sequence
              </p>
          
              <p>
                <me>0 \longrightarrow \mathbb{Z} \stackrel{i}{\longrightarrow} \mathbb{Q} \stackrel{p}{\longrightarrow} \mathbb{Q} / \mathbb{Z} \longrightarrow 0</me>
              </p>
          
              <p>
                Applying the functor <m>\mathbb{Z} / 2 \otimes_{\mathbb{Z}}-</m>, we get an exact sequence
              </p>
          
              <p>
                <me>\mathbb{Z} / 2 \otimes_{\mathbb{Z}} \mathbb{Z} \stackrel{1 \otimes i}{\longrightarrow} \mathbb{Z} / 2 \otimes_{\mathbb{Z}} \mathbb{Q} \stackrel{1 \otimes p}{\longrightarrow} \mathbb{Z} / 2 \otimes_{\mathbb{Z}} \mathbb{Q} / \mathbb{Z} \longrightarrow 0</me>
              </p>
          
              <p>
                However, we claim that <m>1 \otimes i</m> is not injective. On the one hand, by Lemma 3.40 we have an isomorphism <m>\mathbb{Z} / 2 \otimes_{\mathbb{Z}} \mathbb{Z} \cong \mathbb{Z} / 2 \neq 0</m>. On the other hand, we have seen in Example 3.25 that <m>\mathbb{Z} / 2 \otimes_{\mathbb{Z}} \mathbb{Q}=0</m>, so the map <m>1 \otimes i: \mathbb{Z} / 2 \rightarrow 0</m> cannot possibly be injective.
              </p>
            </example>
        
            <p>
              We can now show that extension of scalars turns an <m>R</m>-module into the <m>S</m>-module with the same presentation.
            </p>

            <remark>
              <p>
                Remark 3.49. Let <m>R</m> be a ring, <m>M</m> be a right <m>R</m>-module, and <m>N</m> be a left <m>R</m>-module. We can compute <m>M \otimes_{R} N</m> by taking a presentation of <m>M</m>
              </p>
          
              <p>
                <me>R^{\oplus \Gamma} \stackrel{\phi}{\longrightarrow} R^{\oplus \Lambda} \longrightarrow M \longrightarrow 0</me>
              </p>
          
              <p>
                and tensoring with <m>N</m> to get
              </p>
          
              <p>
                <me>N^{\oplus \Gamma} \longrightarrow N^{\oplus \Lambda} \longrightarrow M \otimes_{R} N \longrightarrow 0</me>
              </p>
          
              <p>
                so <m>M \otimes_{R} N</m> is the cokernel of the map <m>N^{\oplus \Gamma} \rightarrow N^{\oplus \Lambda}</m> induced by <m>\phi</m>. We can also compute <m>M \otimes_{R} N</m> by taking a presentation of <m>N</m>
              </p>
          
              <p>
                <me>R^{\oplus \Xi} \stackrel{\psi}{\longrightarrow} R^{\oplus \Omega} \longrightarrow N \longrightarrow 0</me>
              </p>
          
              <p>
                and tensoring with <m>M</m> to get
              </p>
          
              <p>
                <me>M^{\oplus \Xi} \longrightarrow M^{\oplus \Omega} \longrightarrow M \otimes_{R} N \longrightarrow 0</me>
              </p>
          
              <p>
                so <m>M \otimes_{R} N</m> is isomorphic to the cokernel of the map <m>M^{\oplus \Gamma} \rightarrow M^{\oplus \Lambda}</m> induced by <m>\psi</m>.
              </p>
            </remark>

          </subsection>
          
        </section>

        <section xml:id="sec-localization"><title>Localization</title>
          
          <p>
            Recall that a multiplicatively closed subset of a <m>\operatorname{ring} R</m> is a set <m>W \ni 1</m> that is closed for products. 
            The three most important classes of multiplicatively closed sets are the following:
          </p>

          <example>
            <p>
              Example 3.50. Let <m>R</m> be a commutative ring.
            </p>
      
            <p><ol>
              <li>
                    <p>
              For any <m>f \in R</m>, the set <m>W=\left\{1, f, f^{2}, f^{3}, \ldots\right\}</m> is a multiplicatively closed set.
            </p>
              </li>
      
              <li>
                    <p>
              If <m>P \subseteq R</m> is a prime ideal, the set <m>W=R \backslash P</m> is multiplicatively closed: this is an immediate translation of the definition.
            </p>
              </li>
      
              <li>
                    <p>
              An element that is not a zerodivisor is called a nonzerodivisor or regular element. The set of regular elements in <m>R</m> forms a multiplicatively closed subset. When <m>R</m> is a domain, this set is precisely the set of all nonzero elements <m>R \backslash\{0\}</m>.
            </p>
              </li>
      
            </ol></p>
          </example>

          <definition xml:id="def-3.51">
            <statement>
              <p>
                Definition 3.51 (Localization of a ring). Let <m>R</m> be a commutative ring, and <m>W</m> be a multiplicative set with <m>0 \notin W</m>. The localization of <m>R</m> at <m>W</m> is a ring, denoted by <m>W^{-1} R</m> or <m>R_{W}</m>, given by where <m>\sim</m> is the equivalence relation
              </p>
        
              <p>
                <me>\frac{r}{w} \sim \frac{r^{\prime}}{w^{\prime}} \text { if there exists } u \in W \text { such that } u\left(r w^{\prime}-r^{\prime} w\right)=0</me>
              </p>
        
              <p>
                The operations are given by
              </p>
        
              <p>
                <me>\frac{r}{v}+\frac{s}{w}=\frac{r w+s v}{v w} \quad \text { and } \quad \frac{r}{v} \frac{s}{w}=\frac{r s}{v w}</me>
              </p>
        
              <p>
                The zero in <m>W^{-1} R</m> is <m>\frac{0}{1}</m> and the multiplcative identity is <m>\frac{1}{1}</m>. There is a canonical ring homomorphism
              </p>
        
              <p>
                <me>\begin{aligned}
        &amp; R \longrightarrow W^{-1} R \\
        &amp; r \longmapsto \frac{r}{1}
        \end{aligned}</me>
              </p>
        
              <p>
                Note that we write elements in <m>W^{-1} R</m> in the form <m>\frac{r}{w}</m> even though they are equivalence classes of such expressions.
              </p>
        
              <p>
                Let <m>M</m> be an <m>R</m>-module. The localization of <m>M</m> at <m>W</m> is the <m>W^{-1} R</m>-module <m>W^{-1} M</m> or <m>M_{W}</m> given by
              </p>
        
              <p>
                <me>W^{-1} M:=\left\{\frac{m}{w} \mid m \in M, w \in W\right\} / \sim</me>
              </p>
        
              <p>
                where <m>\sim</m> is the equivalence relation <m>\frac{m}{w} \sim \frac{m^{\prime}}{w^{\prime}}</m> if <m>u\left(m w^{\prime}-m^{\prime} w\right)=0</m> for some <m>u \in W</m>. The operations are given by
              </p>
        
              <p>
                <me>\frac{m}{v}+\frac{n}{w}=\frac{m w+n v}{v w} \quad \text { and } \quad \frac{r}{v} \frac{m}{w}=\frac{r m}{v w}</me>
              </p>
        
              <p>
                The zero in the module <m>W^{-1} M</m> is given by <m>\frac{0}{1}</m>.
              </p>
            </statement>
          </definition>
    
          <p>
            Here are the most important examples of localizations you will come across in commutative algebra.
          </p>

          <example>
            <p>
              Example 3.52 (Most important localizations). Let <m>R</m> be a commutative ring.
            </p>
      
            <p><ol>
              <li>
                    <p>
              For <m>f \in R</m> and <m>W=\left\{1, f, f^{2}, f^{3}, \ldots\right\}=\left\{f^{n} \mid n \geqslant 0\right\}</m>, we usually write <m>R_{f}</m> for <m>W^{-1} R</m>.
            </p>
              </li>
      
              <li>
                    <p>
              When <m>W</m> is the set of nonzerodivisors on <m>R</m>, we call <m>W^{-1} R</m> the total ring of fractions of <m>R</m>. When <m>R</m> is a domain, this is just the fraction field of <m>R</m>, and in this case this coincides with the localization at the prime <m>(0)</m>, as described below.
            </p>
              </li>
      
              <li>
                    <p>
              For a prime ideal <m>P</m> in <m>R</m>, we generally write <m>R_{P}</m> for <m>(R \backslash P)^{-1} R</m>, and call it the localization of <m>R</m> at <m>P</m>. Given an ideal <m>I</m> in <m>R</m>, we sometimes write <m>I_{P}</m> to refer to <m>I R_{P}</m>, the image of <m>I</m> via the canonical map <m>R \rightarrow R_{P}</m>. Notice that when we localize at a prime <m>P</m>, the resulting ring is a local ring <m>\left(R_{P}, P_{P}\right)</m>. We can think of the process of localization at <m>P</m> as zooming in at the prime <m>P</m>. Many properties of an ideal <m>I</m> can be checked locally, by checking them for <m>I R_{P}</m> for each prime <m>P \in V(I)</m>.
            </p>
              </li>
      
            </ol></p>
          </example>

          <remark>
            <p>
              Remark 3.53. If <m>R</m> is a domain, the equivalence relation defining the localization simplifies to <m>r w^{\prime}=r^{\prime} w</m>. In particular, <m>\operatorname{Frac}(R)=R_{(0)}=(R \backslash\{0\})^{-1} R</m> is a localization of <m>R</m>.
            </p>
          </remark>
    
          <p>
            If <m>R</m> is not a domain, the canonical map <m>R \rightarrow W^{-1} R</m> is not necessarily injective.
          </p>

          <example>
            <p>
              Example 3.54. Consider <m>R=k[x, y] /(x y)</m>. The canonical maps <m>R \longrightarrow R_{(x)}</m> and <m>R \longrightarrow R_{y}</m> are not injective, since in both cases <m>y</m> is invertible in the localization, and thus
            </p>
      
            <p>
              <me>x \mapsto \frac{x}{1}=\frac{x y}{y}=\frac{0}{y}=\frac{0}{1}</me>
            </p>
          </example>
    
          <p>
            In <m>W^{-1} R</m>, every element of <m>W</m> becomes a unit. The following universal property says roughly that <m>W^{-1} R</m> is the smallest <m>R</m>-algebra in which every element of <m>W</m> is a unit.
          </p>

          <theorem xml:id="thm-3.55">
            <statement>
              <p>
                Theorem 3.55. 
                Let <m>R</m> be a commutative ring, and <m>W</m> a multiplicative set with <m>0 \notin W</m>. Let <m>S</m> be an <m>R</m>-algebra in which every element of <m>W</m> is a unit. Then there is a unique homomorphism <m>\alpha</m> such that the following diagram commutes:
              </p>
        
              <image source="2023_10_23_e2d6a27704be928b3deeg-101.jpg"/>
        
              <p>
                where the vertical map is the structure homomorphism and the horizontal map is the canonical homomorphism.
              </p>
            </statement>

            <proof>
              <p>
                Proof. Given an <m>R</m>-algebra <m>S</m> such that every element of <m>W</m> is a unit, where the algebra structure is induced by the ring homomorphism <m>f: R \rightarrow S</m>, consider the map
              </p>
        
              <p>
                <me>
                  \begin{aligned}
                  &amp; W^{-1} R \longrightarrow S \\
                  &amp; \quad \frac{r}{w} \longmapsto f(w)^{-1} f(r) .
                  \end{aligned}
                </me>
              </p>
        
              <p>
                First, note that our assumption that every element of <m>W</m> is invertible in <m>S</m> means that <m>f(w)</m> is invertible in <m>S</m>, and thus <m>f(w)^{-1} f(r)</m> makes sense. Moreover, we claim that <m>\alpha</m> is a ring homomorphism:
              </p>
        
              <p>
                <me>\alpha(1)=f(1)^{-1} f(1)=1</me>
              </p>
        
              <p>
                and moreover
              </p>
        
              <p>
                <me>
                  \begin{aligned}
                  \alpha\left(\frac{a}{u} \frac{b}{v}\right) \alpha &amp; \left(\frac{a b}{u v}\right) \\
                  &amp; =f(u v)^{-1} f(a b) \\
                  &amp; =\left(f(u)^{-1} f(a)\right)\left(f(v)^{-1} f(b)\right) \\
                  &amp; =\alpha\left(\frac{a}{u}\right)\left(\frac{b}{v}\right)
                  \end{aligned}
                </me>
              </p>
        
              <p>
                and
              </p>
        
              <p>
                <me>
                  \begin{aligned}
                  \alpha\left(\frac{a}{u}+\frac{b}{v}\right) &amp; \alpha\left(\frac{a v+b u}{u v}\right) \\
                  &amp; =f(u v)^{-1} f(a v+b u) \\
                  &amp; =\left(f(u)^{-1} f(v)^{-1}\right)(f(a) f(v)+f(b) f(u)) \\
                  &amp; =\left(f(u)^{-1} f(a)+\left(f(v)^{-1} f(b)\right.\right. \\
                  &amp; =\alpha\left(\frac{a}{u}\right)+\left(\frac{b}{v}\right)
                  \end{aligned}
                </me>
              </p>
        
              <p>
                Our definition of <m>\alpha</m> gives us
              </p>
        
              <p>
                <me>\alpha\left(\frac{r}{1}\right)=f(1)^{-1} f(r)=f(r)</me>
              </p>
        
              <p>
                as desired. Moreover, if <m>\beta: W^{-1} R \rightarrow S</m> is any ring homomorphism such that
              </p>
        
              <p>
                <me>\beta\left(\frac{r}{1}\right)=f(1)^{-1} f(r)=f(r)</me>
              </p>
        
              <p>
                then
              </p>
        
              <p>
                <me>\beta\left(\frac{r}{s}\right)=\beta\left(\frac{s}{1}\right)^{-1} \beta\left(\frac{r}{1}\right)=f(s)^{-1} f(r)=\alpha\left(\frac{s}{1}\right)^{-1} \alpha\left(\frac{r}{1}\right)=\alpha\left(\frac{r}{s}\right)</me>
              </p>
        
              <p>
                This proves our uniqueness claim.
              </p>
            </proof>
          </theorem>

          <definition xml:id="def-3.56">
            <statement>
              <p>
                Definition 3.56. Let <m>R</m> be a commutative ring and let <m>W</m> be a multiplicative subset of <m>R</m>. The localization at <m>W</m> is the functor <m>R</m>-Mod <m>\rightarrow W^{-1} R</m>-mod that sends each <m>R</m>-module <m>M</m> to the <m>W^{-1} R</m>-module <m>W^{-1} M</m>, and that sends each <m>R</m>-module homomorphism <m>f: M \rightarrow N</m> to the homomorphism of <m>W^{-1} R</m>-modules given by
              </p>
        
              <p>
                <me>
                  \begin{gathered}
                  W^{-1} M \longrightarrow W^{-1} N \\
                  \frac{m}{w} \longmapsto \frac{f(m)}{w}
                  \end{gathered}
                </me>
              </p>
        
              <p>
                We might denote this functor by <m>W^{-1}(-)</m> or <m>(-)_{W}</m>. When <m>W</m> is the complement of a prime ideal <m>P</m>, we write the localization at <m>P</m> as <m>(-)_{P}</m>.
              </p>
            </statement>
          </definition>

          <exercise>
            <p>
              Exercise 52. Show that for all <m>R</m>-module homomorphisms <m>f: M \rightarrow N</m>,
            </p>
      
    
            <image source="2023_10_23_e2d6a27704be928b3deeg-102.jpg"/>
              
      
            <p>
              is a homomorphism of modules over <m>W^{-1} R</m>.
            </p>
          </exercise>

          <exercise>
            <p>
              Exercise 53. Show that localization is an exact additive functor.
            </p>
          </exercise>

          <theorem xml:id="thm-3.57">
            <statement>
              <p>
                Theorem 3.57. Let <m>R</m> be a commutative ring, and <m>W \ni 1</m> a multiplicative subset of <m>R</m>. Then the localization at <m>W</m> and <m>W^{-1} R \otimes-</m> are naturally isomorphic functors. In particular, for every <m>R</m>-module <m>M</m>, there is an isomorphism of <m>W^{-1} R</m>-modules
              </p>
        
              <p>
                <me>W^{-1} R \otimes_{R} M \cong W^{-1} M</me>
              </p>
        
              <p>
                and given an <m>R</m>-module map <m>\alpha: M \rightarrow N</m>, the map of <m>W^{-1} R</m>-modules <m>W^{-1} R \otimes \alpha</m> corresponds to <m>W^{-1} \alpha=\alpha_{W}</m> under these isomorphisms.
              </p>
            </statement>

            <proof>
              <p>
                Proof. The bilinear map <m>\quad W^{-1} R \times M \longrightarrow W^{-1} M</m>
              </p>
        
              <p>
                <me>\left(\frac{r}{w}, m\right) \longmapsto \frac{r m}{w}</me>
              </p>
        
              <p>
                induces a homomorphism <m>\psi: W^{-1} R \times M \rightarrow W^{-1} M</m> that is surjective.
              </p>
        
              <p>
                For an inverse map, set <m>\phi\left(\frac{m}{w}\right):=\frac{1}{w} \otimes m</m>. To see this is well-defined, suppose <m>\frac{m}{w}=\frac{m^{\prime}}{w^{\prime}}</m>, so there exists some <m>v \in W</m> such that <m>v\left(m w^{\prime}-m^{\prime} w\right)=0</m>. Then,
              </p>
        
              <p>
                <me>\phi\left(\frac{m}{w}\right)-\phi\left(\frac{m^{\prime}}{w^{\prime}}\right)=\frac{1}{w} \otimes m-\frac{1}{w^{\prime}} \otimes m^{\prime}</me>
              </p>
        
              <p>
                We can multiply through by <m>\frac{v w w^{\prime}}{v w w^{\prime}}</m> to get
              </p>
        
              <p>
                <me>\frac{v w^{\prime}}{v w w^{\prime}} \otimes m-\frac{v w}{v w w^{\prime}} \otimes m^{\prime}=\frac{1}{v w w^{\prime}} \otimes v\left(m w^{\prime}-m^{\prime} w\right)=0</me>
              </p>
        
              <p>
                To see this is a homomorphism, we note that
              </p>
        
              <p>
                <me>
                  \begin{aligned}
                  \phi\left(\frac{m}{w}+\frac{m^{\prime}}{w^{\prime}}\right) &amp; =\phi\left(\frac{m w^{\prime}+m^{\prime} w}{w w^{\prime}}\right)=\frac{1}{w w^{\prime}} \otimes\left(m w^{\prime}+m^{\prime} w\right)=\frac{1}{w w^{\prime}} \otimes m w^{\prime}+\frac{1}{w w^{\prime}} \otimes m^{\prime} w \\
                  &amp; =\frac{w^{\prime}}{w w^{\prime}} \otimes m+\frac{w}{w w^{\prime}} \otimes m^{\prime}=\frac{1}{w} \otimes m+\frac{1}{w^{\prime}} \otimes m^{\prime}=\phi\left(\frac{m}{w}\right)+\phi\left(\frac{m^{\prime}}{w^{\prime}}\right)
                  \end{aligned}
                </me>
              </p>
        
              <p>
                and
              </p>
        
              <p>
                <me>\phi\left(r \frac{m}{w}\right)=\frac{1}{w} \otimes r m=r\left(\frac{1}{w} \otimes m\right)=r \phi\left(\frac{m}{w}\right)</me>
              </p>
        
              <p>
                The composition <m>\phi \circ \psi</m> sends
              </p>
        
              <p>
                <me>\frac{r}{w} \otimes m \mapsto \frac{r m}{w} \mapsto \frac{1}{w} \otimes r m=\frac{r}{w} \otimes m</me>
              </p>
        
              <p>
                Since this is the identity on simple tensors, and simple tensors generated the tensor product, it must be the identity.
              </p>
        
              <p>
                For the claim about maps, we need check that <m>\psi_{N} \circ\left(W^{-1} R \otimes \alpha\right)=W^{-1} \alpha \circ \psi_{M}</m> for every <m>R</m>-module homomorphism <m>\alpha !: M \rightarrow N</m>. And indeed,
              </p>
        
              <p>
                <me>
                  \begin{aligned}
                  \left(\psi_{N} \circ\left(W^{-1} R \otimes \alpha\right)\right)\left(\frac{r}{w} \otimes m\right) &amp; =\psi_{N}\left(\frac{r}{w} \otimes \alpha(m)\right)=\frac{r \alpha(m)}{w} \\
                  &amp; =\frac{\alpha(r m)}{w}=W^{-1} \alpha\left(\frac{r m}{w}\right)=\left(W^{-1} \alpha \circ \psi_{M}\right)\left(\frac{r}{w} \otimes m\right)
                  \end{aligned}
                </me>
              </p>
        
              <p>
                Finally, we note that our isomorphisms <m>W^{-1} R \otimes_{R} M \cong W^{-1} M</m> give a natural isomorphism between the localization functor <m>W^{-1}(-)</m> and the tensor functor <m>W^{-1} R \otimes_{R}-</m>. Indeed, given a map of <m>R</m>-modules <m>M \stackrel{f}{\rightarrow} N</m>, the diagram
              </p>
        
              <image source="2023_10_23_e2d6a27704be928b3deeg-104(1).jpg"/>
                
              <p>
                commutes, since it commutes for simple tensors:
              </p>
      
              <image source="2023_10_23_e2d6a27704be928b3deeg-104.jpg"/>
        
              <p>
                Now since localization is exact, we conclude that <m>W^{-1} R \otimes_{R}-</m> is an exact functor for all commutative rings <m>R</m> and all multiplicatively closed subsets <m>W</m>.
              </p>
            </proof>
          </theorem>

          <exercise>
            <p>
              Exercise 54. Let <m>R</m> be a commutative noetherian ring, <m>W</m> be a multiplicative set, <m>M</m> be a finitely generated <m>R</m>-module, and <m>N</m> an arbitrary <m>R</m>-module. Show that
            </p>
      
            <p>
              <me>\operatorname{Hom}_{W^{-1} R}\left(W^{-1} M, W^{-1} N\right) \cong W^{-1} \operatorname{Hom}_{R}(M, N) .</me>
            </p>
      
            <p>
              In particular, if <m>P</m> is prime,
            </p>
      
            <p>
              <me>\operatorname{Hom}_{R_{P}}\left(M_{P}, N_{P}\right) \cong \operatorname{Hom}_{R}(M, N)_{P}</me>
            </p>
          </exercise>
    
          <p>
            Localization is a very powerful tool in commutative algebra. Many important concepts localize well, in the sense that to prove that <m>R</m> or a module satisfy a certain property, it is often sufficient to show that all localizations of <m>R</m> or of that module also have that property. This is a very common and helpful technique in commutative algebra. For example, a module <m>M</m> is zero if and only if all its localizations are zero; one can even reduce to showing all localizations of <m>M</m> at a prime ideal are zero.
          </p>
    
          <p>
            One important thing to keep in mind, however, is that if <m>M</m> is a finitely generated <m>R</m> module, a localization <m>M_{W}</m> of <m>M</m> is typically not finitely generated over <m>R</m>, though it is finitely generated over <m>R_{W}</m>.
          </p>

          <exercise>
            <p>
              Exercise 55. Let <m>R</m> be a domain and let <m>f \in R</m> be a nonzero nonunit. Then <m>R_{f}</m> is not a finitely generated <m>R</m>-module.
            </p>
          </exercise>
    
          <p>
            To solve this exercise, however, one needs a little bit of commutative algebra that we are not covering in this course.
          </p>

        </section>

        <section xml:id="sec-hom-tensor"><title>Hom-Tensor Adjunction</title>

          <p>
            The Hom and tensor functors are closely related. First, we note that <m>\operatorname{Hom}_{R}(A, B)</m> can be a module over a ring <m>S</m> when <m>A</m> or <m>B</m> have a bimodule structure.
          </p>

          <exercise>
            <p>
              Exercise 56. Let <m>R</m> and <m>S</m> be rings.
            </p>
      
            <p><ul>
              <li>
                    <p>
              If <m>A</m> is an <m>(R, S)</m>-bimodule and <m>B</m> is a left <m>R</m>-module, then <m>\operatorname{Hom}_{R}(A, B)</m> has a left <m>S</m>-module structure via <m>(s \cdot f)(a)=f(a s)</m>.
            </p>
              </li>
      
              <li>
                    <p>
              If <m>A</m> is an <m>(R, S)</m>-bimodule and <m>B</m> is a right <m>S</m>-module, then <m>\operatorname{Hom}_{R}(A, B)</m> has a right <m>R</m>-module structure via <m>(f \cdot r)(a)=f(r a)</m>.
            </p>
              </li>
      
              <li>
                    <p>
              If <m>B</m> is an <m>(S, R)</m>-bimodule and <m>A</m> is a right <m>R</m>-module, then <m>\operatorname{Hom}_{R}(A, B)</m> has a left <m>S</m>-module structure via <m>(s \cdot f)(a)=s f(a)</m>.
            </p>
              </li>
      
              <li>
                    <p>
              If <m>B</m> is an <m>(S, R)</m>-bimodule and <m>A</m> is a left <m>S</m>-module, then <m>\operatorname{Hom}_{R}(A, B)</m> has a right <m>R</m>-module structure via <m>(f \cdot r)(a)=f(a) r</m>.
            </p>
              </li>
      
            </ul></p>
          </exercise>
    
          <p>
            These structures can be a bit confusing at first - especially since we have left module structures written on the right and vice-versa. While the exercise is not difficult, it can be extremely enlightening - we strongly recommend the reader tries their hand at the details.
          </p>
    
          <p>
            The following statements are known as Hom-tensor adjunction - and as we will see, they do encode an adjunction of functors.
          </p>

          <theorem xml:id="thm-3.58">
            <statement>
              <p>
                Theorem 3.58. Let <m>R</m> and <m>S</m> be rings. Assume that
              </p>
        
              <p><ul>
                <li>
                      <p>
                <m>A</m> is a right <m>R</m>-module,
              </p>
                </li>
        
                <li>
                      <p>
                <m>B</m> is an <m>(R, S)</m>-bimodule, and
              </p>
                </li>
        
                <li>
                      <p>
                <m>C</m> is a right <m>S</m>-module.
              </p>
                </li>
        
              </ul></p>
        
              <p>
                There is a natural isomorphism of abelian groups
              </p>
        
              <p>
                <me>\operatorname{Hom}_{S}\left(A \otimes_{R} B, C\right) \cong \operatorname{Hom}_{R}\left(A, \operatorname{Hom}_{S}(B, C)\right)</me>
              </p>
        
              <p>
                If <m>A</m> also has a <m>(T, R)</m>-bimodule structure, or <m>C</m> has a <m>(T, S)</m>-bimodule structure, then this is an isomorphism of (left or right, respectively) <m>T</m>-modules.
              </p>
            </statement>
          </theorem>

          <theorem xml:id="thm-3.59">
            <statement>
              <p>
                Theorem 3.59. Let <m>R</m> and <m>S</m> be rings. Assume that
              </p>
        
              <p><ul>
                <li>
                      <p>
                <m>A</m> is a left <m>R</m>-module,
              </p>
                </li>
        
                <li>
                      <p>
                <m>B</m> is an <m>(S, R)</m>-bimodule, and
              </p>
                </li>
        
                <li>
                      <p>
                <m>C</m> is a left <m>S</m>-module.
              </p>
                </li>
        
              </ul></p>
        
              <p>
                There is a natural isomorphism of abelian groups
              </p>
        
              <p>
                <me>\operatorname{Hom}_{S}\left(B \otimes_{R} A, C\right) \cong \operatorname{Hom}_{R}\left(A, \operatorname{Hom}_{S}(B, C)\right)</me>
              </p>
            </statement>
          </theorem>
    
          <p>
            We leave the details to the reader, and prove the case when the underlying rings are commutative. First, let's do the case when <m>R=S</m>.
          </p>

          <theorem xml:id="thm-3.60">
            <statement>
              <p>
                Theorem 3.60 (Hom-tensor adjunction I). Let <m>R</m> be a commutative ring and let <m>M, N</m>, and <m>P</m> be <m>R</m>-modules. There is an isomorphism of <m>R</m>-modules
              </p>
        
              <p>
                <me>\operatorname{Hom}_{R}\left(M \otimes_{R} N, P\right) \cong \operatorname{Hom}_{R}\left(M, \operatorname{Hom}_{R}(N, P)\right)</me>
              </p>
        
              <p>
                that is natural on <m>M, N</m>, and <m>P</m>.
              </p>
            </statement>

            <proof>
              <p>
                Proof. The universal property of the tensor product says that to give an <m>R</m>-module homomorphism <m>M \otimes_{R} N \longrightarrow P</m> is the same as giving an <m>R</m>-bilinear map <m>M \times N \longrightarrow P</m>. Given such a bilinear map <m>f</m>, the map <m>n \mapsto f(m \otimes n)</m> is <m>R</m>-linear for each <m>m \in M</m>, so it defines an <m>R</m>-module homomorphism <m>N \longrightarrow P</m>. Now the assignment
              </p>
        
              <p>
                <me>
                  \begin{aligned}
                  &amp; M \longrightarrow \operatorname{Hom}_{S}(N, P) \\
                  &amp; m \longrightarrow(n \mapsto f(m \otimes n))
                  \end{aligned}
                </me>
              </p>
        
              <p>
                is <m>R</m>-linear, <m>f</m> is an <m>R</m>-module homomorphism, and <m>m \mapsto m \otimes n</m> is <m>R</m>-linear on <m>m</m>.
              </p>
        
              <p>
                Conversely, given an <m>R</m>-module homomorphism <m>f \in \operatorname{Hom}_{R}\left(M, \operatorname{Hom}_{R}(N, P)\right)</m>, one can check (exercise!) that <m>(m, n) \mapsto f(m)(n)</m> is an <m>R</m>-bilinear map, so it induces an <m>R</m>-module homomorphism <m>M \otimes_{R} N \longrightarrow P</m>. Moreover, the two constructions are inverse to each other.
              </p>
        
              <p>
                So we have constructed a bijection of Hom-sets
              </p>
        
              <p>
                <me>
                  \begin{gathered}
                  \operatorname{Hom}_{R}\left(M \otimes_{R} N, P\right) \stackrel{\tau}{\longrightarrow} \operatorname{Hom}_{R}\left(M, \operatorname{Hom}_{R}(N, P)\right) . \\
                  f \longmapsto(m \mapsto(n \mapsto f(m \otimes n))) \\
                  (m \otimes n \mapsto g(m)(n)) \longleftrightarrow g
                  \end{gathered}
                </me>
              </p>
        
              <p>
                It's routine to check that both of these bijections are indeed homomorphisms of <m>R</m>-modules, so we leave it as an exercise.
              </p>
        
              <p>
                Finally, naturality means we have the following commutative diagrams:
              </p>
        
              <image source="2023_10_23_e2d6a27704be928b3deeg-106(1).jpg"/>
                
              <p>
                and
              </p>
      
              <image source="2023_10_23_e2d6a27704be928b3deeg-106.jpg"/>
                
              <p>
                We leave checking these do indeed commute as an exercise.
              </p>
            </proof>
          </theorem>

          <corollary xml:id="cor-3.61">
            <statement>
              <p>
                Corollary 3.61 (Tensor and Hom are adjoint functors). Let <m>R</m> be a commutative ring, and <m>M</m> an <m>R</m>-module. The functor <m>-\otimes_{R} M: R</m>-Mod <m>\longrightarrow R</m>-Mod is left adjoint to the functor <m>\operatorname{Hom}_{R}(M,-): R</m>-Mod <m>\longrightarrow R</m>-Mod.
              </p>
            </statement>

            <proof>
              <p>
                Proof. The adjointness translates into the fact that for all <m>R</m>-modules <m>N</m> and <m>P</m> there is a bijection
              </p>
        
              <p>
                <me>\operatorname{Hom}_{R}\left(N \otimes_{R} M, P\right) \cong \operatorname{Hom}_{R}\left(N, \operatorname{Hom}_{R}(M, P)\right)</me>
              </p>
        
              <p>
                which is natural on <m>N</m> and <m>P</m>, which is a corollary of Theorem 3.60.
              </p>
            </proof>
          </corollary>
    
          <p>
            Later, when we talk about more general abelian categories, we will see that this adjunction implies that Hom is left exact and that tensor is right exact; in fact, this is a more general fact about adjoint pairs. For now, we want to discuss a more general version of this Hom-tensor adjunction.
          </p>

          <theorem xml:id="thm-3.62">
            <statement>
              <p>
                Theorem 3.62 (Hom-tensor adjunction II). Let <m>f: R \rightarrow S</m> be a ring homomorphism of commutative rings. Let <m>M</m> be an <m>R</m>-module, and <m>P</m> and <m>N</m> be <m>S</m>-modules. There is an isomorphism of abelian groups
              </p>
        
              <p>
                <me>\operatorname{Hom}_{S}\left(M \otimes_{R} N, P\right) \cong \operatorname{Hom}_{R}\left(M, \operatorname{Hom}_{S}(N, P)\right) .</me>
              </p>
        
              <p>
                Moreover, this isomorphism is natural on <m>M, N</m>, and <m>P</m>, so it induces natural isomorphisms
              </p>
        
              <p><ul>
                <li>
                      <p>
                between <m>\operatorname{Hom}_{S}\left(-\otimes_{R} N, P\right)</m> and <m>\operatorname{Hom}_{R}\left(-, \operatorname{Hom}_{S}(N, P)\right)</m>.
              </p>
                </li>
        
                <li>
                      <p>
                between <m>\operatorname{Hom}_{S}\left(M \otimes_{R}-, P\right)</m> and <m>\operatorname{Hom}_{R}\left(M, \operatorname{Hom}_{S}(-, P)\right)</m>.
              </p>
                </li>
        
                <li>
                      <p>
                between <m>\operatorname{Hom}_{S}\left(M \otimes_{R} N,-\right)</m> and <m>\operatorname{Hom}_{R}\left(M, \operatorname{Hom}_{S}(N,-)\right)</m>.
              </p>
                </li>
        
              </ul></p>
            </statement>

            <proof>
              <p>
                Proof. Consider the map
              </p>
        
              <p>
                <me>
                  \begin{array}{r}
                  \operatorname{Hom}_{S}\left(M \otimes_{R} N, P\right) \stackrel{\tau}{\longrightarrow} \operatorname{Hom}_{R}\left(M, \operatorname{Hom}_{S}(N, P)\right) \\
                  f \longmapsto m \mapsto(n \mapsto f(m \otimes n))
                  \end{array}
                </me>
              </p>
        
              <p>
                Fix <m>f</m>. For each <m>m \in M</m>, let <m>\tau_{m}</m> be the map <m>N \longrightarrow P</m> defined by <m>\tau_{m}(n):=f(m \otimes n)</m>. Note that <m>\tau_{m}</m> is indeed a homomorphism of <m>S</m>-modules, since it is the composition of two <m>S</m>-module maps, <m>f</m> and <m>m \otimes_{R} \operatorname{id}_{N}</m>, where <m>m</m> is the constant map <m>M \longrightarrow M</m> equal to <m>m</m>.
              </p>
        
              <p>
                We should check that our proposed map <m>\tau</m> is indeed a map of abelian groups. It is immediate from the definition that <m>\tau</m> sends the 0-map to the 0-map. Moreover, given <m>S</m> module homomorphisms <m>f, g: M \otimes N \longrightarrow P</m>, and any <m>n \in N</m>, we have
              </p>
        
              <p>
                <me>
                  \begin{array}{rlr}
                  \tau_{m}(f+g)(n) &amp; =(f+g)(m \otimes n) &amp; \text { by definition } \\
                  &amp; =f(m \otimes n)+g(m \otimes n) &amp; \text { since } f \text { and } g \text { are } S \text {-module maps } \\
                  &amp; =\tau_{m}(f)(n)+\tau_{m}(g)(n) &amp; \text { by definition }
                  \end{array}
                </me>
              </p>
        
              <p>
                so <m>\tau_{m}(f+g)=\tau_{m}(f)+\tau_{m}(g)</m> for all <m>m \in M</m>, and thus <m>\tau(f+g)=\tau(f)+\tau(g)</m>.
              </p>
        
              <p>
                Suppose that <m>\tau(f)=0</m>. Then for every <m>m \in M</m> and every <m>n \in N</m>,
              </p>
        
              <p>
                <me>0=\tau(f)(m)(n)=\tau_{m}(f)(n)=f(m \otimes n)</me>
              </p>
        
              <p>
                so <m>f</m> vanishes at every simple tensor, and we must have <m>f=0</m>. On the other hand, if we are given <m>g \in \operatorname{Hom}_{R}\left(M, \operatorname{Hom}_{S}(N, P)\right)</m>, consider the map <m>M \times N \longrightarrow P</m> defined by <m>\tilde{f}(m, n)=g(m)(n)</m>. Since <m>g</m> is a homomorphism of <m>R</m>-modules, it is <m>R</m>-linear on <m>m</m>. Moreover, for each fixed <m>m, g(m)</m> is a homomorphism of <m>S</m>-modules, so in particular <m>g(m)</m> is <m>R</m>-linear. Together, these say that <m>\tilde{f}</m> is an <m>R</m>-bilinear map. Let <m>f</m> be the homomorphism of <m>R</m>-modules <m>M \otimes_{R} N \longrightarrow P</m> induced by <m>\tilde{f}</m>. By definition, <m>f(m \otimes n)=\tilde{f}(m, n)=g(m)(n)</m>, so <m>\tau(f)=g</m>. We conclude that <m>\tau</m> is a bijection.
              </p>
        
              <p>
                We leave the statements about naturality as exercises.
              </p>
            </proof>
          </theorem>

          <corollary xml:id="cor-3.63">
            <statement>
              <p>
                Corollary 3.63 (Adjointness of restriction and extension of scalars). Let <m>f R \longrightarrow S</m> be <m>a</m> ring homomorphism. The restriction of scalars functor <m>f^{*}: S</m>-Mod <m>\longrightarrow R</m>-Mod is the right adjoint of the extension of scalars functor <m>f_{*}: R</m>-Mod <m>\longrightarrow S</m>-Mod.
              </p>
            </statement>

            <proof>
              <p>
                Proof. We need to show that for every <m>R</m>-module <m>M</m> and every <m>S</m>-module <m>N</m> there are bijections
              </p>
        
              <p>
                <me>\operatorname{Hom}_{S}\left(f_{*}(M), N\right) \cong \operatorname{Hom}_{R}\left(M, f^{*}(N)\right)</me>
              </p>
        
              <p>
                which are natural on both <m>M</m> and <m>N</m>. By Theorem 3.62, we have natural bijections
              </p>
        
              <p>
                <me>\operatorname{Hom}_{S}\left(M \otimes_{R} S, N\right) \cong \operatorname{Hom}_{R}\left(M, \operatorname{Hom}_{S}(S, N)\right)</me>
              </p>
        
              <p>
                The module <m>M \otimes_{R} S</m> is precisely <m>f_{*}(M)</m>. By Exercise <m>38, \operatorname{Hom}_{S}(S, N) \cong N</m> as an <m>S</m>-module. An isomorphism of <m>S</m>-modules <m>\operatorname{Hom}_{S}(S, N) \longrightarrow N</m> is in particular an <m>R</m>-linear map, and thus also an isomorphism of <m>R</m>-modules. So <m>\operatorname{Hom}_{S}(S, N) \cong f^{*}(N)</m> as <m>R</m>-modules. Therefore, the Hom-tensor adjuntion gives us the natural bijections we were looking for.
              </p>
            </proof>
          </corollary>
    
          <p>
            The idea is that restriction of scalars and extension of scalars are the most efficient ways of making an <m>R</m>-module out of an <m>S</m>-module, and vice-versa.
          </p>
          
        </section>
        
      </chapter>

      <chapter xml:id="ch-proj-inj"><title>Projectives and Injectives</title>

        <section xml:id="sec-projective"><title>Projective Modules</title>
          <p></p>
        </section>

        <section xml:id="sec-injective"><title>Injective Modules</title>
          <p></p>
        </section>

        <section xml:id="sec-flat"><title>Flat Modules</title>
          <p></p>
        </section>
        
      </chapter>

    </part>

    <backmatter xml:id="backmatter">
      <title>Backmatter</title>

      <colophon>
        <p> This book was authored in <pretext />. </p>
      </colophon>

    </backmatter>

  </book>
</pretext>
