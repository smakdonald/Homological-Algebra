<?xml version='1.0' encoding='utf-8'?>

<pretext xml:lang="en-US" xmlns:xi="http://www.w3.org/2001/XInclude">

  <docinfo>

    <!-- the other option is "long" which will produce an -->
    <!-- entire front matter section with more headings   -->
    <author-biographies length="short" />

    <!--
    <brandlogo url="http://abstract.pugetsound.edu" source="images/cover_aata_2014.png" />
    -->

    <!--
    <covers front="images/original-front-cover-aata.pdf"
            back="images/plain-back-cover-aata.pdf"/>
    -->

    <!-- Prefix to enhance Sage notebook contents -->
    <!--
    <initialism>AATA</initialism>
    -->

    <macros>
        <!-- Operators     -->
        \def\ann{\operatorname{ann}}
        \newcommand{\Ass}{\operatorname{Ass}}
        \def\Aut{\operatorname{Aut}}
        \def\can{{\mathrm {can}}}
        \def\char{\operatorname{char}}
        \def\cp{\operatorname{CharPoly}}
        \def\codim{\operatorname{codim}} 
        \def\coker{\operatorname{coker}}
        \DeclareMathOperator*{\colim}{colim} 
        \def\cont{\operatorname{cont}} 
        \def\diam{\operatorname{diam}} 
        \def\dm{\operatorname{dim}} 
        \DeclareMathOperator{\edim}{embdim} 
        \def\End{\operatorname{End}} 
        \def\eval{\operatorname{eval}} 
        \def\Ext{\operatorname{Ext}} 
        \def\Frac{\operatorname{Frac}}
        \def\Fun{\operatorname{Fun}}
        \def\Gal{\operatorname{Gal}}
        \def\gcd{\operatorname{gcd}}
        \newcommand{\GL}{\operatorname{GL}} 
        \newcommand{\ht}{\operatorname{height}} 
        \def\Hom{\operatorname{Hom}} 
        \def\id{\operatorname{id}} 
        \def\im{\operatorname{im}} 
        \def\Inn{\operatorname{Inn}}
        \def\ker{\operatorname{ker}}
        \def\lcm{\operatorname{lcm}} 
        \def\Mat{\operatorname{Mat}}
        \newcommand{\Min}{\operatorname{Min}}
        \def\mp{\operatorname{MinPoly}}
        \def\mSpec{\operatorname{mSpec}}
        \def\MSpec{\operatorname{MSpec}}
        \def\null{\operatorname{Nul}}
        \DeclareMathOperator{\ns}{nullspace}
        \newcommand{\opp}{\operatorname{opp}}
        \def\Orb{\operatorname{Orb}} 
        \def\Out{\operatorname{Out}}
        \def\Perm{\operatorname{Perm}}
        \def\ptstab{\operatorname{PtStab}} 
        \def\rad{\operatorname{rad}}
        \DeclareMathOperator{\range}{range}
        \def\rank{\operatorname{rank}}
        \def\res{\operatorname{res}}
        \def\setstab{\operatorname{SetStab}}
        \def\sign{{\operatorname{sign}}}
        \newcommand{\SL}{\operatorname{SL}}
        \def\Span{\operatorname{Span}}
        \def\Spec{\operatorname{Spec}}
        \def\Stab{\operatorname{Stab}} 
        \DeclareMathOperator{\Supp}{Supp}
        \def\Syl{\operatorname{Syl}}
        \def\Tor{\operatorname{Tor}}
        \def\trace{\operatorname{trace}}
        \def\uSpec{\operatorname{\underline{Spec}}}
        <!-- Categories     -->
        \newcommand{\Ob}{\mathrm{Ob}}
        \newcommand{\Set}{\mathbf{Set}}
        \newcommand{\Grp}{\mathbf{Grp}}
        \newcommand{\Ab}{\mathbf{Ab}}
        \newcommand{\Sgrp}{\mathbf{Sgrp}}
        \newcommand{\Ring}{\mathbf{Ring}} 
        \newcommand{\Fld}{\mathbf{Fld}}
        \newcommand{\cRing}{\mathbf{cRing}}
        \newcommand{\Mod}{-\mathbf{Mod}}
        \newcommand{\mod}{-\mathbf{mod}} 
        \newcommand{\Cx}[1]{#1-\mathbf{Comp}} 
        \newcommand{\vs}[1]{#1-\mathbf{vect}}
        \newcommand{\Vs}[1]{#1-\mathbf{Vect}}
        \newcommand{\vsp}[1]{#1-\mathbf{vect}^+} 
        \newcommand{\Top}{\mathbf{Top}} 
        \newcommand{\Setp}{\mathbf{Set}_*} 
        \newcommand{\Alg}[1]{#1-\mathbf{Alg}} 
        \newcommand{\cAlg}[1]{#1-\mathbf{cAlg}} 
        \newcommand{\PO}{\mathbf{PO}}
        \newcommand{\Cont}{\mathrm{Cont}}
        \newcommand{\MaT}[1]{\mathbf{Mat}_{#1}}
        \newcommand{\Rep}[2]{\mathbf{Rep}_{#1}(#2)}
        <!-- Greek     -->
        \def\l{\lambda}
        \def\lx{\lambda_x}
        \newcommand{\a}{\alpha}
        \def\b{\beta}
        \def\d{\delta}
        \def\e{\varepsilon}
        \def\g{\gamma}
        \def\t{\theta}
        \def\s{\sigma}
        \def\z{\zeta}
        \def\vp{\varphi}
        <!-- Letters     -->
        <!-- MathBB     -->
        \newcommand{\A}{\mathbb{A}}
        \newcommand{\B}{\mathbb{B}}
        \newcommand{\C}{\mathbb{C}}
        \newcommand{\D}{\mathbb{D}}
        \newcommand{\E}{\mathbb{E}}
        \newcommand{\F}{\mathbb{F}}
        \newcommand{\G}{\mathbb{G}}
        \newcommand{\H}{\mathbb{H}}
        \newcommand{\I}{\mathbb{I}}
        \newcommand{\J}{\mathbb{J}}
        \newcommand{\K}{\mathbb{K}}
        \newcommand{\L}{\mathbb{L}} 
        \newcommand{\M}{\mathbb{M}}
        \newcommand{\N}{\mathbb{N}}
        \newcommand{\O}{\mathbb{O}}
        \newcommand{\P}{\mathbb{P}}
        \newcommand{\Q}{\mathbb{Q}} 
        \newcommand{\R}{\mathbb{R}} 
        \newcommand{\S}{\mathbb{S}}
        \newcommand{\T}{\mathbb{T}}
        \newcommand{\U}{\mathbb{U}}
        \newcommand{\V}{\mathbb{V}}
        \newcommand{\W}{\mathbb{W}}
        \newcommand{\X}{\mathbb{X}}
        \newcommand{\Y}{\mathbb{Y}}
        \newcommand{\Z}{\mathbb{Z}} 
        \newcommand{\ON}{\mathbb{ON}}
        <!-- MathCal     -->
        \def\cA{\mathcal A} 
        \def\cB{\mathcal B} 
        \def\cC{\mathcal C} 
        \def\cD{\mathcal D} 
        \def\cE{\mathcal E} 
        \def\cF{\mathcal F} 
        \def\cG{\mathcal G} 
        \def\cH{\mathcal H} 
        \def\cI{\mathcal I} 
        \def\cJ{\mathcal J} 
        \def\cK{\mathcal K} 
        \def\cL{\mathcal L}
        \def\cM{\mathcal M} 
        \def\cN{\mathcal N} 
        \def\cO{\mathcal O} 
        \def\cP{\mathcal P} 
        \def\cQ{\mathcal Q} 
        \def\cR{\mathcal R} 
        \def\cS{\mathcal S} 
        \def\cT{\mathcal T} 
        \def\cU{\mathcal U} 
        \def\cV{\mathcal V} 
        \def\cW{\mathcal W} 
        \def\cX{\mathcal X} 
        \def\cY{\mathcal Y} 
        \def\cZ{\mathcal Z} 
        <!-- MathFrak     -->
        \newcommand{\fa}{{\mathfrak a}} 
        \newcommand{\fb}{{\mathfrak b}} 
        \newcommand{\fc}{{\mathfrak c}} 
        \newcommand{\fd}{{\mathfrak d}} 
        \newcommand{\fe}{{\mathfrak e}}
        \newcommand{\fm}{{\mathfrak m}} 
        \newcommand{\fp}{{\mathfrak p}} 
        \newcommand{\fq}{{\mathfrak q}} 
        \newcommand{\fK}{{\mathfrak K}} 
        \newcommand{\fR}{{\mathfrak R}} 
        <!-- MathScr     -->
        \def\sA{\mathscr A} 
        \def\sB{\mathscr B} 
        \def\sC{\mathscr C} 
        \def\sD{\mathscr D} 
        \def\sE{\mathscr E} 
        \def\sF{\mathscr F} 
        \def\sG{\mathscr G} 
        \def\sH{\mathscr H} 
        \def\sI{\mathscr I} 
        \def\sJ{\mathscr J} 
        \def\sK{\mathscr K} 
        \def\sL{\mathscr L}
        \def\sM{\mathscr M}
        \def\sN{\mathscr N}
        \def\sO{\mathscr O}
        \def\sP{\mathscr P}
        \def\sQ{\mathscr Q}
        \def\sR{\mathscr R}
        \def\sS{\mathscr S}
        \def\sT{\mathscr T}
        \def\sU{\mathscr U}
        \def\sV{\mathscr V}
        \def\sW{\mathscr W}
        \def\sX{\mathscr X}
        \def\sY{\mathscr Y}
        \def\sZ{\mathscr Z}
        <!-- Tildes     -->
        \def\tS{\tilde{S}}
        <!-- Algebra     -->
        \def\sdp{\rtimes}
        \newcommand{\tensor}{\otimes} 
        \newcommand{\igen}[1]{\langle #1 \rangle} 
        \def\nsg{\unlhd} 
        \def\kval{{k-\mathrm{valued}}} 
        \def\kalg{{k-\mathrm{alg}}}
        \newcommand\GG[2]{\Gal(#1/#2)}
        <!-- Matrices     -->
        \newcommand{\MF}[3]{\Mat_{#1\times #2}(#3)}
        \newcommand{\vectwo}[2]{\begin{bmatrix} #1 \\ #2 \end{bmatrix}} 
        \newcommand{\vecthree}[3]{\begin{bmatrix} #1 \\ #2 \\ #3\end{bmatrix}} 
        \def\ob{{\mathfrak{ob}} }
        <!-- Misc     -->
        \def\qed{\square}
        \def\sse{\subseteq}
        \def\ss{\subset} 
        \def\ssne{\subsetneq}
        \def\sm{\setminus}
        \def\inv{^{-1}} 
        \newcommand{\es}{\emptyset} 
        \newcommand{\Zm}[1]{\Z/({#1})} 
        \def\ov#1{\overline{#1}} 
        \def\xdots{x_1, \dots, x_n} 
        \def\adots{a_1, \dots, a_n} 
        \def\bdots{b_1, \dots, b_n} 
        \def\udots{u_1, \dots, u_n} 
        \newcommand{\leg}[2]{\left(\frac{{#1}}{{#2}}\right)} 
        \def\th{^{th}} 
        \def\htpy{\simeq_{\mathrm{htpc}}} 
        <!-- Math Text     -->
        \def\textand{ \, \text{and} \, } 
        \def\textor{ \, \text{or} \, } 
        \def\textfor{ \, \text{for} \, } 
        \def\textfa{ \, \text{for all} \, } 
        \def\textst{ \, \text{such that} \, } 
        \def\textin{ \, \text{in} \, } 
        \def\fg{ \, \text{finitely generated} \, }
        \newcommand{\op}{\mathrm{op}}
        <!-- Arrows     -->
        \newcommand{\xra}[1]{\xrightarrow{#1}} 
        \newcommand{\xora}[1]{\xtwoheadrightarrow{#1}} 
        \newcommand{\xira}[1]{\xhookrightarrow{#1}} 
        \newcommand{\xla}[1]{\xleftarrow{#1}} 
        \def\lra{\longrightarrow}
        \def\into{\hookrightarrow}
        \def\onto{\twoheadrightarrow}
        <!-- Vectors     -->
        \newcommand{\vv}[1]{\mathbf{#1}}
        \newcommand{\lm}[2]{{#1}\,\l + {#2}\,\mu} 
        \renewcommand{\v}{\vv{v}}
        \renewcommand{\u}{\vv{u}}
        \newcommand{\w}{\vv{w}}
        \newcommand{\x}{\vv{x}}
        \renewcommand{\k}{\vv{k}}
        \newcommand{\0}{\vv{0}}
        \newcommand{\1}{\vv{1}}
        \newcommand{\vecs}[2]{#1_1,#1_2,\dots,#1_{#2}}
        \newcommand{\us}[1][n]{\vecs{\u}{#1}}
        \newcommand{\vs}[1][n]{\vecs{\v}{#1}}
        \newcommand{\ws}[1][n]{\vecs{\w}{#1}}
        \newcommand{\vps}[1][n']{\vecs{\v'}{#1}}
        \newcommand{\ls}[1][n]{\vecs{\l}{#1}}
        \newcommand{\mus}[1][n]{\vecs{\mu}{#1}} 
        \newcommand{\lps}[1][n]{\vecs{\l'}{#1}}
        \def\td{\tilde{\delta}}
        \def\oo{\overline{\omega}}
        \def\ctJ{\tilde{\mathcal J}}
        \def\tPhi{\tilde{\Phi}}
        \def\te{\tilde{e}}
        \def\M{\operatorname{M}}
        \newcommand{\homotopic}{\simeq}
        \newcommand{\homeq}{\cong}
        \newcommand{\iso}{\approx}
        \newcommand{\dual}{\vee} 
        \DeclarePairedDelimiter{\abs}{|}{|}
        \newcommand{\bv}{{\bar{v}}}
        \newcommand{\bu}{{\bar{u}}}
        \newcommand{\bw}{{\bar{w}}}
        \newcommand{\by}{{\bar{y}}}
        \newcommand{\ba}{{\bar{a}}}
        \newcommand{\bb}{{\bar{b}}}
        \newcommand{\bx}{{\bar{x}}}
        \DeclarePairedDelimiterX\setof[2]{\{}{\}}{#1\,|\,#2}
        \newcommand{\vx}{\underline{x}}
        \renewcommand{mod}[1]{\text{(mod }{#1})}
        \newcommand{\Slv}[3]{\sum_{{#2}=1}^{{#3}} {#1}_{{#2}} \v_{{#2}}}
    </macros>

    <!-- this is the default, but supresses a warning -->
    <cross-references text="type-global" />

    <!-- tikz package and libraries for images -->
    <latex-image-preamble>
      \usepackage{tikz}
      \usetikzlibrary{backgrounds}
      \usetikzlibrary{snakes}
      \usepackage{tkz-graph}
      \usepackage{tkz-euclide}
      \usetikzlibrary{patterns}
      \usetikzlibrary{positioning}
      \usetikzlibrary{matrix,arrows}
      \usetikzlibrary{calc}
      \usetikzlibrary{shapes}
      \usetikzlibrary{through,intersections,decorations,shadows,fadings}
      
      \usepackage{pgfplots}
    </latex-image-preamble>

    <rename element="inlineexercise">Exercise</rename>
    <rename element="outcomes">Summary</rename>
    <rename element="objectives">Reminders and Recollections</rename>

  </docinfo>

  <book xml:id="book-homological"><title>Homological Algebra</title>

    <frontmatter xml:id="frontmatter">

      <titlepage>
        <author>
          <personname>Sam Macdonald</personname>
          <department>Department of Mathematics</department>
          <institution>University of Nebraska -- Lincoln</institution>
        </author>
        <date>
          <today />
        </date>
      </titlepage>

      <colophon>
        <website>
          <url href="https://smakdonald.github.io/index.html" visual="">smakdonald.github</url>
        </website>

        <copyright>
          <year>2020<ndash />2023</year>
          <holder>Sam Macdonald</holder>
          <shortlicense> 
            This work is licensed under the Creative Commons Attribution-ShareAlike 4.0 International License. To view a copy of this license, visit <url href="http://creativecommons.org/licenses/by-sa/4.0/" visual="creativecommons.org/licenses/by-sa/4.0"> CreativeCommons.org</url>
          </shortlicense>
        </copyright>
      </colophon>

    </frontmatter>

    <part xml:id="part-homalg"><title>Homological Algebra</title>

      <chapter xml:id="ch-intro"><title>Where are we going?</title>

        <paragraphs><title>Chain Complexes and Short Exact Sequences</title>
          
          <p>
            Homological algebra first appeared in the study of topological spaces. 
            Roughly speaking, homology is a way of associating a sequence of abelian groups (or modules, or other more sophisticated algebraic objects) to another object, for example a topological space. 
            The homology of a topological space encodes topological information about the space in algebraic language - this is what algebraic topology is all about.
          </p>
      
          <p>
            More formally, we will study complexes and their homology from a more abstract perspective. 
            While algebraic topologists are often concerned with complexes of abelian groups, we will work a bit more generally with complexes of <m>R</m>-modules. 
            The basic assumptions and notation about rings and modules we will use in this class can be found in Appendix A. 
            As an appetizer, we begin with some basic homological algebra definitions.
          </p>

          <definition xml:id="def-chain-complex"><title>Chain Complex</title>
            <statement>
              <p>
                A <em>chain complex</em> of <m>R</m>-modules <m>\left(C_{\bullet}, \partial_{\bullet}\right)</m>, also referred to simply as a <em>complex</em>, is a sequence of <m>R</m>-modules <m>C_{i}</m> and <m>R</m>-module homomorphisms
                <me>
                  \cdots \longrightarrow C_{n+1} \stackrel{\partial_{n+1}}{\longrightarrow} C_{n} \stackrel{\partial_{n}}{\longrightarrow} C_{n-1} \longrightarrow \cdots
                </me>
                such that <m>\partial_{n} \partial_{n+1}=0</m> for all <m>n</m>. 
                The maps <m>\partial_{n}</m> are the <em>differentials</em> of our complex.
                <idx><h>chain complex</h></idx>
                <idx><h>differential</h></idx>
              </p>
            </statement>
          </definition>

          <convention>
            <p>
              We may sometimes omit the differentials <m>\partial_{n}</m> and simply refer to the complex <m>C_{\bullet}</m> or even <m>C</m>; 
              we may also sometimes refer to <m>\partial_{\bullet}</m> as the differential of <m>C_{\bullet}</m>.
            </p>
          </convention>

          <definition xml:id="def-ses"><title>Exact Sequences</title>
            <statement>
              <p>
                The complex <m>\left(C_{\bullet}, \partial_{\bullet}\right)</m> is exact at <m>n</m> if im <m>\partial_{n+1}=\operatorname{ker} \partial_{n}</m>. 
                An exact sequence is a complex that is exact everywhere. 
                More precisely, an exact sequence of <m>R</m>-modules is a sequence
                <me>
                  \cdots \stackrel{f_{n-1}}{\longrightarrow} C_{n} \stackrel{f_{n}}{\longrightarrow} C_{n+1} \stackrel{f_{n+1}}{\longrightarrow} \cdots
                </me>
                of <m>R</m>-modules and <m>R</m>-module homomorphisms such that <m>\operatorname{im} f_{n}=\operatorname{ker} f_{n+1}</m> for all <m>n</m>. 
                An exact sequence of the form
                <me>
                  0 \longrightarrow A \longrightarrow B \longrightarrow C \longrightarrow 0
                </me>
                is a short exact sequence, sometimes written ses.
                <idx><h>exact sequence</h></idx>
                <idx><h>short exact sequence</h></idx>
              </p>
            </statement>
          </definition>

          <exercise xml:id="rem-0.2">
            <statement>
              <p>
                The condition that <m>\partial_{n} \partial_{n+1}=0</m> for all <m>n</m> implies that <m>\im \partial_{n+1} \subseteq \operatorname{ker} \partial_{n}</m>.
              </p>
            </statement>
          </exercise>
      
          <theorem xml:id="thm-0.4">
            <p>
              The sequence
              <me>
                0 \longrightarrow M \stackrel{f}{\longrightarrow} N
              </me>
              is exact if and only if <m>f</m> is injective. 
              Similarly,
              <me>
                M \stackrel{f}{\longrightarrow} N \longrightarrow 0
              </me>
              is exact if and only if <m>f</m> is surjective. 
              So
              <me>
                0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0
              </me>
              is a short exact sequence if and only if
              <ul>
                <li>
                  <p>
                    <m>f</m> is injective
                  </p>
                </li>
        
                <li>
                  <p>
                    <m>g</m> is surjective
                  </p>
                </li>
          
                <li>
                  <p>
                    <m>\operatorname{im} f=\operatorname{ker} g</m>.
                  </p>
                </li>
              </ul>
            </p>
          </theorem>
      
          <p>
            When this is indeed a short exact sequence, we can identify <m>A</m> with its image <m>f(A)</m>, and <m>A=\operatorname{ker} g</m>. 
            Moreover, since <m>g</m> is surjective, by the First Isomorphism Theorem we conclude that <m>C \cong B / f(A)</m>, so we might abuse notation and identify <m>C</m> with <m>B / A</m>.
          </p>

          <convention>
            <p>
              We write <m>A \rightarrow B</m> to denote a surjective map, and <m>A \hookrightarrow B</m> to denote an injective map.
            </p>
          </convention>

          <definition xml:id="def-cokernel"><title>Cokernel</title>
            <statement>
              <p>
                The cokernel of a map of <m>R</m>-modules <m>A \stackrel{f}{\rightarrow} B</m> is the module
                <me>
                  \text { coker } f:=B / \operatorname{im}(f).
                </me>
              </p>
            </statement>
          </definition>

          <exercise xml:id="rem-0.7">
            <p>
              We can rephrase <xref ref="thm-0.4"/> in a fancier language: if
              <me>
                0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0
              </me>
              is a short exact sequence, then <m>A=\operatorname{ker} g</m> and <m>C=\operatorname{coker} f</m>.
            </p>
          </exercise>

          <example>
            <p>
              Let <m>\pi</m> be the canonical projection <m>\mathbb{Z} \longrightarrow \mathbb{Z} / 2 \mathbb{Z}</m>. 
              The following is a short exact sequence:
              <me>
                0 \longrightarrow \mathbb{Z} \stackrel{2}{\longrightarrow} \mathbb{Z} \stackrel{\pi}{\longrightarrow} \mathbb{Z} / 2 \mathbb{Z} \longrightarrow 0
              </me>
            </p>
          </example>

          <example>
            <p>
              Let <m>R=k[x]</m> be a polynomial ring over the field <m>k</m>. 
              The following is a short exact sequence:
              <me>
                0 \longrightarrow R \stackrel{\cdot x}{\longrightarrow} R \stackrel{\pi}{\longrightarrow} R /\igen x \longrightarrow 0 \text {. }
              </me>
            </p>
        
            <p>
              The first map is multiplication by <m>x</m>, and the second map is the canonical projection.
            </p>
          </example>

          <example>
            <p>
              Given an ideal <m>I</m> in a ring <m>R</m>, the inclusion map <m>\iota: I \rightarrow R</m> and the canonical projection <m>\pi: R \rightarrow R / I</m> give us the following short exact sequence:
              <me>
                0 \longrightarrow I \stackrel{\iota}{\longrightarrow} R \stackrel{\pi}{\longrightarrow} R / I \longrightarrow 0
              </me>
            </p>
          </example>

          <example>
            <p>
              Let <m>R=k[x] /\igen x</m>. 
              The following complex is exact:
            </p>
        
            <p>
              <me>
                \cdots \longrightarrow R \stackrel{\cdot x}{\longrightarrow} R \stackrel{\cdot x}{\longrightarrow} R \longrightarrow \cdots
              </me>
            </p>
        
            <p>
              Indeed, the image and the kernel of multiplication by <m>x</m> are both <m>\igen x</m>.
            </p>
          </example>
      
          <p>
            Sometimes we can show that certain modules vanish or compute them explicitly when they do not vanish by seeing that they fit in some naturally constructed exact sequence involving other modules we understand better. 
            We will discuss this in more detail when we talk about long exact sequences.
          </p>

          <remark>
            <p>
              The complex <m>0 \longrightarrow M \stackrel{f}{\longrightarrow} N \longrightarrow 0</m> is exact if and only if <m>f</m> is an isomorphism.
            </p>
          </remark>

          <remark>
            <p>
              The complex <m>0 \longrightarrow M \longrightarrow 0</m> is exact if and only if <m>M=0</m>.
            </p>
          </remark>

        </paragraphs>

        <paragraphs><title>Homology</title>
    
          <p>
            Historically, chain complexes first appeared in topology. 
            To study a topological space, one constructs a particular chain complex that arises naturally from information from the space, and then calculates its homology, which ends up encoding important topological information in the form of a sequence of abelian groups.
          </p>

          <definition xml:id="def-homology"><title>Homology</title>
            <statement>
              <p>
                The homology of the complex <m>\left(C_{\bullet}, \partial_{\bullet}\right)</m> is the sequence of <m>R</m>-modules
                <me>
                  \mathrm{H}_{n}\left(C_{\bullet}\right)=\mathrm{H}_{n}(C):=\frac{\operatorname{ker} \partial_{n}}{\operatorname{im} \partial_{n+1}} .
                </me>
              </p>
          
              <p>
                The <m>n</m>th homology of <m>\left(C_{\bullet}, \partial_{\bullet}\right)</m> is <m>\mathrm{H}_{n}(C)</m>. 
              </p>
            </statement>
          </definition>

          <convention>
            <p>
              The submodules <m>Z_{n}\left(C_{\bullet}\right)=Z_{n}(C):=\operatorname{ker} \partial_{n} \subseteq C_{n}</m> are sometimes called <em>cycles</em>, while the submodules <m>B_{n}\left(C_{\bullet}\right)=B_{n}(C):=\operatorname{im} \partial_{n+1} \subseteq C_{n}</m> are sometimes called <em>boundaries</em>. 
              One sometimes uses the word boundary to refer an element of <m>B_{n}(C)</m> (an <m>n</m>-boundary), and the word cycle to refer to an element of <m>Z_{n}(C)</m> (an <m>n</m>-cycle).
            </p>
          </convention>

          <remark>
            <p>
              The homology of a complex measures how far our complex is from being exact at each point. 
              Again, we can talk about the cohomology of a cochain complex instead, which we write as <m>\mathrm{H}^{n}(C)</m>; we will for now not worry about the distinction.
            </p>
          </remark>

          <exercise xml:id="rem-0.15">
            <p>
              Note that <m>\left(C_{\bullet}, \partial_{\bullet}\right)</m> is exact at <m>n</m> if and only if <m>\mathrm{H}_{n}\left(C_{\bullet}\right)=0</m>. 
            </p>
          </exercise>

          <example>
            <p>
              Let <m>R=k[x] /\igen{x^3}</m>. 
              Consider the following complex:
              <me>
                F_{\bullet}=\cdots \longrightarrow R \stackrel{\cdot x^{2}}{\longrightarrow} R \stackrel{\cdot x^{2}}{\longrightarrow} R \longrightarrow \cdots .
              </me>
              The image of multiplication by <m>x^{2}</m> is <m>\igen{x^2}</m>, while the the kernel of multiplication by <m>x^{2}</m> is <m>\igen{x} \supseteq\igen{x^2}</m>. 
              For all <m>n</m>,
              <me>
                \mathrm{H}_{n}\left(F_{\bullet}\right)=\igen{x} /\igen{x^2} \cong R /\igen{x}
              </me>
            </p>
          </example>

          <example>
            <p>
              Let <m>\mathbb{Z} \stackrel{\pi}{\longrightarrow} \mathbb{Z} / 2 \mathbb{Z}</m> be the canonical projection map. 
              Then
            </p>
            <image source="2023_08_28_614593e69373955f3addg-07.jpg" width="50%"/>
            <p>
              is a complex of abelian groups, since the image of multiplication by <m>4</m> is <m>4 \mathbb{Z}</m>, and that is certainly contained in <m>\operatorname{ker} \pi=2 \mathbb{Z}</m>. 
              The homology of <m>C</m> is
              <me>
                \begin{array}{ll}
                \mathrm{H}_{n}(C)=0 &amp; \text { for } n \geqslant 3 \\
                \mathrm{H}_{2}(C)=\frac{\operatorname{ker}(\mathbb{Z} \stackrel{4}{\rightarrow} \mathbb{Z})}{\operatorname{im}(0 \longrightarrow \mathbb{Z})}=\frac{0}{0}=0 &amp; \\
                \mathrm{H}_{1}(C)=\frac{\operatorname{ker}(\mathbb{Z} \stackrel{\pi}{\rightarrow} \mathbb{Z} / 2 \mathbb{Z})}{\operatorname{im}(\mathbb{Z} \stackrel{4}{\rightarrow} \mathbb{Z})}=\frac{2 \mathbb{Z}}{4 \mathbb{Z}} \cong \mathbb{Z} / 2 \mathbb{Z} &amp; \\
                \mathrm{H}_{0}(C)=\frac{\operatorname{ker}(\mathbb{Z} / 2 \mathbb{Z} \longrightarrow 0)}{\operatorname{im}(\mathbb{Z} \longrightarrow \mathbb{Z} / 2 \mathbb{Z})}=\frac{\mathbb{Z} / 2 \mathbb{Z}}{\mathbb{Z} / 2 \mathbb{Z}}=0 &amp; \text { for } n&lt;0 \\
                \mathrm{H}_{n}(C)=0 &amp;
                \end{array}
              </me>
            </p>
        
            <p>
              Notice that our complex is exact at <m>2</m> and <m>0</m>. 
              The exactness at <m>2</m> says that the map <m>\mathbb{Z} \stackrel{4}{\rightarrow} \mathbb{Z}</m> is injective, while exactness at <m>0</m> says that <m>\pi</m> is surjective.
            </p>
          </example>
      
          <p>
            Before we can continue any further into the world of homological algebra, we will need some categorical language. 
            We will take a short break to introduce category theory, and then armed with that knowledge we will be ready to study homological algebra.
          </p>

        </paragraphs>

      </chapter>

      <chapter xml:id="ch-categories"><title>Categories for the Working Homological Algebraist</title>

        <introduction>
          <p>
            Most fields in modern mathematics follow the same basic recipe: there is a main type of object one wants to study - groups, rings, modules, topological spaces, etc - and a natural notion of arrows between these - group homomorphisms, ring homomorphisms, module homomorphisms, continuous maps, etc. 
            The objects are often sets with some extra structure, and the arrows are often maps between the objects that preserve whatever that extra structure is. 
            Category theory is born of this realization, by abstracting the basic notions that make math and studying them all at the same time. 
            How many times have we felt a sense of déjà vu when learning about a new field of math? Category theory unifies all those ideas we have seen over and over in different contexts.
          </p>

          <p>
            Category theory is an entire field of mathematics in its own right. 
            As such, there is a lot to say about category theory, and unfortunately it doesn't all fit in the little time we have to cover it in this course. 
            You are strongly encouraged to learn more about category theory, for example from [ML98] or [Rie17].
          </p>
      
          <p>
            Before we go any further, note that there is a long and fun story about why we use the word collection when describing the objects in a category. 
            Not all collections are allowed to be sets, an issue that was first discovered by Russel with his famous Russel's Paradox. 
            <fn>The collection of all sets that don't contain themselves cannot be a set. Do you see why? </fn>
            Russel exposed the fact that one has to be careful with how we formalize set theory. 
            We follow the ZFC (Zermelo-Fraenkel with choice, short for the Zermelo-Fraenkel axioms plus the Axiom of Choice) axiomatization of set theory, and while we will not discuss the details of this formalization here, you are encouraged to read more on the subject.
          </p>
        </introduction>

        <section xml:id="sec-categories"><title>Categories</title>

          <objectives>
            <ul>
              <li>
                
              </li>
            </ul>
          </objectives>

          <subsection xml:id="subsec-cat"><title>Definition and First Examples</title>

            <blockquote>
              <p>
                <q>
                  We'll only use as much category theory as is necessary. Famous last words...
                </q>
              </p>
              <attribution>Roman Abramovich</attribution>
            </blockquote>
          
            <p>
              A category consists of a collection of objects and arrows or morphisms between those objects. 
              While these are often sets and some kind of functions between them, beware that this will not always be the case. 
              We will use the words morphism and arrows interchangeably, though arrow has the advantage of reminding us we are not necessarily talking about functions.
            </p>

            <definition xml:id="def-category"><title>Category</title>
              <statement>
                <p>
                  A <em>category</em> <m>\mathscr{C}</m> consists of three different pieces of data:
                  <ul>
                    <li>
                      <p>
                        a collection of <em>objects</em>, <m>\mathbf{ob}(\mathscr{C}),</m>
                      </p>
                    </li>

                    <li>
                      <p>
                        for each two objects, say <m>A</m> and <m>B</m>, a collection <m>\operatorname{Hom}_{\mathscr{C}}(A, B)</m> of <em>arrows</em> or <em>morphisms</em> from <m>A</m> to <m>B</m>, and
                      </p>
                    </li>
          
                    <li>
                      <p>
                        for each three objects <m>A, B</m>, and <m>C</m>, a <em>composition</em>
                      </p>
                  
                      <p>
                        <me>
                          \begin{gathered}
                          \operatorname{Hom}_{\mathscr{C}}(A, B) \times \operatorname{Hom}_{\mathscr{C}}(B, C) \longrightarrow \operatorname{Hom}_{\mathscr{C}}(A, C) . \\
                          (f, g) \longmapsto g \circ f
                          \end{gathered}
                        </me>
                      </p>
                    </li>
                  </ul>
                  </p>
          
                <p>
                  We will often drop the <m>\circ</m> and write simply <m>gf</m> for <m>g \circ f</m>.
                </p>
          
                <p>
                  These ingredients satisfy the following axioms:
                  <ol>
                    <li>
                      <p>
                        The <m>\operatorname{Hom}_{\mathscr{C}}(A, B)</m> are all disjoint. 
                        In particular, if <m>f</m> is an arrow in <m>\mathscr{C}</m>, we can talk about its <em>source</em> <m>A</m> and its <em>target</em> <m>B</m> as the objects such that <m>f \in \operatorname{Hom}_{\mathscr{C}}(A, B)</m>.
                      </p>
                    </li>
            
                    <li>
                      <p>
                        For each object <m>A</m>, there is an <em>identity arrow</em> <m>1_{A} \in \operatorname{Hom}_{\mathscr{C}}(A, A)</m> such that <m>1_{A} \circ f=f</m> and <m>g \circ 1_{A}=g</m> for all <m>f \in \operatorname{Hom}_{\mathscr{C}}(B, A)</m> and all <m>g \in \operatorname{Hom}_{\mathscr{C}}(A, B)</m>.
                      </p>
                    </li>
            
                    <li>
                      <p>
                        Composition is <em>associative</em>: <m>f \circ(g \circ h)=(f \circ g) \circ h</m> for all appropriately chosen arrows.
                      </p>
                    </li>
                  </ol>
                </p>
              </statement>
            </definition>

            <convention>
              <p>
                We sometimes write <m>f: A \rightarrow B</m> or <m>A \stackrel{f}{\rightarrow} B</m> for an arrow <m>f \in \operatorname{Hom}(A, B)</m>.
              </p>
            </convention>

            <exercise xml:id="exp-unique-id-morphism"><title>Unique Identity Morphism</title>
              <statement>
                <p>
                  Every object in a category has a unique identity morphism.
                </p>
              </statement>
            </exercise>

            <p>
              Here are some categories you have likely encountered before:
            </p>

            <example xml:id="ex-categories"><title>Categories</title>
              <p>
                <ol>
                  <li>
                    <p>
                      The category <m>\Set</m> with objects all sets and arrows all functions between sets.
                    </p>
                  </li>
            
                  <li>
                    <p>
                      The category <m>\Grp</m> whose objects are the collection of all groups, and whose arrows are all the homomorphisms of groups.
                      The identity arrows are the identity homomorphisms.
                    </p>
                  </li>
            
                  <li>
                    <p>
                      The category <m>\mathbf{Ab}</m> with objects all abelian groups, and arrows the homomorphisms of abelian groups. 
                      The identity arrows are the identity homomorphisms.
                    </p>
                  </li>
            
                  <li>
                    <p>
                      The category <m>\Ring</m> of rings and ring homomorphisms. 
                      Contrary to what you may expect, this is not nearly as important as the next one.
                    </p>
                  </li>
            
                  <li>
                    <p>
                      The category <m>R</m><m>\mod</m> of modules over a fixed ring <m>R</m> and with <m>R</m>-module homomorphisms. 
                      Sometimes one writes <m>R</m><m>\Mod</m> for this category, and reserve <m>R</m><m>\mod</m> for the category of finitely generated <m>R</m>-modules with <m>R</m><m>\Mod</m>ule homomorphisms. 
                      When <m>R=k</m> is a field, the objects in the category <m>k</m>-Mod are <m>k</m>-vector spaces, and the arrows are linear transformations; 
                      we may instead refer to this category as Vect-<m>k</m>.
                    </p>
                  </li>
            
                  <li>
                    <p>
                      The category Top of topological spaces and continuous functions. 
                      One may consider many variations of the categories above. 
                      Here are some variations on vector spaces:
                    </p>
                  </li>
                </ol>
              </p>
            </example>

            <p>
              While the collections of objects and arrows might not actually be sets, sometimes they are.
            </p>

            <definition xml:id="def-locally-small"><title>Locally Small</title>
              <statement>
                <p>
                  A category <m>\mathscr{C}</m> is <em>locally small</em> if for all objects <m>A</m> and <m>B</m> in <m>\mathscr{C}, \operatorname{Hom}_{\mathscr{C}}(A, B)</m> is a set. 
                  A category <m>\mathscr{C}</m> is <em>small</em> if it is locally small and the collection of all objects in <m>\mathscr{C}</m> is a set.
                </p>
              </statement>
            </definition>
        
            <p>
              In fact, one can define a small category as one where the collection of all arrows is a set. 
              It follows immediately that the collection of all objects is also a set, since it must be a subset of the set of arrows - for each object, there is an identity arrow.
            </p>

            <p>
              Many important categories are at least locally small. 
            </p>

            <example>
              <p>
                <m>\Set</m> is locally small but not small. 
              </p>
            </example>

            <definition xml:id="def-concrete">
              <statement>
                <p>
                  Categories where the objects are sets with some extra structure and the arrows are some kind of functions between the objects are called concrete.
                </p>
              </statement>
            </definition>

            <p>
              All of the categories we have seen thus far have been conctrete, but this is not the case in general.
            </p>

            <example xml:id="non-concrete-categories"><title>Non-Concrete Categories</title>
              <p>
                <ol>
                  <li xml:id="ex-poset-category">
                    <p>
                      Given a partially ordered set <m>(X, \leqslant)</m>, we can regard <m>X</m> itself as a category: 
                      the objects are the elements of <m>X</m>, and for each <m>x</m> and <m>y</m> in <m>X, \operatorname{Hom}_{X}(x, y)</m> is either a singleton if <m>x \leqslant y</m> or empty if <m>x \neq y</m>. 
                      There is only one possible way to define composition, and the transitive property of <m>\leqslant</m> guarantees that the composition of arrows is indeed well-defined: 
                      if there is an arrow <m>i \rightarrow j</m> and an arrow <m>j \rightarrow k</m>, then <m>i \leqslant j</m> and <m>j \leqslant k</m>, so <m>i \leqslant k</m> and thus there is a unique arrow <m>i \rightarrow k</m>. 
                      This category is locally small, since all nonempty Hom-sets are in fact singletons. 
                      It is in fact small, since the objects are by construction the set <m>X</m>.
                    </p>
                  </li>

                  <li xml:id="poset-categories-2"><title><m>\mathbf{n}</m> Category</title>
                    <p>
                      For each positive integer <m>n</m>, the category <m>\mathbf{n}</m> has <m>n</m> objects <m>0,1, \ldots, n-1</m> and <m>\operatorname{Hom}(i, j)</m> is either empty if <m>i&gt;j</m> or a singleton if <m>i \leqslant j</m>. 
                      As <xref ref="ex-poset-category"/>, composition is defined in the only way possible, and things work out. 
                      This is the poset category for the poset <m>(\{0,1, \ldots, n-1\}, \leqslant)</m> with the usual <m>\leqslant</m>.
                    </p>
                  </li>

                  <li xml:id="ex-mat-category"><title>Matrix Category</title>
                    <p>
                      Fix a field <m>k</m>. 
                      We define a category Mat-<m>k</m> with objects all positive integers, and given two positive integers <m>a</m> and <m>b</m>, the <m>\operatorname{Hom}</m>-set <m>\operatorname{Hom}(a, b)</m> consists of all <m>b \times a</m> matrices with entries in <m>k</m>. 
                      The composition rule is given by product of matrices: given <m>A \in \operatorname{Hom}(a, b)</m> and <m>B \in \operatorname{Hom}(b, c)</m>, the composition <m>B \circ A</m> is the matrix <m>B A \in \operatorname{Hom}(a, c)</m>. 
                      For each object <m>a</m>, its identity arrow is given by the <m>a \times a</m> identity matrix.
                    </p>
                  </li>

                  <li xml:id="ex-directed-graph-category">
                    <p>
                      Let <m>G</m> be a directed graph. 
                      We can construct a category from <m>G</m> as follows: the objects are the vertices of <m>G</m>, and the arrows are directed paths in the graph <m>G</m>. 
                      In this category, composition of arrows corresponds to concatenation of paths. 
                      For each object <m>A</m>, the identity arrow corresponds to the empty path from <m>A</m> to <m>A</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </example>

            <remark>
              <p>
                A locally small category with just one element is completely determined by its unique Hom-set; 
                it thus consists of a set <m>S</m> with an associative operation that has an identity element, which in this class is what we call a semigroup. 
                <fn>Some authors prefer the term monoid.</fn>
              </p>
            </remark>

          </subsection>

          <subsection xml:id="subsec-diagrams-arrows"><title>Diagrams and Morphisms</title>

            <blockquote>
              <p>
                <q>
                  Make big plans; aim high in hope and work, remembering that a noble, logical diagram once recorded will not die.
                </q>
              </p>
              <attribution>Daniel Burnham</attribution>
            </blockquote>

            <p>
              A key insight we get from category theory is that many important concepts can be understood through diagrams. 
              Homological algebra is in many ways the study of commutative diagrams. 
              One way to formalize what a diagram is involves talking about functors, which we will discuss in Section 1.2; here is a more down to earth definition.
            </p>

            <definition xml:id="def-diagram"><title>Diagram</title>
              <statement>
                <p>
                  A <em>diagram</em> in a category <m>\mathscr{C}</m> is a directed multigraph whose vertices are objects in <m>\mathrm{C}</m> and whose arrows/edges are morphisms in <m>\mathscr{C}</m>. 
                  A <em>commutative diagram</em> in <m>\mathscr{C}</m> is a diagram in which for each pair of vertices <m>A</m> and <m>B</m>, any two paths from <m>A</m> to <m>B</m> compose to the same morphism.
                </p>
              </statement>
            </definition>

            <example xml:id="ex-commutative-diagram"><title>Commutative Diagram</title>
              <p>
                The diagram
              </p>
              <image source="2023_08_28_614593e69373955f3addg-11.jpg" width="30%"/>
              <p>
                commutes if and only if <m>g f=v u</m>.
              </p>
            </example>
        
            <p>
              There are some special types of arrows we will want to consider.
            </p>

            <definition xml:id="def-inverses"><title>Morphism Inverses</title>
              <statement>
                <p>
                  Let <m>\mathscr{C}</m> be any category.
                  <ul>
                    <li>
                      <p>
                        An arrow <m>f \in \operatorname{Hom}_{\mathscr{C}}(A, B)</m> is <em>left invertible</em> if there exists <m>g \in \operatorname{Hom}_{\mathscr{C}}(B, A)</m> such that <m>g f=1_{A}</m>. 
                        In this case, we say that <m>g</m> is the left inverse of <m>f</m>. 
                        So <m>g</m> is a left inverse of <m>f</m> if the diagram
                      </p>
                      <image source="2023_08_28_614593e69373955f3addg-11(1).jpg" width="30%"/>
                      <p>
                        commutes.
                      </p>
                    </li>

                    <li>
                      <p>
                        An arrow <m>f \in \operatorname{Hom}_{\mathscr{C}}(A, B)</m> is <em>right invertible</em> if there exists <m>g \in \operatorname{Hom}_{\mathscr{C}}(B, A)</m> such that <m>f g=1_{B}</m>. 
                        In this case, we say that <m>g</m> is the right inverse of <m>f</m>. So <m>g</m> is a right inverse of <m>f</m> if the diagram
                      </p>
                      <image source="2023_08_28_614593e69373955f3addg-12.jpg" width="30%"/>
                      <p>
                        commutes.
                      </p>
                    </li>
                
                    <li>
                      <p>
                        An arrow <m>f \in \operatorname{Hom}_{\mathscr{C}}(A, B)</m> is an <em>isomorphism</em> if there exists <m>g \in \operatorname{Hom}_{\mathscr{C}}(B, A)</m> such that <m>g f=1_{A}</m> and <m>f g=1_{B}</m>. 
                        Unsurprisingly, such an arrow <m>g</m> is called the <em>inverse</em> of <m>f</m>.
                      </p>
                    </li>
                  </ul>
                </p>
              </statement>
            </definition>

            <example xml:id="ex-isomorphisms"><title>Isomorphisms</title>
              <p>
                <ol>
                  <li>
                    <p>
                      In <m>\Grp</m>, <m>\Ring</m>, and R<m>\Mod</m> the isomorphisms are the morphisms that are bijective functions.
                    </p>
                  </li>

                  <li>
                    <p>
                      In contrast, in <m>\Top</m> the isomorphisms are the homeomorphisms, which are the bijective continuous functions with continuous inverses. 
                      These are not the same thing as just the bijective continuous functions.
                    </p>
                  </li>
                </ol>
              </p>
            </example>

          </subsection>

          <subsection xml:id="subsec-sub-dual"><title>Opposite Categories and Subcategories</title>

            <blockquote>
              <p>
                <q>
                  The life of this world is nothing but the harmony of opposites.
                </q>
              </p>
              <attribution>Rumi</attribution>
            </blockquote>
      
            <p>
              We will now continue to follow a familiar pattern and define the related concepts one can guess should be defined.
            </p>

            <definition xml:id="def-subcategory"><title>Subcategory</title>
              <statement>
                <p>
                  A <em>subcategory</em> <m>\mathscr{C}</m> of a category <m>\mathscr{D}</m> consists of a subcollection of the objects of <m>\mathscr{D}</m> and a subcollection of the morphisms of <m>\mathscr{D}</m> such that the following hold:
                  <ul>
                    <li>
                      <p>
                        For every object <m>C</m> in <m>\mathscr{C}</m>, the arrow <m>1_{C} \in \operatorname{Hom}_{\mathscr{D}}(C, C)</m> is an arrow in <m>\mathscr{C}</m>.
                      </p>
                    </li>
              
                    <li>
                      <p>
                        For every arrow in <m>\mathscr{C}</m>, its source and target in <m>\mathscr{D}</m> are objects in <m>\mathscr{C}</m>.
                      </p>
                    </li>
              
                    <li>
                      <p>
                        For every pair of arrows <m>f</m> and <m>g</m> in <m>\mathscr{C}</m> such that <m>f g</m> is an arrow that makes sense in <m>\mathscr{D}</m>, <m>f g</m> is an arrow in <m>\mathscr{C}</m>.
                      </p>
                    </li>
                  </ul>
                </p>
              </statement>
            </definition>
        
            <p>
              In particular, <m>\mathscr{C}</m> is a category in its own right.
            </p>

            <example xml:id="ex-subcategories"><title>Subcategories</title>
              <p>
                The category of finitely generated <m>R</m>-modules with <m>R</m>-module homomorphisms is a subcategory of <m>R</m><m>\Mod</m>.
              </p>
            </example>

            <example xml:id="ex-more-categories"><title>Subcategories of Vector Spaces</title>
              <p>
                Let <m>k</m> be a field.
                <ol>
                  <li>
                    <p>
                      The collection of finite dimensional <m>k</m>-vector spaces with all linear transformations is a category.
                    </p>
                  </li>
            
                  <li>
                    <p>
                      The collection of all <m>n</m>-dimensional <m>k</m>-vector spaces with all linear transformations is a category.
                    </p>
                  </li>
            
                  <li>
                    <p>
                      The collection of all <m>k</m>-vector spaces (or <m>n</m>-dimensional vector spaces) with linear isomorphisms is a category.
                    </p>
                  </li>
            
                  <li>
                    <p>
                      The collection of all <m>k</m>-vector spaces (or <m>n</m>-dimensional vector spaces) with nonzero linear transformations is not a category, since it is not closed under composition.
                    </p>
                  </li>
            
                  <li>
                    <p>
                      The collection of all <m>n</m>-dimensional vector spaces with linear transformations of determinant 0 is not a category, since it does not have identity maps.
                    </p>
                  </li>
                </ol>
              </p>
            </example>
            
            <definition xml:id="def-full-subcategory"><title>Full Subcategory</title>
              <statement>
                <p>
                  A subcategory <m>\mathscr{C}</m> of <m>\mathscr{D}</m> is a <em>full subcategory</em> if <m>\mathscr{C}</m> includes all of the arrows in <m>\mathscr{D}</m> between any two objects in <m>\mathscr{C}</m>.
                </p>
              </statement>
            </definition>

            <example xml:id="ex-full-subcategories"><title>Full Subcategories</title>
              <p>
                <ol>
                  <li>
                    <p>
                      The category <m>\mathbf{Ab}</m> of abelian groups is a full subcategory of <m>\Grp</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      Since every group is a set, and every homomorphism is a function, <m>\Grp</m> is a subcategory of <m>\Set</m>. 
                      However, not every function between two groups is a group homomorphism, so <m>\Grp</m> is not a full subcategory of <m>\Set</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      The category whose objects are all sets and with arrows all bijections is a subcategory of <m>\Set</m> that is not full.
                    </p>
                  </li>
                </ol>
              </p>
            </example>
        
            <p>
              Here is another way of constructing a new category out of an old one.
            </p>

            <definition xml:id="def-opposite-category"><title>Opposite Category</title>
              <statement>
                <p>
                  Let <m>\mathscr{C}</m> be a category. 
                  The <em>opposite category</em> of <m>\mathscr{C}</m>, denoted <m>\mathscr{C}^{op}</m>, is a category whose objects are the objects of <m>\mathscr{C}</m>, and such that each arrow <m>f \in \operatorname{Hom}_{\mathscr{C} \text { op }}(A, B)</m> is the same as some arrow in <m>\operatorname{Hom}_{\mathscr{C}}(B, A)</m>. 
                  The composition <m>f g</m> of two morphisms <m>f</m> and <m>g</m> in <m>\mathscr{C}^{\text {op }}</m> is defined as the composition <m>g f</m> in <m>\mathscr{C}</m>.
                </p>
              </statement>
            </definition>
        
            <p>
              Many objects and concepts one might want to describe are obtained from existing ones by flipping the arrows. 
              Opposite categories give us the formal framework to talk about such things. 
              We will often want to refer to dual notions, which will essentially mean considering the same notion in a category <m>\mathscr{C}</m> and in the opposite category <m>\mathscr{C}^{\mathrm{op}}</m>; 
              in practice, this means we should flip all the arrows involved.
              We will see examples of this later on.
            </p>
        
            <p>
              The dual category construction gives us a formal framework to talk about dual notions. 
              We will often make a statement in a category <m>\mathscr{C}</m> and make comments about the dual statement; 
              in practice, this corresponds to simply switching the way all arrows go. 
              Here are some examples of dual notions and statements:
            </p>
        
            <table><title></title>
              <tabular>
              <row bottom="minor">
                <cell halign="center"><term>source</term></cell>
                <cell halign="center"><term>target</term></cell>
              </row>
              <row>
                <cell halign="center">epi</cell>
                <cell halign="center">mono</cell>
              </row>
              <row>
                <cell halign="center"><m>g</m> is a right inverse for <m>f</m></cell>
                <cell halign="center"><m>g</m> is a left inverse for <m>f</m></cell>
              </row>
              <row>
                <cell halign="center"><m>f</m> is invertible</cell>
                <cell halign="center"><m>f</m> is invertible</cell>
              </row>
              <row>
                <cell halign="center">initial objects</cell>
                <cell halign="center">terminal objects</cell>
              </row>
              <row>
                <cell halign="center">homology</cell>
                <cell halign="center">cohomology</cell>
              </row>
              </tabular>
            </table>
        
            <p>
              Note that the dual of the dual is the original statement; 
              we can make this more formal by saying that <m>\left(\mathscr{C}^{\mathrm{op}}\right)^{\text {op }}=\mathscr{C}</m>. 
              Sometimes we can easily prove a statement by dualizing; however, this is not always straightforward, and one needs to carefully dualize all portions of the statement in question. 
              Nevertheless, Sanders MacLane, one of the fathers of category theory, wrote that "If any statement about a category is deducible from the axioms for a category, the dual statement is likely deducible".
              One of the upshots of duality is that any theorem in category theory must simultaneously prove two theorems: the original statement and its dual. 
              But for this to hold, we need proofs that use the abstraction of a purely categorical proof.
            </p>
        
            <p>
              Opposite categories are more interesting than they might appear at first; 
              there is more than just flipping all the arrows. 
              For example, consider the opposite category of Set. 
              For any nonempty set <m>X</m>, there is a unique morphism in Set (a function) <m>i: \emptyset \rightarrow X</m>, but there are no functions <m>X \rightarrow \emptyset</m>, so <m>i^{\text {op }}: \emptyset \rightarrow X</m> is not a function. 
              Thus thinking about Set <m>{ }^{\text {op }}</m> is a bit difficult. 
              One can show that this is the category of complete atomic Boolean algebras - but we won't concern ourselves with what that means.
            </p>

          </subsection>

          <outcomes>
            <ul>
              <li>
                <p>

                </p>
              </li>
            </ul>
          </outcomes>
          
        </section>

        <section xml:id="sec-functors"><title>Functors</title>

          <objectives>
            <ul>
              <li>
                <xref text="title" ref="def-category"/>
                <xref text="title" ref="def-inverses"/>
                <xref text="title" ref="def-diagram"/>
              </li>
            </ul>
          </objectives>

          <subsection xml:id="subsec-functors"><title>Functor? Damn Near Killed 'er!</title>

            <blockquote>
              <p>
                <q>
                  If you're brave enough to say goodbye, life will reward you with a new hello.
                </q>
              </p>
              <attribution>Paulo Coelho</attribution>
            </blockquote>
            
            <p>
              Many mathematical constructions are functorial, in the sense that they behave well with respect to morphisms. 
              In the formalism of category theory, this means that we can think of a functorial construction as a functor.
            </p>

            <definition xml:id="def-functor"><title>Functor</title>
              <statement>
                <p>
                  Let <m>\mathscr{C}</m> and <m>\mathscr{D}</m> be categories. 
                  A covariant functor <m>F: \mathscr{C} \longrightarrow \mathscr{D}</m> is a mapping that assigns to each object <m>A</m> in <m>\mathscr{C}</m> an object <m>F(A)</m> in <m>\mathscr{D}</m>, and to each arrow <m>f \in \operatorname{Hom}_{\mathscr{C}}(A, B)</m> an arrow <m>F(f) \in \operatorname{Hom}_{\mathscr{D}}(F(A), F(B))</m>, such that
                  <ul>
                    <li>
                      <p>
                        <m>F</m> preserves the composition of maps, meaning <m>F(f g)=F(f) F(g)</m> for all arrows <m>f</m> and <m>g</m> in <m>\mathscr{C}</m>, and
                      </p>
                    </li>
          
                    <li>
                      <p>
                        <m>F</m> preserves the identity arrows, meaning <m>F\left(1_{A}\right)=1_{F(A)}</m> for all objects <m>A</m> in <m>\mathscr{C}</m>.
                      </p>
                    </li>
                  </ul>
                </p>
            
                <p>
                  A <em>contravariant functor</em> <m>F: \mathscr{C} \longrightarrow \mathscr{D}</m> is a mapping that assigns to each object <m>A</m> in <m>\mathscr{C}</m> an object <m>F(A)</m> in <m>\mathscr{D}</m>, and to each arrow <m>f \in \operatorname{Hom}_{\mathscr{C}}(A, B)</m> an arrow <m>F(f) \in \operatorname{Hom}_{\mathscr{D}}(F(B), F(A))</m>, such that
                  <ul>
                    <li>
                      <p>
                        <m>F</m> preserves the composition of maps, meaning <m>F(f g)=F(g) F(f)</m> for all composable arrows <m>f</m> and <m>g</m> in <m>\mathscr{C}</m>, and
                      </p>
                    </li>
          
                    <li>
                      <p>
                        <m>F</m> preserves the identity arrows, meaning <m>F\left(1_{A}\right)=1_{F(A)}</m> for all objects <m>A</m> in <m>\mathscr{C}</m>.
                      </p>
                    </li>
                  </ul>
                </p>
              </statement>
            </definition>
      
            <p>
              So a contravariant functor is a functor that flips all the arrows. 
              We can also describe a contravariant functor as a covariant functor from <m>\mathscr{C}</m> to the opposite category of <m>\mathscr{D}</m>, <m>\mathscr{D}{ }^{\text {op }}</m>.
            </p>

            <remark>
              <p>
                A contravariant functor <m>F: \mathscr{C} \longrightarrow \mathscr{D}</m> can be thought of as a covariant functor <m>\mathscr{C}^{\text {op }} \longrightarrow \mathscr{D}</m>, or also as a covariant functor <m>\mathscr{C} \longrightarrow \mathscr{D}^{\text {op }}</m>. 
                If using one of these conventions, one needs to be careful, however, when composing functors, so that the respective sources and targets match up correctly.
                While we haven't specially discussed how one composes functors, it should be clear that applying a functor <m>F: \mathscr{C} \longrightarrow \mathscr{D}</m> and <m>G: \mathscr{D} \longrightarrow \mathscr{E}</m> is the same as applying a functor <m>\mathscr{C} \longrightarrow \mathscr{D}</m>, which we can write as <m>G F</m>.
              </p>
        
              <p>
                For example, if <m>F: \mathscr{C} \longrightarrow \mathscr{D}</m> and <m>G: \mathscr{D} \longrightarrow \mathscr{E}</m> are both contravariant functors, the composition <m>G F: \mathscr{C} \longrightarrow \mathscr{E}</m> is a covariant functor, since
              </p>
              <image source="2023_08_28_614593e69373955f3addg-15.jpg"/>
              <p>
                So we could think of <m>F</m> as a covariant functor <m>\mathscr{C} \longrightarrow \mathscr{D}^{\text {op }}</m> and <m>G</m> as a covariant functor <m>\mathscr{D}^{\text {op }} \longrightarrow \mathscr{E}</m>. 
                Similarly, if <m>F: \mathscr{C} \longrightarrow \mathscr{D}</m> is a covariant functor and <m>G: \mathscr{D} \longrightarrow \mathscr{E}</m> is a contravariant functor, <m>G F: \mathscr{C} \longrightarrow \mathscr{E}</m> is a contravariant functor. 
                In this case, we can think of <m>G</m> as a covariant functor <m>\mathscr{D} \longrightarrow \mathscr{E}^{\mathrm{op}}</m>, so that <m>G F</m> is now a covariant functor <m>\mathscr{C} \longrightarrow \mathscr{E}^{\mathrm{op}}</m>.
              </p>
            </remark>

            <exercise><title>Functors Preserve Isomorphisms</title>
              <p>
                Show that functors preserve isomorphisms.
              </p>
            </exercise>

            <p>
              Here are some examples of functors you may have encountered before.
            </p>

            <example><title>Functors</title>
              <p>
                <ol>
                  <li>
                    <p>
                      Many categories one may think about are concrete categories, where the objects are sets with some extra structure, and the arrows are functions between those sets that preserved that extra structure. 
                      The <term>forgetful functor</term> from such a category to <m>\Set</m> is the functor that, just as the name says, forgets that extra structure, and sees only the underlying sets and functions of sets. 
                      For example, the forgetful functor <m>\mathbf{G r} \longrightarrow</m> <m>\Set</m> sends each group to its underlying set, and each group homomorphism to the corresponding function of sets.
                    </p>
                  </li>

                  <li>
                    <p>
                      The <term>identity functor</term> <m>1_{\mathscr{C}}</m> on any category <m>\mathscr{C}</m> does what the name suggests: it sends each object to itself and each arrow to itself.
                    </p>
                  </li>

                  <li>
                    <p>
                      Given a group <m>G</m>, the subgroup <m>[G, G]</m> of <m>G</m> generated by the set of commutators
                      <me>
                        \left\{g h g^{-1} h^{-1} \mid g, h \in G\right\}
                      </me>
                      is a normal subgroup, and the quotient <m>G^{\text {ab }}:=G /[G, G]</m> is called the abelianization of <m>G</m>. 
                      The group <m>G^{\text {ab }}</m> is abelian. 
                      Given a group homomorphism <m>f: G \rightarrow H, f</m> automatically takes commutators to commutators, so it induces a homomorphism <m>\tilde{f}: G^{\mathrm{ab}} \rightarrow H^{\mathrm{ab}}</m>. 
                      More precisely, abelianization gives a covariant functor from <m>\Grp</m> to <m>\Ab</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      The <em>unit group functor</em> <m>-^{*}</m> : <m>\Ring</m> <m>\rightarrow</m> <m>\Grp</m> sends a ring <m>R</m> to its group of units <m>R^{*}</m>. 
                      To see this is indeed a functor, we should check it behaves well on morphisms; 
                      and indeed if <m>f: R \rightarrow S</m> is a ring homomorphism, and <m>u \in R^{*}</m> is a unit in <m>R</m>, then
                      <me>
                        f(u) f\left(u^{-1}\right)=f\left(u u^{-1}\right)=f\left(1_{R}\right)=1_{S},
                      </me>
                      so <m>f(u)</m> is a unit in <m>S</m>. 
                      Thus <m>f</m> induces a function <m>R^{*} \rightarrow S^{*}</m> given by restriction of <m>f</m> to <m>R^{*}</m>, which must therefore be a group homomorphism since <m>f</m> preserves products.
                    </p>
                  </li>

                  <li>
                    <p>
                      Fix a field <m>k</m>. 
                      Given a vector space <m>V</m>, the collection <m>V^{*}</m> of linear transformations from <m>V</m> to <m>k</m> is again a <m>k</m>-vector space, the <em>dual vector space</em> of <m>V</m>. If <m>\varphi: W \rightarrow V</m> is a linear transformation and <m>\ell: V \rightarrow K</m> is an element of <m>V^{*}</m>, then <m>\ell \circ \varphi: W \rightarrow k</m> is in <m>W^{*}</m>. 
                      Doing this for all elements <m>\ell \in V^{*}</m> gives a function <m>\varphi^{*}: V^{*} \rightarrow W^{*}</m>, and one can show that <m>\varphi^{*}</m> is a linear transformation. 
                      The assignment that sends each vector space <m>V</m> to its dual vector space <m>V^{*}</m> and each linear transformation <m>\varphi</m> to <m>\varphi^{*}</m> is a contravariant functor on Vect- <m>k</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      Localization is a functor. 
                      Let <m>R</m> be a ring and <m>W</m> be a multiplicatively closed set in <m>R</m>. 
                      There is localization at <m>W</m> induces a a functor <m>R</m><m>\mod</m> <m>\longrightarrow W^{-1} R</m><m>\mod</m> that sends each <m>R</m>-module <m>M</m> to <m>W^{-1} M</m>, and each <m>R</m>-module homomorphism <m>\alpha: M \longrightarrow N</m> to the <m>R</m>-module homomorphism <m>W^{-1} \alpha: W^{-1} M \longrightarrow W^{-1} N</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </example>
      
            <exercise>
              <statement>
                <p>
                  If we apply a covariant functor to a diagram, then we get a diagram of the same shape: 
                </p>
                <image source='2023_08_28_614593e69373955f3addg-16.jpg'/>
                <p>
                  However, if we apply a contravariant functor to the same diagram, we get a similar diagram but with the arrows reversed:
                </p> 
                <image source='2023_08_28_614593e69373955f3addg-17.jpg'/>
              </statement>
            </exercise>

          </subsection>

          <subsection xml:id="subsec-funcor-props"><title>Properties of Functors</title>
            
            <blockquote>
              <p>
                <q>

                </q>
              </p>
              <attribution></attribution>
            </blockquote>

            <p>
              If we think about functors as functions between categories, it's natural to consider what would be the appropriate versions of the notions of injective or surjective.
            </p>

            <definition xml:id="def-functor-properties">
              <statement>
                <p>
                  A covariant functor <m>F: \mathscr{C} \longrightarrow \mathscr{D}</m> between locally small categories is
                  <ul>
                    <li>
                      <p>
                        <em>faithful</em> if all the functions of sets
                        <me>
                          \begin{gathered}
                          \operatorname{Hom}_{\mathscr{C}}(A, B) \longrightarrow \operatorname{Hom}_{\mathscr{D}}(F(A), F(B)) \\
                          f \longmapsto F(f)
                          \end{gathered}
                        </me>
                        are injective.
                      </p>
                    </li>
              
                    <li>
                      <p>
                        <em>full</em> if all the functions of sets
                        <me>
                          \begin{gathered}
                          \operatorname{Hom}_{\mathscr{C}}(A, B) \longrightarrow \operatorname{Hom}_{\mathscr{D}}(F(A), F(B)) \\
                          f \longmapsto F(f)
                          \end{gathered}
                        </me>
                        are surjective.
                      </p>
                    </li>
              
                    <li>
                      <p>
                        <em>fully faithful</em> if it is full and faithful.
                      </p>
                    </li>
              
                    <li>
                      <p>
                        <em>essentially surjective</em> if every object <m>d</m> in <m>\mathscr{D}</m> is isomorphic to <m>F c</m> for <m>c</m> in <m>\mathscr{C}</m>.
                      </p>
                    </li>
            
                    <li>
                      <p>
                        an <em>embedding</em> if it is fully faithful and injective on objects.
                      </p>
                    </li>
                  </ul>
                </p>
              </statement>
            </definition>

            <example><title>Forgetfull Functor is Faithful</title>
              <p>
                The forgetful functor <m>R</m><m>\mod</m> <m>\longrightarrow</m> <m>\Set</m> is faithful since any two maps of <m>R</m>-modules with the same source and target coincide if and only if they are the same function of sets. 
                This functor is not full, since there not every functions between the underlying sets of two <m>R</m>-modules is an <m>R</m>-module homomorphism.
              </p>
            </example>

            <remark>
              <p>
                A fully faithful functor is not necessarily injective on objects, but it is injective on objects up to isomorphism.
              </p>
            </remark>

            <remark>
              <p>
                A subcategory <m>\mathscr{C}</m> of <m>\mathscr{D}</m> is <em>full</em> if the inclusion functor <m>\mathscr{C} \longrightarrow \mathscr{D}</m> is full.
              </p>
            </remark>

            <example><title>Full Subcategories</title>
              <p>
                <ol>
                  <li>
                    <p>
                      The category <m>\mathbf{A b}</m> of abelian groups is a full subcategory of <m>\Grp</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      The category whose objects are all sets and with arrows all bijections is a subcategory of <m>\Set</m> that is not full. 
                    </p>
                  </li>
                </ol>
              </p>
            </example>

          </subsection>

          <subsection xml:id="subsec-hom-functors"><title>The <m>\Hom</m> Functors</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>

            <p>
              To close this section, here are the two of the most important functors we will discuss this semester:
            </p>

            <definition xml:id="def-hom-functor"><title><m>\Hom</m> Functors</title>
              <statement>
                <p>
                  Let <m>\mathscr{C}</m> be a locally small category. 
                  An object <m>A</m> in <m>\mathscr{C}</m> induces two <m>\Hom</m> functors:
                  <ul>
                    <li>
                      <p>
                        The covariant functor <m>\operatorname{Hom}_{\mathscr{C}}(A,-): \mathscr{C} \longrightarrow</m> Set is defined as follows:
                      </p>
                      <image source="2023_08_28_614593e69373955f3addg-18(1).jpg"/>
                      <p>
                        We may refer to this functor as the covariant functor represented by <m>A</m>. 
                        Given an arrow <m>f</m> in <m>\mathscr{C}</m>, we write <m>f_{*}:=\operatorname{Hom}_{\mathscr{C}}(A, f)</m>. 
                        It is easier to see what <m>f_{*}</m> does through the following commutative diagram:
                        <me>
                          f_{*}=\operatorname{Hom}_{\mathscr{C}}(A, f):
                        </me>
                      </p>
                      <image source="2023_08_28_614593e69373955f3addg-18(3).jpg" width="30%"/>
                    </li>
                  
                    <li>
                      <p>
                        The contravariant functor <m>\operatorname{Hom}_{\mathscr{C}}(-, B): \mathscr{C} \longrightarrow\Set</m> is defined as follows:
                      </p>
                      <image source="2023_08_28_614593e69373955f3addg-18(2).jpg"/>
                      <p>
                        We may refer to this functor as the contravariant functor represented by <m>B</m>. 
                        Given an arrow <m>f</m> in <m>\mathscr{C}</m>, we write <m>f^{*}:=\operatorname{Hom}_{\mathscr{C}}(A,-)</m>. 
                        It is easier to see what <m>f^{*}</m> does through the following commutative diagram:
                        <me>
                          f^{*}=\operatorname{Hom}_{\mathscr{C}}(f, B):
                        </me>
                      </p>
                      <image source="2023_08_28_614593e69373955f3addg-18.jpg" width="30%"/>
                    </li>
                  </ul>
                </p>
              </statement>
            </definition>

            <exercise>
              <p>
                Check that <m>\operatorname{Hom}(A,-)</m> and <m>\operatorname{Hom}(-, B)</m> are indeed functors.
              </p>
            </exercise>
      
            <p>
              We will be particularly interested in the <m>\Hom</m>-functors in the category <m>R</m><m>\mod</m>, which we will study in detail in a later chapter.
            </p>
          </subsection>

          <conclusion>
            <p>
              Functors we will be using:
              Hom, tensor, homology, localization
            </p>
          </conclusion>

          <outcomes>
            <ul>
              <li>
                <p>
                  Functors are generalizatons of functions that allow us to move between categories. 
                  They can be either covariant or contravariant.
                </p>
              </li>

              <li>
                <p>
                  Two extremely important functors are the <m>\Hom</m> functors.
                </p>
              </li>
            </ul>
          </outcomes>

        </section>

        <section xml:id="sec-natural-transformations"><title>Natural Transformations</title>

          <objectives>
            <ul>
              <li>
                Definitions: functor, hom sets, diagram, hom functors
              </li>
            </ul>
          </objectives>

          <subsection xml:id="subsec-natural"><title>Natural Transformations</title>

            <blockquote>
              <p>
                <q>
                  The beauty of the natural world lies in the details.
                </q>
              </p>
              <attribution>Natalie Angier</attribution>
            </blockquote>
            
            <definition xml:id="def-natural-transformation">
              <statement>
                <p>
                  Let <m>F</m> and <m>G</m> be covariant functors <m>\mathscr{C} \longrightarrow \mathscr{D}</m>. 
                  A <em>natural transformation</em> between <m>F</m> and <m>G</m> is a mapping that to each object <m>A</m> in <m>\mathscr{C}</m> assigns an arrow <m>\eta_{A} \in \operatorname{Hom}_{\mathscr{D}}(F(A), G(A))</m> such that for all <m>f \in \operatorname{Hom}_{\mathscr{C}}(A, B)</m>, the diagram
                </p>
                <image source="2023_08_28_614593e69373955f3addg-19(1).jpg" width="30%"/>
                <p>
                  commutes. 
                  A natural isomorphism is a <em>natural transformation</em> <m>\eta</m> where each <m>\eta_{A}</m> is an isomorphism. 
                  We sometimes write
                </p>
                <image source="2023_08_28_614593e69373955f3addg-19(2).jpg" width="30%"/>
                <p>
                  or simply <m>\eta: F \Longrightarrow G</m>.
                </p>

                <p>
                  Let <m>F</m> and <m>G</m> be contravariant functors <m>\mathscr{C} \longrightarrow \mathscr{D}</m>. 
                  A natural transformation between <m>F</m> and <m>G</m> is a mapping that to each object <m>A</m> in <m>\mathscr{C}</m> assigns an arrow <m>\eta_{A} \in \operatorname{Hom}_{\mathscr{D}}(F(A), G(A))</m> such that for all <m>f \in \operatorname{Hom}_{\mathscr{C}}(A, B)</m>, the diagram
                </p>
                <image source="2023_08_28_614593e69373955f3addg-19.jpg" width="30%"/>
                <p>
                  commutes.
                </p>
              </statement>
            </definition>

            <p>
              Often, when studying a particular topic, we sometimes say a certain map is natural to mean that there is actually a natural transformation behind it.
            </p>

            <example>
              <p>
                Recall the abelianization functor we discussed in Example 1.26. 
                The abelianization comes equipped with a natural projection map <m>\pi_{G}: G \longrightarrow G^{\text {ab }}</m>, the usual quotient map from <m>G</m> to a normal subgroup. 
                Here we mean natural in two different ways: both that this is common sense map to consider, and that this is in fact coming from a natural transformation. 
                What's happening behind the scenes is that abelianization is a functor <m>ab: \Grp\longrightarrow \Grp</m>. 
                On objects, the abelianizations functor is defined as <m>G \mapsto G^{\text {ab }}</m>. 
                Given an arrow, meaning a group homomorphism <m>G \stackrel{f}{\rightarrow} H</m>, one can check that <m>[G, G]</m> is contained in the kernel of <m>\pi_{H} f</m>, so <m>\pi_{H} f</m> factors through <m>G^{\text {ab }}</m>, and there exists a group homomorphism <m>f^{\mathrm{ab}}</m> making the following diagram commute:
              </p>
              <image source="2023_08_28_614593e69373955f3addg-19(3).jpg" width="30%"/>
              <p>
                So the abelianization functor takes the arrow <m>f</m> to <m>f^{\text {ab }}</m>. 
                The commutativity of the diagram above says that <m>\pi_{-}</m>is a natural transformation between the identity functor on <m>\Grp</m> and the abelianization functor, which we can write more compactly as
                <me>
                  \operatorname{Grp} \underset{\frac{\mathrm{id}}{\Downarrow \pi}}{\stackrel{\mathrm{ab}}{\longrightarrow}} \operatorname{Grp}.
                </me>
              </p>
            </example>

            <definition xml:id="def-functor-category"><title>Functor Category</title>
              <statement>
                <p>
                  Let <m>F, G: \mathscr{C} \longrightarrow \mathscr{D}</m> be two functors between the categories <m>\mathscr{C}</m> and <m>\mathscr{D}</m>. 
                  We write
                  <me>
                    \operatorname{Nat}(F, G)=\{\text { natural transformations } F \longrightarrow G\}.
                  </me>
                </p>
          
                <p>
                  Given two categories <m>\mathscr{C}</m> and <m>\mathscr{D}</m>, one can build a <em>functor category</em>
                  <fn>Yes, the madness is neverending.</fn>
                  with objects all covariant functors <m>\mathscr{C} \longrightarrow \mathscr{D}</m>, and arrows the corresponding natural transformations. 
                  This category is denoted <m>\mathscr{D}^{\mathscr{C}}</m>. 
                  Sometimes one writes <m>\operatorname{Hom}(F, G)</m> for <m>\operatorname{Nat}(F, G)</m>, but we will avoid that, as it might make things even more confusing.
                </p>
              </statement>
            </definition>
      
            <p>
              For the functor category to truly be a category, though, we need to know how to compose natural transformations.
            </p>

            <remark><title>Composition of Natural Transformations</title>
              <p>
                Consider natural transformations
              </p>
              <image source="2023_08_28_614593e69373955f3addg-20(3).jpg" width="30%"/>
              <p>
                and
              </p>
              <image source="2023_08_28_614593e69373955f3addg-20(1).jpg" width="30%"/>
              <p>
                We can compose them for form a new natural transformation
              </p>
              <image source="2023_08_28_614593e69373955f3addg-20.jpg" width="30%"/>
              <p>
                We should think of this composition as happening vertically. 
                For each object <m>C</m> in <m>\mathscr{C}, \eta \varphi</m> sends <m>C</m> to the arrow <m>F(A) \stackrel{\varphi_{A}}{\longrightarrow} G(A) \stackrel{\eta_{A}}{\longrightarrow} H(A)</m>. 
                This makes the diagram
              </p>
              <image source="2023_08_28_614593e69373955f3addg-20(2).jpg" width="30%"/>
              <p>
                commute.
              </p>
            </remark>

            <exploration>
              <p>
                Show that a natural transformation <m>\eta: \mathscr{C} \Longrightarrow \mathscr{D}</m> is a natural isomorphism if and only if there exists a natural transformation <m>\mu: \mathscr{D} \Longrightarrow \mathscr{C}</m> such that <m>\eta \circ \mu</m> is the identity natural isomorphism on <m>G</m> and <m>\mu \circ \eta</m> is the identity natural isomorphism on <m>F</m>.
              </p>
            </exploration>

            <definition xml:id="def-equivalent-categories"><title>Equivalent Categories</title>
              <statement>
                <p>
                  Two categories <m>\mathscr{C}</m> and <m>\mathscr{D}</m> are equivalent if there exist functors <m>F: \mathscr{C} \rightarrow \mathscr{D}</m> and <m>G: \mathscr{D} \rightarrow \mathscr{C}</m> and two natural isomorphisms <m>\alpha: G F \Longrightarrow 1_{\mathscr{C}}</m> and <m>\beta: F G \Longrightarrow 1_{\mathscr{D}}</m>. 
                  We say that a functor <m>F: \mathscr{C} \rightarrow \mathscr{D}</m> is an equivalence of categories if there exists a functor <m>G</m> and natural isomorphisms <m>\alpha</m> and <m>\beta</m> as above.
              </p>
              </statement>
            </definition>

            <p>
              If one assumes the Axiom of Choice, this is the right notion of isomorphism of two categories (though not in the categorical sense!); better said, two categories that are equivalent are essentially the same. 
              Note that this does not mean that there is a bijection between the objects of <m>\mathscr{C}</m> and the objects of <m>\mathscr{D}</m>. 
              In fact, one can show that a functor is an equivalence of categories if and only if it is fully faithful and essentially surjective - though this fact requires the Axiom of Choice!
            </p>

            <exploration>
              <p>
                Let <m>\mathscr{C}</m> be the category with one object <m>C</m> and a unique arrow <m>1_{C}</m>. Let <m>\mathscr{D}</m> be the category with two objects <m>D_{1}</m> and <m>D_{2}</m> and four arrows: 
                the identities <m>1_{D_{i}}</m> and two isomorphisms <m>\alpha: D_{1} \rightarrow D_{2}</m> and <m>\beta: D_{2} \rightarrow D_{1}</m>. 
                Let <m>\mathscr{E}</m> be the category with two objects <m>E_{1}</m> and <m>E_{2}</m> and only two arrows, <m>1_{E_{1}}</m> and <m>1_{E_{2}}</m>.
                <ol>
                  <li>
                    <p>
                      Show that <m>\mathscr{C}</m> and <m>\mathscr{D}</m> are equivalent categories.
                    </p>
                  </li>

                  <li>
                    <p>
                      Show that <m>\mathscr{C}</m> and <m>\mathscr{E}</m> are not equivalent categories.
                    </p>
                  </li>
                </ol>
              </p>
            </exploration>

          </subsection>

          <subsection xml:id="subsec-yoneda"><title>The Yoneda Lemma</title>

            <blockquote>
              <p>
                <q>
                  If it walks like a duck and homs like a duck, it's naturally isomorphic to a duck.
                </q>
              </p>
              <attribution>Twitter User @_julesh_</attribution>
            </blockquote>
            
            <p>
              Even though this is only a short introduction to category theory, we would be remiss not to mention the <xref text="title" ref="thm-yoneda"/>, arguably the most important statement in category theory.
            </p>

            <theorem xml:id="thm-yoneda"><title>Yoneda Lemma</title>
              <statement>
                <p>
                  Let <m>\mathscr{C}</m> be a locally small category, and fix an object <m>A</m> in <m>\mathscr{C}</m>. 
                  Let <m>F: \mathscr{C} \longrightarrow</m> Set be a covariant functor. 
                  Then there is a bijection
                  <me>\operatorname{Nat}\left(\operatorname{Hom}_{\mathscr{C}}(A,-), F\right) \stackrel{\gamma}{\longrightarrow} F(A)</me>
                  Moreover, this correspondence is natural in both <m>A</m> and <m>F</m>.
                </p>
              </statement>

              <proof>
                <p>
                  Let <m>\varphi</m> be a natural transformation in <m>\operatorname{Nat}\left(\operatorname{Hom}_{\mathscr{C}}(A,-), F\right)</m>. 
                  The proof of the Yoneda Lemma is essentially the following diagram:
                </p>
                <image source="2023_08_28_614593e69373955f3addg-21.jpg"/>
                <p>
                  Our bijection will be defined by <m>\gamma(\varphi):=\varphi_{A}\left(1_{A}\right)</m>. 
                  We should first check that this makes sense: 
                  arrows in Set are just functions between sets, and so <m>\varphi_{A}</m> is a function of sets <m>\operatorname{Hom}_{\mathscr{C}}(A, A) \longrightarrow F(A)</m>. 
                  Also, <m>\operatorname{Hom}_{\mathscr{C}}(A, A)</m> is a set that contains at least the element <m>1_{A}</m>, and <m>\varphi_{A}\left(1_{A}\right)</m> is some element in the set <m>F(A)</m>.
                </p>
          
                <p>
                  Given any fixed <m>f \in \operatorname{Hom}_{\mathscr{C}}(A, X)</m>, the fact that <m>\varphi</m> is a natural transformation translates into the outer commutative diagram. 
                  In particular, the maps of sets <m>F(f) \varphi_{A}</m> and <m>\varphi_{X} \operatorname{Hom}_{\mathscr{C}}(A, f)</m> coincide, and must in particular take <m>1_{A}</m> to the same element in <m>F(X)</m>. 
                  This is the commutativity of the inner diagram, with <m>u:=\varphi_{A}\left(1_{A}\right)</m>.
                </p>
          
                <p>
                  The commutativity of the diagram above says that <m>\varphi</m> is completely determined by <m>\varphi_{A}\left(1_{A}\right)</m>, since for any other object <m>X</m> in <m>\mathscr{C}</m> and any arrow <m>f \in \operatorname{Hom}_{\mathscr{C}}(A, X)</m>, we necessarily have <m>\varphi_{X}(f)=F(f) \varphi_{A}\left(1_{A}\right)</m>. 
                  In particular, our map <m>\gamma(\varphi)=\varphi_{A}\left(1_{A}\right)</m> is injective. 
                  Moreover, note that each choice of <m>u \in F(A)</m> gives rise to a different natural transformation <m>\varphi</m> by setting <m>\varphi_{X}(f)=F(f) u</m>. 
                  So our map <m>\gamma</m> is indeed a bijection.
                </p>
          
                <p>
                  We now have two naturality statements to prove. 
                  Naturality in the functor means that given a natural isomorphism <m>\eta: F \longrightarrow G</m>, the diagram
                </p>
                <image source="2023_08_28_614593e69373955f3addg-22.jpg" width="50%"/>
                <p>
                  commutes. 
                  Given a natural transformation <m>\varphi</m> between <m>\operatorname{Hom}_{\mathscr{C}}(A,-)</m> and <m>F</m>,
                  <me>
                    \begin{array}{rlr}
                    \eta_{A} \circ \gamma_{F}(\varphi) &amp; =\eta_{A}\left(\varphi_{A}\left(1_{A}\right)\right) &amp; \text { by definition of } \gamma \\
                    &amp; =(\eta \circ \varphi)_{A}\left(1_{A}\right) &amp; \text { by definition of composition of natural transformations } \\
                    &amp; =\gamma_{G}(\eta \circ \varphi) &amp; \text { by definition of } \gamma \\
                    &amp; =\gamma_{G} \circ \eta_{*}(\varphi) &amp; \text { by definition of } \eta_{*}
                    \end{array}
                  </me>
                  so commutativity does hold. 
                  Naturality on the object means that given an arrow <m>f: A \longrightarrow B</m>, the diagram
                </p>
                <image source="2023_08_28_614593e69373955f3addg-22(1).jpg" width="50%"/>
                <p>
                  commutes. 
                  Given a natural transformation <m>\varphi</m> between <m>\operatorname{Hom}_{\mathscr{C}}(A,-)</m> and <m>F</m>,
                  <me>
                    F(f) \circ \gamma_{A}(\varphi)=F(f)\left(\varphi_{A}\left(1_{A}\right)\right)
                  </me>
                  while
                  <me>
                    \gamma_{B} \circ\left(f^{*}\right)^{*}(\varphi)=\gamma_{B}\left(\varphi \circ f^{*}\right)=\left(\varphi \circ f^{*}\right)_{B}\left(1_{B}\right)
                  </me>
                  Now notice that
                  <me>
                    \begin{array}{r}
                    \operatorname{Hom}_{\mathscr{C}}(B, B) \stackrel{f^{*}}{\longrightarrow} \operatorname{Hom}_{\mathscr{C}}(A, B) \stackrel{\varphi_{B}}{\longrightarrow} F(B) . \\
                    1_{B} \longmapsto f \longmapsto \varphi_{B}(f)
                    \end{array}
                  </me>
                </p>

                <p>
                  Let's look back at the big commutative diagram we started our proof with: it says in particular that <m>\varphi_{B}(f)=F(f)\left(\varphi_{A}\left(1_{A}\right)\right)</m>. 
                  So commutativity does hold, and we are done. 
                </p>
              </proof>
            </theorem>

            <p>
              One can naturally (pun intended) define the notion of functor category of contravariant functors, and then prove the corresponding <xref text="title" ref="thm-yoneda"/>, which will instead use the contravariant Hom functor.
            </p>

            <exploration><title>Contravariant version of the Yoneda Lemma</title>
              <p>
                Let <m>\mathscr{C}</m> be a locally small category, and fix an object <m>B</m> in <m>\mathscr{C}</m>. Let <m>F: \mathscr{C} \longrightarrow</m> Set be a contravariant functor. 
                Then there is a bijection
                <me>
                  \text { Nat }\left(\operatorname{Hom}_{\mathscr{C}}(-, B), F\right) \stackrel{\gamma}{\longrightarrow} F(B).
                </me>
              </p>
            </exploration>

            <p>
              In a way, the <xref text="title" ref="thm-yoneda"/> says that to give a natural transformation between the functors <m>\operatorname{Hom}_{\mathscr{C}}(A,-)</m> and <m>F</m> is choosing an element in <m>F(A)</m>.
            </p>

            <remark>
              <p>
                Notice that the <xref text="title" ref="thm-yoneda"/> says in particular that the collection of all natural transformations from <m>\operatorname{Hom}_{\mathscr{C}}(A,-)</m> to <m>F</m> is a set. 
                This wasn't clear a priori, since the collection of objects in <m>\mathscr{C}</m> is not necessarily a set.
              </p>
            </remark>

            <remark>
              <p>
                If we apply the <xref text="title" ref="thm-yoneda"/> to the case when <m>F</m> itself is also a Hom functor, say <m>F=\operatorname{Hom}_{\mathscr{C}}(B,-)</m>, the <xref text="title" ref="thm-yoneda"/> says that there is a bijection between <m>\operatorname{Nat}\left(\operatorname{Hom}_{\mathscr{C}}(A,-), \operatorname{Hom}_{\mathscr{C}}(B,-)\right)</m> and <m>\operatorname{Hom}_{\mathscr{C}}(B, A)</m>. 
                In particular, each arrow in <m>\mathscr{C}</m> determines a natural transformation between Hom functors.
              </p>
            </remark>
      
            <p>
              One of the consequences of the <xref text="title" ref="thm-yoneda"/> is the Yoneda Embedding, which roughly says that every locally small category can be embedded into the category of contravariant functors from <m>\mathscr{C}</m> to Set. 
              In particular, the Yoneda embedding says that natural transformations between representable functors correspond to arrows between the representing objects.
            </p>

            <theorem xml:id="thm-yondea-embedding"><title>Yoneda Embedding</title>
              <statement>
                <p>
                  Let <m>\mathscr{C}</m> be a locally small category. The covariant functor
                </p>
                <image source="2023_08_28_614593e69373955f3addg-23(1).jpg" width="50%"/>
                <p>
                  from <m>\mathscr{C}</m> to the category of contravariant functors <m>\mathscr{C} \longrightarrow</m> Set is an embedding. 
                  Moreover, the contravariant functor 
                </p>
                <image source="2023_08_28_614593e69373955f3addg-23.jpg" width="50%"/>
                <p>
                  from the category <m>\mathscr{C}</m> to the category of covariant functors <m>\mathscr{C} \longrightarrow</m> Set is also an embedding.
                </p>
              </statement>

              <proof>
                <p>
                  First, note that our functors are injective on objects because the Hom-sets in our category are all disjoint. 
                  We need to check that given objects <m>A</m> and <m>B</m> in <m>\mathscr{C}</m>, we have bijections
                  <me>
                    \operatorname{Hom}_{\mathscr{C}}(A, B) \cong \operatorname{Nat}\left(\operatorname{Hom}_{\mathscr{C}}(-, A), \operatorname{Hom}_{\mathscr{C}}(-, B)\right)
                  </me>
                  and
                  <me>
                    \operatorname{Hom}_{\mathscr{C} \text { op }}(A, B) \cong \operatorname{Nat}\left(\operatorname{Hom}_{\mathscr{C}}(A,-) \operatorname{Hom}_{\mathscr{C}}(B,-)\right).
                  </me>
                </p>
          
                <p>
                  We will do the details for the first one, and leave the second as an exercise.
                </p>
          
                <p>
                  First, let us take a sanity check and confirm that indeed our proposed functors take arrows <m>f: A \longrightarrow B</m> in <m>\mathscr{C}</m> to natural transformations between <m>\operatorname{Hom}_{\mathscr{C}}(-, A)</m> and <m>\operatorname{Hom}_{\mathscr{C}}(-, B)</m>. 
                  This is essentially the content of Remark 1.43, but let's carefully check the details. 
                  The <xref text="title" ref="thm-yoneda"/> applied here tells us that each natural transformation <m>\varphi</m> between <m>\mathrm{Hom}_{\mathscr{C}}(-, A)</m> and <m>F=\operatorname{Hom}_{\mathscr{C}}(-, B)</m> corresponds to an element <m>u \in \operatorname{Hom}_{\mathscr{C}}(A, B)</m>, which we obtain by taking <m>u:=\varphi_{A}\left(1_{A}\right)</m>. 
                  As we discussed in the proof of the <xref text="title" ref="thm-yoneda"/>, we can recover <m>\varphi</m> from <m>u</m> by taking the natural transformation <m>\varphi</m> that for each object <m>X</m> in <m>\mathscr{C}</m> has <m>\varphi_{X}: \operatorname{Hom}_{\mathscr{C}}(X, A) \longrightarrow \operatorname{Hom}_{\mathscr{C}}(X, B)</m> given by <m>\varphi_{X}(f)=\operatorname{Hom}_{\mathscr{C}}(f, B)(u)=f_{*}(u)</m>.
                </p>
          
                <p>
                  We can see that different arrows <m>f</m> give rise to different natural transformations by applying the resulting natural transformation <m>f_{;} *</m> to the identity arrow <m>1_{A}</m>, which takes it to <m>f</m>. 
                  Moreover, the <xref text="title" ref="thm-yoneda"/> tells us that every natural transformation <m>\varphi</m> between <m>\operatorname{Hom}_{\mathscr{C}}(-, A)</m> and <m>\operatorname{Hom}_{\mathscr{C}}(-, B)</m> is the image of some <m>u</m>, as described above.
                </p>
              </proof>
            </theorem>
      
            <p>
              The functors that are naturally isomorphic to some Hom functor are important.
            </p>

            <definition xml:id="def-representable-functor">
              <statement>
                <p>
                  A covariant functor <m>F: \mathscr{C} \longrightarrow</m> Set is representable if there exists an object <m>A</m> in <m>\mathscr{C}</m> such that <m>F</m> is naturally isomorphic to <m>\operatorname{Hom}_{\mathscr{C}}(A,-)</m>. 
                  A contravariant functor <m>F: \mathscr{C} \longrightarrow</m> Set is representable if there exists an object <m>B</m> in <m>\mathscr{C}</m> such that <m>F</m> is naturally isomorphic to <m>\operatorname{Hom}_{\mathscr{C}}(-, B)</m>.
                </p>
              </statement>
            </definition>

            <example>
              <p>
                We claim that the identity functor Set <m>\longrightarrow</m> Set is representable. 
                Let 1 be a singleton set. 
                Given any set <m>X</m>, there is a bijection between elements <m>x \in X</m> and functions <m>\mathbf{1} \longrightarrow X</m> sending the one element in <m>\mathbf{1}</m> to each <m>x</m>. 
                Moreover, given any other set <m>Y</m>, and a function <m>f: X \longrightarrow Y</m>, our bijections make the following diagram commute:
              </p>
              <image source="2023_08_28_614593e69373955f3addg-24.jpg" width="30%"/>
              <p>
                This data gives a natural isomorphism between the identity functor and <m>\operatorname{Hom}_{\text {Set }}(\mathbf{1},-)</m>.
              </p>
            </example>

            <p>
              A representable functor encodes a universal property of the object that represents it. 
              For example, in Example 1.46, mapping out of the singleton set is the same as choosing an element <m>x</m> in a set <m>X</m>. 
              We have all seen constructions that are at first a bit messy but that end up satisfying some nice universal property that makes everything work out. 
              At the end of the day, a universal property allows us to ignore the messy details and focus on the universal property, which usually says everything we need to know about the construction. 
              And as you may have already realized, universal properties are everywhere. 
              Before we give a formal definition, we want to discuss some important examples.
            </p>

          </subsection>

          <outcomes>
            <ul>
              <li>
                <p>

                </p>
              </li>
            </ul>
          </outcomes>
          
        </section>
        
      </chapter>

      <chapter xml:id="ch-chain-complexes"><title>The Category of Chain Complexes</title>

        <section xml:id="sec-compelx-maps"><title>Maps of Complexes</title>

          <objectives>
            <ul>
              <li>
                
              </li>
            </ul>
          </objectives>

          <subsection xml:id="subsec-"><title>Establishing <m>\mathrm{Ch}(R)</m></title>

            <blockquote>
              <p>
                <q>
                  A chain is no stronger than its weakest link, and life is after all a chain.
                </q>
              </p>
              <attribution>William James</attribution>
            </blockquote>
            
            <p>
              Unsurprisingly, we can form a category of complexes, but to do that we need the right definition of maps between complexes. 
              We also take this section as a chance to set up some definitions we will need later. 
              One thing to keep in mind as we build our basic definitions: we also want homology to be functorial.
            </p>

            <definition xml:id="def-2.1"><title>Chain Map</title>
              <statement>
                <p>
                  Let <m>\left(F_{\bullet}, \partial_{\bullet}^{F}\right)</m> and <m>\left(G_{\bullet}, \partial_{\bullet}^{G}\right)</m> be complexes. 
                  A <em>map of complexes</em> or a <em>chain map</em>, which we write as <m>h:\left(F_{\bullet}, \partial_{\bullet}^{F}\right) \longrightarrow\left(G_{\bullet}, \partial_{\bullet}^{G}\right)</m> or simply <m>h: F \longrightarrow G</m>, is a sequence of homomorphisms of <m>R</m>-modules <m>h_{n}: F_{n} \longrightarrow G_{n}</m> such that the following diagram commutes:
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-051.jpg" width="75%"/>
                <p>
                  This means that <m>h_{n} \partial_{n+1}^{F}=\partial_{n+1}^{G} h_{n+1}</m> for all <m>n</m>.
                </p>
              </statement>
            </definition>

            <p>
              Note that throughout, whenever we call a function <m>f: M \rightarrow N</m> between <m>R</m>-modules <m>M</m> and <m>N</m> a map, we really mean to say it is a homomorphism of <m>R</m>-modules.
            </p>

            <example xml:id="ex-2.2"><title>Zero and Identity Chain Maps</title>
              <p>
                The zero and the identity maps of complexes <m>\left(F_{\bullet}, \partial_{\bullet}\right) \longrightarrow\left(F_{\bullet}, \partial_{\bullet}\right)</m> are exactly what they sound like: the zero map <m>0_{F_{\bullet}}</m> is 0 in every homological degree, and the identity map <m>1_{F_{\bullet}}</m> is the identity in every homological degree.
              </p>
            </example>
      
            <p>
              This is the notion of morphism we would want to form a category of chain complexes.
            </p>

            <definition xml:id="def-2.3"><title>Category of Chain Complexes</title>
              <statement>
                <p>
                  Let <m>R</m> be a ring. 
                  The <em>category of chain complexes</em> of <m>R</m>-modules, denoted <m>\mathrm{Ch}(R-\mod)</m> or simply <m>\mathrm{Ch}(R)</m>, is the category with objects all chain complexes of <m>R</m>-modules and arrows all maps of complexes of <m>R</m>-modules.
                  When <m>R=\mathbb{Z}</m>, we write <m>\mathrm{Ch}(\mathrm{Ab})</m> for <m>\mathrm{Ch}(\mathbb{Z})</m>, the category of chain complexes of abelian groups.
                </p>
              </statement>
            </definition>
      
            <p>
              Note that the identity maps defined above are precisely the identity arrows in the category of chain complexes.
            </p>

            <exercise xml:id="exe-25"><title>Isomorphisms in <m>\mathrm{Ch}(R)</m></title>
              <p>
                Show that the isomorphisms in the category <m>\mathrm{Ch}(R)</m> are precisely the maps of complexes
              </p>
              
              <image source="2023_10_23_e2d6a27704be928b3deeg-052.jpg" width="75%"/>
                    
              <p>
                such that <m>h_{n}</m> is an isomorphism for all <m>n</m>.
              </p>
            </exercise>
      
            <p>
              This is a good notion of map of complexes: it induces homomorphisms in homology, which in particular allows us to say that homology is a functor.
            </p>

            <lemma xml:id="lem-2.4">
              <statement>
                <p>
                  Let <m>h:\left(F_{\bullet}, \partial_{\bullet}^{F}\right) \longrightarrow\left(G_{\bullet}, \partial_{\bullet}^{G}\right)</m> be a map of complexes. 
                  For all <m>n, h_{n}</m> restricts to homomorphisms <m>B_{n}(h): B_{n}\left(F_{\bullet}\right) \longrightarrow B_{n}\left(G_{\bullet}\right)</m> and <m>Z_{n}(h): Z_{n}\left(F_{\bullet}\right) \longrightarrow Z_{n}\left(G_{\bullet}\right)</m>. 
                  As a consequence, <m>h</m> induces homomorphisms on homology <m>\mathrm{H}_{n}(h): \mathrm{H}_{n}\left(F_{\bullet}\right) \longrightarrow \mathrm{H}_{n}\left(G_{\bullet}\right)</m>.
                </p>
              </statement>

              <proof>
                <p>
                  Since <m>h_{n} \partial_{n+1}^{F}=\partial_{n+1}^{G} h_{n+1}</m>, any element <m>a \in B_{n}\left(F_{\bullet}\right)</m>, say <m>a=\partial_{n+1}^{F}(b)</m>, is taken to
                  <me>
                    h_{n}(a)=h_{n} \partial_{n+1}^{F}(b)=\partial_{n+1}^{G} h_{n+1}(b) \in \operatorname{im} \partial_{n+1}^{G}=B_{n}\left(G_{\bullet}\right)
                  </me>
                </p>
          
                <p>
                  Similarly, if <m>a \in Z_{n}\left(F_{\bullet}\right)=\operatorname{ker} \partial_{n}^{F}</m>, then   
                  <me>
                    \partial_{n} h_{n}(a)=h_{n-1} \partial_{n}^{F}(a)=0
                  </me>
                  so <m>h_{n}(a) \in \operatorname{ker} \partial_{n}^{G}=Z_{n}\left(G_{\bullet}\right)</m>. 
                  Finally, the restriction of <m>h_{n}</m> to <m>Z_{n}\left(F_{\bullet}\right) \longrightarrow Z_{n}\left(G_{\bullet}\right)</m> sends <m>B_{n}\left(F_{\bullet}\right)</m> into <m>B_{n}\left(G_{\bullet}\right)</m>, and thus it induces a well-defined homomorphism on the quotients <m>\mathrm{H}_{n}\left(F_{\bullet}\right) \longrightarrow \mathrm{H}_{n}\left(G_{\bullet}\right)</m>.
                </p>
              </proof>
            </lemma>

            <definition xml:id="def-2.5"><title>Induced Map in Homology</title>
              <statement>
                <p>
                  Let <m>h:\left(F_{\bullet}, \partial_{\bullet}^{F}\right) \longrightarrow\left(G_{\bullet}, \partial_{\bullet}^{G}\right)</m> be a map of complexes. 
                  We call the map
                  <me>
                    \begin{aligned}
                    \mathrm{H}_{n}(h): &amp; \mathrm{H}_{n}\left(F_{\bullet}\right) \longrightarrow \mathrm{H}_{n}\left(G_{\bullet}\right) \\
                    &amp; a+B_{n}(F) \longmapsto h_{n}(a)+B_{n}(G)
                    \end{aligned}
                  </me>
                  the <em>induced map in homology</em>, and sometimes denote it by <m>h_{*}</m>.
                </p>
              </statement>
            </definition>
      
            <p>
              One can show that <m>\mathrm{H}_{n}</m> preserves compositions, and that moreover, the map in homology induced by the identity is the identity. 
              Thus taking <m>n</m>th homology is a functor
              <me>
                \mathrm{H}_{n}: \mathrm{Ch}(R) \longrightarrow R \text {-Mod }
              </me>
              which takes each map of complexes <m>h: F_{\bullet}, \longrightarrow G_{\bullet}</m> to the <m>R</m>-module homomorphism
              <me>
                \mathrm{H}_{n}(h): \mathrm{H}_{n}\left(F_{\bullet}\right) \longrightarrow \mathrm{H}_{n}\left(G_{\bullet}\right)
              </me>
            </p>

            <definition xml:id="def-2.6"><title>Quasi-Isomorphism</title>
              <statement>
                <p>
                  A map of chain complexes <m>h</m> is a <em>quasi-isomorphism</em> if it induces an isomorphism in homology, meaning <m>\mathrm{H}_{n}(h)</m> is an isomorphism of <m>R</m>-modules for all <m>n</m>. 
                  If there exists a quasi-isomorphism between two complexes <m>C</m> and <m>D</m>, we say that <m>C</m> and <m>D</m> are <em>quasi-isomorphic</em>, and write <m>C \simeq D</m>.
                </p>
              </statement>
            </definition>

            <remark xml:id="rem-2.7">
              <p>
                Note that saying that if <m>f</m> is a quasi-isomorphism between <m>F</m> and <m>G</m> is a stronger statement that the fact that <m>\mathrm{H}_{n}(F) \cong \mathrm{H}_{n}(G)</m> for all <m>n</m>: 
                it also says that there are isomorphisms <m>\mathrm{H}_{n}(F) \cong \mathrm{H}_{n}(G)</m> that are all induced by <m>f</m>.
              </p>
            </remark>

            <p>
              Not all quasi-isomorphisms are isomorphisms, as the following example shows:
            </p>

            <exercise xml:id="exe-26">
              <p>
                Let <m>\pi</m> denote the projection map from <m>\mathbb{Z}</m> to <m>\mathbb{Z} / 2 \mathbb{Z}</m>. 
                The chain map
              </p>
              <image source="2023_10_23_e2d6a27704be928b3deeg-053.jpg" width="75%"/>
              <p>
                is a quasi-isomorphism.
              </p>
            </exercise>

          </subsection>

          <subsection xml:id="subsec-homotopy"><title>Homotopy</title>

            <blockquote>
              <p>
                <q>
                  Transformation is not automatic. It must be learned; it must be led.
                </q>
              </p>
              <attribution>W. Edwards Deming</attribution>
            </blockquote>
            
            <definition xml:id="def-2.8"><title>Homotopy</title>
              <statement>
                <p>
                  Let <m>f, g: F \longrightarrow G</m> be maps complexes. 
                  A <em>homotopy</em>, sometimes referred to as a <em>chain homotopy</em>, between <m>f</m> and <m>g</m> is a sequence of maps <m>h_{n}: F_{n} \longrightarrow G_{n+1}</m>
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-053(1).jpg"/>
                <p>
                  such that
                  <me>
                    \partial_{n+1} h_{n}+h_{n-1} \partial_{n}=f_{n}-g_{n}
                  </me>
                  for all <m>n</m>. 
                  If there exists a homotopy between <m>f</m> and <m>g</m>, we say that <m>f</m> and <m>g</m> are <em>homotopic</em> or that they have the <em>same homotopy type</em>. 
                  We write <m>f \simeq g</m> to say that <m>f</m> and <m>g</m> are homotopic. 
                  If <m>f</m> is homotopic to the zero map, we say <m>f</m> is <em>nullhomotopic</em>, and write <m>f \simeq 0</m>. 
                  This should not be confused with the notation <m>C \simeq D</m> on complexes.
                </p>
              </statement>
            </definition>

            <exercise xml:id="exe-27"><title>Homotopy is an Equivalence Relation</title>
              <p>
                Homotopy is an equivalence relation.
              </p>
            </exercise>
          
            <p>
              The equivalence classes under homotopy are called homotopy classes. 
              Homotopy is an interesting equivalence relation because homotopic maps induce the same map on homology.
            </p>

            <lemma xml:id="lem-2.9"><title>Nullhomotopic Maps Induce Zero Map in Homology</title>
              <statement>
                <p>
                  Let <m>f, g:\left(F_{\bullet}, \partial_{\bullet}^{F}\right) \longrightarrow\left(G_{\bullet}, \partial_{\bullet}^{G}\right)</m> be maps of complexes. 
                  If <m>f</m> is homotopic to <m>g</m>, then <m>\mathrm{H}_{n}(f)=\mathrm{H}_{n}(g)</m> for all <m>n</m>. 
                  In particular, every nullhomotopic map induces the zero map in homology.
                </p>
              </statement>

              <proof>
                <p>
                  Let <m>f, g:\left(F_{\bullet}, \partial_{\bullet}^{F}\right) \longrightarrow\left(G_{\bullet}, \partial_{\bullet}^{G}\right)</m> be homotopic maps of complexes, and let <m>h</m> be a homotopy between <m>f</m> and <m>g</m>. 
                  We claim that the map of complexes <m>f-g</m> (defined in the obvious way) sends cycles to boundaries. 
                  If <m>a \in Z_{n}\left(F_{\bullet}\right)</m>, then
                  <me>
                    (f-g)_{n}(a)=\partial_{n+1} h_{n}(a)+h_{n-1} \underbrace{\partial_{n}(a)}_{0}=\partial_{n+1}\left(h_{n}(a)\right) \in B_{n}\left(G_{\bullet}\right)
                  </me>
                  The map on homology induced by <m>f-g</m> must then be the <m>0</m> map, so <m>f</m> and <m>g</m> induce the same map on homology. 
                  Here we are implicitly using the fact that <m>\mathrm{H}_{n}(f+h)=\mathrm{H}_{n}(f)+\mathrm{H}_{n}(g)</m>, which we leave as an exercise to be further explored in <xref ref="rem-3.4"/>.
                </p>
              </proof>
            </lemma>
      
            <p>
              Notice, however, that the converse is false: the induced map in homology can be the zero map (for all homological degrees) even if the original map of complexes is not nullhomotopic.
            </p>

            <exercise xml:id="exe-28">
              <p>
                Consider the following map of complexes:
              </p>
              
              <image source="2023_10_23_e2d6a27704be928b3deeg-054(1).jpg" width="75%"/>
              
              <p>
                Show that this map is not nullhomotopic, but that the induced map in homology is zero.
              </p>
            </exercise>

            <definition xml:id="def-2.10"><title>Homotopy Equivalent</title>
              <statement>
                <p>
                  If <m>f:\left(F_{\bullet}, \partial_{\bullet}^{F}\right) \longrightarrow\left(G_{\bullet}, \partial_{\bullet}^{G}\right)</m> and <m>g:\left(G_{\bullet}, \partial_{\bullet}^{G}\right) \longrightarrow\left(F_{\bullet}, \partial_{\bullet}^{F}\right)</m> are maps of complexes such that <m>f g</m> is homotopic to the identity map on <m>\left(G_{\bullet}, \partial_{\bullet}^{G}\right)</m> and <m>g f</m> is homotopic to the identity chain map on <m>\left(F_{\bullet}, \partial_{\bullet}^{F}\right)</m>, we say that <m>f</m> and <m>g</m> are <em>homotopy equivalences</em> and <m>\left(F_{\bullet}, \partial_{\bullet}^{F}\right)</m> and <m>\left(G_{\bullet}, \partial_{\bullet}^{G}\right)</m> are <em>homotopy equivalent</em>.
                </p>
              </statement>
            </definition>

            <corollary xml:id="cor-2.11"><title>Homotopy Equvivalences are Quasi-Isomorphisms</title>
              <statement>
                <p>
                  Homotopy equivalences are quasi-isomorphisms.
                </p>
              </statement>

              <proof>
                <p>
                  If <m>f:\left(F_{\bullet}, \partial_{\bullet}^{F}\right) \longrightarrow\left(G_{\bullet}, \partial_{\bullet}^{G}\right)</m> and <m>g:\left(G_{\bullet}, \partial_{\bullet}^{G}\right) \longrightarrow\left(F_{\bullet}, \partial_{\bullet}^{F}\right)</m> are such that <m>f g</m> is homotopic to <m>1_{G_{\bullet}}</m> and <m>g f</m> is homotopic to <m>1_{F_{\bullet}}</m>, then by <xref ref="lem-2.9"/> the map <m>f g</m> induces the identity map on homology. 
                  So for all <m>n</m> we have
                  <me>
                    \mathrm{H}_{n}(f) \mathrm{H}_{n}(g)=\mathrm{H}_{n}(f g)=\mathrm{H}_{n}(1)=1.
                  </me>
                  Therefore, <m>\mathrm{H}_{n}(f)</m> and <m>\mathrm{H}_{n}(g)</m> must both be isomorphisms.
                </p>
              </proof>
            </corollary>
      
            <p>
              The converse is false.
            </p>

            <exercise xml:id="exe-29">
              <p>
                Let <m>\pi</m> denote the projection map from <m>\mathbb{Z}</m> to <m>\mathbb{Z} / 2 \mathbb{Z}</m>. 
                The chain map
              </p>
              <image source="2023_10_23_e2d6a27704be928b3deeg-054.jpg" width="75%"/>
              <p>
                is a quasi-isomorphism but not a homotopy equivalence.
              </p>
            </exercise>

            <remark xml:id="rem-2.12">
              <p>
                The relation <m>F \simeq G</m>, meaning "there is a quasi-isomorphism from <m>F</m> to <m>G</m> ", is not symmetric: in <xref ref="exe-29"/>, there is no quasi-isomorphism going in the opposite direction of the one given.
              </p>
            </remark>

          </subsection>

          <subsection xml:id="subsec-complex-complex"><title>Complexes of Complexes</title>

            <blockquote>
              <p>
                <q>
                  Every complex problem has a simple solution that doesn't work.
                </q>
              </p>
              <attribution>H.L. Mencken</attribution>
            </blockquote>
    
            <p>
              Now that we know about maps between complexes, it's time to point out that we can also talk about complexes of complexes and exact sequences of complexes. 
              While we will later formalize this a little better when we discover that <m>\mathrm{Ch}(R)</m> is an <em>abelian category</em>, let's for now give quick definitions that we can use.
            </p>

            <definition xml:id="def-2.13"><title>Subcomplexes and Quotient Complexes</title>
              <statement>
                <p>
                  Given complexes <m>B</m> and <m>C, B</m> is a <em>subcomplex</em> of <m>C</m> if <m>B_{n}</m> is a submodule of <m>C_{n}</m> for all <m>n</m>, and the inclusion maps <m>\iota_{n}: B_{n} \subseteq C_{n}</m> define a map of complexes <m>\iota: B \longrightarrow C</m>. 
                  Given a subcomplex <m>B</m> of <m>C</m>, the <em>quotient</em> of <m>C</m> by <m>B</m> is the complex <m>C / B</m> that has <m>C_{n} / B_{n}</m> in homological degree <m>n</m>, with differential induced by the differential on <m>C_{n}</m>.
                </p>
              </statement>
            </definition>

            <exercise xml:id="exe-30">
              <p>
                If <m>B</m> is a subcomplex of <m>C</m>, then the differential <m>d</m> on <m>C</m> satisfies <m>d_{n}\left(B_{n}\right) \subseteq B_{n-1}</m>. 
                Therefore, <m>d_{n}</m> induces a map of <m>R</m>-modules <m>C_{n} / B_{n} \longrightarrow C_{n-1} / B_{n-1}</m> for all <m>n</m>, so that our definition of the differential on <m>C / B</m> actually makes sense.
              </p>
            </exercise>
      
            <p>
              We can also talk about kernels and cokernels of maps of complexes.
            </p>

            <definition xml:id="def-2.14"><title>Kernel, Cokernel</title>
              <statement>
                <p>
                  Given any map of complexes <m>f: B_{\bullet} \longrightarrow C_{\bullet}</m>, the <em>kernel</em> of <m>f</m> is the subcomplex <m>\ker f</m> of <m>B_{\bullet}</m> that we can assemble from the the kernels <m>\ker f_{n}</m>. 
                  More precisely, <m>\operatorname{ker} f</m> is the complex
                  <me>
                    \cdots \longrightarrow \operatorname{ker} f_{n+1} \longrightarrow \operatorname{ker} f_{n} \longrightarrow \operatorname{ker} f_{n-1} \longrightarrow \cdots
                  </me>
                  where the differentials are simply the corresponding restrictions of the differentials on <m>B_{\bullet}</m>. Similarly, the image of <m>f</m> is the subcomplex of <m>C</m>.
                  <me>
                    \cdots \longrightarrow \operatorname{im} f_{n+1} \longrightarrow \operatorname{im} f_{n} \longrightarrow \operatorname{im} f_{n-1} \longrightarrow \cdots
                  </me>
                  where the differentials are given by restriction of the corresponding differentials in <m>C_{\bullet}</m>. 
                  The <em>cokernel</em> of <m>f</m> is the quotient complex <m>C_{\bullet} / \operatorname{im} f</m>.
                </p>
              </statement>
            </definition>

            <p>
              Again, there are some details to check.
            </p>

            <exercise xml:id="exe-31">
              <p>
                Show that the kernel, image, and cokernel of a complex map are indeed complexes.
              </p>
            </exercise>

            <definition xml:id="def-2.15"><title>Complexes in <m>\mathrm{Ch}(R)</m></title>
              <statement>
                <p>
                  A <em>complex</em> in <m>\mathrm{Ch}(R)</m> is a sequence of complexes of <m>R</m>-modules <m>C_{n}</m> and chain maps <m>d_{n}: C_{n} \longrightarrow C_{n-1}</m> between them
                  <me>
                    \cdots \longrightarrow C_{n+1} \stackrel{d_{n+1}}{\longrightarrow} C_{n} \stackrel{d_{n}}{\longrightarrow} C_{n-1} \longrightarrow \cdots
                  </me>
                  such that <m>d_{n} d_{n+1}=0</m> for all <m>n</m>. 
                  A complex of complexes is a diagram of the form
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-055.jpg" width="75%"/>
                <p>
                  where <m>C_{i, j}</m> is the module in homological degree <m>j</m> in the complex <m>C_{i}</m>. 
                  The <m>n</m>th column corresponds to the complex <m>C_{n}</m>, and every row is also a complex. 
                  The vertical maps are the differentials on each individual complex; 
                  the horizontal maps are the differentials on the complex of complexes.
                </p>
              </statement>
            </definition>
      
            <p>
              Given a complex <m>C</m> in <m>\operatorname{Ch}(R)</m>, we can talk about cycles and boundaries, which are a sequence of subcomplexes of the complexes in <m>C</m>, and thus its homology. 
              Such a complex is exact if <m>\operatorname{im} d_{n+1}=\operatorname{ker} d_{n}</m> for all <m>n</m>.
            </p>

            <definition xml:id="def-2.16"><title>Short Exact Sequences in <m>\mathrm{Ch}(R)</m></title>
              <statement>
                <p>
                  A <em>short exact sequence</em> of complexes is an exact complex in <m>\mathrm{Ch}(R)</m> of the form
                  <me>
                    0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0 .
                  </me>
                  Equivalently, a short exact sequence of complexes is a commutative diagram
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-056.jpg" width="75%"/>
                <p>
                  where the rows are exact and the columns are complexes.
                </p>
              </statement>
            </definition>

          </subsection>

          <outcomes>
            <ul>
              <li>
                <p>

                </p>
              </li>
            </ul>
          </outcomes>

        </section>

        <section xml:id="sec-split"><title>Split Exact Sequences</title>

          <objectives>
            <ul>
              <li>
                
              </li>
            </ul>
          </objectives>

          <subsection xml:id="subsec-splitting"><title>Definition and the Splitting Lemma</title>

            <blockquote>
              <p>
                <q>
                  The split in you is clear.
                </q>
              </p>
              <attribution>John Cantwell Kiley</attribution>
            </blockquote>
          
            <p>
              In this section, we will discuss short exact sequences of modules in a bit more detail. 
              We note, however, that everything we will discuss here can be extended for short exact sequences of complexes, and that the generalization is not too difficult: one just needs to replace modules with complexes and maps of modules by maps of complexes.
            </p>

            <example xml:id="ex-2.17">
              <p>
                Fix a ring <m>R</m>, and let <m>A</m> and <m>C</m> be <m>R</m>-modules. 
                Consider the inclusion <m>i: A \rightarrow A \oplus C</m> of <m>A</m> into the first component of the direct sum, and the projection map <m>\pi: A \oplus C \rightarrow C</m> onto the second component of the product. 
                These two maps fit into a short exact sequence
                <me>
                  0 \longrightarrow A \stackrel{i}{\longrightarrow} A \oplus C \stackrel{p}{\longrightarrow} C \longrightarrow 0
                </me>
                These are sometimes called <em>trivial short exact sequences</em>.
              </p>
            </example>
        
            <p>
              On the one hand, the short exact sequences that look like this one are very important; 
              on the other hand, not all short exact sequences are of this type.
            </p>

            <definition xml:id="def-2.18"><title>Split Short Exact Sequences</title>
              <statement>
                <p>
                  We say that a short exact sequence
                  <me>
                    0 \longrightarrow A \longrightarrow B \longrightarrow C \longrightarrow 0
                  </me>
                  <em>splits</em> or is a <em>split short exact sequence</em> if it is isomorphic to
                  <me>
                    0 \longrightarrow A \stackrel{i}{\longrightarrow} A \oplus C \stackrel{p}{\longrightarrow} C \longrightarrow 0
                  </me>
                  where <m>i</m> is the inclusion of the first component and <m>p</m> is the projection onto the second component.
                </p>
              </statement>
            </definition>

            <lemma xml:id="lem-2.19"><title>Splitting Lemma</title>
              <statement>
                <p>
                  Consider the short exact sequence
                  <me>
                    0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0
                  </me>
                  of <m>R</m>-modules. 
                  The following are equivalent:
                  <ol>
                    <li>
                      <p>
                        There exists a homomorphism of <m>R</m>-modules <m>q: B \longrightarrow A</m> such that <m>q f=\operatorname{id}_{A}</m>.
                      </p>
                    </li>
        
                    <li>
                      <p>
                        There exists a homomorphism of <m>R</m>-modules <m>r: C \longrightarrow B</m> such that <m>g r=\operatorname{id}_{C}</m>.
                      </p>
                    </li>
        
                    <li>
                      <p>
                        The short exact sequence splits.
                      </p>
                    </li>
                  </ol>
                </p>
              </statement>

              <proof>
                <p>
                  First, we will show that c implies a and b. If the sequence splits, then consider an isomorphism of complexes
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-057.jpg" width="50%"/>
                <p>
                  meaning that the diagram commutes and <m>a, b</m>, and <m>c</m> are isomorphisms of <m>R</m>-modules, <m>i</m> is the inclusion in the first component, and <m>p</m> is the projection onto the second component. 
                  Let <m>\pi: A \oplus C \longrightarrow A</m> be the projection onto the first component, and <m>j: C \longrightarrow A \oplus C</m> be the inclusion onto the first component. 
                  Now consider the maps <m>q:=a^{-1} \pi b</m> and <m>r:=b^{-1} j c</m>. 
                  Then
                  <me>
                    \begin{array}{rlr}
                    q f &amp; =a^{-1} \pi b f &amp; \\
                    &amp; =a^{-1} \pi i a &amp; \text { by commutativity } \\
                    &amp; =a^{-1} a &amp; \text { because } \pi i=\mathrm{id}_{A} \\
                    &amp; =1_{A} &amp;
                    \end{array}
                  </me>
                  and
                  <me>
                    \begin{aligned}
                    g r &amp; =g b^{-1} j c &amp; &amp; \\
                    &amp; =c^{-1}(c g) b^{-1} j c &amp; &amp; \text { multiplying by } c^{-1} c=1_{C} \\
                    &amp; =c^{-1}(p b) b^{-1} j c &amp; &amp; \text { by commutativity } \\
                    &amp; =c^{-1} p j c &amp; &amp; \text { because } b b^{-1}=1_{B} \\
                    &amp; =c^{-1} c &amp; &amp; \text { because } p j=\mathrm{id}_{C} \\
                    &amp; =1_{C} . &amp; &amp;
                    \end{aligned}
                  </me>
                  Therefore, c implies a and b.
                </p>
            
                <p>
                  Now suppose that a holds, and let's show that the sequence splits. 
                  First, we need to show that <m>B \cong A \oplus C</m>. 
                  Every <m>b \in B</m> can be written as
                  <me>
                    b=(b-f q(b))+f q(b)
                  </me>
                  where <m>f q(b) \in \operatorname{im} f \cong A</m>, and
                  <me>
                    q(b-f q(b))=q(b)-\underbrace{q f}_{\operatorname{id}_{A}}(q(b))=q(b)-q(b)=0
                  </me>
                  so <m>b-f q(b) \in \operatorname{ker} q</m>. 
                  This shows that <m>B=\operatorname{im} f+\operatorname{ker} q</m>. 
                  Moreover, if <m>f(a) \in \operatorname{ker} q</m>, then <m>a=q f(a)=0</m>, so <m>\operatorname{im} f \cap \operatorname{ker} q=0</m>, and <m>B=\operatorname{im} f \oplus \operatorname{ker} q</m>. 
                  Now when we restrict <m>g</m> to <m>\operatorname{ker} q, g</m> becomes injective. 
                  We claim it is also surjective, and thus an isomorphism. 
                  Indeed, for any <m>c \in C</m> we can pick <m>b \in B</m> such that <m>g(b)=c</m>, since <m>g</m> is surjective, and we showed that we can write <m>b=f(a)+k</m> for some <m>k \in \operatorname{ker} q</m>. 
                  Then
                  <me>
                    g(k)=\underbrace{g f}_{0}(a)+g(k)=g(b)=c.
                  </me>
                  Finally, note that <m>\operatorname{im} f \cong A</m>, so we conclude that <m>B \cong A \oplus C</m>, via the isomorphism <m>\varphi</m> given by
                  <me>
                    \begin{aligned}
                    &amp; B \longrightarrow \operatorname{im} f \oplus \operatorname{ker} q \longrightarrow A \oplus C \\
                    &amp; b \longmapsto(f q(b), b-f q(b)) \longmapsto(q(b), g(b)) .
                    \end{aligned}
                  </me>
                  Since <m>g f=0</m> and <m>q f=\operatorname{id}_{A}, \varphi f(a)=(q f(a), 0)=(a, 0)</m>, so <m>\varphi f=i</m>, where <m>i: A \longrightarrow A \oplus C</m> is the inclusion on the first factor. 
                  If <m>p: A \oplus C \longrightarrow C</m> denotes the projection onto the second factor, <m>p \varphi=g</m>. 
                  Together, these two facts say that the following is a map of complexes:
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-058.jpg" width="50%"/>
                <p>
                  Since <m>\varphi</m> is an isomorphism, so is our map of complexes, and thus our original sequence is a split exact sequence. 
                  This shows that a implies <m>c</m>.
                </p>
            
                <p>
                  Now assume b holds. 
                  Every <m>b \in B</m> can be written as
                  <me>
                    b=(b-r g(b))+r g(b)
                  </me>
                  where <m>r g(b) \in \operatorname{im} r</m> and
                  <me>
                    g(b-r g(b))=g(b)-\underbrace{g r}_{\mathrm{id}_{C}}(g(b))=g(b)-g(b)=0
                  </me>
                  so <m>b-r g(b) \in \operatorname{ker} g</m>. 
                  This shows that <m>B=\operatorname{ker} g+\operatorname{im} r</m>. 
                  Moreover, if <m>r(c) \in \operatorname{ker} g</m>, then
                  <me>
                    c=\operatorname{id}_{C}(c)=g r(c)=0
                  </me>
                  Therefore, <m>B=\operatorname{ker} g \oplus \operatorname{im} r</m>. 
                  Now <m>r</m> is injective, since <m>r(c)=0 \Longrightarrow c=g r(c)=0</m>, and thus <m>\operatorname{im} r \cong C</m>. 
                  Since <m>\operatorname{ker} g=\operatorname{im} f \cong A</m>, we conclude that <m>B \cong A \oplus C</m>, via the isomorphism
                  <me>
                    \begin{aligned}
                    &amp; A \oplus C \stackrel{\psi}{\longrightarrow} B \\
                    &amp; (a, c) \longmapsto f(a)+r(c) .
                    \end{aligned}
                  </me>
                  Finally, let <m>i: A \longrightarrow A \oplus C</m> denote the inclusion of the first factor, and <m>p: A \oplus C \longrightarrow C</m> denote the projection onto the second factor. 
                  By construction, <m>\psi i=f</m>. 
                  Moreover,
                  <me>
                    g \psi(a, c)=\underbrace{g f}_{0}(a)+\underbrace{g r}_{\mathrm{id}_{C}}(c)=c
                  </me>
                  so <m>g \psi=p</m>. 
                  Together, these say that the diagram
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-059.jpg" width="50%"/>
                <p>
                  commutes, and must then be an isomorphism of short exact sequences.
                </p>
              </proof>
            </lemma>
        
            <definition xml:id="def-2.20">
              <statement>
                <p>
                  Given a split short exact sequence
                  <me>
                    0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0
                  </me>
                  maps <m>q</m> and <m>r</m> satisfying the conditions of the Splitting Lemma are called splittings.
                </p>
              </statement>
            </definition>

            <remark xml:id="rem-2.21">
              <p>
                In the split short exact sequence
                <me>
                  0 \longrightarrow A \stackrel{i}{\longrightarrow} A \oplus C \stackrel{p}{\longrightarrow} C \longrightarrow 0
                </me>
                the canonical projection <m>q: A \oplus C \rightarrow A</m> and the usual inclusion <m>r: C \rightarrow A \oplus C</m> are splittings.
              </p>
            </remark>

          </subsection>

          <subsection xml:id="subsec-when-split"><title>When Do Short Exact Sequences Split?</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>

            <exercise xml:id="exe-32">
              <p>
                Let <m>k</m> be a field. 
                Show that every short exact sequence of <m>k</m>-vector spaces splits.
              </p>
            </exercise>
        
            <p>
              The Rank-Nulity Theorem can be recast in this setting as a consequence of the fact that every short exact sequence of <m>k</m>-vector spaces splits.
            </p>
  
            <exercise xml:id="exe-33">
              <p>
                Prove the Rank-Nulity Theorem using <xref ref="exe-32"/>: show that given any linear transformation <m>T: V \rightarrow W</m> of <m>k</m>-vector spaces,
                <me>
                  \operatorname{dim}(\operatorname{im} T)+\operatorname{dim}(\operatorname{ker} T)=\operatorname{dim} V
                </me>
              </p>
            </exercise>
  
            <p>
              But over a general ring, not every short exact sequence splits.
            </p>
  
            <example xml:id="ex-2.22">
              <p>
                The short exact sequence
                <me>
                  0 \longrightarrow \mathbb{Z} \stackrel{2}{\longrightarrow} \mathbb{Z} \longrightarrow \mathbb{Z} / 2 \longrightarrow 0
                </me>
                is not split. 
                Indeed, <m>\mathbb{Z}</m> does not have any 2 -torsion elements, so it is not isomorphic to <m>\mathbb{Z} \oplus \mathbb{Z} / 2</m>.
              </p>
              <p>
                An alternative explanation is that there is no splitting to the inclusion <m>\mathbb{Z} \stackrel{2}{\longrightarrow} \mathbb{Z}</m>. 
                On the one hand, every <m>\mathbb{Z}</m>-module map is given by multiplication by a fixed integer <m>n</m>, so a splitting <m>f: \mathbb{Z} \longrightarrow \mathbb{Z}</m> would be of the form <m>f(a)=n a</m> for some fixed <m>n</m>. 
                On the other hand, our proposed splitting <m>f</m> must send <m>2</m> to <m>1</m> , but there is no integer solution <m>n</m> to <m>2 n=f(2)=1</m>.
              </p>
            </example>
  
            <p>
              More surprisingly, a short exact sequence of the form
              <me>
                0 \longrightarrow A \stackrel{f}{\longrightarrow} A \oplus C \stackrel{g}{\longrightarrow} C \longrightarrow 0
              </me>
              is not necessarily split, not unless <m>f</m> is the inclusion of the first component and <m>g</m> is the projection onto the second component, as the next example will show.
            </p>
  
            <example xml:id="ex-2.23">
              <p>
                Consider the short exact sequence
                <me>
                  0 \longrightarrow \mathbb{Z} /(2) \stackrel{f}{\longrightarrow} \mathbb{Z} /(4) \stackrel{g}{\longrightarrow} \mathbb{Z} /(2) \longrightarrow 0
                </me>
                where <m>f</m> is the inclusion of the subgroup generated by 2, so <m>f(1+(2))=2+(4)</m>, and <m>g</m> is the quotient onto that subgroup, meaning <m>g(1)=1</m>. 
                This is not a split short exact sequence, because <m>\mathbb{Z} /(4) \nsucceq \mathbb{Z} /(2) \oplus \mathbb{Z} /(2)</m>. 
                Now let
                <me>
                  M:=\bigoplus_{\mathbb{N}}(\mathbb{Z} /(2) \oplus \mathbb{Z} /(4))
                </me>
                be the direct sum of infinitely many copies of <m>\mathbb{Z} /(2) \oplus \mathbb{Z} /(4)</m>. 
                Then
                <me>
                  \mathbb{Z} /(2) \oplus M \cong M \cong M \oplus \mathbb{Z} /(4)
                </me>
                and the sequence
                <me>
                  0 \longrightarrow \mathbb{Z} /(2) \stackrel{h}{\longrightarrow} \mathbb{Z} /(4) \oplus M \stackrel{t}{\longrightarrow} \mathbb{Z} /(2) \oplus M \longrightarrow 0
                </me>
                with <m>h(a)=(f(a), 0)</m> and <m>t(a, m)=(g(a), m)</m> is still exact. 
                The middle term is indeed isomorphic to the direct sum of the other two:
                <me>
                  \mathbb{Z} /(4) \oplus M \cong M \cong(M \oplus \mathbb{Z} /(2)) \oplus \mathbb{Z} /(2)
                </me>
                And yet this is not a split exact sequence: 
                if we had a splitting <m>q: \mathbb{Z} /(4) \oplus M \longrightarrow \mathbb{Z} /(2)</m> of <m>h</m>, then its restriction to the first factor would give us a splitting <m>\mathbb{Z} /(4) \longrightarrow \mathbb{Z} /(2)</m> of <m>f</m>, which we know cannot exist, since
                <me>
                  0 \longrightarrow \mathbb{Z} /(2) \stackrel{f}{\longrightarrow} \mathbb{Z} /(4) \stackrel{g}{\longrightarrow} \mathbb{Z} /(2) \longrightarrow 0
                </me>
                does not split.
              </p>
            </example>
        
            <p>
              Given splittings <m>q</m> and <m>r</m> for a short exact sequence as in <xref ref="lem-2.19"/>, we can quickly show that our short exact sequence splits using the Five Lemma. 
              To prove the Five Lemma, one needs to use diagram chasing. 
              Diagram chasing is a common technique in homological algebra, which essentially consists of tracing elements around in the diagram. 
              We will see some examples of diagram chasing in the next section.
            </p>
  
            <exercise xml:id="five-lemma"><title>The Five Lemma</title>
              <p>
                Consider the following commutative diagram of <m>R</m>-modules with exact rows:
              </p>
              <image source="2023_10_23_e2d6a27704be928b3deeg-060.jpg" width="50%"/>
              <p>
                Show that if <m>a, b, d</m>, and <m>e</m> are isomorphisms, then <m>c</m> is an isomorphism.
              </p>
            </exercise>
  
            <remark xml:id="rem-2.24">
              <p>
                Given a short exact sequence, suppose we have <m>R</m>-module homomorphisms <m>q</m> and <m>r</m>
              </p>
  
              <image source="2023_10_23_e2d6a27704be928b3deeg-061.jpg" width="30%"/>
            
              <p>
                such that <m>q f=\operatorname{id}_{A}</m> and <m>r g=\operatorname{id}_{C}</m>. 
                Then we get an induced map
                <me>
                  \begin{aligned}
                  &amp; B \stackrel{\varphi}{\longrightarrow} A \oplus C \\
                  &amp; b \longmapsto(q(b), g(b))
                  \end{aligned}
                </me>
                such that the diagram
              </p>
              <image source="2023_10_23_e2d6a27704be928b3deeg-061(1).jpg" width="30%"/>
              <p>
                commutes. 
                The <xref text="title" ref="five-lemma"/> guarantees that <m>\varphi</m> must be an isomorphism, so our diagram is an isomorphism of short exact sequences.
              </p>
            </remark>
      
            <p>
              There are many ways in which <m>R</m>-Mod behaves better than the category of groups, and this is one of them.
            </p>
  
            <remark xml:id="rem-2.25">
              <p>
                The <xref text="title" ref="lem-2.19"/> does not hold if we replace <m>R</m>-modules with the category <m>\Grp</m> of groups. 
                For example, consider the symmetric group on 3 elements <m>S_{3}</m> and the inclusion <m>A_{3} \hookrightarrow S_{3}</m> of the alternating group in <m>S_{3}</m>. 
                Notice that <m>A_{3}</m> is precisely the kernel of the sign map
                <me>
                  \operatorname{sign}: S_{3} \longrightarrow \mathbb{Z} / 2
                </me>
                which sends even permutations to <m>0</m> and odd permutations to <m>1</m> . 
                Therefore,
                <me>
                  0 \longrightarrow A_{3} \longrightarrow S_{3} \longrightarrow \mathbb{Z} / 2 \longrightarrow 0
                </me>
                is a short exact sequence.
                When writing exact sequences of nonabelian groups such as this one, one sometimes uses <m>\{e\}</m> for instead of <m>0</m>, to indicate that trivial group. 
                So our short exact sequence is
                <me>
                  \{e\} \longrightarrow A_{3} \longrightarrow S_{3} \longrightarrow \mathbb{Z} / 2 \longrightarrow\{e\}
                </me>
              </p>
          
              <p>
                Moreover, this exact sequence is not split, since <m>S_{3}</m> is not abelian but <m>A_{3} \oplus \mathbb{Z} / 2</m> is, and thus <m>S_{3} \neq A_{3} \oplus \mathbb{Z} / 2</m>. 
                However, any group homomorphism <m>u: \mathbb{Z} / 2 \rightarrow S_{3}</m> defined by sending the generator to any two cycle is a splitting for our short exact sequence, meaning signo <m>u=\mathrm{id}_{\mathbb{Z} / 2}</m>.
              </p>
          
              <p>
                Funny enough, there is no splitting for the inclusion <m>A_{3} \subseteq S_{3}</m>, since there are no nontrivial homomorphisms <m>S_{3} \rightarrow A_{3}: A_{3}</m> has no elements of order <m>2</m>, so a group homomorphism <m>S_{3} \rightarrow A_{3}</m> must send every <m>2</m>-cycle in <m>S_{3}</m> must be sent to the identity, but <m>2</m>-cycles generate <m>S_{3}</m>.
              </p>
            </remark>
        
            <p>
              We will return to the topic of split short exact sequences when we talk about projective and injective modules.
            </p>
        
            <exercise xml:id="exe-35">
              <p>
                Fix a ring <m>R</m>. 
                Show that if <m>F</m> is a free <m>R</m>-module, then every short exact sequence of <m>R</m>-modules
                <me>
                  0 \longrightarrow A \longrightarrow B \longrightarrow F \longrightarrow 0
                </me>
                splits.
              </p>
            </exercise>

          </subsection>

          <outcomes>
            <ul>
              <li>
                <p>

                </p>
              </li>
            </ul>
          </outcomes>
          
        </section>

        <section xml:id="sec-les"><title>Long Exact Sequences</title>

          <objectives>
            <ul>
              <li>
                
              </li>
            </ul>
          </objectives>

          <subsection xml:id="subsec-snake"><title>The Snake Lemma</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>

            <p>
              A long exact sequence is just what it sounds like: an exact sequence that is, well, long. 
              Usually, we use the term long exact sequence to refer to any exact sequence, especially if it is not a short exact sequence. 
              So in particular, a long exact sequence does not literally have to be that long.
            </p>
      
            <p>
              Long exact sequences arise naturally in various ways, and are often induced by some short exact sequence. 
              The first long exact sequence one encounters is the long exact sequence on homology. 
              All other long exact sequences are, in some way, a special case of this one. 
              The main tool we need to build it is the Snake Lemma.
            </p>
  
            <theorem xml:id="thm-2.26"><title>Snake Lemma</title>
              <statement>
                <p>
                  Consider the commutative diagram of <m>R</m>-modules
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-062.jpg" width="75%"/>
                <p>
                  If the rows of the diagram are exact, then there exists an exact sequence
                  <me>
                    \operatorname{ker} f \longrightarrow \operatorname{ker} g \longrightarrow \operatorname{ker} h \stackrel{\partial}{\longrightarrow} \operatorname{coker} f \longrightarrow \operatorname{coker} g \longrightarrow \text { coker } h
                  </me>
                  Given <m>c^{\prime} \in \operatorname{ker} h</m>, pick <m>b^{\prime} \in B^{\prime}</m> such that <m>p^{\prime}\left(b^{\prime}\right)=c^{\prime}</m>, and <m>a \in A</m> such that <m>i(a)=g\left(b^{\prime}\right)</m>. 
                  Then
                  <me>
                    \partial\left(c^{\prime}\right)=a+\operatorname{im} f \in \operatorname{coker} f
                  </me>
                  The picture to keep in mind (and which explains the name of the lemma) is the following:
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-062(1).jpg" width="75%"/>
              </statement>
  
              <proof>
                <p>
                  If <m>a^{\prime} \in \operatorname{ker} f</m>, then
                  <me>
                    g\left(i^{\prime}\left(a^{\prime}\right)\right)=i f\left(a^{\prime}\right)=0
                  </me>
                  by commutativity, so <m>i^{\prime}\left(a^{\prime}\right) \in \operatorname{ker} g</m>. 
                  Similarly, if <m>b^{\prime} \in \operatorname{ker} g</m> then <m>p^{\prime}\left(b^{\prime}\right) \in \operatorname{ker}(g)</m>. 
                  So
                  <me>A^{\prime} \stackrel{i^{\prime}}{\longrightarrow} B^{\prime} \stackrel{p^{\prime}}{\longrightarrow} C^{\prime} \quad \text { restrict to maps } \quad \operatorname{ker} f \stackrel{i^{\prime}}{\longrightarrow} \operatorname{ker} g \stackrel{p^{\prime}}{\longrightarrow} \operatorname{ker} h \text {. }</me>
                </p>
          
                <p>
                  We claim that the sequence obtained by restriction
                  <me>\operatorname{ker} f \stackrel{i^{\prime}}{\longrightarrow} \operatorname{ker} g \stackrel{p^{\prime}}{\longrightarrow} \operatorname{ker} h</me>
                  is exact. 
                  On the one hand, we already know that the original maps satisfy <m>p^{\prime} i^{\prime}=0</m>, so their restrictions must satisfy this as well, guaranteeing that
                  <me>i^{\prime}(\operatorname{ker} f) \subseteq \operatorname{ker}\left(\operatorname{ker} g \stackrel{p^{\prime}}{\rightarrow} \operatorname{ker} h\right)</me>
                  On the other and, if <m>b^{\prime} \in \operatorname{ker} g</m> is such that <m>p^{\prime}\left(b^{\prime}\right)=0</m>, then by exactness of the original sequence there exists <m>a^{\prime} \in A^{\prime}</m> such that <m>i^{\prime}\left(a^{\prime}\right)=b^{\prime}</m>; 
                  we only need to check that we can choose such <m>a^{\prime}</m> satisfying <m>a^{\prime} \in \operatorname{ker} f</m>. 
                  An indeed, by commutativity, any <m>a^{\prime}</m> with <m>i^{\prime}\left(a^{\prime}\right)=b^{\prime}</m> satisfies
                  <me>i f\left(a^{\prime}\right)=g i^{\prime}\left(a^{\prime}\right)=g\left(b^{\prime}\right)=0 \text {, }</me>
                  and since <m>i</m> is injective, we must have <m>f\left(a^{\prime}\right)=0</m>. 
                  So we have shown that the following is an exact sequence:
                  <me>\operatorname{ker} f \stackrel{i^{\prime}}{\longrightarrow} \operatorname{ker} g \stackrel{p^{\prime}}{\longrightarrow} \operatorname{ker} h</me>
                </p>
          
                <p>
                  Similarly, if <m>a \in \operatorname{im} f</m>, the commutativity of the diagram guarantees that <m>i(a) \in \operatorname{im} g</m>, and if <m>b \in \operatorname{im} g</m>, then <m>p(b) \in \operatorname{im} h</m>. 
                  So the maps <m>A \stackrel{i}{\longrightarrow} B \stackrel{p}{\longrightarrow} C</m> restrict to maps
                  <me>\operatorname{im} f \stackrel{i}{\longrightarrow} \operatorname{im} g \stackrel{p}{\longrightarrow} \operatorname{im} h</me>
                  which then induce maps
                  <me>\text { coker } f \longrightarrow \text { coker } g \longrightarrow \text { coker } h \text {. }</me>
                  To make the notation less heavy, we denote the induced maps on the quotients by <m>i</m> and <m>p</m>. 
                  Again, the fact that <m>p i=0</m> automatically gives us that the restrictions satisfy
                  <me>\operatorname{im}(\operatorname{coker} f \rightarrow \operatorname{coker} g) \subseteq \operatorname{ker}(\operatorname{coker} g \rightarrow \operatorname{coker} h)</me>
                  so we only need to check equality. 
                  Consider <m>b+\operatorname{im} g</m> such that <m>p(b+\operatorname{im} g)=0</m>, meaning that <m>p(b)=0</m>, meaning that <m>p(b) \in \operatorname{im} h</m>. 
                  Let <m>c^{\prime} \in C</m> be such that <m>h\left(c^{\prime}\right)=p(b)</m>. Since <m>p^{\prime}</m> is surjective, there exists <m>b^{\prime} \in B^{\prime}</m> such that <m>p^{\prime}\left(b^{\prime}\right)=c^{\prime}</m>, and by commutativity,
                  <me>p g\left(b^{\prime}\right)=h p^{\prime}\left(b^{\prime}\right)=h\left(c^{\prime}\right)=p(b) \text {. }</me>
                  Then <m>b-g\left(b^{\prime}\right) \in \operatorname{ker} p=\operatorname{im} i</m>. 
                  Let <m>a \in A</m> be such that <m>i(a)=b-g\left(b^{\prime}\right)</m>. 
                  Now in coker <m>g</m> we have
                  <me>
                    \begin{aligned}
                    b+\operatorname{im} g &amp; =b-g\left(b^{\prime}\right)+\operatorname{im} g \\
                    &amp; =i(a)+\operatorname{im} g \\
                    &amp; =i(a+\operatorname{im} f)
                    \end{aligned}
                  </me>
                  This concludes the proof of exactness of <m>\operatorname{ker} f \longrightarrow \operatorname{ker} g \longrightarrow \operatorname{ker} h \quad</m> and <m>\quad</m> coker <m>f \longrightarrow \operatorname{coker} g \longrightarrow\coker h</m>.
                </p>
          
                <p>
                  We still need to show the parts of the statement related to the connecting homomorphism <m>\partial</m>. 
                  Our definition of <m>\partial</m> can be visualized as follows:
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-064(1).jpg"/>
                <p>
                  Let's recap the process in words. 
                  First, we fix <m>c^{\prime} \in \operatorname{ker} h \subseteq C^{\prime}</m>. 
                  Since <m>p^{\prime}</m> is surjective, we can always pick <m>b^{\prime} \in B^{\prime}</m> such that <m>p^{\prime}\left(b^{\prime}\right)=c^{\prime}</m>. 
                  Since <m>c^{\prime} \in</m> ker <m>h</m>, by commutativity we have
                  <me>p g\left(b^{\prime}\right)=h p^{\prime}\left(b^{\prime}\right)=h\left(c^{\prime}\right)=0,</me>
                  so <m>g\left(b^{\prime}\right) \in \operatorname{ker} p=\operatorname{im} i</m>. 
                  Therefore, there exists <m>a \in A</m> such that <m>i(a)=g\left(b^{\prime}\right)</m>. 
                  In fact, since <m>i</m> is injective, there exists a unique <m>a \in A</m> such that <m>i(a)=g\left(b^{\prime}\right)</m>. 
                  Our definition of <m>\partial\left(c^{\prime}\right)</m> sets
                  <me>\partial\left(c^{\prime}\right)=a+\operatorname{im} f \in \operatorname{coker} f .</me>
                  The fact that <m>\partial</m> is a homomorphism of <m>R</m>-modules follows from the fact that all the maps involved are homomorphisms of <m>R</m>-modules: 
                  given <m>c_{1}^{\prime}, c_{2}^{\prime} \in \operatorname{ker} h</m>, and <m>b_{1}^{\prime}, b_{2}^{\prime} \in B^{\prime}, a_{1}, a_{2} \in A</m> such that
                  <me>p^{\prime}\left(b_{1}^{\prime}\right)=c_{1}^{\prime}, \quad p^{\prime}\left(b_{2}^{\prime}\right)=c_{2}^{\prime}, \quad i\left(a_{1}\right)=g\left(b_{1}^{\prime}\right), \quad i\left(a_{2}\right)=g\left(b_{2}^{\prime}\right),</me>
                  we have
                  <me>i\left(a_{1}+a_{2}\right)=i\left(a_{1}\right)+i\left(a_{2}\right)=g\left(b_{1}^{\prime}\right)+g\left(b_{2}^{\prime}\right)=g\left(b_{1}^{\prime}+b_{2}^{\prime}\right) \text {, }</me>
                  So
                  <me>\partial\left(c_{1}^{\prime}\right)=a_{1}+\operatorname{im} f, \quad \partial\left(c_{2}^{\prime}\right)=a_{2}+\operatorname{im} f, \quad \text { and } \quad \partial\left(c_{1}^{\prime}+c_{2}^{\prime}\right)=\left(a_{1}+a_{2}\right)+\operatorname{im} f</me>
                  Therefore, <m>\partial\left(c_{1}^{\prime}\right)+\partial\left(c_{2}^{\prime}\right)=\partial\left(c_{1}^{\prime}+c_{2}^{\prime}\right)</m>. 
                  Similarly, given any <m>r \in R</m>,
                  <m>r\left(a_{1}+\operatorname{im} f\right)=r a_{1}+\operatorname{im} f, \quad i\left(r a_{1}\right)=r i\left(a_{1}\right)=r g\left(b_{1}^{\prime}\right)=g\left(r b_{1}^{\prime}\right), \quad</m> and <m>\quad p^{\prime}\left(r b_{1}\right)=r p^{\prime}\left(b_{1}\right)=r c_{1}</m>,
                  so <m>\partial\left(r c_{1}\right)=r\left(a_{1}+\operatorname{im} f\right)=r \partial\left(c_{1}\right)</m>. We now need to show the following:
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-064.jpg"/>
                <p>
                  Points 2) and 3) together say that the sequence
                  <m>\operatorname{ker} g \longrightarrow \operatorname{ker} h \stackrel{\partial}{\longrightarrow} \operatorname{coker} f \longrightarrow \operatorname{coker} g</m>
                  is exact, and this will complete the proof.
                </p>
          
                <p>
                  First, let's show that <m>\partial(0)</m> is well-defined. 
                  Ultimately, our definition of <m>\partial</m> only involves one choice, when we pick <m>b^{\prime} \in B^{\prime}</m> such that <m>p^{\prime}\left(b^{\prime}\right)=0</m>; 
                  we need to show that <m>\partial(0)</m> does not depend on the choice of <m>b^{\prime}</m>. 
                  Given <m>b^{\prime} \in B^{\prime}</m> such that <m>p^{\prime}\left(b^{\prime}\right)=0</m>, by exactness we have <m>b^{\prime} \in \operatorname{ker} p^{\prime}=\operatorname{im} i^{\prime}</m>. 
                  Therefore, there exists <m>a^{\prime} \in A^{\prime}</m> such that <m>i^{\prime}\left(a^{\prime}\right)=b^{\prime}</m>. 
                  Notice that <m>a:=f\left(a^{\prime}\right) \in A</m> is such that
                  <me>i(a)=i f\left(a^{\prime}\right)=g i^{\prime}\left(a^{\prime}\right)=g\left(b^{\prime}\right) .</me>
                  Thus our definition says that <m>\partial(0)=a+\operatorname{im} f \in \operatorname{coker} f</m>. 
                  Since <m>a=f\left(a^{\prime}\right) \in \operatorname{im} f</m>, we conclude that <m>a+\operatorname{im} f=0</m>, so <m>\partial(0)=0</m> for any choice of <m>b^{\prime}</m>.
                  Now consider any <m>c^{\prime} \in \operatorname{ker} h</m>. 
                  Again, to show <m>\partial</m> is well-defined, we need only to show it does not depend on the choice of <m>b^{\prime}</m> such that <m>p^{\prime}\left(b^{\prime}\right)=c^{\prime}</m>. 
                  Consider <m>b_{1}^{\prime}, b_{2}^{\prime} \in B^{\prime}</m> such that
                  <me>p^{\prime}\left(b_{1}^{\prime}\right)=p^{\prime}\left(b_{2}^{\prime}\right)=c^{\prime},</me>
                  and <m>a_{1}, a_{2} \in A</m> such that
                  <me>i\left(a_{1}\right)=g\left(b_{1}^{\prime}\right) \quad \text { and } \quad i\left(a_{2}\right)=g\left(b_{2}^{\prime}\right) \text {. }</me>
                  Note that
                  <me>i\left(a_{1}-a_{2}\right)=g\left(b_{1}^{\prime}-b_{2}^{\prime}\right)</me>
                  and since
                  <me>p^{\prime}\left(b_{1}^{\prime}-b_{2}^{\prime}\right)=c^{\prime}-c^{\prime}=0</me>
                  we must have
                  <me>a_{1}-a_{2}+\operatorname{im} f=\partial(0)=0</me>
                  Thus
                  <me>a_{1}+\operatorname{im} f=a_{2}+\operatorname{im} f,</me>
                  and this concludes our proof that <m>\partial</m> is well-defined.
                </p>
          
                <p>
                  Now we show 2): that <m>p^{\prime}(\operatorname{ker} g)=\operatorname{ker} \partial</m>.
                </p>
          
                <p>
                  If <m>b^{\prime} \in \operatorname{ker} g</m>, then the only <m>a \in A</m> such that <m>i(a)=g\left(b^{\prime}\right)=0</m> is <m>a=0</m>. 
                  Therefore, <m>\partial\left(p^{\prime}\left(b^{\prime}\right)\right)=0</m>, so <m>p^{\prime}(\operatorname{ker} g) \subseteq \operatorname{ker} \partial</m>. 
                  On the other hand, let <m>c^{\prime} \in \operatorname{ker} h</m> be such that <m>\partial\left(c^{\prime}\right)=0</m>. 
                  That means that for any <m>b^{\prime} \in B^{\prime}</m> such that <m>p^{\prime}\left(b^{\prime}\right)=c^{\prime}</m> we must have <m>g\left(b^{\prime}\right)=i(a)</m> for some <m>a \in \operatorname{im} f</m>. Let <m>a^{\prime} \in A^{\prime}</m> be such that <m>f\left(a^{\prime}\right)=a</m>. 
                  Then
                </p>
          
                <p>
                  <me>g i^{\prime}\left(a^{\prime}\right)=i f\left(a^{\prime}\right)=i(a)=g\left(b^{\prime}\right)</me>
                </p>
          
                <p>
                  so <m>b^{\prime}-i^{\prime}\left(a^{\prime}\right) \in \operatorname{ker} g</m>. 
                  Since <m>p^{\prime} i^{\prime}=0</m>,
                </p>
          
                <p>
                  <me>c^{\prime}=p^{\prime}\left(b^{\prime}\right)=p^{\prime}\left(b^{\prime}-i^{\prime}\left(a^{\prime}\right)\right) \in p^{\prime}(\operatorname{ker} g) .</me>
                </p>
          
                <p>
                  We conclude that <m>\operatorname{ker} \partial=p^{\prime}(\operatorname{ker} g)</m>, and this shows 2<m>)</m>.
                </p>
          
                <p>
                  Now we show 3 ), that is, <m>\operatorname{im} \partial=\operatorname{ker}(\operatorname{coker} f \stackrel{i}{\rightarrow} \operatorname{coker} g)</m>.
                </p>
          
                <p>
                  Let <m>a \in A</m> be such that <m>i(a+\operatorname{im} f)=0</m>. 
                  In <m>B</m>, this says that <m>i(a) \in \operatorname{im} g</m>, so we can choose <m>b^{\prime} \in B^{\prime}</m> such that <m>g\left(b^{\prime}\right)=i(a)</m>. 
                  Using commutativity and the fact that <m>p i=0</m>, we have
                </p>
          
                <p>
                  <me>h p^{\prime}\left(b^{\prime}\right)=p g\left(b^{\prime}\right)=p i(a)=0 \quad \text { so } \quad p^{\prime}\left(b^{\prime}\right) \in \operatorname{ker} h \text {. }</me>
                </p>
          
                <p>
                  This shows that <m>a+\operatorname{im} f=\partial\left(p^{\prime}\left(b^{\prime}\right)\right)</m>, and thus <m>\operatorname{ker}(\operatorname{coker} f \stackrel{i}{\rightarrow} \operatorname{coker} g) \subseteq \operatorname{im} \partial</m>.
                  Finally, if <m>p^{\prime}\left(b^{\prime}\right)=c^{\prime}</m> and <m>i(a)=g\left(b^{\prime}\right)</m>, then
                </p>
          
                <p>
                  <me>i \partial\left(c^{\prime}\right)=i(a+\operatorname{im} f)=g\left(b^{\prime}\right)+\operatorname{im} g=0, \quad \text { so } \quad \operatorname{im} \partial \subseteq \operatorname{ker}(\operatorname{coker} f \stackrel{i}{\rightarrow} \operatorname{coker} g)</me>
                </p>
              </proof>
            </theorem>
  
            <definition xml:id="def-2.27"><title>Connecting Homomorphism</title>
              <statement>
                <p>
                  The map <m>\partial</m> in the <xref text="title" ref="thm-2.26"/> is the <em>connecting homomorphism</em>.
                </p>
              </statement>
            </definition>
  
            <p>
              The proof of the <xref text="title" ref="thm-2.26"/> is what we call a diagram chase, for reasons that may be obvious by now: 
              we followed the diagram in the natural way, and everything worked out in the end. 
              The <xref text="title" ref="five-lemma"/> is another classical example of a diagram chase.
            </p>
            
          </subsection>

          <subsection xml:id="subsec-long-exact"><title>The Long Exact Sequence in Homology</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>

            <p>
              Now that we have the <xref text="title" ref="thm-2.26"/>, we can construct the long exact sequence in homology:
            </p>
  
            <theorem xml:id="thm-2.28"><title>Long Exact Sequence in Homology</title>
              <statement>
                <p>
                  Given a short exact sequence in <m>\mathrm{Ch}(R)</m>
                  <me>
                    0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0
                  </me>
                  there are connecting homomorphisms <m>\partial: \mathrm{H}_{n}(C) \longrightarrow \mathrm{H}_{n-1}(A)</m> such that
                  <me>
                    \cdots \longrightarrow \mathrm{H}_{n+1}(C) \stackrel{\partial}{\longrightarrow} \mathrm{H}_{n}(A) \stackrel{f}{\longrightarrow} \mathrm{H}_{n}(B) \stackrel{g}{\longrightarrow} \mathrm{H}_{n}(C) \stackrel{\partial}{\longrightarrow} \mathrm{H}_{n-1}(A) \longrightarrow \cdots
                  </me>
                  is an exact sequence.
                </p>
              </statement>
  
              <proof>
                <p>
                  For each <m>n</m>, we have short exact sequences
                  <me>
                    0 \longrightarrow A_{n} \longrightarrow B_{n} \longrightarrow C_{n} \longrightarrow 0
                  </me>
                </p>
          
                <p>
                  The condition that <m>f</m> and <m>g</m> are maps of complexes implies, by <xref ref="lem-2.4"/>, that <m>f</m> and <m>g</m> take cycles to cycles, so we get exact sequences
                  <me>
                    0 \longrightarrow Z_{n}(A) \longrightarrow Z_{n}(B) \longrightarrow Z_{n}(C)
                  </me>
                  Again by <xref ref="lem-2.4"/>, the condition that <m>f</m> and <m>g</m> are maps of complexes also implies that <m>f</m> and <m>g</m> both take boundaries to boundaries, so that we get exact sequences
                  <me>
                    A_{n} / \mathrm{im} d_{n+1}^{A} \longrightarrow B_{n} / \operatorname{im} d_{n+1}^{B} \longrightarrow C_{n} / \mathrm{im} d_{n+1}^{C} \longrightarrow 0
                  </me>
                </p>
          
                <p>
                  Let <m>F</m> be any complex. 
                  The boundary maps on <m>F</m> induce maps <m>F_{n} \longrightarrow Z_{n-1}(F)</m> that send <m>\operatorname{im} d_{n+1}</m> to <m>0</m>, so we get induced maps <m>F_{n} / \operatorname{im} d_{n+1} \longrightarrow Z_{n-1}(F)</m>. 
                  Applying this general fact to <m>A, B</m>, and <m>C</m>, and putting all this together, we have a commutative diagram with exact rows
                </p>
        
                <image source="2023_10_23_e2d6a27704be928b3deeg-066.jpg"/>
                
                <p>
                  For any complex <m>F</m>,
                  <me>
                    \operatorname{ker}\left(F_{n} / \operatorname{im} d_{n+1}^{F} \stackrel{d_{n}^{F}}{\longrightarrow} Z_{n-1}(F)\right)=\mathrm{H}_{n}(F)
                  </me>
                  and
                  <me>
                    \operatorname{coker}\left(F_{n} / \operatorname{im} d_{n+1}^{F} \stackrel{d_{n}^{F}}{\longrightarrow} Z_{n-1}(F)\right)=Z_{n-1}(F) / \operatorname{im} d_{n}^{F}=\mathrm{H}_{n-1}(F)
                  </me>
                </p>
          
                <p>
                  The <xref text="title" ref="thm-2.26"/> now gives us exact sequences
                  <me>
                    \mathrm{H}_{n}(A) \longrightarrow \mathrm{H}_{n}(B) \longrightarrow \mathrm{H}_{n}(C) \stackrel{\partial}{\longrightarrow} \mathrm{H}_{n-1}(A) \longrightarrow \mathrm{H}_{n-1}(B) \longrightarrow \mathrm{H}_{n-1}(C)
                  </me>
                </p>
          
                <p>
                  Finally, we glue all these together to obtain the long exact sequence in homology.
                </p>
              </proof>
            </theorem>
  
            <remark xml:id="rem-2.29">
              <p>
                It's helpful to carefully consider how to compute the connecting homomorphisms in the long exact sequence in homology, which we can easily put together from the proof of the <xref text="title" ref="thm-2.26"/>. 
                Suppose that <m>c \in Z_{n+1}(C)=\operatorname{ker} d_{n+1}^{C}</m>. 
                When we view <m>c</m> as an element in <m>C_{n+1}</m>, we can find <m>b \in B_{n+1}</m> such that <m>g_{n+1}(b)=c</m>, since <m>g_{n+1}</m> is surjective by assumption. 
                Since <m>g</m> is a map of complexes, we have
                <me>
                  g_{n} d_{n+1}^{B}(b)=d_{n+1}^{C} g_{n+1}(b)=d_{n+1}^{C}(c)=0
                </me>
                so <m>d_{n+1}^{B}(b) \in \operatorname{ker} g_{n}</m>. 
                In fact, note that <m>d_{n+1}^{B}(b) \in \mathbb{Z}_{n}(B)</m>, so
                <me>
                  b \in \operatorname{ker}\left(Z_{n}(B) \stackrel{g_{n}}{\rightarrow} Z_{n}(C)\right)=\operatorname{im}\left(Z_{n}(A) \rightarrow Z_{n}(B)\right)
                </me>
              </p>
        
              <p>
                Thus there exists <m>a \in Z_{n}(A)</m> such that <m>f_{n}(a)=d_{n+1}^{B}(b)</m>. 
                Finally,
                <me>
                  \partial\left(c+\operatorname{im} d_{n+2}\right)=a+\operatorname{im} d_{n+1}^{A}.
                </me>
              </p>
        
              <p>
                So in summary, the recipe goes as follows: given <m>c+\operatorname{im} d_{n+2} \in H_{n+1}(C)</m>, we find <m>b \in B_{n+1}</m> such that <m>g_{n+1}(b)=c</m> and <m>a \in Z_{n}(A)</m> such that <m>f_{n}(a)=d_{n+1}^{B}(b)</m>, and
                <me>
                  \partial(c)=a+\operatorname{im} d_{n+1}^{A}.
                </me>
              </p>
            </remark>
      
            <p>
              We will soon see that long exact sequences appear everywhere, and that they are very helpful. 
              Before we see more examples, we want to highlight a connection between long and short exact sequences.
            </p>
  
            <remark xml:id="rem-2.30">
              <p>
                Suppose that
                <me>
                  \cdots \longrightarrow C_{n+1} \stackrel{f_{n+1}}{\longrightarrow} C_{n} \stackrel{f_{n}}{\longrightarrow} \cdots
                </me>
                is a long exact sequence. 
                This long exact sequence breaks into the short exact sequences
                <me>
                  0 \longrightarrow \operatorname{ker} f_{n} \stackrel{i}{\longrightarrow} C_{n} \stackrel{\pi}{\longrightarrow} \operatorname{coker} f_{n+1} \longrightarrow 0
                </me>
              </p>
        
              <p>
                The first map <m>i</m> is simply the inclusion of the submodule  <m>\ker f_{n}</m> into <m>C_{n}</m>, while the second map <m>\pi</m> is the canonical projection onto the quotient. 
                While it is clear that <m>i</m> is injective and <m>\pi</m> is surjective, exactness at the middle is less obvious. 
                This follows from the exactness of the original complex, which gives <m>\operatorname{im} i=\operatorname{ker} f_{n}=\operatorname{im} f_{n+1}=\operatorname{ker} \pi</m>.
              </p>
            </remark>
      
            <p>
              The long exact sequence in homology is natural.
            </p>
  
            <theorem xml:id="thm-2.31"><title>Naturality of the long exact sequence in homology</title>
              <statement>
                <p>
                  Any commutative diagram in <m>\mathrm{Ch}(R)</m>
                </p>
          
                <image source="2023_10_23_e2d6a27704be928b3deeg-067(1).jpg" width="50%"/>
          
                <p>
                  with exact rows induces a commutative diagram with exact rows
                </p>
          
                <image source="2023_10_23_e2d6a27704be928b3deeg-067.jpg"/>
              </statement>
  
              <proof>
                <p>
                  The rows of the resulting diagram are the long exact sequences in homology induced by each row of the original diagram, as in <xref text="title" ref="thm-2.28"/>. 
                  So the content of the theorem is that the maps induced in homology by <m>f, g</m>, and <m>h</m> make the diagram commute. 
                  The commutativity of
                </p>
          
                <image source="2023_10_23_e2d6a27704be928b3deeg-068(2).jpg" width="50%"/>
                
                <p>
                  follows from the fact that <m>\mathrm{H}_{n}</m> is a functor, so we only need to check commutativity of the square
                </p>
          
              <image source="2023_10_23_e2d6a27704be928b3deeg-068(1).jpg" width="30%"/>
                
                <p>
                  that involves the connecting homomorphisms <m>\partial</m> and <m>\partial^{\prime}</m>. 
                  Consider the following commutative diagram:
                </p>
          
                <image source="2023_10_23_e2d6a27704be928b3deeg-068(3).jpg"/>
          
                <p>
                  Given <m>c \in \operatorname{ker}\left(d_{n}: C_{n} \longrightarrow C_{n-1}\right)</m>, we need to check that <m>f_{n-1}(\partial(c))=\partial^{\prime} h_{n}(c)</m> in <m>\mathrm{H}_{n-1}\left(A^{\prime}\right)</m>. 
                  To compute <m>\partial(c)</m>, we find a lift <m>b \in B_{n}</m> such that <m>p_{n}(b)=c</m>, and <m>a \in A_{n-1}</m> with <m>i_{n-1}(a)=d_{n}(b)</m>, and set <m>\partial(c)=a+\operatorname{im} d_{n} \in \mathrm{H}_{n-1}(A)</m>. 
                  So <m>f_{n-1} \partial(c)=f_{n-1}(a)+\operatorname{im} d_{n}</m>. 
                  On the other hand, to compute <m>\partial^{\prime} h_{n}(c)</m>, we start by finding <m>b^{\prime} \in B_{n}^{\prime}</m> such that <m>p_{n}^{\prime}\left(b^{\prime}\right)=h_{n}(c)</m>. 
                  By commutativity of the right back square
                </p>
          
                <image source="2023_10_23_e2d6a27704be928b3deeg-068.jpg" width="30%"/>
                
                <p>
                  we can choose <m>b^{\prime}=g_{n}(b)</m>, since
                  <me>
                    p_{n}^{\prime}\left(b^{\prime}\right)=p_{n}^{\prime} g_{n}(b)=h_{n} p_{n}(b)=h_{n}(c)
                  </me>
                </p>
          
                <p>
                  Next we take <m>a^{\prime} \in A_{n-1}^{\prime}</m> such that <m>i_{n-1}^{\prime}\left(a^{\prime}\right)=d_{n}\left(b^{\prime}\right)</m>, and set <m>\partial^{\prime}(h(c))=a^{\prime}+\operatorname{im} d_{n} \in \mathrm{H}_{n-1}\left(A^{\prime}\right)</m>.
                  By commutativity of the middle square
                </p>
          
                <image source="2023_10_23_e2d6a27704be928b3deeg-069.jpg" width="30%"/>
                
                <p>
                  we have
                  <me>
                    d_{n}\left(b^{\prime}\right)=d_{n} g_{n}(b)=g_{n-1} d_{n}(b).
                  </me>
                </p>
          
                <p>
                  By our choice of <m>a</m>, we have
                  <me>
                    d_{n}\left(b^{\prime}\right)=g_{n-1} d_{n}(b)=g_{n-1} i_{n-1}(a)
                  </me>
                  and by commutativity of the front left square
                </p>
          
                <image source="2023_10_23_e2d6a27704be928b3deeg-069(1).jpg" width="30%"/>
          
                <p>
                  we have
                  <me>
                    i_{n-1}^{\prime} f_{n-1}(a)=g_{n-1} i_{n-1}(a)=d_{n}\left(b^{\prime}\right)
                  </me>
                </p>
          
                <p>
                  So we can take <m>a^{\prime}=f_{n-1}(a)</m>. 
                  Finally, this means <m>\partial^{\prime}\left(h_{n}(c)\right)=f_{n-1}(a)+\operatorname{im} d_{n-1}</m>, as we wanted to prove.
                </p>
              </proof>
            </theorem>
  
            <remark xml:id="rem-2.32">
              <p>
                Let
                <me>
                  0 \longrightarrow A \stackrel{i}{\longrightarrow} B \stackrel{p}{\longrightarrow} C \longrightarrow 0
                </me>
                be a short exact sequence in <m>\operatorname{Ch}(R)</m>. 
                We can think of <xref ref="thm-2.31"/> as saying that the induced maps on homology <m>i_{*}: \mathrm{H}_{n}(A) \longrightarrow \mathrm{H}_{n}(B)</m> and <m>p_{*}: \mathrm{H}_{n}(B) \longrightarrow \mathrm{H}_{n}(C)</m> and the connecting homomorphism <m>\partial: \mathrm{H}_{n}(C) \longrightarrow \mathrm{H}_{n-1}(A)</m> are all natural transformations. 
                More precisely, consider the category SES of short exact sequences of <m>R</m>-modules, which is a full subcategory of <m>\mathrm{Ch}(R)</m>. 
                Homology gives us functors SES <m>\longrightarrow R</m>-Mod that given a short exact sequence
                <me>
                  0 \longrightarrow A \stackrel{i}{\longrightarrow} B \stackrel{p}{\longrightarrow} C \longrightarrow 0
                </me>
                return the <m>R</m>-modules <m>\mathrm{H}_{n}(A), \mathrm{H}_{n}(B)</m>, or <m>\mathrm{H}_{n}(C)</m>. 
                A map between two short exact sequences then induces <m>R</m>-module homomorphisms between the corresponding homologies. 
                With this framework, <xref ref="thm-2.31"/> says that <m>i_{*}: \mathrm{H}_{n}(A) \longrightarrow \mathrm{H}_{n}(B)</m>, and <m>p_{*}: \mathrm{H}_{n}(B) \longrightarrow \mathrm{H}_{n}(C)</m> and the connecting homomorphism <m>\partial: \mathrm{H}_{n}(C) \longrightarrow \mathrm{H}_{n-1}(A)</m> are all natural transformations between the corresponding homology functors.
              </p>
            </remark>
            
          </subsection>

          <outcomes>
            <ul>
              <li>
                <p>

                </p>
              </li>
            </ul>
          </outcomes>

        </section>
        
      </chapter>

      <chapter xml:id="ch-rmod"><title><m>R</m>-Mod</title>

        <section xml:id="sec-hom"><title><m>\Hom</m></title>

          <objectives>
            <ul>
              <li>
                
              </li>
            </ul>
          </objectives>

          <subsection xml:id="subsec-hom"><title>There's No Place Like <m>\Hom</m></title>

            <blockquote>
              <p>
                <q>
                  We shape our <m>\Hom</m>s and then our <m>\Hom</m>s shape us.
                </q>
              </p>
              <attribution>Winston Churchill</attribution>
            </blockquote>

            <p>
              From now on, let's fix a ring <m>R</m>. 
              Recall that whenever we say an <m>R</m>-module <m>M</m>, we mean a left <m>R</m>-module; any general facts about left modules can be naturally converted into statements about right <m>R</m>-modules, under small appropriate corrections. 
              When <m>M</m> is commutative, left and right module structures agree, so the distinction is not relevant.
            </p>
      
            <p>
              Our goal is to get to know the category <m>R</m>-Mod, which as we are about to discover is a very nice category. 
              One of the many nice things about <m>R</m>-Mod is that the Hom-sets have an extra structure. 
              (Roughly speaking, a locally small category where the Hom-sets are objects in some other category is called an enriched category).
            </p>
      
            <p>
              To make the notation less heavy, we write <m>\operatorname{Hom}_{R}(M, N)</m> instead of <m>\operatorname{Hom}_{R-\operatorname{Mod}}(M, N)</m> for the Hom-set between <m>M</m> and <m>N</m> in <m>R</m>-Mod. 
              The arrows in <m>\operatorname{Hom}_{R}(M, N)</m> are all the <m>R</m>-module homomorphisms from <m>M</m> to <m>N</m>. 
              This is a locally small category, meaning that the Hom-sets are actual sets, but more even is true: 
              the Hom-sets are actually abelian groups, and when <m>R</m> is commutative, they are even <m>R</m>-modules.
            </p>
      
            <p>
              Given <m>f, g \in \operatorname{Hom}_{R}(M, N), f+g</m> is the <m>R</m>-module homomorphism defined by
              <me>
                (f+g)(m):=f(m)+g(m)
              </me>
              When <m>R</m> is a commutative ring, given <m>r \in R</m> and <m>f \in \operatorname{Hom}_{R}(M, N), r \cdot f</m> is the <m>R</m>-module homomorphism defined by
            </p>
      
            <p>
              <me>
                (r \cdot f)(m):=f(r m)
              </me>
            </p>

            <exercise xml:id="exe-36">
              <p>
                Let <m>M</m> and <m>N</m> be <m>R</m>-modules. 
                Then <m>\operatorname{Hom}_{R}(M, N)</m> is an abelian group under the sum defined above.
              </p>
            </exercise>

            <exercise xml:id="exe-37">
              <p>
                Let <m>M</m> and <m>N</m> be <m>R</m>-modules over a commutative <m>\operatorname{ring} R</m>. 
                Then <m>\operatorname{Hom}_{R}(M, N)</m> is an <m>R</m>-module.
              </p>
            </exercise>
            
            <remark xml:id="rem-3.1">
              <p>
                The main reason we need commutativity for <m>\operatorname{Hom}_{R}(M, N)</m> to be a module is that given any <m>r \in R</m> and <m>f \in \operatorname{Hom}_{R}(M, N)</m>, we need <m>r f</m> to be an <m>R</m>-module homomorphism, so in particular for any <m>a \in M</m> and any <m>s \in R</m> we need
                <me>
                  (r f)(s a)=s(r f)(a)
                </me>
                So
                <me>
                  (r s) f(a)=r f(s a)=(r f)(s a)=s(r f)(a)=s(r f(a))=(s r) f(a).
                </me>
                This holds whenever <m>r s=s r</m>, but not in general.
              </p>
            </remark>
      
            <p>
              Some Hom-sets can easily be identified with other well-understood modules.
            </p>

            <exercise xml:id="exe-38">
              <p>
                Let <m>R</m> be a commutative ring. 
                Let <m>M</m> be an <m>R</m>-module, and <m>I</m> an ideal in <m>R</m>. 
                Then we have the following isomorphisms of <m>R</m>-modules:
                <ol>
                  <li>
                    <p>
                      <m>\operatorname{Hom}_{R}(R, M) \cong M</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>\operatorname{Hom}_{R}\left(R^{n}, M\right) \cong M^{n}</m> for any <m>n \geqslant 1</m>.
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>\operatorname{Hom}_{R}(R / I, M) \cong\left(0:_{M} I\right):=\{m \in M \mid I m=0\}</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </exercise>

          </subsection>

          <subsection xml:id="subsec-additive-functors"><title>Additive Functors</title>

            <blockquote>
              <p>
                <q>
                  To split yourself in two is just about the most radical thing you can do.
                </q>
              </p>
              <attribution>Ani DiFranco</attribution>
            </blockquote>
            
            <p>
              Since <m>R</m>-Mod is a locally small category, we saw in Definition 1.34 that there are two Hom-functors from <m>R</m>-Mod to <m>\Set</m>, the covariant functor <m>\operatorname{Hom}_{R}(M,-): R</m>-Mod <m>\longrightarrow</m> Set and the contravariant functor <m>\operatorname{Hom}_{R}(-, N): R</m>-Mod <m>\longrightarrow</m> Set. 
              In light of <xref ref="exe-37"/>, we can upgrade these functors to land in <m>\mathbf{A b}</m>, or in <m>R</m>-Mod when <m>R</m> is commutative, not just in <m>\Set</m>. 
              Note that while there are two Hom-functors, we will sometimes refer to the Hom functor when talking about properties that are common to both of them.
            </p>
      
            <p>
              A functor that lands in <m>\mathbb{R}-\bmod</m>, or <m>\mathbf{A b}</m> in particular, can have some additional good properties.
            </p>

            <definition xml:id="def-3.2"><title>Additive Functor</title>
              <statement>
                <p>
                  Let <m>R</m> and <m>S</m> be rings. 
                  A functor <m>T: R</m>-Mod <m>\longrightarrow S</m>-Mod is an <em>additive functor</em> if
                  <me>T(f+g)=T(f)+T(g)</me>
                  for all <m>f, g \in \operatorname{Hom}_{R}(M, N)</m>.
                </p>
              </statement>
            </definition>

            <p>
              Note that to say that <m>T</m> is a covariant additive functor is to say that for all <m>A</m> and <m>B</m>, the map
              <me>
                \begin{gathered}
                \operatorname{Hom}(A, B) \longrightarrow \operatorname{Hom}(T(A), T(B)) \\
                f \longmapsto T(f)
                \end{gathered}
              </me>
              induced by <m>T</m> is a homomorphism of abelian groups. 
              Similarly, a contravariant additive functor <m>T</m> is one such that
              <me>
                \begin{gathered}
                \operatorname{Hom}(A, B) \longrightarrow \operatorname{Hom}(T(B), T(A)) \\
                f \longmapsto T(f)
                \end{gathered}
              </me>
              is a homomorphism of abelian groups.
              Notice moreover that this definition makes sense more generally in any category <m>\mathscr{C}</m> whose objects have an abelian group structure.
            </p>

            <exercise xml:id="exe-39"><title><m>\Hom</m> is Additive</title>
              <p>
                Show that <m>\operatorname{Hom}_{R}(M,-)</m> and <m>\operatorname{Hom}_{R}(-, N)</m> are both additive functors.
              </p>
            </exercise>
      
            <p>
              Note that in <xref ref="exe-39"/> we were purposely vague about where <m>\operatorname{Hom}_{R}(M,-)</m> and <m>\operatorname{Hom}_{R}(-, N)</m> land: 
              these are additive functors whether we consider them as functors with target <m>\mathbf{A b}</m> or target <m>R</m>-Mod, when appropriate.
            </p>
      
            <p>
              Additive functors have many nice properties.
            </p>

            <lemma xml:id="lem-3.3"><title>Properties of Additive Functors</title>
              <statement>
                <p>
                  Let <m>T: R-</m> Mod <m>\longrightarrow S</m>-Mod be an additive functor.
                  <ol>
                    <li>
                      <p>
                        Let <m>0</m> denote the <m>0</m>-map between any two <m>R</m>-modules <m>M</m> and <m>N</m>. 
                        Then <m>T(0)=0</m> is the <m>0-\operatorname{map} T(M) \rightarrow T(N)</m>.
                      </p>
                    </li>

                    <li>
                      <p>
                        Let <m>0</m> denote the zero <m>R</m>-module. 
                        Then <m>T(0)=0</m> is the zero <m>S</m>-module.
                      </p>
                    </li>
                  </ol>
                </p>
              </statement>

              <proof>
                <p>
                  <ol>
                    <li>
                      <p>
                        As a function defined on each fixed <m>\operatorname{Hom}_{R}(M, N), T</m> is a group homomorphism, so it must send <m>0</m> to <m>0</m>.
                      </p>
                    </li>

                    <li>
                      <p>
                        An <m>R</m>-module <m>M</m> is the zero module if and only if the zero and identity maps on <m>M</m> coincide. 
                        Let <m>N</m> be the image of the zero <m>R</m>-module via <m>T</m>. 
                        On the one hand, any functor must send identity maps to identity maps, so the identity map on the zero module must be sent to the identity on <m>N</m>. 
                        On the other hand, we have shown that the zero map must be sent to the zero map on <m>N</m>, so the zero and identity maps on <m>N</m> must coincide, so <m>N=0</m>.
                      </p>
                    </li>
                  </ol>
                </p>
              </proof>
            </lemma>

            <remark xml:id="rem-3.4">
              <p>
                Note that the category of chain complexes also has a similar structure to <m>R</m>-Mod: 
                given two maps of complexes <m>f, g: C \rightarrow D</m>, we define a map of complexes <m>f+g</m> : <m>C \rightarrow D</m> given by
                <me>(f+g)_{n}:=f_{n}+g_{n}</me>
                It is routine to check that this again gives a map of complexes, and that this operation gives the <m>\Hom</m>-sets in <m>\operatorname{Ch}(R)</m> the structure of an abelian group. 
                In fact, this abelian group structure can be upgraded to an <m>R</m>-module structure when <m>R</m> is commutative, by setting
                <me>(r f)_{n}:=r f_{n}</me>
                for all <m>r \in R</m>. 
                This allows us to talk about additive functors to and from the category <m>\operatorname{Ch}(R)</m>, and there is a version of <xref ref="lem-3.3"/> in <m>\mathrm{Ch}(R)</m>.
              </p>
            </remark>

            <exercise xml:id="exe-40"><title>Homology is Additive</title>
              <p>
                Show that homology is an additive functor.
              </p>
            </exercise>
      
            <p>
              Most functors between categories or modules or chain complexes are additive. 
              In fact, we will spend the rest of this chapter studying three very important additive functors: the two <m>\Hom</m> functors, and a third functor we have yet to define.
            </p>

            <exercise xml:id="exe-41"><title>Additive Functors Preserve Direct Sums</title>
              <p>
                Let <m>R</m> and <m>S</m> be rings and let <m>T: R</m>-Mod <m>\longrightarrow S</m>-Mod be an additive functor. 
                Show that for all <m>R</m>-modules <m>A</m> and <m>B</m>,
                <me>T(A \oplus B) \cong T(A) \oplus T(B)</me>
              </p>
            </exercise>
      
            <p>
              <m>\Hom</m> satisfies a stronger version of this property.
            </p>

            <theorem xml:id="thm-3.5">
              <statement>
                <p>
                  For all <m>R</m>-modules <m>M, N, M_{i}, N_{i}</m>, there are isomorphisms of abelian groups
                  <me>\operatorname{Hom}_{R}\left(M, \prod_{i} N_{i}\right) \cong \prod_{i} \operatorname{Hom}_{R}\left(M, N_{i}\right) \text { and } \operatorname{Hom}_{R}\left(\bigoplus_{i} M_{i}, N\right) \cong \prod_{i} \operatorname{Hom}_{R}\left(M_{i}, N\right)</me>
                  Moreover, when <m>R</m> is commutative, these are in fact isomorphisms of <m>R</m>-modules.
                </p>
          
                <p>
                  In particular,
                  <me>\operatorname{Hom}_{R}(A \oplus B, C) \cong \operatorname{Hom}_{R}(A, C) \oplus \operatorname{Hom}_{R}(B, C)</me>
                  and
                  <me>\operatorname{Hom}_{R}(A, B \oplus C) \cong \operatorname{Hom}_{R}(A, B) \oplus \operatorname{Hom}_{R}(A, C) .</me>
                </p>
              </statement>

              <proof>
                <p>
                  For each <m>i</m>, let <m>\pi_{i}: \prod_{j} N_{j} \longrightarrow N_{i}</m> be the canonical projection map. 
                  Consider the map
                  <me>
                    \begin{gathered}
                    \operatorname{Hom}_{R}\left(M, \prod_{i} N_{i}\right) \stackrel{\alpha}{\longrightarrow} \prod_{i} \operatorname{Hom}_{R}\left(M, N_{i}\right) \\
                    f \longmapsto\left(\pi_{i} f\right)
                    \end{gathered}
                  </me>
                  We claim this map is the desired isomorphism. 
                  We leave it as an exercise to show that <m>\alpha</m> is a homomorphism of abelian groups, and a homomorphism of <m>R</m>-modules when <m>R</m> is commutative; 
                  we focus on proving that <m>\alpha</m> is a bijection. 
                  First, take <m>\left(f_{i}\right)_{i} \in \prod_{i} \operatorname{Hom}_{R}\left(M, N_{i}\right)</m>. 
                  Define a map
                  <me>
                    \begin{aligned}
                    &amp; M \stackrel{\psi}{\longrightarrow} \prod_{i} N_{i} \\
                    &amp; m \longmapsto\left(f_{i}(m)\right)
                    \end{aligned}
                  </me>
                  This makes the diagram
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-073.jpg" width="50%"/>
                <p>
                  commute, so that <m>\alpha(\psi)=\left(\pi_{i} \psi\right)_{i}=\left(f_{i}\right)</m>. 
                  This shows that <m>\alpha</m> us surjective.
                  Now let us show that <m>\alpha</m> is injective. 
                  Suppose <m>f \in \operatorname{Hom}_{R}\left(M, \prod_{i} N_{i}\right)</m> is such that <m>\alpha(f)=0</m>. 
                  For each <m>m \in M</m>, let <m>f(m)=\left(n_{i}\right)_{i}</m>, so <m>\pi_{i} f(m)=n_{i}</m>. 
                  By assumption, <m>\left(\pi_{i} f(m)\right)=0</m>, which means that <m>\pi_{i} \alpha=0</m> for all <m>i</m>, and thus <m>n_{i}=0</m> for all <m>i</m>. 
                  So <m>f=0</m>. 
                  We conclude that <m>\alpha</m> is an isomorphism.
                </p>
          
                <p>
                  Now consider the map
                  <me>
                    \begin{gathered}
                    \operatorname{Hom}_{R}\left(\bigoplus_{i} M_{i}, N\right) \stackrel{\beta}{\longrightarrow} \prod_{i} \operatorname{Hom}_{R}\left(M_{i}, N\right) \\
                    f \longmapsto\left(f \iota_{i}\right)
                    \end{gathered}
                  </me>
                  where <m>\iota_{j}: M_{j} \longrightarrow \bigoplus_{i} M_{i}</m> is the inclusion of the <m>j</m> th factor. 
                  We leave it as an exercise to prove that <m>\beta</m> is a homomorphism of abelian groups, and that whenever <m>R</m> is commutative, <m>\beta</m> is in fact a homomorphism of <m>R</m>-modules.
                </p>
          
                <p>
                  Given <m>\left(f_{i}\right)_{i} \in \prod_{i} \operatorname{Hom}_{R}\left(M_{i}, N\right)</m>, let
                </p>
        
                <image source="2023_10_23_e2d6a27704be928b3deeg-074.jpg" width="50%"/>
                  
                <p>
                  Then <m>\beta(\psi)=\left(\psi \iota_{i}\right)_{i}</m>, so for each <m>i</m> and each <m>m_{i} \in M_{i}, \psi \iota_{i}\left(m_{i}\right)=f_{i}\left(m_{i}\right)</m>, and <m>\beta(\psi)=\left(f_{i}\right)_{i}</m>. 
                  This shows that <m>\beta</m> is surjective.
                </p>
          
                <p>
                  Now assume <m>\beta(f)=0</m>, which implies that <m>f \iota_{i}</m> is the zero map for each <m>i</m>. 
                  Consider any <m>\left(m_{i}\right)_{i} \in \bigoplus_{i} M_{i}</m>. 
                  For each <m>i, f \iota_{i}\left(m_{i}\right)=0</m>. 
                  On the other hand, <m>\left(m_{i}\right)_{i}=\sum_{i} \iota_{i}\left(m_{i}\right)</m>, so <m>f\left(\left(m_{i}\right)_{i}\right)=\sum_{i} \iota_{i}\left(m_{i}\right)=0</m>. 
                  We conclude that <m>f=0</m>, and <m>\beta</m> is injective.
                </p>
              </proof>
            </theorem>
          
            <p>
              These two properties, however, are consequences of <xref ref="exe-39"/> and <xref ref="exe-41"/>: 
              <m>\Hom</m> is additive, and additive functors preserve finite direct sums.
            </p>

            <exercise xml:id="exe-42">
              <p>
                Show that the isomorphisms in <xref ref="thm-3.5"/> are natural on both components. 
                More precisely, given any other family of <m>R</m>-modules <m>L_{i}</m> such that for each <m>i</m> there exists <m>j</m>, a map <m>\sigma_{i j}</m> there exist <m>R</m>-module maps making the following diagrams commute: 
              </p>
              <image source='2023_10_23_e2d6a27704be928b3deeg-074(1).jpg'/>
              <p>
                In fact, one can show that more generally, <m>\Hom</m> behaves well with limits and colimits.
              </p>
            </exercise>

            <exercise xml:id="exe-43">
              <p>
                Let <m>R</m> be any ring and consider <m>R</m>-modules <m>A</m> and <m>\left\{M_{i}\right\}</m>.
                <ol>
                  <li>
                    <p>
                      For any inverse system <m>\left\{M_{i}\right\}</m>, there is a natural isomorphism
                      <me>\operatorname{Hom}_{R}\left(A, \lim _{i} M_{i}\right) \cong \lim _{i} \operatorname{Hom}_{R}\left(A, M_{i}\right)</me>
                    </p>
                  </li>

                  <li>
                    <p>
                      For any direct system <m>\left\{M_{i}\right\}</m> or <m>R</m>-modules, there is a natural isomorphism
                      <me>\operatorname{Hom}_{R}\left(\operatorname{colim}_{i} M_{i}, A\right) \cong \lim _{i} \operatorname{Hom}_{R}\left(M_{i}, B\right)</me>
                    </p>
                  </li>
                </ol>
                Moreover, when <m>R</m> is commutative, these are isomorphisms of modules.
              </p>
            </exercise>

          </subsection>

          <subsection xml:id="subsec-exact-functors"><title>Exact Functors</title>

            <blockquote>
              <p>
                <q>
                  My biggest problem is retaining the exact information.
                </q>
              </p>
              <attribution>David Cross</attribution>
            </blockquote>

            <p>
              Another important property of <m>\Hom</m> is how it interacts with exact sequences. 
              First, an important note about general additive functors:
            </p>

            <remark xml:id="rem-3.6">
              <p>
                Let <m>F: R</m>-Mod <m>\rightarrow S</m>-Mod be an additive functor. 
                Thanks to <xref ref="lem-3.3"/>, if <m>g f=0</m>, then
                <me>F(g f)=F(g) F(f)=F(0)=0.</me>
                Thus <m>F</m> must send complexes to complexes, and in fact, <m>F</m> induces a functor <m>\operatorname{Ch}(R) \rightarrow \operatorname{Ch}(S)</m>, which we also call <m>F</m>. 
                Now if <m>h</m> is a homotopy between two maps of complexes, <m>F</m> must preserve the identities
                <me>\delta_{n+1} h_{n}+h_{n-1} \delta_{n}=f_{n}-g_{n}</me>
                for all <m>n</m>, so <m>F(h)</m> is a homotopy between <m>F(f)</m> and <m>F(g)</m>.
              </p>
            </remark>
    
            <p>
              While additive functors send complexes to complexes, they don't have to preserve exactness. 
              Functors that do preserve exactness are very special.
            </p>

            <definition xml:id="def-3.7"><title>Exact Functors</title>
              <statement>
                <p>
                  An additive functor <m>T: R</m>-Mod <m>\longrightarrow S</m>-Mod is an <em>exact functor</em> if it preserves short exact sequences. 
                  When <m>T</m> is covariant, this means that every short exact sequence
                  <me>0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0</me>
                  is taken to the short exact sequence
                  <me>0 \longrightarrow T(A) \stackrel{T(f)}{\longrightarrow} T(B) \stackrel{T(g)}{\longrightarrow} T(C) \longrightarrow 0</me>
                </p>
          
                <p>
                  When <m>T</m> is contravariant, this means that any short exact sequence
                  <me>0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0</me>
                  is taken to the short exact sequence
                  <me>0 \longrightarrow T(C) \stackrel{T(g)}{\longrightarrow} T(B) \stackrel{T(f)}{\longrightarrow} T(A) \longrightarrow 0</me>
                </p>
              </statement>
            </definition>

            <exercise xml:id="exe-44"><title>Functors are Exact iff They Commute with Homology</title>
              <p>
                Show that an additive functor <m>T</m> is exact if it commutes with homology, that is, for all complexes <m>C</m> and all <m>n</m>,
                <me>\mathrm{H}_{n}(T(C))=T\left(\mathrm{H}_{n}(C)\right)</me>
              </p>
            </exercise>
      
            <p>
              As we will soon see, most functors are not exact. 
              However, many functors of interest preserve some exactness.
            </p>

            <definition xml:id="def-3.8"><title>Left and Right Exact Functors</title>
              <statement>
                <p>
                  A covariant additive functor <m>T: R</m>-Mod <m>\longrightarrow S</m>-Mod is left exact if it takes every exact sequence
                  <me>0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C</me>
                  of <m>R</m>-modules to the exact sequence
                  <me>0 \longrightarrow T(A) \stackrel{T(f)}{\longrightarrow} T(B) \stackrel{T(g)}{\longrightarrow} T(C)</me>
                  of <m>S</m>-modules, and right exact if it takes every exact sequence of <m>R</m>-modules
                  <me>A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0</me>
                  to the exact sequence of <m>S</m>-modules
                  <me>T(A) \stackrel{T(f)}{\longrightarrow} T(B) \stackrel{T(g)}{\longrightarrow} T(C) \longrightarrow 0 .</me>
                </p>
              </statement>
            </definition>

            <definition xml:id="def-3.9"><title>Left and Right Exact Functors</title>
              <statement>
                <p>
                  A contravariant additive functor <m>T: R</m>-Mod <m>\longrightarrow S</m>-Mod is left exact if it takes every exact sequence
                  <me>A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0</me>
                  of <m>R</m>-modules to the exact sequence
                  <me>0 \longrightarrow T(C) \stackrel{T(g)}{\longrightarrow} T(B) \stackrel{T(f)}{\longrightarrow} T(A)</me>
                  of <m>S</m>-modules, and right exact if it takes every exact sequence of <m>R</m>-modules
                  <me>0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C</me>
                  to the exact sequence of <m>S</m>-modules
                  <me>T(C) \stackrel{T(g)}{\longrightarrow} T(B) \stackrel{T(f)}{\longrightarrow} T(A) \longrightarrow 0 .</me>
                </p>
              </statement>
            </definition>

            <exercise xml:id="exe-45"><title>Exactness and SESs</title>
              <p>
                The definitions above all stay unchanged if for each condition we start with a short exact sequence. 
                For example, a covariant additive functor <m>T</m> is left exact if and only if for every short exact sequence
                <me>0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0</me>
                of <m>R</m>-modules,
                <me>0 \longrightarrow T(A) \stackrel{T(f)}{\longrightarrow} T(B) \stackrel{T(g)}{\longrightarrow} T(C)</me>
                is exact.
              </p>
            </exercise>

            <remark xml:id="rem-3.10">
              <p>
                Left exact covariant functors take kernels to kernels, while right exact covariant functors take cokernels to cokernels: 
                the kernel of <m>f</m> fits in an exact sequence
                <me>0 \longrightarrow \operatorname{ker} f \longrightarrow A \stackrel{f}{\longrightarrow} B</me>
                and applying a left exact functor <m>F</m> gives us an exact sequence
                <me>0 \longrightarrow F(\operatorname{ker} f) \longrightarrow F(A) \stackrel{F(f)}{\longrightarrow} F(B)</me>
                Exactness tells us that <m>F(\operatorname{ker} f)</m> is the kernel of <m>F(f)</m>. 
              </p>
                
              <p>
                Similarly, the cokernel of <m>f</m> fits into an exact sequence
                <me>A \stackrel{f}{\longrightarrow} B \longrightarrow \operatorname{coker} f \longrightarrow 0</me>
                which any right exact functor <m>G</m> will take to an exact sequence
                <me>G(A) \stackrel{G(f)}{\longrightarrow} G(B) \longrightarrow G(\operatorname{coker} f) \longrightarrow 0</me>
                Exactness says that <m>G(\operatorname{coker} f)</m> is the cokernel of <m>G(f)</m>.
              </p>
        
              <p>
                Similarly, left exact contravariant functors take cokernels to kernels, and right exact contravariant functors take kernels to cokernels. 
                A left exact contravariant functor <m>F</m> will take the exact sequence
                <me>A \stackrel{f}{\longrightarrow} B \longrightarrow \operatorname{coker} f \longrightarrow 0</me>
                to an exact sequence
                <me>0 \longrightarrow F(\operatorname{coker} f) \longrightarrow F(B) \stackrel{F(f)}{\longrightarrow} F(A)</me>
                and exactness tells us that <m>F(\operatorname{coker} f)</m> is the kernel of <m>F(f)</m>.
              </p>
        
              <p>
                A right exact contravariant functor <m>G</m> will take the exact sequence
                <me>0 \longrightarrow \operatorname{ker} f \longrightarrow A \stackrel{f}{\longrightarrow} B</me>
                to the exact sequence
                <me>G(B) \stackrel{G(f)}{\longrightarrow} G(A) \longrightarrow G(\operatorname{ker} f) \longrightarrow 0</me>
                and exactness says that <m>G(\operatorname{ker} f)</m> is the cokernel of <m>G(f)</m>.
              </p>
            </remark>
      
            <p>
              Exactness is preserved by natural isomorphisms.
            </p>

            <remark xml:id="rem-3.11">
              <p>
                Suppose that <m>F, G: R</m>-Mod <m>\longrightarrow S</m>-Mod are naturally isomorphic additive functors. 
                We claim that <m>F</m> is exact if and only if <m>G</m> is exact. 
                Let's prove it in the case when <m>F</m> and <m>G</m> are covariant. 
                Given any short exact sequence
                <me>0 \longrightarrow A \longrightarrow B \longrightarrow C \longrightarrow 0</me>
                applying each of our functors yields complexes of <m>R</m>-modules which may or may not be exact. 
                Our natural isomorphism gives us an isomorphism of complexes
              </p>

              <image source="2023_10_23_e2d6a27704be928b3deeg-077.jpg"/>

              <p>
                Isomorphisms of complexes induce isomorphisms in homology, so the top sequence is exact if and only if the bottom sequence is exact. 
                Thus <m>F</m> preserves the short exact sequence if and only if <m>G</m> does.
              </p>
        
              <p>
                A similar argument shows that <m>F</m> is left (respectively, right) exact if and only if <m>G</m> is left (respectively, right) exact; we leave the details as an exercise.
              </p>
            </remark>
      
            <p>
              However, an additive functor does not have to be left exact nor right exact. 
              There are even some functors that preserve exactness in the middle.
            </p>

            <example xml:id="ex-3.12"><title>Homology is Exact in the Middle</title>
              <p>
                The homology functor is exact in the middle: given a short exact sequence
                <me>0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0</me>
                the exactness of the long exact sequence in homology says in particular that
                <me>\mathrm{H}_{n}(A) \stackrel{\mathrm{H}_{n}(f)}{\longrightarrow} \mathrm{H}_{n}(B) \stackrel{\mathrm{H}_{n}(g)}{\longrightarrow} \mathrm{H}_{n}(C)</me>
                is exact for all <m>n</m>. On the other hand, we claim that the homology functor is neither left exact nor right exact. More precisely, <m>\mathrm{H}_{n}(f)</m> might fail to be injective and <m>\mathrm{H}_{n}(g)</m> might fail to be surjective. Finding a counterexample amounts to finding a short exact sequence of complexes such that the connecting homomorphism in the long exact sequence in homology is not the zero map.
              </p>
        
              <p>
                For example, consider the following complexes and maps of complexes:
              </p>
        
              <image source="2023_10_23_e2d6a27704be928b3deeg-078.jpg"/>
                
              <p>
                Applying <m>\mathrm{H}_{0}</m> gives us
                <me>
                  \begin{gathered}
                  \mathrm{H}_{0}(A) \stackrel{\mathrm{H}_{0}(f)}{\longrightarrow} \mathrm{H}_{0}(B) \\
                  \mathbb{Z} \stackrel{0}{\longrightarrow} 0
                  \end{gathered}
                </me>
                which is not injective, so
                <me>0 \longrightarrow \mathrm{H}_{0}(A) \stackrel{\mathrm{H}_{0}(f)}{\longrightarrow} \mathrm{H}_{0}(B) \stackrel{\mathrm{H}_{0}(g)}{\longrightarrow} \mathrm{H}_{0}(C)</me>
                is not exact. 
                Similarly, applying <m>\mathrm{H}_{1}</m> gives
                <me>
                  \begin{gathered}
                  \mathrm{H}_{1}(B) \stackrel{\mathrm{H}_{1}(g)}{\longrightarrow} \mathrm{H}_{1}(C) \\
                  0 \stackrel{0}{\longrightarrow} \mathbb{Z}
                  \end{gathered}
                </me>
                which is not surjective, so
                <me>\mathrm{H}_{1}(A) \stackrel{\mathrm{H}_{1}(f)}{\longrightarrow} \mathrm{H}_{1}(B) \stackrel{\mathrm{H}_{1}(g)}{\longrightarrow} \mathrm{H}_{1}(C) \longrightarrow 0</me>
                is not exact. 
                Thus homology is neither left exact nor right exact, though it is exact in the middle.
              </p>
            </example>
      
            <p>
              But in general, an additive functor might fail to preserve exactness even in the middle.
            </p>

            <example xml:id="ex-3.13">
              <p>
                Fix a prime <m>p</m> and consider the functor <m>F: \mathbf{A b} \rightarrow \mathbf{A b}</m> which on objects is defined by
                <me>F(M)=\operatorname{Hom}_{\mathbb{Z}}\left(\mathbb{Z} / p, M / p^{2} M\right)</me>
                given a homomorphism of abelian groups <m>f: M \rightarrow N</m>, we get an induced homomorphism of abelian groups
                <me>
                  \begin{gathered}
                  M / p^{2} M \stackrel{\bar{f}}{\longrightarrow} N / p^{2} N \\
                  m+p^{2} M \longmapsto f(m)+p^{2} N
                  \end{gathered}
                </me>
                and <m>F(f)=\bar{f} \circ-</m> is postcomposition with <m>\bar{f}</m>. 
                Consider the short exact sequence
                <me>0 \longrightarrow \mathbb{Z} / p^{2} \stackrel{f}{\longrightarrow} \mathbb{Z} / p^{3} \stackrel{g}{\longrightarrow} \mathbb{Z} / p \longrightarrow 0</me>
                where <m>f</m> is the multiplication by <m>p</m> map, which sends <m>1 \mapsto p</m>, and <m>g</m> is the canonical quotient map by the subgroup generated by <m>p</m>.
              </p>
        
              <p>
                Note that
                <me>F\left(\mathbb{Z} / p^{2}\right)=\operatorname{Hom}_{\mathbb{Z}}\left(\mathbb{Z} / p, \mathbb{Z} / p^{2}\right)</me>
                is the submodule of <m>\mathbb{Z} / p^{2}</m> of elements killed by <m>p</m>, which is generated by the class of <m>p</m>, so <m>F\left(\mathbb{Z} / p^{2}\right)=\mathbb{Z} / p</m>. 
                Moreover,
                <me>\frac{\mathbb{Z} / p^{3}}{p^{2} \mathbb{Z} / p^{3}} \cong \mathbb{Z} / p^{2}</me>
                so <m>F\left(\mathbb{Z} / p^{3}\right)</m> is the the submodule of <m>\mathbb{Z} / p^{2}</m> of elements killed by <m>p</m>, which is generated by <m>p</m> and isomorphic to <m>\mathbb{Z} / p</m>, so <m>F\left(\mathbb{Z} / p^{3}\right)=\mathbb{Z} / p</m>.
                Now
                <me>F(f): \mathbb{Z} / p \rightarrow \mathbb{Z} / p</me>
                is the map induced by multiplication by <m>p</m>, so it is the zero map. 
                The map
                <me>\bar{g}: \mathbb{Z} / p^{2} \rightarrow \mathbb{Z} / p</me>
                is the canonical quotient by the subgroup generated by <m>p</m>; 
                any element in
                <me>F\left(Z / p^{3}\right)=\operatorname{Hom}_{\mathbb{Z}}\left(\mathbb{Z} / p, \mathbb{Z} / p^{2}\right)</me>
                corresponds to choosing an element of order <m>p</m>, and thus in the subgroup generated by <m>p</m>, so applying <m>\bar{g}</m> always results in <m>0</m>. 
                We conclude that <m>F(g)=0</m>. 
                Finally, this shows that applying <m>F</m> to the original short exact sequence gives us the complex
                <me>0 \longrightarrow \mathbb{Z} / p \stackrel{0}{\longrightarrow} \mathbb{Z} / p \stackrel{0}{\longrightarrow} \mathbb{Z} / p \longrightarrow 0</me>
                which is not exact anywhere.
              </p>
            </example>
      
            <p>
              One amazing fact, however, is that even if a functor is not exact, it must always preserve split short exact sequences.
            </p>

            <exercise xml:id="exe-46"><title>Additive Functors Preserve Split Exact Sequences</title>
              <p>
                Show that additive functors preserve split short exact sequences.
              </p>
            </exercise>

          </subsection>

          <subsection xml:id="subsec-hom-left"><title><m>\Hom</m> is Left Exact</title>

            <blockquote>
              <p>
                <q>
                  One should always aim at being interesting, rather than exact.
                </q>
              </p>
              <attribution>Voltaire</attribution>
            </blockquote>
            
            <p>
              We are now ready for our first important example of a left exact functor: 
              <m>\Hom</m> is left exact.
            </p>

            <theorem xml:id="thm-3.14"><title><m>\Hom</m> is Left Exact</title>
              <statement>
                <p>
                  Let <m>M</m> be an R-module.
                  <ol>
                    <li>
                      <p>
                        The covariant functor <m>\operatorname{Hom}_{R}(M,-)</m> is left exact: 
                        for every exact sequence
                        <me>0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C</me>
                        of <m>R</m>-modules, the sequence
                        <me>0 \longrightarrow \operatorname{Hom}_{R}(M, A) \stackrel{\operatorname{Hom}_{R}(M, f)}{\longrightarrow} \operatorname{Hom}_{R}(M, B) \stackrel{\operatorname{Hom}_{R}(M, g)}{\longrightarrow} \operatorname{Hom}_{R}(M, C)</me>
                        is exact.
                      </p>
                    </li>

                    <li>
                      <p>
                        The contravariant functor <m>\operatorname{Hom}_{R}(-, M)</m> is left exact: for every exact sequence
                        <me>A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0</me>
                        of <m>R</m>-modules, the sequence
                        <me>0 \longrightarrow \operatorname{Hom}_{R}(C, M) \stackrel{\operatorname{Hom}_{R}(g, M)}{\longrightarrow} \operatorname{Hom}_{R}(B, M) \stackrel{\operatorname{Hom}_{R}(f, M)}{\longrightarrow} \operatorname{Hom}_{R}(A, M)</me>
                        is exact.
                      </p>
                    </li>
                  </ol>
                </p>
              </statement>

              <proof>
                <p>
                  To make the notation less heavy, we will write
                  <me>f_{*}:=\operatorname{Hom}_{R}(M, f) \quad \text { and } \quad g_{*}:=\operatorname{Hom}_{R}(M, g)</me>
                  and similarly
                  <me>f^{*}:=\operatorname{Hom}_{R}(f, M) \quad \text { and } \quad g^{*}:=\operatorname{Hom}_{R}(g, M) \text {. }</me>
                </p>
          
                <p>
                  Since additive functors send complexes to complexes, as outlined in <xref ref="rem-3.6"/>, we at least know that
                  <me>0 \longrightarrow \operatorname{Hom}_{R}(M, A) \stackrel{\operatorname{Hom}_{R}(M, f)}{\longrightarrow} \operatorname{Hom}_{R}(M, B) \stackrel{\operatorname{Hom}_{R}(M, g)}{\longrightarrow} \operatorname{Hom}_{R}(M, C)</me>
                  and
                  <me>0 \longrightarrow \operatorname{Hom}_{R}(C, M) \stackrel{\operatorname{Hom}_{R}(g, M)}{\longrightarrow} \operatorname{Hom}_{R}(B, M) \stackrel{\operatorname{Hom}_{R}(f, M)}{\longrightarrow} \operatorname{Hom}_{R}(A, M)</me>
                  are functors, so in particular
                  <me>g_{*} f_{*}=0 \Longrightarrow \operatorname{im} f_{*} \subseteq \operatorname{ker} g_{*}</me>
                  and
                  <me>f^{*} g^{*}=0 \Longrightarrow \operatorname{im} g^{*} \subseteq \operatorname{ker} f^{*}</me>
                </p>
          
                <p>
                  <ol>
                    <li>
                      <p>
                        We have two things to show:
                        <ol>
                          <li><title><m>\underline{f_{*} \text { is injective: }}</m></title>
                            <p>
                              Suppose that <m>h \in \operatorname{Hom}_{R}(M, A)</m> is such that <m>f_{*}(h)=0</m>. 
                              By definition, this means that <m>f h=0</m>. 
                              But <m>f</m> is injective, so for any <m>m \in M</m>
                              <me>f h(m)=0 \Longrightarrow h(m)=0 \text {. }</me>
                              We conclude that <m>h=0</m>, and <m>f_{*}</m> is injective.
                            </p>
                          </li>

                          <li><title><m>\underline{\operatorname{ker} g_{*} \subseteq \operatorname{im} f_{*}:}</m></title>
                            <p>
                              Let <m>h \in \operatorname{Hom}_{R}(M, B)</m> be in the kernel of <m>g_{*}</m>. 
                              Then <m>g h=g_{*}(h)=0</m>, so for each <m>m \in M</m>, <m>g h(m)=0</m>. 
                              Then <m>h(m) \in \operatorname{ker} g=\operatorname{im} f</m>, so there exists <m>a \in A</m> such that <m>f(a)=h(m)</m>. 
                              Since <m>f</m> is injective, this element <m>a</m> is unique for each <m>m \in M</m>. So setting <m>k(m):=a</m> gives us a well-defined function <m>k: M \longrightarrow A</m>. 
                            </p>

                            <p>
                              We claim that <m>k</m> is in fact an <m>R</m>-module homomorphism. 
                              To see that, notice that if <m>k\left(m_{1}\right)=a_{1}</m> and <m>k\left(m_{2}\right)=a_{2}</m>, then
                              <me>f\left(a_{1}+a_{2}\right)=f\left(a_{1}\right)+f\left(a_{2}\right)=h\left(m_{1}\right)+h\left(m_{2}\right)=h\left(m_{1}+m_{2}\right)</me>
                              so that <m>k\left(m_{1}+m_{2}\right)=a_{1}+a_{2}=k\left(m_{1}\right)+k\left(m_{2}\right)</m>. 
                            </p>
                            
                            <p>
                              Similarly, given any <m>r \in R</m>,
                              <me>f\left(r a_{1}\right)=r f\left(a_{1}\right)=r h\left(m_{1}\right)=h\left(r m_{1}\right)</me>
                              so <m>k\left(r m_{1}\right)=r a_{1}=r k\left(m_{1}\right)</m>. 
                              Finally, this element <m>k \in \operatorname{Hom}_{R}(M, A)</m> satisfies
                              <me>f_{*}(k)(m)=f(k(m))=h(m)</me>
                              for all <m>m \in M</m>, so <m>f_{*}(k)=h</m> and <m>h \in \operatorname{im} f_{*}</m>.
                            </p>
                          </li>
                        </ol>
                      </p>
                    </li>

                    <li>
                      <p>
                        Again, we have two things to show:
                        <ol>
                          <li><title><m>g^{*}</m> is injective:</title>
                            <p>
                              If <m>g^{*}(h)=0</m> for some <m>h \in \operatorname{Hom}_{R}(C, M)</m>, then <m>h g=g^{*}(h)=0</m>. 
                              Consider any <m>c \in C</m>. 
                              Since <m>g</m> is surjective, there exists <m>b \in B</m> such that <m>g(b)=c</m>. 
                              Then <m>h(c)=h g(b)=0</m>, so <m>h=0</m>.
                            </p>
                          </li>

                          <li><title><m>\underline{\operatorname{ker} f^{*} \subseteq \operatorname{im} g^{*}:}</m></title>
                            <p>
                              Let <m>h \in \operatorname{Hom}_{R}(B, M)</m> be in <m>\ker f^{*}</m>, so that <m>h f=0</m>. 
                              Given any <m>c \in C</m>, there exists <m>b \in B</m> such that <m>g(b)=c</m>, since <m>g</m> is surjective. 
                              Let <m>k: C \longrightarrow M</m> be the function defined by <m>k(c):=h(b)</m> for some <m>b</m> with <m>g(b)=c</m>. 
                              This function is well-defined, since whenever <m>g\left(b^{\prime}\right)=g(b)=c, b-b^{\prime} \in \operatorname{ker} g=\operatorname{im} f</m>, say <m>b-b^{\prime}=f(a)</m>, and thus <m>h\left(b-b^{\prime}\right)=h(f(a))=0</m>. 
                              Moreover, we claim that <m>k</m> is indeed a homomorphism of <m>R</m>-modules. 
                              If <m>c_{1}, c_{2} \in C</m>, and <m>g\left(b_{1}\right)=c_{1}, g\left(b_{2}\right)=c_{2}</m>, then <m>g\left(b_{1}+b_{2}\right)=c_{1}+c_{2}</m>, so
                              <me>k\left(c_{1}+c_{2}\right)=h\left(b_{1}+b_{2}\right)=h\left(b_{1}\right)+h\left(b_{2}\right)=k\left(b_{1}\right)+k\left(b_{2}\right)</me>
                            </p>
                      
                            <p>
                              Finally, this element <m>k \in \operatorname{Hom}_{R}(C, M)</m> is such that <m>g^{*}(k)</m> satisfies
                              <me>\left(g_{*}(k)\right)(b)=k(g(b))=h(b)</me>
                              for all <m>b \in B</m>, so <m>g^{*}(k)=h</m>, and <m>h \in \operatorname{im} g^{*}</m>.
                            </p>
                          </li>
                        </ol>
                      </p>
                    </li>
                  </ol>
                </p>
                <p>
                  So <m>\operatorname{Hom}_{R}(M,-)</m> preserves kernels, and <m>\operatorname{Hom}_{R}(-, N)</m> sends cokernels to kernels.
                </p>
              </proof>
            </theorem>

            <p>
              However, <m>\Hom</m> is not right exact in general.
            </p>

            <example xml:id="ex-3.15">
              <p>
                Consider the short exact sequence of abelian groups
                <me>0 \longrightarrow \mathbb{Z} \longrightarrow \mathbb{Q} \longrightarrow \mathbb{Q} / \mathbb{Z} \longrightarrow 0</me>
                where the first map is the inclusion of <m>\mathbb{Z}</m> into <m>\mathbb{Q}</m>, and the second map is the canonical projection. 
                The elements in the abelian group <m>\mathbb{Q} / \mathbb{Z}</m> are cosets of the form <m>\frac{p}{q}+\mathbb{Z}</m>, where <m>\frac{p}{q} \in \mathbb{Q}</m>, and whenever <m>\frac{p}{q} \in \mathbb{Z}, \frac{p}{q}+\mathbb{Z}=0</m>. 
                While <xref ref="thm-3.14"/> says that
                <me>0 \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} / 2, \mathbb{Z}) \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} / 2, \mathbb{Q}) \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} / 2, \mathbb{Q} / \mathbb{Z})</me>
                is exact, we claim that this cannot be extended to a short exact sequence, since the map <m>\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} / 2, \mathbb{Q}) \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} / 2, \mathbb{Q} / \mathbb{Z})</m> is not surjective.
                On the one hand, there are no nontrivial homomorphisms from <m>\mathbb{Z} / 2</m> to either <m>\mathbb{Z}</m> nor <m>\mathbb{Q}</m>, since there are no elements in <m>\mathbb{Z}</m> nor <m>\mathbb{Q}</m> of order <m>2</m>. 
                This shows that
                <me>\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} / 2, \mathbb{Q}) \cong 0.</me>
              </p>
        
              <p>
                On the other hand, <m>\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} / 2, \mathbb{Q} / \mathbb{Z})</m> is nonzero: 
                to give a homomorphism of abelian groups <m>\mathbb{Z} / 2 \rightarrow \mathbb{Q} / Z Z</m> is to choose an element in <m>\mathbb{Q} / \mathbb{Z}</m> of order <m>2</m>. 
                Since <m>\frac{1}{2}+\mathbb{Z}</m> is an element of order 2 in <m>\mathbb{Q} / \mathbb{Z}</m>, the map sending <m>1</m> in <m>\mathbb{Z} / 2</m> to <m>\frac{1}{2}+\mathbb{Z}</m> in <m>\mathbb{Z} / \mathbb{Q}</m> is nonzero. 
                So after applying <m>\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} / 2,-)</m>, we get the exact sequence
                <me>0 \longrightarrow 0 \longrightarrow 0 \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} / 2, \mathbb{Q} / \mathbb{Z})</me>
                So this shows that <m>\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} / 2,-)</m> is not an exact functor, only left exact.
              </p>
            </example>

            <p>
              Similarly, we can show that <m>\operatorname{Hom}_{\mathbb{Z}}(-, \mathbb{Z})</m> is not exact:
            </p>

            <example xml:id="ex-3.16">
              <p>
                Let's apply <m>\operatorname{Hom}_{\mathbb{Z}}(-, \mathbb{Z})</m> to the short exact sequence
                <me>0 \longrightarrow \mathbb{Z} \longrightarrow \mathbb{Q} \longrightarrow \mathbb{Q} / \mathbb{Z} \longrightarrow 0</me>
                This time, <xref ref="thm-3.14"/> says that
                <me>0 \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Q} / \mathbb{Z}, \mathbb{Z}) \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Q}, \mathbb{Z}) \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}, \mathbb{Z})</me>
                is exact. 
                We claim that the last map is not surjective.
                First, we claim that <m>\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Q}, \mathbb{Z})=0</m>. 
                Indeed, if <m>f: \mathbb{Q} \longrightarrow \mathbb{Z}</m> is a homomorphism of abelian groups, then for all <m>n \geqslant 1</m> we have
                <me>f(1)=n f\left(\frac{1}{n}\right)</me>
                So <m>f(1)</m> is an integer that is divisible by every integer, which is impossible unless <m>f(1)=0</m>. 
                We conclude that <m>f=0</m>, and thus <m>\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Q}, \mathbb{Z}) \cong 0</m>. 
                So our exact sequence above is actually
                <me>0 \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Q} / \mathbb{Z}, \mathbb{Z}) \longrightarrow 0 \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}, \mathbb{Z})</me>
                By <xref ref="exe-38"/>, <m>\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}, \mathbb{Z}) \cong \mathbb{Z} \neq 0</m>, so the last map in our sequence can't possibly be surjective, so our sequence is not a short exact sequence.
              </p>
        
              <p>
                The other fun consequence is that <m>\operatorname{since} \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Q}, \mathbb{Z})=0</m> and we have an exact sequence
                <me>0 \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Q} / \mathbb{Z}, \mathbb{Z}) \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Q}, \mathbb{Z})=0</me>
                we can now conclude that
                <me>\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Q} / \mathbb{Z}, \mathbb{Z})=0</me>
              </p>
            </example>

            <p>
              The last observation is a common trick: once we know we have an exact sequence involving certain modules we do not know, we can sometimes calculate them exactly by studying the other modules and maps in the exact sequence.
            </p>
      
            <p>
              We can use the left exactness of Hom to compute some modules of interest:
            </p>

            <example xml:id="exe-3.17">
              <p>
                Let <m>R</m> be a commutative ring and <m>M</m> be a finitely presented <m>R</m>-module. 
                This means that <m>M</m> has a presentation with finitely many generators and relations, which translates into an exact sequence of the form
                <me>R^{m} \stackrel{f}{\longrightarrow} R^{n} \longrightarrow M \longrightarrow 0</me>
              </p>
        
              <p>
                Since <m>R^{m}</m> and <m>R^{n}</m> are free modules, we can think of the map <m>f</m> as multiplication by a matrix <m>A</m> with <m>n</m> rows and <m>m</m> columns, after we fix a basis for <m>R^{n}</m> and <m>R^{m}</m>. 
                Applying <m>\operatorname{Hom}_{R}(-, R)</m> to the exact sequence above, we get an exact sequence
                <me>0 \longrightarrow \operatorname{Hom}_{R}(M, R) \longrightarrow \operatorname{Hom}_{R}\left(R^{n}, R\right) \stackrel{f^{*}}{\longrightarrow} \operatorname{Hom}\left(R^{m}, R\right)</me>
                By <xref ref="exe-38"/>, <m>\operatorname{Hom}_{R}\left(R^{n}, R\right) \cong R^{n}</m> and <m>\operatorname{Hom}_{R}\left(R^{m}, R\right) \cong R^{m}</m>. 
                Moreover, we claim that <m>f^{*}</m> is multiplication by the transpose of <m>A</m>.
              </p>
        
              <p>
                First, note that given a basis <m>\left\{e_{1}, \ldots, e_{n}\right\}</m> for <m>R^{n}</m>, we get a dual basis <m>\left\{e_{1}^{*}, \ldots, e_{n}^{*}\right\}</m> for <m>\operatorname{Hom}_{R}\left(R^{n}, R\right)</m>, where
                <me>e_{i}^{*}\left(e_{j}\right)= \begin{cases}1 &amp; \text { if } i=j \\ 0 &amp; \text { otherwise }\end{cases}</me>
              </p>
        
              <p>
                Similarly, we have a dual basis <m>\left\{e_{1}^{*}, \ldots, e_{m}^{*}\right\}</m> for <m>\operatorname{Hom}_{R}\left(R^{m}, R\right) \cong R^{m}</m>; 
                we might as well assume that we picked the canonical basis in both cases, so that we can use similar notation on both.
              </p>
        
              <p>
                Now the map <m>f^{*}</m> is also given by multiplication by a matrix, now having <m>m</m> rows and <m>n</m> columns. 
                To calculate its <m>j\th</m> column, we need to calculate <m>f^{*}\left(e_{j}^{*}\right)</m>, which is given by precomposition with <m>f</m>, so <m>f^{*}\left(e_{j}^{*}\right)=e_{j}^{*} A</m>; 
                this reads off the <m>j</m> th row of <m>A</m>. Thus <m>f^{*}</m> is indeed multiplication by <m>A^{T}</m>, and we have an exact sequence
                <me>0 \longrightarrow \operatorname{Hom}_{R}(M, R) \longrightarrow R^{n} \stackrel{A^{T}}{\longrightarrow} R^{m}</me>
              </p>
        
              <p>
                In particular, we have shown that <m>\operatorname{Hom}_{R}(M, R)</m> is the kernel of multiplication by <m>A^{T}</m>.
              </p>
            </example>

          </subsection>

          <outcomes>
            <ul>
              <li>
                <p>

                </p>
              </li>
            </ul>
          </outcomes>
          
        </section>

        <section xml:id="sec-tensor"><title>Tensor Products</title>

          <objectives>
            <ul>
              <li>
                
              </li>
            </ul>
          </objectives>

          <subsection xml:id="subsec-biadditive"><title>Biadditive Maps and First Properties</title>

            <blockquote>
              <p>
                <q>
                 Tenser, said the Tensor. Tension, apprehension, and dissension have begun.
                </q>
              </p>
              <attribution>Alfred Bester</attribution>
            </blockquote>
            
            <definition xml:id="def-3.18">
              <statement>
                <p>
                  Definition 3.18. Fix a ring <m>R</m>, and consider:
                </p>
          
                <p><ul>
                  <li>
                        <p>
                  a right <m>R</m>-module <m>M</m>,
                </p>
                  </li>
          
                  <li>
                        <p>
                  a left <m>R</m>-module <m>N</m>,
                </p>
                  </li>
          
                  <li>
                        <p>
                  an abelian group <m>L</m>.
                </p>
                  </li>
          
                </ul></p>
          
                <p>
                  A function <m>f: M \times N \longrightarrow L</m> is <m>R</m>-biadditive if for all <m>m, m^{\prime} \in M</m>, all <m>n, n^{\prime} \in N</m>, and all <m>r \in R</m> we have
                </p>
          
                <p><ul>
                  <li>
                        <p>
                  <m>f\left(m+m^{\prime}, n\right)=f(m, n)+f\left(m^{\prime}, n\right)</m>
                </p>
                  </li>
          
                  <li>
                        <p>
                  <m>f\left(m, n+n^{\prime}\right)=f(m, n)+f\left(m, n^{\prime}\right)</m>
                </p>
                  </li>
          
                  <li>
                        <p>
                  <m>f(m r, n)=f(m, r n)</m>.
                </p>
                  </li>
          
                </ul></p>
          
                <p>
                  When <m>R</m> is a commutative ring, suppose that <m>L</m> is also an <m>R</m>-module. We say that a function <m>f: M \times N \longrightarrow L</m> is <m>R</m>-bilinear if for all <m>m, m^{\prime} \in M</m>, all <m>n, n^{\prime} \in N</m>, and all <m>r \in R</m> we have
                </p>
          
                <p><ul>
                  <li>
                        <p>
                  <m>f\left(m+m^{\prime}, n\right)=f(m, n)+f\left(m^{\prime}, n\right)</m>
                </p>
                  </li>
          
                  <li>
                        <p>
                  <m>f\left(m, n+n^{\prime}\right)=f(m, n)+f\left(m, n^{\prime}\right)</m>
                </p>
                  </li>
          
                  <li>
                        <p>
                  <m>f(r m, n)=f(m, r n)=r f(m, n)</m>.
                </p>
                  </li>
          
                </ul></p>
              </statement>
            </definition>
      
            <p>
              Note that an <m>R</m>-bilinear function is an <m>R</m>-biadditive function that satisfies
            </p>
      
            <p>
              <me>f(r m, n)=f(m, r n)=r f(m, n)</me>
            </p>

            <example>
              <p>
                Example 3.19. The product on <m>R</m> is an <m>R</m>-biadditive function <m>R \times R \longrightarrow R</m>. The first two rules follow from distributivity of multiplication over the sum; the final rule is a consequence of the associativity of multiplication.
              </p>
        
              <p>
                When <m>R</m> is commutative, this is an <m>R</m>-bilinear function.
              </p>
            </example>

            <definition xml:id="def-3.20">
              <statement>
                <p>
                  Definition 3.20. Let <m>M</m> be a right <m>R</m>-module and let <m>N</m> be a left <m>R</m>-module. The tensor product of <m>M</m> and <m>N</m> is an abelian group <m>M \otimes_{R} N</m> together with an <m>R</m>-biadditive function <m>\tau: M \times N \longrightarrow M \otimes_{R} N</m> with the following universal property: for every abelian group <m>A</m> and every <m>R</m>-biadditive map <m>f: M \times N \longrightarrow A</m>, there exists a unique group homomorphism <m>\tilde{f}: M \otimes_{R} N \longrightarrow A</m> such that the following diagram commutes:
                </p>
          
        
                <image source="2023_10_23_e2d6a27704be928b3deeg-084.jpg"/>
              </statement>
            </definition>  
      
            <p>
              We will now show that tensor products exist and are unique up to isomorphism; in particular, we can talk about the tensor product of <m>M</m> and <m>N</m>.
            </p>

            <lemma xml:id="lem-3.21">
              <statement>
                <p>
                  Lemma 3.21. Let <m>R</m> be any ring, <m>M</m> be a right <m>R</m>-module, and <m>N</m> a left <m>R</m>-module. The tensor product of <m>M</m> and <m>N</m> is unique up to unique isomorphism. More precisely, if <m>M \times N \stackrel{\tau_{1}}{\rightarrow} T_{1}</m> and <m>M \times N \stackrel{\tau_{2}}{\rightarrow} T_{2}</m> are two tensor products, then there exists a unique isomorphism <m>T_{1} \stackrel{i}{\rightarrow} T_{2}</m> such that
                </p>
          
        
                <image source="2023_10_23_e2d6a27704be928b3deeg-085(1).jpg"/>
              </statement>

              <proof>
                <p>
                  Proof. First, note that the universal property of the tensor product implies that there exists a unique <m>\varphi</m> such that
                </p>
          
        
                <image source="2023_10_23_e2d6a27704be928b3deeg-085.jpg"/>
                  
          
                <p>
                  commutes. Since the identity map <m>T_{i} \longrightarrow T_{i}</m> is such a map, it must be the only such map.
                </p>
          
                <p>
                  Similarly, there are unique maps <m>\varphi_{1}: T_{1} \longrightarrow T_{2}</m> and <m>\varphi_{2}: T_{2} \longrightarrow T_{1}</m> such that 
                </p>
                <image source='2023_10_23_e2d6a27704be928b3deeg-085(2).jpg'/>
                <p>
                  both commute. Stacking these up, we get commutative diagrams 
                </p>
        
                <image source='2023_10_23_e2d6a27704be928b3deeg-085(4).jpg'/>
        
                <p>
                  Note that the identity maps on <m>T_{1}</m> and <m>T_{2}</m> are homomorphisms <m>T_{1} \rightarrow T_{1}</m> and <m>T_{2} \rightarrow T_{2}</m> that would make each of these triangles commute: 
                </p>
                <image source='2023_10_23_e2d6a27704be928b3deeg-085(3).jpg'/>
                <p>
                  By uniqueness, <m>\varphi_{2} \varphi_{1}</m> must be the identity on <m>T_{1}</m> and <m>\varphi_{1} \varphi_{2}</m> must be the identity on <m>T_{2}</m>. In particular, <m>T_{1}</m> and <m>T_{2}</m> are isomorphic, and the isomorphisms <m>\varphi_{1}</m> and <m>\varphi_{2}</m> are unique.
                </p>
              </proof>
            </lemma>
      
            <theorem xml:id="thm-3.22">
              <statement>
                <p>
                  Theorem 3.22. Given any right <m>R</m>-modules <m>M</m> and any left <m>R</m>-module <m>N</m>, their tensor product <m>M \otimes_{R} N</m> exists, and it is given by the abelian group <m>M \otimes_{R} N</m> defined as follows:
                </p>
          
                <p><ul>
                  <li>
                        <p>
                  Generators: For each pair of elements <m>m \in M</m> and <m>n \in N</m>, we have a generator <m>m \otimes n</m>.
                </p>
                  </li>
          
                  <li>
                        <p>
                  Relations: the generators of <m>m \otimes n</m> satisfy the following relations, where <m>m, m^{\prime} \in M</m>, <m>n, n^{\prime} \in N</m>, and <m>r \in R</m> :
                </p>
                  </li>
          
                </ul></p>
          
                <p>
                  <me>\begin{aligned}
          m \otimes\left(n+n^{\prime}\right) &amp; =m \otimes n+m \otimes n^{\prime} \\
          \left(m+m^{\prime}\right) \otimes n &amp; =m \otimes n+m \otimes n^{\prime} \\
          (m r) \otimes n &amp; =m \otimes(r n) .
          \end{aligned}</me>
                </p>
              </statement>

              <proof>
                <p>
                  Proof. Let <m>F</m> be the free abelian group on the set <m>M \times N</m>. In what follows, we identify a pair <m>(m, n) \in M \times N</m> with the corresponding basis element for <m>F</m>. Let <m>S</m> be the subgroup of <m>F</m> generated by
                </p>
          
                <p>
                  <me>\left.S=\left(\begin{array}{c|c}
          \left(m, n+n^{\prime}\right)-(m, n)-\left(m, n^{\prime}\right) &amp; m, m^{\prime} \in M \\
          \left(m+m^{\prime}, n\right)-(m, n)-\left(m^{\prime}, n\right) &amp; n, n^{\prime} \in N \\
          (m r, n)-(m, r n) &amp; r \in R
          \end{array}\right\}\right)</me>
                </p>
          
                <p>
                  Let <m>M \otimes_{R} N:=F / S</m>, and let <m>m \otimes n</m> denote the class of <m>(m, n)</m> in the quotient. We claim that this abelian group <m>M \otimes_{R} N</m> is a tensor product for <m>M</m> and <m>N</m>, together with the map
                </p>
          
                <p>
                  <me>\begin{gathered}
          M \times N \stackrel{\tau}{\longrightarrow} M \otimes N \\
          (m, n) \longmapsto M \otimes n
          \end{gathered}</me>
                </p>
          
                <p>
                  Notice <m>\tau</m> is the restriction of the quotient map <m>F \longrightarrow F / S</m> to the basis elements of <m>F</m>. Moreover, by construction of <m>M \otimes_{R} N</m>, the following identities hold:
                </p>
          
                <p>
                  <me>\begin{array}{r}
          m \otimes\left(n+n^{\prime}\right)=m \otimes n+m \otimes n^{\prime} \\
          \left(m+m^{\prime}\right) \otimes n=m \otimes n+m \otimes n^{\prime} \\
          (m r) \otimes n=m \otimes(r n)
          \end{array}</me>
                </p>
          
                <p>
                  Together, these make <m>\tau</m> an <m>R</m>-biadditive map. The map <m>M \times N \longrightarrow F</m> that sends each pair <m>(m, n)</m> to the corresponding basis element is <m>R</m>-bilinear by construction. Moreover, there is a natural quotient map <m>F \longrightarrow M \otimes_{R} N</m>, and these maps make the diagram
                </p>
          
        
                <image source="2023_10_23_e2d6a27704be928b3deeg-086.jpg"/>
                  
          
                <p>
                  commute.
                </p>
          
                <p>
                  Now suppose that <m>A</m> is any other abelian group, and let <m>M \times N \stackrel{f}{\rightarrow} A</m> by any <m>R</m>-biadditive map. Since <m>F</m> is the free <m>R</m>-module on <m>M \times N, f</m> induces a homomorphism of abelian groups <m>\varphi: F \longrightarrow A</m> such that <m>f i=\varphi</m>, meaning <m>f(m, n)=\varphi(m, n)</m> for all <m>m \in M</m> and all <m>n \in N</m>.
                </p>
          
                <p>
                  Finally, the fact that <m>f</m> is bilinear implies that <m>S \subseteq \operatorname{ker} \varphi</m>. Therefore, <m>\varphi</m> induces a group homomorphism on <m>F / S=M \otimes_{R} N</m>. All this fits in the following commutative diagram:
                </p>
          
        
                <image source="2023_10_23_e2d6a27704be928b3deeg-087.jpg"/>
                  
          
                <p>
                  Finally, this map <m>\tilde{f}</m> we constructed satisfies <m>\tilde{f}(n \otimes n)=f(m, n)</m>, and since <m>M \otimes_{R} N</m> is generated by such elements, <m>\tilde{f}</m> is completely determined by the images of <m>m \otimes n</m>, and thus unique.
                </p>
              </proof>
            </theorem>
      
            <p>
              The construction in Theorem 3.22 gives us generators <m>m \otimes n</m> for <m>M \otimes_{R} N</m>. These are usually called simple tensors. So any element in <m>M \otimes_{R} N</m> is of the form
            </p>
      
            <p>
              <me>\sum_{i=1}^{k} m_{i} \otimes n_{i}</me>
            </p>
      
            <p>
              Such expressions are not unique. For a cheap example, consider the relations we used to construct <m>M \otimes_{R} N</m> from the abelian group on <m>M \times N</m>, which gives us nontrivial ways to write the 0 element in <m>M \otimes_{R} N</m> :
            </p>
      
            <p>
              <me>
                \begin{array}{r}
                0=m \otimes\left(n+n^{\prime}\right)-m \otimes n-m \otimes n^{\prime} \\
                0=\left(m+m^{\prime}\right) \otimes n-m \otimes n-m \otimes n^{\prime} \\
                0=(m r) \otimes n-m \otimes(r n) .
                \end{array}
              </me>
            </p>
      
            <p>
              This makes things unexpectedly tricky. For starters, the tensor product of two nonzero modules might be zero nevertheless. Also, whenever we try to define some <m>R</m>-module homomorphism from <m>M \otimes_{R} N</m> into some other <m>R</m>-module, we must carefully check that our map is well-defined, which is in principle not an easy task. Therefore, the easiest way to define some <m>R</m>-module homomorphism from <m>M \otimes_{R} N</m> is to give some <m>R</m>-bilinear map from <m>M \times N</m> into our desired <m>R</m>-module.
            </p>
      
            <p>
              In summary: the tensor product <m>M \otimes_{R} N</m> of <m>M</m> and <m>N</m> is generated by the simple tensors <m>m \otimes n</m>, but it's important to remember (though we're all bound to forget once or twice) that not all elements in <m>M \otimes_{R} N</m> are simple tensors. Moreover, even if <m>M</m> and <m>N</m> are nonzero, <m>M \otimes_{R} N</m> could very well be zero.
            </p>

            <remark>
              <p>
                Remark 3.23. Two group homomorphisms <m>M \otimes_{R} N \longrightarrow L</m> coincide if and only if they agree on simple tensors, since these are generators for <m>M \otimes_{R} N</m>.
              </p>
            </remark>

            <remark>
              <p>
                Remark 3.24. In any tensor product <m>M \otimes_{R} N</m>, the simple tensor <m>0 \otimes 0</m> is the zero element, and
              </p>
        
              <p>
                <me>m \otimes 0=0=0 \otimes n</me>
              </p>
        
              <p>
                for all <m>m \in M</m> and <m>n \in N</m>.
              </p>
            </remark>

          </subsection>

          <subsection xml:id="subsec-tensor-elements"><title>Elements in Tensor Products</title>

            <blockquote>
              <p>
                <q>
                  In the beginning God said, the four-dimensional divergence of an antisymmetric, second rank tensor equals zero, and there was light, and it was good. And on the seventh day he rested.
                </q>
              </p>
              <attribution>Michio Kaku</attribution>
            </blockquote>
          
            <p>
              Let's see some examples of how tensor products can be zero.
            </p>

            <example>
              <p>
                Example 3.25. We claim that <m>\mathbb{Z} / 2 \otimes_{\mathbb{Z}} \mathbb{Q}=0</m>, despite the fact that both of these <m>\mathbb{Z}</m>-modules are nonzero. To see that, simply note that given any <m>a \in \mathbb{Z} / 2</m> and any <m>p \in \mathbb{Q}</m>,
              </p>
        
              <p>
                <me>a \otimes p=a \otimes \frac{2 p}{2}=(2 a) \otimes \frac{p}{2}=0 \otimes \frac{p}{2}=0</me>
              </p>
        
              <p>
                Since <m>\mathbb{Z} / 2 \otimes_{\mathbb{Z}} \mathbb{Q}</m> is generated by simple tensors, which are all 0 , we conclude that <m>\mathbb{Z} / 2 \otimes_{\mathbb{Z}} \mathbb{Q}=0</m>.
              </p>
            </example>

            <example>
              <p>
                Example 3.26. Consider the abelian group <m>\mathbb{Q} / \mathbb{Z}</m>. Again, this is very much nonzero, and yet we claim that <m>\mathbb{Q} / \mathbb{Z} \otimes_{\mathbb{Z}} \mathbb{Q} / \mathbb{Z}=0</m>. For any simple tensor,
              </p>
        
              <p>
                <me>
                  \begin{aligned}
                  \left(\frac{p}{q}+\mathbb{Z}\right) \otimes\left(\frac{a}{b}+\mathbb{Z}\right)=\left(\frac{b p}{b q}+\mathbb{Z}\right) \otimes\left(\frac{a}{b}+\mathbb{Z}\right) &amp; =\left(\frac{p}{b q}+\mathbb{Z}\right) \otimes b\left(\frac{a}{b}+\mathbb{Z}\right) \\
                  &amp; =\left(\frac{p}{b q}+\mathbb{Z}\right) \otimes 0=0 \otimes 0=0
                  \end{aligned}
                </me>
              </p>
            </example>

            <example>
              <p>
                Example 3.27. Let <m>p</m> and <m>q</m> be distinct prime integers. Then <m>p</m> has inverse modulo <m>q</m>, say <m>a p \equiv 1 \bmod q</m>, and <m>q</m> has an inverse modulo <m>p</m>, say <m>b q \equiv 1 \bmod p</m>. Given any simple tensor <m>n \otimes m</m> in <m>\mathbb{Z} / p \otimes_{\mathbb{Z}} \mathbb{Z} / q</m>
              </p>
        
              <p>
                <me>n \otimes m=((b q) n) \otimes((a p) m)=(p b n) \otimes(q a m)=0 \otimes 0</me>
              </p>
        
              <p>
                Since all simple tensors are 0 and <m>\mathbb{Z} / p \otimes_{\mathbb{Z}} \mathbb{Z} / q</m> is generated by simple tensors, we conclude that <m>\mathbb{Z} / p \otimes_{\mathbb{Z}} \mathbb{Z} / q=0</m>.
              </p>
            </example>
      
            <p>
              More generally, the following holds:
            </p>

            <exercise>
              <p>
                Exercise 47. Show that if <m>d=\operatorname{gcd}(m, n)</m>, then <m>\mathbb{Z} / n \otimes_{\mathbb{Z}} \mathbb{Z} / m \cong \mathbb{Z} / d</m>.
              </p>
            </exercise>
      
            <p>
              Of course not all tensor products are zero. A good method for showing that a particular element <m>m</m> in a module <m>M</m> is nonzero is to give a homomorphism from <m>M</m> sending <m>m</m> to some nonzero element. We apply this technique to tensor products: to show that a particular element <m>x</m> in <m>M \otimes_{R} N</m> is nonzero, we construct a homomorphism from <m>M \otimes_{R} N</m> that takes <m>x</m> no some nonzero element. This is typically easier for simple tensors: we need an <m>R</m>-biadditive map out of <m>M \times N</m> that sends the corresponding pair to a nonzero element.
            </p>

            <example>
              <p>
                Example 3.28. Consider the abelian group <m>2 \mathbb{Z} \otimes_{\mathbb{Z}} \mathbb{Z} / 2</m>. The map
              </p>
        
              <p>
                <me>
                  \begin{array}{r}
                  2 \mathbb{Z} \times \mathbb{Z} / 2 \longrightarrow \mathbb{Z} / 2 \\
                  (a, b) \longmapsto \frac{a b}{2}
                  \end{array}
                </me>
              </p>
        
              <p>
                is <m>\mathbb{Z}</m>-bilinear, and thus it induces a homomorphism <m>2 \mathbb{Z} \otimes_{\mathbb{Z}} \mathbb{Z} / 2 \longrightarrow \mathbb{Z} / 2</m>. Via this map, <m>2 \otimes 1 \mapsto 1 \neq 0</m>, so <m>2 \otimes 1</m> is nonzero in <m>2 \mathbb{Z} \otimes_{\mathbb{Z}} \mathbb{Z} / 2</m>, and <m>2 \mathbb{Z} \otimes_{\mathbb{Z}} \mathbb{Z} / 2 \neq 0</m>.
              </p>
            </example>
      
            <p>
              Moreover, not all elements in a tensor product are simple tensors.
            </p>

            <exercise>
              <p>
                Exercise 48. Let <m>R=\mathbb{Z}[x]</m> and consider the ideal <m>I=(2, x)</m>. Show that in <m>I \otimes_{R} I</m>, the element <m>2 \otimes 2+x \otimes x</m> is not a simple tensor.
              </p>
            </exercise>

          </subsection>

          <subsection xml:id="subsec-tensor-module"><title>Bimodules and When Tensor Products are Modules</title>

            <blockquote>
              <p>
                <q>
                  Envy, like a false mirror, distorts the symmetry of the sweetest form.
                </q>
              </p>
              <attribution>Norm Macdonald</attribution>
            </blockquote>
    
            <p>
              We can sometimes give <m>M \otimes_{R} N</m> the structure of an <m>R</m>-module.
            </p>

            <remark>
              <p>
                Remark 3.29. Let <m>R</m> be a commutative ring, and let <m>M</m> and <m>N</m> be <m>R</m>-modules. We can give <m>M \otimes_{R} N</m> the structure of an <m>R</m>-module, as follows: given <m>r \in R</m> and a simple tensor <m>m \otimes n</m>,
              </p>
        
              <p>
                <me>r(m \otimes n)=(r m) \otimes n=m \otimes(r n)</me>
              </p>
        
              <p>
                We can then extend this linearly to all other elements of <m>M \otimes_{R} N</m>. We leave it as an exercise to check that this does indeed make the abelian group <m>M \otimes_{R} N</m> into an <m>R</m>-module.
              </p>
            </remark>
      
            <p>
              Alternatively, over a commutative ring we can define the tensor product as follows:
            </p>

            <definition xml:id="def-3.30">
              <statement>
                <p>
                  Definition 3.30. 
                  Let <m>R</m> be a commutative ring and <m>M</m> and <m>N</m> be <m>R</m>-modules. 
                  The tensor product of <m>M</m> and <m>N</m> is an <m>R</m>-module <m>M \otimes_{R} N</m> together with an <m>R</m>-bilinear map <m>\tau: M \times N \longrightarrow</m> <m>M \otimes_{R} N</m> with the following universal property: 
                  for every <m>R</m>-module <m>A</m> and every <m>R</m>-bilinear map <m>f: M \times N \longrightarrow A</m> there exists a unique <m>R</m>-module homomorphism <m>\tilde{f}: M \otimes_{R} N \longrightarrow A</m> such that the following diagram commutes:
                </p>
          
        
                <image source="2023_10_23_e2d6a27704be928b3deeg-089(1).jpg"/>
              </statement>
            </definition>
      
            <p>
              One can now check that if we take the abelian group <m>M \otimes_{R} N</m>, which is the unique abelian group which satisfies the universal property of the tensor product (as defined for a general ring <m>R</m> ), and endow it with the <m>R</m>-module structure defined in Remark 3.29, the resulting <m>R</m>-module satisfies the universal property in Definition 3.30, and the argument we gave in Lemma 3.21 can be repurposed to show that this is the unique <m>R</m>-module satisfying this universal property.
            </p>

            <remark>
              <p>
                Remark 3.31. We can express the universal property of the tensor product in the framework of Definition 1.87. For simplicity, assume that <m>R</m> is a commutative ring. Consider the functor <m>\operatorname{Bilin}(M \times N,-): R</m>-Mod <m>\longrightarrow</m> Set that sends an <m>R</m>-module <m>A</m> to the set of <m>R</m>-bilinear maps <m>M \times N \longrightarrow A</m>, and a map of <m>R</m>-modules <m>f A \longrightarrow B</m> to the function of sets induced by post-composition of functions. The universal property of the tensor product is encoded in the representable functor <m>\operatorname{Bilin}(M \times N,-): R</m>-Mod <m>\longrightarrow</m> Set together with the bilinear map <m>\tau \in \operatorname{Bilin}\left(M \times N, M \otimes_{R} N\right)</m>. Indeed, this says that <m>\tau</m> induces a natural isomorphism between <m>\operatorname{Hom}_{R}\left(M \otimes_{R} N,-\right)</m> and <m>\operatorname{Bilin}(M \times N,-)</m> by sending each <m>R</m>-module <m>A</m> to the bijection
              </p>
        
              <p>
                <me>
                  \begin{aligned}
                  \operatorname{Hom}_{R}\left(M \otimes_{R} N, A\right) &amp; \longrightarrow \operatorname{Bilin}(M \times N, A) \\
                  f &amp; \longmapsto \operatorname{Bilin}(M \times N, f) \tau=f_{*}(\tau)=f \tau
                  \end{aligned}
                </me>
              </p>
        
              <p>
                The fact that this is a bijection says that for every <m>R</m>-bilinear map <m>g</m> there exists a unique <m>R</m>-module homomorphism <m>f</m> such that
              </p>
        
      
              <image source="2023_10_23_e2d6a27704be928b3deeg-089.jpg"/>
                
        
              <p>
                commutes. So this is indeed the universal property we described before.
              </p>
            </remark>
      
            <p>
              More generally, <m>M \otimes_{R} N</m> has a module structure when one of <m>M</m> or <m>N</m> is a bimodule.
            </p>

            <definition xml:id="def-3.32">
              <statement>
                <p>
                  Definition 3.32. Fix rings <m>R</m> and <m>S</m>. An <m>(R, S)</m>-bimodule is an abelian group <m>M</m> together with a left <m>R</m>-module structure and a right <m>S</m>-module structure such that for all <m>r \in R, s \in S</m>, and <m>m \in M</m>,
                </p>
          
                <p>
                  <me>(r m) s=r(m s)</me>
                </p>
          
                <p>
                  One sometimes writes <m>{ }_{R} M_{S}</m> to indicate <m>M</m> is an <m>(R, S)</m>-bimodule. An <m>R</m>-bimodule is an <m>(R, R)</m>-bimodule.
                </p>
              </statement>
            </definition>

            <example>
              <p>Example 3.33.</p>
      
              <p>
                a) Let <m>\mathrm{M}_{m, n}(R)</m> denote the ring of <m>m \times n</m> matrices with entries in a ring <m>R</m>. We can also view <m>\mathrm{M}_{m, n}(R)</m> as an <m>\left(\mathrm{M}_{m, m}, \mathrm{M}_{n, n}\right)</m>-bimodule via left and right multiplication of matrices.
              </p>
          
              <p>
                b) Any two-sided ideal <m>I</m> of a ring <m>R</m> is an <m>R</m>-bimodule.
              </p>
          
              <p>
                c) Let <m>R</m> be a commutative ring and let <m>M</m> be any left <m>R</m>-module. Then <m>M</m> is also a right <m>R</m>-module under the same module structure, by setting
              </p>
          
              <p>
                <me>m \cdot r:=r m \text {. }</me>
              </p>
          
              <p>
                Moreover, <m>M</m> is also an <m>R</m>-bimodule using both of these structures at once.
              </p>
          
              <p>
                d) Let <m>f: R \rightarrow S</m> be a ring homomorphism. We can view <m>S</m> as an <m>(R, S)</m>-bimodule via
              </p>
          
              <p>
                <me>t \cdot s \cdot r:=t s f(r)</me>
              </p>
          
              <p>
                for <m>t, s \in S</m> and <m>r \in R</m>, where the right hand side is just multiplication in <m>s</m>. Similarly, <m>S</m> can be viewed as an <m>(S, R)</m>-bimodule and as an <m>(R, R)</m>-bimodule.
              </p>
          
              <p>
                e) Let <m>R</m> be a commutative ring of prime characteristic <m>p&gt;0</m>, meaning that <m>R</m> contains a copy of <m>\mathbb{F}_{p}</m>, or equivalently, that
              </p>
          
              <p>
                <me>\underbrace{1+\cdots+1}_{p \text { times }}=0</me>
              </p>
          
              <p>
                Then <m>R</m> is an <m>R</m>-bimodule with the left module structure given by the Frobenius map
              </p>
          
              <p>
                <me>\begin{aligned}
          &amp; R \stackrel{F}{\longrightarrow} R \\
          &amp; r \longmapsto r^{p}
          \end{aligned}</me>
              </p>
          
              <p>
                and right module structure given by the usual multiplication on <m>R</m>. More precisely, given <m>r, s, t \in R</m>,
              </p>
          
              <p>
                <me>r \cdot s \cdot t:=r^{p} s t</me>
              </p>
          
              <p>
                where the right hand side is just multiplication in <m>R</m>.
              </p>
            </example>

            <exercise>
              <p>
                Exercise 49. Let <m>M</m> be an <m>(S, R)</m>-bimodule and <m>N</m> a left <m>R</m>-module. Consider <m>M \times N</m> as a left <m>S</m>-module via
              </p>
          
              <p>
                <me>s(m, n)=(s m, n) \text {. }</me>
              </p>
          
              <p>
                Then <m>M \otimes_{R} N</m> is a left <m>S</m>-module via
              </p>
          
              <p>
                <me>s\left(\sum_{i} m_{i} \otimes n_{i}\right)=\left(s m_{i}\right) \otimes n_{i}</me>
              </p>
          
              <p>
                The map
              </p>
          
              <p>
                <me>\begin{gathered}
          M \times N \longrightarrow M \otimes_{R} N \\
          (m, n) \longrightarrow m \otimes n
          \end{gathered}</me>
              </p>
          
              <p>
                is left <m>S</m>-linear, and for any left <m>S</m>-module <m>A</m> and left <m>S</m>-linear <m>R</m>-biadditive map <m>b: M \times N \rightarrow A</m>, there is a unique left <m>S</m>-linear map <m>\alpha: M \otimes_{R} N \rightarrow A</m> such that <m>\alpha(m \otimes n)=b(m, n)</m>.
              </p>
          
              <p>
                Similarly, for a left <m>R</m>-module <m>M</m> and an <m>(R, S)</m>-bimodule <m>N, M \times N</m> is a right <m>S</m>-module via
              </p>
          
              <p>
                <me>(m, n) s=(m, n s)</me>
              </p>
          
              <p>
                Then <m>M \otimes_{R} N</m> is a right <m>S</m>-module via
              </p>
          
              <p>
                <me>\left(\sum_{i} m_{i} \otimes n_{i}\right) s=m_{i} \otimes\left(n_{i} s\right)</me>
              </p>
          
              <p>
                and the map
              </p>
          
              <p>
                <me>\begin{gathered}
          M \times N \longrightarrow M \otimes_{R} N \\
          (m, n) \longrightarrow m \otimes n
          \end{gathered}</me>
              </p>
          
              <p>
                is right <m>S</m>-linear, and for any <m>S</m>-module <m>A</m> and right <m>S</m>-linear <m>R</m>-biadditive map <m>b: M \times N \rightarrow A</m>, there is a unique right <m>S</m>-linear map <m>\alpha: M \otimes_{R} N \rightarrow A</m> such that <m>\alpha(m \otimes n)=b(m, n)</m>.
              </p>
            </exercise>   

          </subsection>

          <subsection xml:id="subsec-tensor-functor"><title>The Tensor Product Functor</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>
      
            <p>
              We can also take tensor products of maps.
            </p>

            <lemma xml:id="lem-3.34">
              <statement>
                <p>
                  Lemma 3.34. Let <m>R</m> be a ring, <m>f: A \rightarrow C</m> be a homomorphism of right <m>R</m>-modules, and <m>g: B \rightarrow D</m> be a homomorphism of left <m>R</m>-modules. There exists a unique homomorphism of abelian groups <m>f \otimes g: A \otimes_{R} B \longrightarrow C \otimes_{R} D</m> such that
                </p>
            
                <p>
                  <me>(f \otimes g)(a \otimes b)=f(a) \otimes g(b)</me>
                </p>
            
                <p>
                  for all <m>a \in A</m> and <m>b \in B</m>. When <m>R</m> is commutative, this map <m>f \otimes g</m> is a homomorphism of <m>R</m>-modules. Moreover, if <m>A</m> and <m>B</m> are <m>(S, R)</m>-bimodules and <m>f</m> is left <m>S</m>-linear, then <m>f \otimes g</m> is also a homomorphism of left <m>S</m>-modules, and if <m>C</m> and <m>D</m> are <m>(R, S)</m>-bimodules and <m>g</m> is right <m>S</m>-linear, then <m>f \otimes g</m> is also a homomorphism of right <m>S</m>-modules.
                </p>
              </statement>

              <proof>
                <p>
                  Proof sketch. The function
                </p>
            
                <p>
                  <me>\begin{aligned}
            A \times B &amp; \longrightarrow C \otimes_{R} D \\
            (a, b) &amp; \longmapsto f(a) \otimes g(b)
            \end{aligned}</me>
                </p>
            
                <p>
                  is <m>R</m>-biadditive, and <m>R</m>-bilinear when <m>R</m> is commutative, and right or left <m>S</m>-linear in the bimodule case, so the universal property of tensor products in each case gives the desired homomorphism and its uniqueness.
                </p>
              </proof>
            </lemma>

            <lemma xml:id="lem-3.35">
              <statement>
                <p>
                  Lemma 3.35. Given <m>R</m>-module maps <m>A_{1} \stackrel{f_{1}}{\longrightarrow} A_{2} \stackrel{f_{2}}{\longrightarrow} A_{3}</m> and <m>B_{1} \stackrel{b_{1}}{\longrightarrow} B_{2} \stackrel{g_{2}}{\longrightarrow} B_{3}</m>, the composition of <m>f_{1} \otimes g_{1}</m> satisfies <m>f_{2} \otimes g_{2}</m>
                </p>
            
                <p>
                  <me>\left(f_{2} \otimes g_{2}\right) \circ\left(f_{1} \otimes g_{1}\right)=\left(f_{2} f_{1}\right) \otimes\left(g_{2} g_{1}\right)</me>
                </p>
              </statement>
            </lemma>

            <proof>
              <p>
                Proof. It's sufficient to check that these maps agree on simple tensors, and indeed they both take <m>a \otimes b</m> to <m>\left(f_{2} f_{1}(a)\right) \otimes\left(g_{2} g_{1}(b)\right)</m>.
              </p>
            </proof>
        
            <p>
              We are particularly interested in tensor products because of the tensor functor.
            </p>

            <theorem xml:id="thm-3.36">
              <statement>
                <p>
                  Theorem 3.36. Let <m>M</m> be a right <m>R</m>-module. There is an additive covariant functor
                </p>
            
                <p>
                  <me>M \otimes_{R}-: R-\operatorname{Mod} \longrightarrow \mathbf{A b}</me>
                </p>
            
                <p>
                  that takes each <m>R</m>-module <m>N</m> to <m>M \otimes_{R} N</m>, and each <m>R</m>-module homomorphism <m>f: A \longrightarrow B</m> to the homomorphism of abelian groups <m>1_{M} \otimes f: M \otimes_{R} A \longrightarrow M \otimes_{R} B</m>.
                </p>
            
                <p>
                  When <m>R</m> is commutative, we can view <m>M \otimes_{R}-</m> as an additive functor <m>R-\boldsymbol{M o d} \rightarrow R</m>-Mod.
                </p>
              </statement>

              <proof>
                <p>
                  Proof. Let <m>T:=M \otimes_{R}-</m>. First, note that <m>T</m> preserves identities, meaning <m>T\left(1_{N}\right)=1_{T(N)}</m>, since the identity map on <m>M \otimes_{R} N</m> agrees with <m>T\left(1_{N}\right)=1_{M} \otimes 1_{N}</m> on simple tensors. Moreover, <m>T</m> preserves compositions, since by Lemma 3.35 we have
                </p>
            
                <p>
                  <me>T(f) T(g)=(1 \otimes f)(1 \otimes g)=1 \otimes(f g)=T(f g)</me>
                </p>
            
                <p>
                  Therefore, <m>T</m> is a functor. To check that it is an additive functor, we need to prove that <m>T(f+g)=T(f)+T(g)</m> for all <m>f, g \in \operatorname{Hom}_{R}(A, B)</m>. It is sufficient to check that the maps <m>T(f+g)=1 \otimes(f+g)</m> and <m>T(f)+T(g)=1 \otimes f+1 \otimes g</m> agree on simple tensors. Indeed,
                </p>
            
                <p>
                  <me>\begin{aligned}
            T(f+g)(a \otimes b) &amp; =(1 \otimes(f+g))(a \otimes b) \\
            &amp; =a \otimes(f+g)(b) \\
            &amp; =a \otimes f(b)+g(b) \\
            &amp; =a \otimes f(b)+a \otimes g(b) \\
            &amp; =(1 \otimes f)(a \otimes b)+(1 \otimes g)(a \otimes b) \\
            &amp; =T(f)(a \otimes b)+T(g)(a \otimes b) .
            \end{aligned}</me>
                </p>
            
                <p>
                  We conclude that <m>T(f+g)=T(f)+T(g)</m>.
                </p>
              </proof>
            </theorem>
            
            <definition xml:id="def-3.37">
              <statement>
                <p>
                  Definition 3.37. Given a ring <m>R</m> and a right <m>R</m>-module <m>M</m>, the functor <m>M \otimes_{R}-</m> is the tensor product functor.
                </p>
              </statement>
            </definition>
            
            <p>
              Note that we were purposely vague on the target of the tensor product functor: when <m>R</m> is commutative, we get both a functor <m>R</m>-Mod <m>\rightarrow \mathrm{Ab}</m> and a functor <m>R</m>-Mod <m>\rightarrow R</m>-Mod. The two functors are essentially the same: the tensor product functor <m>R-\mathbf{M o d} \rightarrow \mathbf{A b}</m> is the composition of functor <m>R</m>-Mod <m>\rightarrow R</m>-Mod followed by the forgetful functor <m>R</m>-Mod <m>\rightarrow \mathbf{A b}</m>.
            </p>
        
            <p>
              We can similarly define the tensor product functor <m>-\otimes_{R} N</m>; when <m>R</m> is commutative, it turns out that the two constructions are essentially the same.
            </p>

            <lemma xml:id="lem-3.38">
              <statement>
                <p>
                  Lemma 3.38 (Commutativity of tensor products). Let <m>R</m> be a commutative ring. There is a natural isomorphism <m>M \otimes_{R}-\cong-\otimes_{R} N</m>. In particular, for all <m>R</m>-modules <m>M</m> and <m>N</m> we have
                </p>
            
                <p>
                  <me>M \otimes_{R} N \cong N \otimes_{R} M</me>
                </p>
              </statement>

              <proof>
                <p>
                  Proof. One can check (exercise!) that the map <m>M \times N \longrightarrow N \otimes_{R} M</m> given by <m>(m, n) \mapsto n \otimes m</m> is <m>R</m>-biadditive, and <m>R</m>-bilinear if <m>R</m> is commutative. The universal property of the tensor product <m>M \otimes_{R} N</m> gives us a homomorphism <m>\varphi</m> of abelian groups or <m>R</m>-modules, depending on the case, such that the diagram
                </p>
            
            
                <image source="2023_10_23_e2d6a27704be928b3deeg-093(1).jpg"/>
                  
            
                <p>
                  commutes. Similarly, we get a map <m>\psi</m> and a commutative diagram
                </p>
            
            
                <image source="2023_10_23_e2d6a27704be928b3deeg-093(3).jpg"/>
                  
            
                <p>
                  Then <m>\varphi \psi</m> agrees with the identity on <m>N \otimes_{R} M</m> on simple tensors, so it is the identity. Similarly, <m>\psi \varphi</m> is the identity on <m>M \otimes_{R} N</m>, and these are the desired isomorphisms.
                </p>
            
                <p>
                  The statement about naturality is more precisely the following: for every <m>R</m>-module maps <m>f: M_{1} \longrightarrow M_{2}</m> and <m>g: N_{1} \longrightarrow N_{2}</m>, our isomorphisms <m>M_{1} \otimes_{R} N_{1} \cong N_{1} \otimes_{R} M_{1}</m> and <m>M_{2} \otimes_{R} N_{2} \cong N_{2} \otimes_{R} M_{2}</m> make the diagram
                </p>
            
            
                <image source="2023_10_23_e2d6a27704be928b3deeg-093.jpg"/>
                  
            
                <p>
                  commute. To check this, it's sufficient to check commutativity on simple tensors, and indeed
                </p>
            
            
                <image source="2023_10_23_e2d6a27704be928b3deeg-093(2).jpg"/>
              </proof>
            </lemma>

            <lemma xml:id="lem-3.39">
              <statement>
                <p>
                  Lemma 3.39 (Associativity of tensors). Given a right <m>R</m>-module <m>A</m>, an <m>(R, S)</m>-bimodule <m>B</m>, and a left <m>S</m>-module <m>C</m>,
                </p>
            
                <p>
                  <me>\left(A \otimes_{R} B\right) \otimes_{S} C \cong A \otimes_{R}\left(B \otimes_{S} C\right)</me>
                </p>
              </statement>

              <proof>
                <p>
                  Proof. Fix <m>c \in C</m>. The map
                </p>
            
                <p>
                  <me>\begin{gathered}
            A \times B \longrightarrow A \otimes_{R}\left(B \otimes_{R} C\right) \\
            (a, b) \longmapsto a \otimes(b \otimes c)
            \end{gathered}</me>
                </p>
            
                <p>
                  is <m>R</m>-biadditive, so it induces a homomorphism of abelian groups
                </p>
            
                <p>
                  <me>\varphi_{c}: A \otimes_{R} B \longrightarrow A \otimes_{R}\left(B \otimes_{R} C\right)</me>
                </p>
            
                <p>
                  This map is in fact a homomorphism of <m>R</m>-modules when <m>R</m> is commutative. Moreover,
                </p>
            
                <p>
                  <me>\begin{gathered}
            \left(A \otimes_{R} B\right) \times C \longrightarrow A \otimes_{R}\left(B \otimes_{R} C\right) \\
            (a \otimes b, c) \longmapsto a \otimes(b \otimes c)
            \end{gathered}</me>
                </p>
            
                <p>
                  is also <m>R</m>-biadditive, and it induces a homomorphism that sends <m>(a \otimes b) \otimes c</m> to <m>a \otimes(b \otimes c)</m>. Similarly, we can define a homomorphism
                </p>
            
                <p>
                  <me>\begin{gathered}
            A \otimes_{R}\left(B \otimes_{R} C\right) \longrightarrow\left(A \otimes_{R} B\right) \otimes_{R} C \\
            a \otimes(b \otimes c) \longmapsto(a \otimes b) \otimes c .
            \end{gathered}</me>
                </p>
            
                <p>
                  The composition of these two homomorphisms in either order is the identity on simple tensors, and thus they are both isomorphisms.
                </p>
              </proof>
            </lemma>

            <lemma xml:id="lem-3.40">
              <statement>
                <p>
                  Lemma 3.40. Let <m>R</m> be any ring. There is a natural isomorphism between <m>R \otimes_{R}-</m> and the identity functor on <m>R</m>-Mod. In particular, for every left <m>R</m>-module <m>M</m> there is an isomorphism of <m>R</m>-modules
                </p>
            
                <p>
                  <me>R \otimes_{R} M \cong M</me>
                </p>
              </statement>

              <proof>
                <p>
                  Proof. First, note that <m>R</m> is an <m>R</m>-bimodule, so <m>R \otimes_{R} M</m> is a left <m>R</m>-module. The map
                </p>
            
                <p>
                  <me>\begin{aligned}
            R \times M &amp; \longrightarrow M \\
            (r, m) &amp; \longmapsto r m
            \end{aligned}</me>
                </p>
            
                <p>
                  is <m>R</m>-biadditive (by the distributive laws), <m>R</m>-bilinear (by associativity of the action on a module), and <m>R</m>-linear, so it induces a homomorphism of <m>R</m>-modules <m>R \otimes_{R} M \stackrel{\varphi_{M}}{\longrightarrow} M</m>. By definition, <m>\varphi_{M}</m> is surjective. Moreover, the map
                </p>
            
                <p>
                  <me>\begin{aligned}
            &amp; M \stackrel{f_{M}}{\longmapsto} R \otimes_{R} M \\
            &amp; m \longmapsto 1 \otimes m
            \end{aligned}</me>
                </p>
            
                <p>
                  is a homomorphism of <m>R</m>-modules, since
                </p>
            
                <p>
                  <me>f_{M}(a+b)=1 \otimes(a+b)=1 \otimes a+1 \otimes b \text { and } f_{M}(r a)=1 \otimes(r a)=r(1 \otimes a)=r f_{M}(a)</me>
                </p>
            
                <p>
                  For every <m>m \in M, \varphi_{M} f_{M}(m)=\varphi_{M}(1 \otimes m)=1 m=m</m>, and for every simple tensor, <m>f_{M} \varphi_{M}(r \otimes m)=f_{M}(r m)=1 \otimes(r m)=r \otimes m</m>. This shows that <m>\varphi_{M}</m> is an isomorphism.
                </p>
            
                <p>
                  Finally, given any <m>f \in \operatorname{Hom}_{R}(M, N)</m>, since <m>f</m> is <m>R</m>-linear we conclude that the diagram
                </p>
            
                <image source="2023_10_23_e2d6a27704be928b3deeg-095.jpg"/>
                  
                <p>
                  commutes, so our isomorphism is natural.
                </p>
              </proof>
            </lemma>

            <p>
              Similarly to the Hom functor, tensor behaves well with respect to arbitrary direct sums.
            </p>

            <theorem xml:id="thm-3.41">
              <statement>
                <p>
                  Theorem 3.41. Let <m>M</m> be a right <m>R</m>-module, and let <m>\left\{N_{i}\right\}_{i \in I}</m> be an arbitrary family of left <m>R</m>-modules. Then the map
                </p>
            
                <p>
                  <me>\begin{gathered}
            M \otimes_{R}\left(\bigoplus_{i \in I} N_{i}\right) \cong \underset{i \in I}{\rightrightarrows} \bigoplus_{i \in I} M \otimes_{R} N_{i} \\
            m \otimes\left(a_{i}\right)_{i} \longmapsto \\
            \longrightarrow\left(m \otimes a_{i}\right)
            \end{gathered}</me>
                </p>
            
                <p>
                  is an isomorphism of abelian groups in general, of <m>R</m>-modules in the commutative case, of <m>S</m> modules if each <m>N_{i}</m> is an <m>(S, R)</m>-bimodule, and of right <m>S</m>-modules if <m>N</m> is an <m>(R, S)</m>-bimodule. Moreover, this isomorphism is natural: given two families of left <m>R</m>-modules <m>\left\{A_{i}\right\}_{i \in I}</m> and <m>\left\{B_{j}\right\}_{j \in J}</m>, and left <m>R</m>-module homomorphisms <m>\sigma_{i j}: A_{i} \longrightarrow B_{j}</m>, the <m>R</m>-module homomorphisms
                </p>
            
                <p>
                  <me>\begin{aligned}
            &amp; \bigoplus_{i \in I} A_{i} \stackrel{\sigma}{\longrightarrow} \bigoplus_{j \in J} B_{j} \quad \text { and } \quad \tilde{\sigma}=\bigoplus_{i \in I} \sigma_{i j}: \bigoplus_{i \in I} M \otimes_{R} A_{i} \longrightarrow \bigoplus_{j \in J} M \otimes_{R} B_{j} \\
            &amp; \left(a_{i}\right)_{i \in I} \longmapsto\left(\sigma_{i j}\left(a_{i}\right)\right)_{j \in J}
            \end{aligned}</me>
                </p>
            
                <p>
                  give a commutative diagram
                </p>
            
                <p>
                  <me>\begin{aligned}
            M \otimes_{R}\left(\bigoplus_{i \in I} A_{i}\right) &amp; \cong \bigoplus_{i \in I} M \otimes_{R} A_{i} \\
            1 \otimes \sigma &amp; \downarrow \\
            M \otimes_{R}\left(\bigoplus_{j \in J} B_{j}\right) &amp; \stackrel{\sim}{\longleftarrow} \bigoplus_{j \in J} M \otimes_{R} B_{j} .
            \end{aligned}</me>
                </p>
              </statement>

              <proof>
                <p>
                  Proof. First, note that the function
                </p>
            
                <p>
                  <me>\begin{gathered}
            M \times\left(\bigoplus_{i \in I} A_{i}\right) \longrightarrow \bigoplus_{i \in I}\left(M \otimes_{R} A_{i}\right) \\
            \left(m,\left(a_{i}\right)_{i}\right) \longmapsto\left(m \otimes a_{i}\right)
            \end{gathered}</me>
                </p>
            
                <p>
                  is <m>R</m>-bilinear, so it induces a homomorphism
                </p>
            
                <p>
                  <me>M \otimes_{R}\left(\bigoplus_{i \in I} A_{i}\right) \stackrel{\tau}{\longrightarrow} \bigoplus_{i \in I}\left(M \otimes_{R} A_{i}\right)</me>
                </p>
            
                <p>
                  For each <m>k \in I</m>, let <m>\iota_{k}</m> denote the inclusion map <m>A_{k} \subseteq \bigoplus_{i} A_{i}</m>. The universal property of the coproduct (which in the case of <m>R</m>-modules, means the direct sum) gives an <m>R</m>-module homomorphism
                </p>
            
                <p>
                  <me>\begin{array}{r}
            \bigoplus_{i \in I}\left(M \otimes_{R} A_{i}\right) \stackrel{\lambda}{\longrightarrow} M \otimes_{R} \bigoplus_{i \in I}\left(A_{i}\right) \\
            \left(m \otimes a_{i}\right)_{i} \longmapsto m \otimes \sum_{i} \iota_{i}\left(a_{i}\right)
            \end{array}</me>
                </p>
            
                <p>
                  which we obtain by assembling the <m>R</m>-module homomorphisms <m>1 \otimes \iota_{i}</m>. It is routine to check that <m>\lambda</m> is the inverse of <m>\tau</m>, which must then be an isomorphism. Finally, we can check naturality by checking commutativity of the square above, element by element:
                </p>
            
            
                <image source="2023_10_23_e2d6a27704be928b3deeg-096.jpg"/>
              </proof>
            </theorem>

            <remark>
              <p>
                Remark 3.42. By commutativity of the tensor product, we also get natural isomorphisms
              </p>
          
              <p>
                <me>\left(\bigoplus_{i \in I} N_{i}\right) \otimes_{R} M \stackrel{\cong}{\longrightarrow} \bigoplus_{i \in I} N_{i} \otimes_{R} M</me>
              </p>
            </remark>
            
            <p>
              The following follows as a corollary of Lemma 3.40 and Theorem 3.41:
            </p>

            <exercise>
              <p>
                Exercise 50. Show that if <m>F</m> and <m>G</m> are free <m>R</m>-modules on bases <m>\left\{e_{\lambda}\right\}_{\lambda \in \Lambda}</m> and <m>\left\{e_{\gamma}\right\}_{\gamma \in \Gamma}</m>, respectively, then <m>F \otimes_{R} G</m> is the free <m>R</m>-module on basis
              </p>
          
              <p>
                <me>\left\{e_{\lambda} \otimes e_{\gamma} \mid \lambda \in \Lambda, \gamma \in \Gamma\right\}</me>
              </p>
          
              <p>
                In particular,
              </p>
          
              <p>
                <me>R^{n} \otimes R^{m} \cong R^{n m}</me>
              </p>
            </exercise>

            <example>
              <p>
                Example 3.43. Let <m>R</m> be any ring and consider <m>R^{2} \otimes_{R} R^{2}</m>. Let <m>e_{1}=(1,0) \in R^{2}</m> and <m>e_{2}=(0,1) \in R^{2}</m>. We claim that the element <m>e_{1} \otimes e_{2}+e_{2} \otimes e_{1}</m> is not a simple tensor. Suppose, by contradiction, that there exist <m>v, y \in R^{2}</m> such that
              </p>
          
              <p>
                <me>e_{1} \otimes e_{2}+e_{2} \otimes e_{1}=v \otimes w</me>
              </p>
          
              <p>
                Since <m>\left\{e_{1}, e_{2}\right\}</m> is a basis for the free module <m>R^{2}</m>, we can write
              </p>
          
              <p>
                <me>v=v_{1} e_{1}+v_{2} e_{2} \quad \text { and } \quad w=w_{1} e_{1}+w_{2} e_{2}</me>
              </p>
          
              <p>
                Substituting above, we see that
              </p>
          
              <p>
                <me>\begin{aligned}
          v \otimes w &amp; =\left(v_{1} e_{1}+v_{2} e_{2}\right) \otimes\left(w_{1} e_{1}+w_{2} e_{2}\right) \\
          &amp; =v_{1} w_{1} e_{1} \otimes e_{1}+v_{1} w_{2} e_{1} \otimes e_{2}+v_{2} w_{1} e_{2} \otimes e_{1}+v_{2} w_{2} e_{2} \otimes e_{2}
          \end{aligned}</me>
              </p>
          
              <p>
                But by Exercise 50, <m>\left\{e_{1} \otimes e_{1}, e_{1} \otimes e_{2}, e_{2} \otimes e_{1}, e_{2} \otimes e_{2}\right\}</m> is a basis for the free <m>R</m>-module <m>R^{2} \otimes R^{2} \cong R^{4}</m>, so we can now compare coefficients: since
              </p>
          
              <p>
                <me>e_{1} \otimes e_{2}+e_{2} \otimes e_{1}=v_{1} w_{1} e_{1} \otimes e_{1}+v_{1} w_{2} e_{1} \otimes e_{2}+v_{2} w_{1} e_{2} \otimes e_{1}+v_{2} w_{2} e_{2} \otimes e_{2}</me>
              </p>
          
              <p>
                we must have
              </p>
          
              <p>
                <me>\left\{\begin{array} { l } 
          { v _ { 1 } w _ { 1 } = 1 } \\
          { v _ { 1 } w _ { 2 } = 0 } \\
          { v _ { 2 } w _ { 1 } = 0 } \\
          { v _ { 2 } w _ { 2 } = 1 }
          \end{array} \Longrightarrow \left\{\begin{array}{l}
          v_{1} \text { and } w_{1} \text { are units } \\
          v_{1} w_{2}=0 \\
          v_{2} w_{1}=0 \\
          v_{2} \text { and } w_{2} \text { are units }
          \end{array}\right.\right.</me>
              </p>
          
              <p>
                But since <m>v_{1}</m> is a unit and <m>v_{1} w_{2}=0</m>, we must have <m>w_{2}=0</m>; similarly, since <m>v_{2}</m> is a unit and <m>v_{2} w_{1}=0</m>, we must have <m>w_{1}=0</m>. But we have both <m>w_{1}=w_{2}=0</m> and that <m>w_{1}, w_{2}</m> are units, which is a contradiction. We conclude that <m>e_{1} \otimes e_{2}+e_{2} \otimes e_{1}</m> is not a simple tensor.
              </p>
            </example>
        
            <p>
              One of the reasons tensor products are useful is that we can use tensor products to extend module structures to ring extensions.
            </p>

            <remark>
              <p>
                Remark 3.44. Let <m>f: R \rightarrow S</m> be a ring homomorphism. Since <m>S</m> is an <m>(S, R)</m>-bimodule, the abelian group <m>S \otimes_{R} M</m> has a left <m>S</m>-module structure for every left <m>R</m>-module <m>M</m>. Thus <m>S \otimes_{R}</m> - determines a functor from <m>R</m>-modules to <m>S</m>-modules.
              </p>
            </remark>

            <definition xml:id="def-3.45">
              <statement>
                <p>
                  Definition 3.45. Let <m>f: R \rightarrow S</m> be a ring homomorphism. The extension of scalars from <m>R</m> to <m>S</m> is the functor <m>S \otimes_{R}-: R</m>-Mod <m>\longrightarrow S</m>-mod: for each <m>R</m>-module <m>M</m>, we get an <m>S</m>-module <m>S \otimes_{R} M</m> with
                </p>
            
                <p>
                  <me>s \cdot\left(\sum_{i} s_{i} \otimes m_{i}\right):=\sum_{i}\left(s s_{i}\right) \otimes m_{i}</me>
                </p>
            
                <p>
                  and for each <m>R</m>-module homomorphism <m>f: M \rightarrow N</m> we get the <m>S</m>-module homomorphism <m>1 \otimes_{R} f: S \otimes_{R} M \longrightarrow S \otimes_{R} N</m>.
                </p>
              </statement>
            </definition>
        
            <p>
              This functor is closely related to restriction of scalars: we will soon show that restriction and extension of scalars are adjoint functors.
            </p>

            <definition xml:id="def-3.46">
              <statement>
                <p>
                  Definition 3.46. Let <m>f: R \rightarrow S</m> be a ring homomorphism. The restriction of scalars functor from <m>S</m> to <m>R</m> is the functor <m>f^{*}: S</m>-mod <m>\longrightarrow R</m>-Mod that takes each <m>S</m>-module <m>M</m> to the <m>R</m>-module <m>f^{*} M</m> with underlying abelian group <m>M</m> and <m>R</m>-module structure
                </p>
            
                <p>
                  <me>r \cdot m:=f(r) m</me>
                </p>
            
                <p>
                  induced by <m>f</m>. Moreover, for each <m>S</m>-module homomorphism <m>g: M \longrightarrow N</m> we get the <m>R</m> module homomorphism <m>f^{*}(g): f^{*}(M) \longrightarrow f^{*}(N)</m> defined by <m>f^{*}(g)(m):=g(n)</m>.
                </p>
              </statement>
            </definition>

            <exercise>
              <p>
                Exercise 51. Check that restriction of scalars as defined above is indeed a functor.
              </p>
            </exercise>

          </subsection>

          <subsection xml:id="subsec-tensor-right-exact"><title>Tensor is Right Exact</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>
            
            <p>
              Tensor is right exact.
            </p>

            <theorem xml:id="thm-3.47">
              <statement>
                <p>
                  Theorem 3.47. Let <m>M</m> be a right <m>R</m>-module. The functor <m>M \otimes_{R}-</m> is right exact, meaning that for every exact sequence
                </p>
            
                <p>
                  <me>A \stackrel{i}{\longrightarrow} B \stackrel{p}{\longrightarrow} C \longrightarrow 0</me>
                </p>
            
                <p>
                  the sequence
                </p>
            
                <p>
                  <me>M \otimes_{R} A \stackrel{1 \otimes i}{\longrightarrow} M \otimes_{R} B \stackrel{1 \otimes p}{\longrightarrow} M \otimes_{R} C \longrightarrow 0</me>
                </p>
            
                <p>
                  is exact.
                </p>
              </statement>

              <proof>
                <p>
                  Proof. Since additive functors send complexes to complexes, <m>(1 \otimes p)(1 \otimes i)=0</m>. We have two more things to show:
                </p>
                <image source='2023_10_23_e2d6a27704be928b3deeg-098.jpg'/>
                <p>
                  we can find <m>b_{1}, \ldots, b_{n} \in B</m> such that <m>p\left(b_{i}\right)=c_{i}</m>. Therefore,
                </p>
            
                <p>
                  <m>(1 \otimes p)\left(m_{1} \otimes b_{1}+\cdots+m_{n} \otimes b_{n}\right)=m_{1} \otimes p\left(b_{1}\right)+\cdots+m_{n} \otimes p\left(b_{n}\right)=m_{1} \otimes c_{1}+\cdots+m_{n} \otimes c_{n}</m>.
                </p>
            
                <p>
                  <m>\operatorname{ker}(1 \otimes p)=\operatorname{im}(1 \otimes i)</m> : Let <m>I=\operatorname{im}(1 \otimes i)</m>. We have already shown that <m>I \subseteq \operatorname{ker}(1 \otimes p)</m>, so <m>\overline{1 \otimes p \text { induces a map } q}:\left(M \otimes_{R} B\right) / I \longrightarrow M \otimes_{R} C</m>. Let <m>\pi: M \otimes_{R} B \longrightarrow\left(M \otimes_{R} B\right) / I</m> be the canonical projection. By definition, <m>q \pi=1 \otimes p</m>.
                </p>
            
                <p>
                  Consider the map
                </p>
            
                <p>
                  <me>\begin{gathered}
            M \times C \stackrel{f}{\longrightarrow}\left(M \otimes_{R} B\right) / I \\
            (m, c) \longmapsto m \otimes b
            \end{gathered}</me>
                </p>
            
                <p>
                  where <m>b</m> is such that <m>p(b)=c</m>. First, we should check this map <m>f</m> is well-defined. To see that, suppose that <m>b^{\prime} \in B</m> is another element with <m>p\left(b^{\prime}\right)=c</m>, so that <m>p\left(b-b^{\prime}\right)=0</m>. Then <m>b-b^{\prime} \in \operatorname{ker} p=\operatorname{im} i</m>, so <m>m \otimes\left(b-b^{\prime}\right) \in \operatorname{im}(1 \otimes i) \subseteq I</m>. Therefore, <m>m \otimes b=m \otimes b^{\prime}</m> modulo <m>I</m>, and <m>f</m> is well-defined.
                </p>
            
                <p>
                  Moreover, one can check (exercise!) that <m>f</m> is <m>R</m>-biadditive, so it induces a homomorphism of <m>R</m>-modules <m>M \otimes_{R} C \longrightarrow\left(M \otimes_{R} B\right) / I</m>, which we will denote by <m>\hat{f}</m>. We will show that <m>\hat{f}</m> is a left inverse of <m>q</m>, so <m>q</m> is injective. And indeed, given <m>m_{i} \in M</m> and <m>b_{i} \in B</m>, we have
                </p>
            
                <p>
                  <me>\hat{f} q\left(\sum_{i=1}^{n} m_{i} \otimes b_{i}\right)=f\left(\sum_{i=1}^{n} m_{i} \otimes p\left(b_{i}\right)\right)=\sum_{i=1}^{n} f\left(m_{i} \otimes p\left(b_{i}\right)\right)=\sum_{i=1}^{n} m_{i} \otimes b_{i}</me>
                </p>
            
                <p>
                  We conclude that <m>q</m> is injective, and thus
                </p>
            
                <p>
                  <me>\operatorname{ker}(1 \otimes p)=\operatorname{ker}(q \pi)=\operatorname{ker} \pi=I=\operatorname{im}(1 \otimes i)</me>
                </p>
              </proof>
            </theorem>

            <p>
              However, tensor is not exact.
            </p>

            <example>
              <p>
                Example 3.48. Consider the short exact sequence
              </p>
          
              <p>
                <me>0 \longrightarrow \mathbb{Z} \stackrel{i}{\longrightarrow} \mathbb{Q} \stackrel{p}{\longrightarrow} \mathbb{Q} / \mathbb{Z} \longrightarrow 0</me>
              </p>
          
              <p>
                Applying the functor <m>\mathbb{Z} / 2 \otimes_{\mathbb{Z}}-</m>, we get an exact sequence
              </p>
          
              <p>
                <me>\mathbb{Z} / 2 \otimes_{\mathbb{Z}} \mathbb{Z} \stackrel{1 \otimes i}{\longrightarrow} \mathbb{Z} / 2 \otimes_{\mathbb{Z}} \mathbb{Q} \stackrel{1 \otimes p}{\longrightarrow} \mathbb{Z} / 2 \otimes_{\mathbb{Z}} \mathbb{Q} / \mathbb{Z} \longrightarrow 0</me>
              </p>
          
              <p>
                However, we claim that <m>1 \otimes i</m> is not injective. On the one hand, by Lemma 3.40 we have an isomorphism <m>\mathbb{Z} / 2 \otimes_{\mathbb{Z}} \mathbb{Z} \cong \mathbb{Z} / 2 \neq 0</m>. On the other hand, we have seen in Example 3.25 that <m>\mathbb{Z} / 2 \otimes_{\mathbb{Z}} \mathbb{Q}=0</m>, so the map <m>1 \otimes i: \mathbb{Z} / 2 \rightarrow 0</m> cannot possibly be injective.
              </p>
            </example>
        
            <p>
              We can now show that extension of scalars turns an <m>R</m>-module into the <m>S</m>-module with the same presentation.
            </p>

            <remark>
              <p>
                Remark 3.49. Let <m>R</m> be a ring, <m>M</m> be a right <m>R</m>-module, and <m>N</m> be a left <m>R</m>-module. We can compute <m>M \otimes_{R} N</m> by taking a presentation of <m>M</m>
              </p>
          
              <p>
                <me>R^{\oplus \Gamma} \stackrel{\phi}{\longrightarrow} R^{\oplus \Lambda} \longrightarrow M \longrightarrow 0</me>
              </p>
          
              <p>
                and tensoring with <m>N</m> to get
              </p>
          
              <p>
                <me>N^{\oplus \Gamma} \longrightarrow N^{\oplus \Lambda} \longrightarrow M \otimes_{R} N \longrightarrow 0</me>
              </p>
          
              <p>
                so <m>M \otimes_{R} N</m> is the cokernel of the map <m>N^{\oplus \Gamma} \rightarrow N^{\oplus \Lambda}</m> induced by <m>\phi</m>. We can also compute <m>M \otimes_{R} N</m> by taking a presentation of <m>N</m>
              </p>
          
              <p>
                <me>R^{\oplus \Xi} \stackrel{\psi}{\longrightarrow} R^{\oplus \Omega} \longrightarrow N \longrightarrow 0</me>
              </p>
          
              <p>
                and tensoring with <m>M</m> to get
              </p>
          
              <p>
                <me>M^{\oplus \Xi} \longrightarrow M^{\oplus \Omega} \longrightarrow M \otimes_{R} N \longrightarrow 0</me>
              </p>
          
              <p>
                so <m>M \otimes_{R} N</m> is isomorphic to the cokernel of the map <m>M^{\oplus \Gamma} \rightarrow M^{\oplus \Lambda}</m> induced by <m>\psi</m>.
              </p>
            </remark>

          </subsection>

          <outcomes>
            <ul>
              <li>
                <p>

                </p>
              </li>
            </ul>
          </outcomes>
          
        </section>

        <section xml:id="sec-localization"><title>Localization</title>
          
          <p>
            Recall that a multiplicatively closed subset of a <m>\operatorname{ring} R</m> is a set <m>W \ni 1</m> that is closed for products. 
            The three most important classes of multiplicatively closed sets are the following:
          </p>

          <example>
            <p>
              Example 3.50. Let <m>R</m> be a commutative ring.
            </p>
      
            <p><ol>
              <li>
                    <p>
              For any <m>f \in R</m>, the set <m>W=\left\{1, f, f^{2}, f^{3}, \ldots\right\}</m> is a multiplicatively closed set.
            </p>
              </li>
      
              <li>
                    <p>
              If <m>P \subseteq R</m> is a prime ideal, the set <m>W=R \backslash P</m> is multiplicatively closed: this is an immediate translation of the definition.
            </p>
              </li>
      
              <li>
                    <p>
              An element that is not a zerodivisor is called a nonzerodivisor or regular element. The set of regular elements in <m>R</m> forms a multiplicatively closed subset. When <m>R</m> is a domain, this set is precisely the set of all nonzero elements <m>R \backslash\{0\}</m>.
            </p>
              </li>
      
            </ol></p>
          </example>

          <definition xml:id="def-3.51">
            <statement>
              <p>
                Definition 3.51 (Localization of a ring). Let <m>R</m> be a commutative ring, and <m>W</m> be a multiplicative set with <m>0 \notin W</m>. The localization of <m>R</m> at <m>W</m> is a ring, denoted by <m>W^{-1} R</m> or <m>R_{W}</m>, given by where <m>\sim</m> is the equivalence relation
              </p>
        
              <p>
                <me>\frac{r}{w} \sim \frac{r^{\prime}}{w^{\prime}} \text { if there exists } u \in W \text { such that } u\left(r w^{\prime}-r^{\prime} w\right)=0</me>
              </p>
        
              <p>
                The operations are given by
              </p>
        
              <p>
                <me>\frac{r}{v}+\frac{s}{w}=\frac{r w+s v}{v w} \quad \text { and } \quad \frac{r}{v} \frac{s}{w}=\frac{r s}{v w}</me>
              </p>
        
              <p>
                The zero in <m>W^{-1} R</m> is <m>\frac{0}{1}</m> and the multiplcative identity is <m>\frac{1}{1}</m>. There is a canonical ring homomorphism
              </p>
        
              <p>
                <me>\begin{aligned}
        &amp; R \longrightarrow W^{-1} R \\
        &amp; r \longmapsto \frac{r}{1}
        \end{aligned}</me>
              </p>
        
              <p>
                Note that we write elements in <m>W^{-1} R</m> in the form <m>\frac{r}{w}</m> even though they are equivalence classes of such expressions.
              </p>
        
              <p>
                Let <m>M</m> be an <m>R</m>-module. The localization of <m>M</m> at <m>W</m> is the <m>W^{-1} R</m>-module <m>W^{-1} M</m> or <m>M_{W}</m> given by
              </p>
        
              <p>
                <me>W^{-1} M:=\left\{\frac{m}{w} \mid m \in M, w \in W\right\} / \sim</me>
              </p>
        
              <p>
                where <m>\sim</m> is the equivalence relation <m>\frac{m}{w} \sim \frac{m^{\prime}}{w^{\prime}}</m> if <m>u\left(m w^{\prime}-m^{\prime} w\right)=0</m> for some <m>u \in W</m>. The operations are given by
              </p>
        
              <p>
                <me>\frac{m}{v}+\frac{n}{w}=\frac{m w+n v}{v w} \quad \text { and } \quad \frac{r}{v} \frac{m}{w}=\frac{r m}{v w}</me>
              </p>
        
              <p>
                The zero in the module <m>W^{-1} M</m> is given by <m>\frac{0}{1}</m>.
              </p>
            </statement>
          </definition>
    
          <p>
            Here are the most important examples of localizations you will come across in commutative algebra.
          </p>

          <example>
            <p>
              Example 3.52 (Most important localizations). Let <m>R</m> be a commutative ring.
            </p>
      
            <p><ol>
              <li>
                    <p>
              For <m>f \in R</m> and <m>W=\left\{1, f, f^{2}, f^{3}, \ldots\right\}=\left\{f^{n} \mid n \geqslant 0\right\}</m>, we usually write <m>R_{f}</m> for <m>W^{-1} R</m>.
            </p>
              </li>
      
              <li>
                    <p>
              When <m>W</m> is the set of nonzerodivisors on <m>R</m>, we call <m>W^{-1} R</m> the total ring of fractions of <m>R</m>. When <m>R</m> is a domain, this is just the fraction field of <m>R</m>, and in this case this coincides with the localization at the prime <m>(0)</m>, as described below.
            </p>
              </li>
      
              <li>
                    <p>
              For a prime ideal <m>P</m> in <m>R</m>, we generally write <m>R_{P}</m> for <m>(R \backslash P)^{-1} R</m>, and call it the localization of <m>R</m> at <m>P</m>. Given an ideal <m>I</m> in <m>R</m>, we sometimes write <m>I_{P}</m> to refer to <m>I R_{P}</m>, the image of <m>I</m> via the canonical map <m>R \rightarrow R_{P}</m>. Notice that when we localize at a prime <m>P</m>, the resulting ring is a local ring <m>\left(R_{P}, P_{P}\right)</m>. We can think of the process of localization at <m>P</m> as zooming in at the prime <m>P</m>. Many properties of an ideal <m>I</m> can be checked locally, by checking them for <m>I R_{P}</m> for each prime <m>P \in V(I)</m>.
            </p>
              </li>
      
            </ol></p>
          </example>

          <remark>
            <p>
              Remark 3.53. If <m>R</m> is a domain, the equivalence relation defining the localization simplifies to <m>r w^{\prime}=r^{\prime} w</m>. In particular, <m>\operatorname{Frac}(R)=R_{(0)}=(R \backslash\{0\})^{-1} R</m> is a localization of <m>R</m>.
            </p>
          </remark>
    
          <p>
            If <m>R</m> is not a domain, the canonical map <m>R \rightarrow W^{-1} R</m> is not necessarily injective.
          </p>

          <example>
            <p>
              Example 3.54. Consider <m>R=k[x, y] /(x y)</m>. The canonical maps <m>R \longrightarrow R_{(x)}</m> and <m>R \longrightarrow R_{y}</m> are not injective, since in both cases <m>y</m> is invertible in the localization, and thus
            </p>
      
            <p>
              <me>x \mapsto \frac{x}{1}=\frac{x y}{y}=\frac{0}{y}=\frac{0}{1}</me>
            </p>
          </example>
    
          <p>
            In <m>W^{-1} R</m>, every element of <m>W</m> becomes a unit. The following universal property says roughly that <m>W^{-1} R</m> is the smallest <m>R</m>-algebra in which every element of <m>W</m> is a unit.
          </p>

          <theorem xml:id="thm-3.55">
            <statement>
              <p>
                Theorem 3.55. 
                Let <m>R</m> be a commutative ring, and <m>W</m> a multiplicative set with <m>0 \notin W</m>. Let <m>S</m> be an <m>R</m>-algebra in which every element of <m>W</m> is a unit. Then there is a unique homomorphism <m>\alpha</m> such that the following diagram commutes:
              </p>
        
              <image source="2023_10_23_e2d6a27704be928b3deeg-101.jpg"/>
        
              <p>
                where the vertical map is the structure homomorphism and the horizontal map is the canonical homomorphism.
              </p>
            </statement>

            <proof>
              <p>
                Proof. Given an <m>R</m>-algebra <m>S</m> such that every element of <m>W</m> is a unit, where the algebra structure is induced by the ring homomorphism <m>f: R \rightarrow S</m>, consider the map
              </p>
        
              <p>
                <me>
                  \begin{aligned}
                  &amp; W^{-1} R \longrightarrow S \\
                  &amp; \quad \frac{r}{w} \longmapsto f(w)^{-1} f(r) .
                  \end{aligned}
                </me>
              </p>
        
              <p>
                First, note that our assumption that every element of <m>W</m> is invertible in <m>S</m> means that <m>f(w)</m> is invertible in <m>S</m>, and thus <m>f(w)^{-1} f(r)</m> makes sense. Moreover, we claim that <m>\alpha</m> is a ring homomorphism:
              </p>
        
              <p>
                <me>\alpha(1)=f(1)^{-1} f(1)=1</me>
              </p>
        
              <p>
                and moreover
              </p>
        
              <p>
                <me>
                  \begin{aligned}
                  \alpha\left(\frac{a}{u} \frac{b}{v}\right) \alpha &amp; \left(\frac{a b}{u v}\right) \\
                  &amp; =f(u v)^{-1} f(a b) \\
                  &amp; =\left(f(u)^{-1} f(a)\right)\left(f(v)^{-1} f(b)\right) \\
                  &amp; =\alpha\left(\frac{a}{u}\right)\left(\frac{b}{v}\right)
                  \end{aligned}
                </me>
              </p>
        
              <p>
                and
              </p>
        
              <p>
                <me>
                  \begin{aligned}
                  \alpha\left(\frac{a}{u}+\frac{b}{v}\right) &amp; \alpha\left(\frac{a v+b u}{u v}\right) \\
                  &amp; =f(u v)^{-1} f(a v+b u) \\
                  &amp; =\left(f(u)^{-1} f(v)^{-1}\right)(f(a) f(v)+f(b) f(u)) \\
                  &amp; =\left(f(u)^{-1} f(a)+\left(f(v)^{-1} f(b)\right.\right. \\
                  &amp; =\alpha\left(\frac{a}{u}\right)+\left(\frac{b}{v}\right)
                  \end{aligned}
                </me>
              </p>
        
              <p>
                Our definition of <m>\alpha</m> gives us
              </p>
        
              <p>
                <me>\alpha\left(\frac{r}{1}\right)=f(1)^{-1} f(r)=f(r)</me>
              </p>
        
              <p>
                as desired. Moreover, if <m>\beta: W^{-1} R \rightarrow S</m> is any ring homomorphism such that
              </p>
        
              <p>
                <me>\beta\left(\frac{r}{1}\right)=f(1)^{-1} f(r)=f(r)</me>
              </p>
        
              <p>
                then
              </p>
        
              <p>
                <me>\beta\left(\frac{r}{s}\right)=\beta\left(\frac{s}{1}\right)^{-1} \beta\left(\frac{r}{1}\right)=f(s)^{-1} f(r)=\alpha\left(\frac{s}{1}\right)^{-1} \alpha\left(\frac{r}{1}\right)=\alpha\left(\frac{r}{s}\right)</me>
              </p>
        
              <p>
                This proves our uniqueness claim.
              </p>
            </proof>
          </theorem>

          <definition xml:id="def-3.56">
            <statement>
              <p>
                Definition 3.56. Let <m>R</m> be a commutative ring and let <m>W</m> be a multiplicative subset of <m>R</m>. The localization at <m>W</m> is the functor <m>R</m>-Mod <m>\rightarrow W^{-1} R</m>-mod that sends each <m>R</m>-module <m>M</m> to the <m>W^{-1} R</m>-module <m>W^{-1} M</m>, and that sends each <m>R</m>-module homomorphism <m>f: M \rightarrow N</m> to the homomorphism of <m>W^{-1} R</m>-modules given by
              </p>
        
              <p>
                <me>
                  \begin{gathered}
                  W^{-1} M \longrightarrow W^{-1} N \\
                  \frac{m}{w} \longmapsto \frac{f(m)}{w}
                  \end{gathered}
                </me>
              </p>
        
              <p>
                We might denote this functor by <m>W^{-1}(-)</m> or <m>(-)_{W}</m>. When <m>W</m> is the complement of a prime ideal <m>P</m>, we write the localization at <m>P</m> as <m>(-)_{P}</m>.
              </p>
            </statement>
          </definition>

          <exercise>
            <p>
              Exercise 52. Show that for all <m>R</m>-module homomorphisms <m>f: M \rightarrow N</m>,
            </p>
      
    
            <image source="2023_10_23_e2d6a27704be928b3deeg-102.jpg"/>
              
      
            <p>
              is a homomorphism of modules over <m>W^{-1} R</m>.
            </p>
          </exercise>

          <exercise>
            <p>
              Exercise 53. Show that localization is an exact additive functor.
            </p>
          </exercise>

          <theorem xml:id="thm-3.57">
            <statement>
              <p>
                Theorem 3.57. Let <m>R</m> be a commutative ring, and <m>W \ni 1</m> a multiplicative subset of <m>R</m>. Then the localization at <m>W</m> and <m>W^{-1} R \otimes-</m> are naturally isomorphic functors. In particular, for every <m>R</m>-module <m>M</m>, there is an isomorphism of <m>W^{-1} R</m>-modules
              </p>
        
              <p>
                <me>W^{-1} R \otimes_{R} M \cong W^{-1} M</me>
              </p>
        
              <p>
                and given an <m>R</m>-module map <m>\alpha: M \rightarrow N</m>, the map of <m>W^{-1} R</m>-modules <m>W^{-1} R \otimes \alpha</m> corresponds to <m>W^{-1} \alpha=\alpha_{W}</m> under these isomorphisms.
              </p>
            </statement>

            <proof>
              <p>
                Proof. The bilinear map <m>\quad W^{-1} R \times M \longrightarrow W^{-1} M</m>
              </p>
        
              <p>
                <me>\left(\frac{r}{w}, m\right) \longmapsto \frac{r m}{w}</me>
              </p>
        
              <p>
                induces a homomorphism <m>\psi: W^{-1} R \times M \rightarrow W^{-1} M</m> that is surjective.
              </p>
        
              <p>
                For an inverse map, set <m>\phi\left(\frac{m}{w}\right):=\frac{1}{w} \otimes m</m>. To see this is well-defined, suppose <m>\frac{m}{w}=\frac{m^{\prime}}{w^{\prime}}</m>, so there exists some <m>v \in W</m> such that <m>v\left(m w^{\prime}-m^{\prime} w\right)=0</m>. Then,
              </p>
        
              <p>
                <me>\phi\left(\frac{m}{w}\right)-\phi\left(\frac{m^{\prime}}{w^{\prime}}\right)=\frac{1}{w} \otimes m-\frac{1}{w^{\prime}} \otimes m^{\prime}</me>
              </p>
        
              <p>
                We can multiply through by <m>\frac{v w w^{\prime}}{v w w^{\prime}}</m> to get
              </p>
        
              <p>
                <me>\frac{v w^{\prime}}{v w w^{\prime}} \otimes m-\frac{v w}{v w w^{\prime}} \otimes m^{\prime}=\frac{1}{v w w^{\prime}} \otimes v\left(m w^{\prime}-m^{\prime} w\right)=0</me>
              </p>
        
              <p>
                To see this is a homomorphism, we note that
              </p>
        
              <p>
                <me>
                  \begin{aligned}
                  \phi\left(\frac{m}{w}+\frac{m^{\prime}}{w^{\prime}}\right) &amp; =\phi\left(\frac{m w^{\prime}+m^{\prime} w}{w w^{\prime}}\right)=\frac{1}{w w^{\prime}} \otimes\left(m w^{\prime}+m^{\prime} w\right)=\frac{1}{w w^{\prime}} \otimes m w^{\prime}+\frac{1}{w w^{\prime}} \otimes m^{\prime} w \\
                  &amp; =\frac{w^{\prime}}{w w^{\prime}} \otimes m+\frac{w}{w w^{\prime}} \otimes m^{\prime}=\frac{1}{w} \otimes m+\frac{1}{w^{\prime}} \otimes m^{\prime}=\phi\left(\frac{m}{w}\right)+\phi\left(\frac{m^{\prime}}{w^{\prime}}\right)
                  \end{aligned}
                </me>
              </p>
        
              <p>
                and
              </p>
        
              <p>
                <me>\phi\left(r \frac{m}{w}\right)=\frac{1}{w} \otimes r m=r\left(\frac{1}{w} \otimes m\right)=r \phi\left(\frac{m}{w}\right)</me>
              </p>
        
              <p>
                The composition <m>\phi \circ \psi</m> sends
              </p>
        
              <p>
                <me>\frac{r}{w} \otimes m \mapsto \frac{r m}{w} \mapsto \frac{1}{w} \otimes r m=\frac{r}{w} \otimes m</me>
              </p>
        
              <p>
                Since this is the identity on simple tensors, and simple tensors generated the tensor product, it must be the identity.
              </p>
        
              <p>
                For the claim about maps, we need check that <m>\psi_{N} \circ\left(W^{-1} R \otimes \alpha\right)=W^{-1} \alpha \circ \psi_{M}</m> for every <m>R</m>-module homomorphism <m>\alpha !: M \rightarrow N</m>. And indeed,
              </p>
        
              <p>
                <me>
                  \begin{aligned}
                  \left(\psi_{N} \circ\left(W^{-1} R \otimes \alpha\right)\right)\left(\frac{r}{w} \otimes m\right) &amp; =\psi_{N}\left(\frac{r}{w} \otimes \alpha(m)\right)=\frac{r \alpha(m)}{w} \\
                  &amp; =\frac{\alpha(r m)}{w}=W^{-1} \alpha\left(\frac{r m}{w}\right)=\left(W^{-1} \alpha \circ \psi_{M}\right)\left(\frac{r}{w} \otimes m\right)
                  \end{aligned}
                </me>
              </p>
        
              <p>
                Finally, we note that our isomorphisms <m>W^{-1} R \otimes_{R} M \cong W^{-1} M</m> give a natural isomorphism between the localization functor <m>W^{-1}(-)</m> and the tensor functor <m>W^{-1} R \otimes_{R}-</m>. Indeed, given a map of <m>R</m>-modules <m>M \stackrel{f}{\rightarrow} N</m>, the diagram
              </p>
        
              <image source="2023_10_23_e2d6a27704be928b3deeg-104(1).jpg"/>
                
              <p>
                commutes, since it commutes for simple tensors:
              </p>
      
              <image source="2023_10_23_e2d6a27704be928b3deeg-104.jpg"/>
        
              <p>
                Now since localization is exact, we conclude that <m>W^{-1} R \otimes_{R}-</m> is an exact functor for all commutative rings <m>R</m> and all multiplicatively closed subsets <m>W</m>.
              </p>
            </proof>
          </theorem>

          <exercise>
            <p>
              Exercise 54. Let <m>R</m> be a commutative noetherian ring, <m>W</m> be a multiplicative set, <m>M</m> be a finitely generated <m>R</m>-module, and <m>N</m> an arbitrary <m>R</m>-module. Show that
            </p>
      
            <p>
              <me>\operatorname{Hom}_{W^{-1} R}\left(W^{-1} M, W^{-1} N\right) \cong W^{-1} \operatorname{Hom}_{R}(M, N) .</me>
            </p>
      
            <p>
              In particular, if <m>P</m> is prime,
            </p>
      
            <p>
              <me>\operatorname{Hom}_{R_{P}}\left(M_{P}, N_{P}\right) \cong \operatorname{Hom}_{R}(M, N)_{P}</me>
            </p>
          </exercise>
    
          <p>
            Localization is a very powerful tool in commutative algebra. Many important concepts localize well, in the sense that to prove that <m>R</m> or a module satisfy a certain property, it is often sufficient to show that all localizations of <m>R</m> or of that module also have that property. This is a very common and helpful technique in commutative algebra. For example, a module <m>M</m> is zero if and only if all its localizations are zero; one can even reduce to showing all localizations of <m>M</m> at a prime ideal are zero.
          </p>
    
          <p>
            One important thing to keep in mind, however, is that if <m>M</m> is a finitely generated <m>R</m> module, a localization <m>M_{W}</m> of <m>M</m> is typically not finitely generated over <m>R</m>, though it is finitely generated over <m>R_{W}</m>.
          </p>

          <exercise>
            <p>
              Exercise 55. Let <m>R</m> be a domain and let <m>f \in R</m> be a nonzero nonunit. Then <m>R_{f}</m> is not a finitely generated <m>R</m>-module.
            </p>
          </exercise>
    
          <p>
            To solve this exercise, however, one needs a little bit of commutative algebra that we are not covering in this course.
          </p>

        </section>

        <section xml:id="sec-hom-tensor"><title>Hom-Tensor Adjunction</title>

          <p>
            The Hom and tensor functors are closely related. 
            First, we note that <m>\operatorname{Hom}_{R}(A, B)</m> can be a module over a ring <m>S</m> when <m>A</m> or <m>B</m> have a bimodule structure.
          </p>

          <exercise>
            <p>
              Exercise 56. 
              Let <m>R</m> and <m>S</m> be rings.<ul>
              <li>
                <p>
                  If <m>A</m> is an <m>(R, S)</m>-bimodule and <m>B</m> is a left <m>R</m>-module, then <m>\operatorname{Hom}_{R}(A, B)</m> has a left <m>S</m>-module structure via <m>(s \cdot f)(a)=f(a s)</m>.
                </p>
              </li>
      
              <li>
                <p>
                  If <m>A</m> is an <m>(R, S)</m>-bimodule and <m>B</m> is a right <m>S</m>-module, then <m>\operatorname{Hom}_{R}(A, B)</m> has a right <m>R</m>-module structure via <m>(f \cdot r)(a)=f(r a)</m>.
                </p>
              </li>
      
              <li>
                <p>
                  If <m>B</m> is an <m>(S, R)</m>-bimodule and <m>A</m> is a right <m>R</m>-module, then <m>\operatorname{Hom}_{R}(A, B)</m> has a left <m>S</m>-module structure via <m>(s \cdot f)(a)=s f(a)</m>.
                </p>
              </li>
      
              <li>
                <p>
                  If <m>B</m> is an <m>(S, R)</m>-bimodule and <m>A</m> is a left <m>S</m>-module, then <m>\operatorname{Hom}_{R}(A, B)</m> has a right <m>R</m>-module structure via <m>(f \cdot r)(a)=f(a) r</m>.
                </p>
              </li>
            </ul>
          </p>
          </exercise>
    
          <p>
            These structures can be a bit confusing at first - especially since we have left module structures written on the right and vice-versa. 
            While the exercise is not difficult, it can be extremely enlightening - we strongly recommend the reader tries their hand at the details.
          </p>
    
          <p>
            The following statements are known as Hom-tensor adjunction - and as we will see, they do encode an adjunction of functors.
          </p>

          <theorem xml:id="thm-3.58">
            <statement>
              <p>
                Let <m>R</m> and <m>S</m> be rings. 
                Assume that
              </p>
        
              <p><ul>
                <li>
                      <p>
                <m>A</m> is a right <m>R</m>-module,
              </p>
                </li>
        
                <li>
                      <p>
                <m>B</m> is an <m>(R, S)</m>-bimodule, and
              </p>
                </li>
        
                <li>
                      <p>
                <m>C</m> is a right <m>S</m>-module.
              </p>
                </li>
        
              </ul></p>
        
              <p>
                There is a natural isomorphism of abelian groups
              </p>
        
              <p>
                <me>\operatorname{Hom}_{S}\left(A \otimes_{R} B, C\right) \cong \operatorname{Hom}_{R}\left(A, \operatorname{Hom}_{S}(B, C)\right)</me>
              </p>
        
              <p>
                If <m>A</m> also has a <m>(T, R)</m>-bimodule structure, or <m>C</m> has a <m>(T, S)</m>-bimodule structure, then this is an isomorphism of (left or right, respectively) <m>T</m>-modules.
              </p>
            </statement>
          </theorem>

          <theorem xml:id="thm-3.59">
            <statement>
              <p>
                Theorem 3.59. Let <m>R</m> and <m>S</m> be rings. Assume that
              </p>
        
              <p><ul>
                <li>
                      <p>
                <m>A</m> is a left <m>R</m>-module,
              </p>
                </li>
        
                <li>
                      <p>
                <m>B</m> is an <m>(S, R)</m>-bimodule, and
              </p>
                </li>
        
                <li>
                      <p>
                <m>C</m> is a left <m>S</m>-module.
              </p>
                </li>
        
              </ul></p>
        
              <p>
                There is a natural isomorphism of abelian groups
              </p>
        
              <p>
                <me>\operatorname{Hom}_{S}\left(B \otimes_{R} A, C\right) \cong \operatorname{Hom}_{R}\left(A, \operatorname{Hom}_{S}(B, C)\right)</me>
              </p>
            </statement>
          </theorem>
    
          <p>
            We leave the details to the reader, and prove the case when the underlying rings are commutative. First, let's do the case when <m>R=S</m>.
          </p>

          <theorem xml:id="thm-3.60">
            <statement>
              <p>
                Theorem 3.60 (Hom-tensor adjunction I). Let <m>R</m> be a commutative ring and let <m>M, N</m>, and <m>P</m> be <m>R</m>-modules. There is an isomorphism of <m>R</m>-modules
              </p>
        
              <p>
                <me>\operatorname{Hom}_{R}\left(M \otimes_{R} N, P\right) \cong \operatorname{Hom}_{R}\left(M, \operatorname{Hom}_{R}(N, P)\right)</me>
              </p>
        
              <p>
                that is natural on <m>M, N</m>, and <m>P</m>.
              </p>
            </statement>

            <proof>
              <p>
                Proof. The universal property of the tensor product says that to give an <m>R</m>-module homomorphism <m>M \otimes_{R} N \longrightarrow P</m> is the same as giving an <m>R</m>-bilinear map <m>M \times N \longrightarrow P</m>. Given such a bilinear map <m>f</m>, the map <m>n \mapsto f(m \otimes n)</m> is <m>R</m>-linear for each <m>m \in M</m>, so it defines an <m>R</m>-module homomorphism <m>N \longrightarrow P</m>. Now the assignment
              </p>
        
              <p>
                <me>
                  \begin{aligned}
                  &amp; M \longrightarrow \operatorname{Hom}_{S}(N, P) \\
                  &amp; m \longrightarrow(n \mapsto f(m \otimes n))
                  \end{aligned}
                </me>
              </p>
        
              <p>
                is <m>R</m>-linear, <m>f</m> is an <m>R</m>-module homomorphism, and <m>m \mapsto m \otimes n</m> is <m>R</m>-linear on <m>m</m>.
              </p>
        
              <p>
                Conversely, given an <m>R</m>-module homomorphism <m>f \in \operatorname{Hom}_{R}\left(M, \operatorname{Hom}_{R}(N, P)\right)</m>, one can check (exercise!) that <m>(m, n) \mapsto f(m)(n)</m> is an <m>R</m>-bilinear map, so it induces an <m>R</m>-module homomorphism <m>M \otimes_{R} N \longrightarrow P</m>. Moreover, the two constructions are inverse to each other.
              </p>
        
              <p>
                So we have constructed a bijection of Hom-sets
              </p>
        
              <p>
                <me>
                  \begin{gathered}
                  \operatorname{Hom}_{R}\left(M \otimes_{R} N, P\right) \stackrel{\tau}{\longrightarrow} \operatorname{Hom}_{R}\left(M, \operatorname{Hom}_{R}(N, P)\right) . \\
                  f \longmapsto(m \mapsto(n \mapsto f(m \otimes n))) \\
                  (m \otimes n \mapsto g(m)(n)) \longleftrightarrow g
                  \end{gathered}
                </me>
              </p>
        
              <p>
                It's routine to check that both of these bijections are indeed homomorphisms of <m>R</m>-modules, so we leave it as an exercise.
              </p>
        
              <p>
                Finally, naturality means we have the following commutative diagrams:
              </p>
        
              <image source="2023_10_23_e2d6a27704be928b3deeg-106(1).jpg"/>
                
              <p>
                and
              </p>
      
              <image source="2023_10_23_e2d6a27704be928b3deeg-106.jpg"/>
                
              <p>
                We leave checking these do indeed commute as an exercise.
              </p>
            </proof>
          </theorem>

          <corollary xml:id="cor-3.61">
            <statement>
              <p>
                Corollary 3.61 (Tensor and Hom are adjoint functors). Let <m>R</m> be a commutative ring, and <m>M</m> an <m>R</m>-module. The functor <m>-\otimes_{R} M: R</m>-Mod <m>\longrightarrow R</m>-Mod is left adjoint to the functor <m>\operatorname{Hom}_{R}(M,-): R</m>-Mod <m>\longrightarrow R</m>-Mod.
              </p>
            </statement>

            <proof>
              <p>
                Proof. The adjointness translates into the fact that for all <m>R</m>-modules <m>N</m> and <m>P</m> there is a bijection
              </p>
        
              <p>
                <me>\operatorname{Hom}_{R}\left(N \otimes_{R} M, P\right) \cong \operatorname{Hom}_{R}\left(N, \operatorname{Hom}_{R}(M, P)\right)</me>
              </p>
        
              <p>
                which is natural on <m>N</m> and <m>P</m>, which is a corollary of Theorem 3.60.
              </p>
            </proof>
          </corollary>
    
          <p>
            Later, when we talk about more general abelian categories, we will see that this adjunction implies that Hom is left exact and that tensor is right exact; in fact, this is a more general fact about adjoint pairs. For now, we want to discuss a more general version of this Hom-tensor adjunction.
          </p>

          <theorem xml:id="thm-3.62">
            <statement>
              <p>
                Theorem 3.62 (Hom-tensor adjunction II). Let <m>f: R \rightarrow S</m> be a ring homomorphism of commutative rings. Let <m>M</m> be an <m>R</m>-module, and <m>P</m> and <m>N</m> be <m>S</m>-modules. There is an isomorphism of abelian groups
              </p>
        
              <p>
                <me>\operatorname{Hom}_{S}\left(M \otimes_{R} N, P\right) \cong \operatorname{Hom}_{R}\left(M, \operatorname{Hom}_{S}(N, P)\right) .</me>
              </p>
        
              <p>
                Moreover, this isomorphism is natural on <m>M, N</m>, and <m>P</m>, so it induces natural isomorphisms
              </p>
        
              <p><ul>
                <li>
                      <p>
                between <m>\operatorname{Hom}_{S}\left(-\otimes_{R} N, P\right)</m> and <m>\operatorname{Hom}_{R}\left(-, \operatorname{Hom}_{S}(N, P)\right)</m>.
              </p>
                </li>
        
                <li>
                      <p>
                between <m>\operatorname{Hom}_{S}\left(M \otimes_{R}-, P\right)</m> and <m>\operatorname{Hom}_{R}\left(M, \operatorname{Hom}_{S}(-, P)\right)</m>.
              </p>
                </li>
        
                <li>
                      <p>
                between <m>\operatorname{Hom}_{S}\left(M \otimes_{R} N,-\right)</m> and <m>\operatorname{Hom}_{R}\left(M, \operatorname{Hom}_{S}(N,-)\right)</m>.
              </p>
                </li>
        
              </ul></p>
            </statement>

            <proof>
              <p>
                Proof. Consider the map
              </p>
        
              <p>
                <me>
                  \begin{array}{r}
                  \operatorname{Hom}_{S}\left(M \otimes_{R} N, P\right) \stackrel{\tau}{\longrightarrow} \operatorname{Hom}_{R}\left(M, \operatorname{Hom}_{S}(N, P)\right) \\
                  f \longmapsto m \mapsto(n \mapsto f(m \otimes n))
                  \end{array}
                </me>
              </p>
        
              <p>
                Fix <m>f</m>. For each <m>m \in M</m>, let <m>\tau_{m}</m> be the map <m>N \longrightarrow P</m> defined by <m>\tau_{m}(n):=f(m \otimes n)</m>. Note that <m>\tau_{m}</m> is indeed a homomorphism of <m>S</m>-modules, since it is the composition of two <m>S</m>-module maps, <m>f</m> and <m>m \otimes_{R} \operatorname{id}_{N}</m>, where <m>m</m> is the constant map <m>M \longrightarrow M</m> equal to <m>m</m>.
              </p>
        
              <p>
                We should check that our proposed map <m>\tau</m> is indeed a map of abelian groups. It is immediate from the definition that <m>\tau</m> sends the 0-map to the 0-map. Moreover, given <m>S</m> module homomorphisms <m>f, g: M \otimes N \longrightarrow P</m>, and any <m>n \in N</m>, we have
              </p>
        
              <p>
                <me>
                  \begin{array}{rlr}
                  \tau_{m}(f+g)(n) &amp; =(f+g)(m \otimes n) &amp; \text { by definition } \\
                  &amp; =f(m \otimes n)+g(m \otimes n) &amp; \text { since } f \text { and } g \text { are } S \text {-module maps } \\
                  &amp; =\tau_{m}(f)(n)+\tau_{m}(g)(n) &amp; \text { by definition }
                  \end{array}
                </me>
              </p>
        
              <p>
                so <m>\tau_{m}(f+g)=\tau_{m}(f)+\tau_{m}(g)</m> for all <m>m \in M</m>, and thus <m>\tau(f+g)=\tau(f)+\tau(g)</m>.
              </p>
        
              <p>
                Suppose that <m>\tau(f)=0</m>. Then for every <m>m \in M</m> and every <m>n \in N</m>,
              </p>
        
              <p>
                <me>0=\tau(f)(m)(n)=\tau_{m}(f)(n)=f(m \otimes n)</me>
              </p>
        
              <p>
                so <m>f</m> vanishes at every simple tensor, and we must have <m>f=0</m>. On the other hand, if we are given <m>g \in \operatorname{Hom}_{R}\left(M, \operatorname{Hom}_{S}(N, P)\right)</m>, consider the map <m>M \times N \longrightarrow P</m> defined by <m>\tilde{f}(m, n)=g(m)(n)</m>. Since <m>g</m> is a homomorphism of <m>R</m>-modules, it is <m>R</m>-linear on <m>m</m>. Moreover, for each fixed <m>m, g(m)</m> is a homomorphism of <m>S</m>-modules, so in particular <m>g(m)</m> is <m>R</m>-linear. Together, these say that <m>\tilde{f}</m> is an <m>R</m>-bilinear map. Let <m>f</m> be the homomorphism of <m>R</m>-modules <m>M \otimes_{R} N \longrightarrow P</m> induced by <m>\tilde{f}</m>. By definition, <m>f(m \otimes n)=\tilde{f}(m, n)=g(m)(n)</m>, so <m>\tau(f)=g</m>. We conclude that <m>\tau</m> is a bijection.
              </p>
        
              <p>
                We leave the statements about naturality as exercises.
              </p>
            </proof>
          </theorem>

          <corollary xml:id="cor-3.63">
            <statement>
              <p>
                Corollary 3.63 (Adjointness of restriction and extension of scalars). Let <m>f R \longrightarrow S</m> be <m>a</m> ring homomorphism. The restriction of scalars functor <m>f^{*}: S</m>-Mod <m>\longrightarrow R</m>-Mod is the right adjoint of the extension of scalars functor <m>f_{*}: R</m>-Mod <m>\longrightarrow S</m>-Mod.
              </p>
            </statement>

            <proof>
              <p>
                Proof. We need to show that for every <m>R</m>-module <m>M</m> and every <m>S</m>-module <m>N</m> there are bijections
              </p>
        
              <p>
                <me>\operatorname{Hom}_{S}\left(f_{*}(M), N\right) \cong \operatorname{Hom}_{R}\left(M, f^{*}(N)\right)</me>
              </p>
        
              <p>
                which are natural on both <m>M</m> and <m>N</m>. By Theorem 3.62, we have natural bijections
              </p>
        
              <p>
                <me>\operatorname{Hom}_{S}\left(M \otimes_{R} S, N\right) \cong \operatorname{Hom}_{R}\left(M, \operatorname{Hom}_{S}(S, N)\right)</me>
              </p>
        
              <p>
                The module <m>M \otimes_{R} S</m> is precisely <m>f_{*}(M)</m>. By Exercise <m>38, \operatorname{Hom}_{S}(S, N) \cong N</m> as an <m>S</m>-module. An isomorphism of <m>S</m>-modules <m>\operatorname{Hom}_{S}(S, N) \longrightarrow N</m> is in particular an <m>R</m>-linear map, and thus also an isomorphism of <m>R</m>-modules. So <m>\operatorname{Hom}_{S}(S, N) \cong f^{*}(N)</m> as <m>R</m>-modules. Therefore, the Hom-tensor adjuntion gives us the natural bijections we were looking for.
              </p>
            </proof>
          </corollary>
    
          <p>
            The idea is that restriction of scalars and extension of scalars are the most efficient ways of making an <m>R</m>-module out of an <m>S</m>-module, and vice-versa.
          </p>
          
        </section>
        
      </chapter>

      <chapter xml:id="ch-proj-inj"><title>Projectives and Injectives</title>

        <section xml:id="sec-projective"><title>Projective Modules</title>

          <objectives>
            <ul>
              <li>
                
              </li>
            </ul>
          </objectives>

          <subsection xml:id="subsec-free-projective"><title>Definition, Free Modules are Projective</title>

            <blockquote>
              <p>
                <q>
                  I don't have time to worry about what I'm projecting to the world. I'm just busy being myself.
                </q>
              </p>
              <attribution>Demi Lovato</attribution>
            </blockquote>

            <p>
              While Hom and tensor are not exact functors in general, <m>\operatorname{Hom}_{R}(M,-), \operatorname{Hom}_{R}(-, M)</m>, and <m>M \otimes_{R}-</m> can be exact functors for carefully chosen modules <m>M</m>. 
              In this chapter, we introduce these three classes of modules (projective, injective, and flat modules) and study their properties. 
              Throughout, we consider general rings and left modules.
            </p>
  
            <definition xml:id="def-4.1"><title>Projective Module</title>
              <statement>
                <p>
                  Let <m>R</m> be a ring. 
                  An <m>R</m>-module <m>P</m> is <em>projective</em> if given any surjective <m>R</m>-module homomorphism <m>s: A \rightarrow B</m> and any <m>R</m>-module homomorphism <m>f: P \rightarrow B</m>, there exists an <m>R</m>-module homomorphism <m>g</m> such that the diagram
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-109(1).jpg" width="30%"/>
                <p>
                  commutes.
                  <idx><h>projective module</h></idx>
                </p>
              </statement>
            </definition>
  
            <remark xml:id="rem-4.2">
              <p>
                The commutativity of the diagram
              </p>
              <image source="2023_10_23_e2d6a27704be928b3deeg-109.jpg" width="30%"/>
              <p>
                says that <m>s_{*}(g)=f</m>, where <m>s_{*}</m> is the <m>\operatorname{map} \operatorname{Hom}_{R}(P, A) \longrightarrow \operatorname{Hom}_{R}(P, B)</m> induced by <m>s</m>. 
                Whenever this happens, we say that <m>g</m> is a lifting of <m>f</m>, and that <m>f</m> lifts, or that <m>f</m> factors through <m>A</m>.
                <idx><h>lift</h></idx>
              </p>
            </remark>
  
            <p>
              There are projective modules over any ring, as the next result shows; in fact, free modules are always projective.
            </p>
  
            <theorem xml:id="thm-4.3"><title>Free Modules are Projective</title>
              <statement>
                <p>
                  Free modules are projective.
                </p>
              </statement>
  
              <proof>
                <p>
                  Let <m>F</m> be a free <m>R</m>-module. 
                  Suppose we are given <m>R</m>-module homomorphisms <m>s: A \rightarrow C</m> and <m>f: F \rightarrow C</m> such that <m>s</m> is surjective. 
                  Fix a basis <m>B=\left\{b_{i}\right\}_{i}</m> for <m>F</m>. 
                  Since <m>s</m> is surjective, for each <m>i</m> we can choose <m>a_{i} \in A</m> such that <m>s\left(a_{i}\right)=f\left(b_{i}\right)</m>. 
                  Consider the function <m>u: B \longrightarrow A</m> given by <m>u\left(b_{i}\right)=a_{i}</m>. 
                  The universal property of free modules says that there exists an <m>R</m>-module homomorphism <m>g: F \longrightarrow A</m> that coincides with <m>u</m> for all basis elements. 
                  Now
                  <me>
                    s g\left(b_{i}\right)=s u\left(b_{i}\right)=s\left(a_{i}\right)=f\left(b_{i}\right)
                  </me>
                  so <m>s g</m> agrees with <m>f</m> for all basis elements. 
                  Since <m>B</m> generates <m>F</m>, we conclude that <m>s g=f</m>.
                </p>
              </proof>
            </theorem>
  
            <p>
              Projective modules are precisely those that make the covariant <m>\Hom</m> functor exact.
            </p>
  
            <theorem xml:id="thm-4.4">
              <statement>
                <p>
                  Let <m>P</m> be an <m>R</m>-module. 
                  The functor <m>\operatorname{Hom}_{R}(P,-)</m> is exact if and only if <m>P</m> is projective.
                </p>
              </statement>
  
              <proof>
                <p>
                  By <xref ref="thm-3.14"/> <m>\operatorname{Hom}_{R}(P,-)</m> is left exact. 
                  The statement is that <m>P</m> is projective if and only for any short exact sequence
                  <me>0 \longrightarrow A \stackrel{i}{\longrightarrow} B \stackrel{p}{\longrightarrow} C \longrightarrow 0</me>
                  the induced map <m>s_{*}: \operatorname{Hom}_{R}(P, B) \longrightarrow \operatorname{Hom}_{R}(P, C)</m> is surjective. Say we are given a surjective map
                  <me>B \stackrel{p}{\longrightarrow} C \longrightarrow 0</me>
                </p>
          
                <p>
                  The induced map <m>s_{*}</m> is surjective if and only if for every <m>f \in \operatorname{Hom}_{R}(P, C)</m> there exists a lifting <m>g \in \operatorname{Hom}_{R}(P, B)</m> of <m>f</m>, meaning <m>s_{*}(g)=f</m>. 
                  By <xref ref="rem-4.2"/>, the existence of such a <m>g</m> for all such surjective maps <m>s</m> is precisely the condition that <m>P</m> is projective.
                </p>
              </proof>
            </theorem>

            <aside>
              <p>
                This is really the definition of what a projective module is, but for those that have not seen category theory, the definition given is used.
              </p>
            </aside>
  
            <corollary xml:id="cor-4.5">
              <statement>
                <p>
                  For any ring <m>R, \operatorname{Hom}_{R}(R,-)</m> is exact. 
                  More generally, if <m>F</m> is any free <m>R</m>-module, then <m>\operatorname{Hom}_{R}(F,-)</m> is exact.
                </p>
              </statement>
  
              <proof>
                <p>
                  By <xref ref="thm-4.3"/>, free modules, and <m>R</m> in particular, are projective. 
                  By <xref ref="thm-4.4"/>, <m>\operatorname{Hom}_{R}(F,-)</m> must be exact for any free <m>R</m>-module <m>F</m>.
                </p>
              </proof>
            </corollary>
  
            <p>
              However, not every projective module is free. 
              But before we see such examples, we need to know a bit more about projective modules.
            </p>
            
          </subsection>

          <subsection xml:id="subsec-direct-summands"><title>Direct Summands</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>
    
            <p>
              First, we show that we can rephrase the condition that a module is projective or injective in terms of split exact sequences.
            </p>

            <theorem xml:id="thm-4.6"><title>Projective Modules and Splitting </title>
              <statement>
                <p>
                  An <m>R</m>-module <m>P</m> is projective if and only if every short exact sequence
                  <me>0 \longrightarrow A \longrightarrow B \longrightarrow P \longrightarrow 0</me>
                  splits.
                </p>
              </statement>

              <proof>
                <p>
                  <m>(\Rightarrow)</m> 
                  Consider a short exact sequence
                  <me>0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} P \longrightarrow 0 .</me>
                </p>
          
                <p>
                  If <m>P</m> is projective, the identity map on <m>P</m> lifts to a map <m>P \longrightarrow B</m>, meaning that
                </p>

                <image source="2023_10_23_e2d6a27704be928b3deeg-111(2).jpg" width="30%"/>
                  
                <p>
                  commutes. 
                  This says that our map <m>h</m>
                  <me>0 \longrightarrow A \stackrel{f}{\longrightarrow} B \underset{\nwarrow}{\stackrel{g}{\longrightarrow}} P \longrightarrow 0</me>
                  is a splitting for our short exact sequence, which must then be split, by Lemma 2.19.
                </p>
          
                <p>
                  <m>(\Leftarrow)</m> Conversely, suppose that every short exact sequence
                  <me>0 \longrightarrow A \longrightarrow B \longrightarrow P \longrightarrow 0</me>
                  splits, and consider any diagram
                </p>
          
                <image source="2023_10_23_e2d6a27704be928b3deeg-111.jpg" width="30%"/>
          
                <p>
                  Let <m>F</m> be a free module that surjects onto <m>P</m> - for example, the free module on a set of generators of <m>P</m> - and fix a surjection <m>\pi: F \rightarrow P</m>. 
                  By assumption, the short exact sequence
                  <me>0 \longrightarrow \operatorname{ker} \pi \longrightarrow \underset{\kappa_{h}^{-}}{\stackrel{\pi}{\longrightarrow}} P \longrightarrow 0</me>
                  splits, so by <xref ref="lem-2.19"/> there exists <m>h</m> such that <m>\pi h=\operatorname{id}_{P}</m>. 
                  Now since <m>F</m> is free, we can define an <m>R</m>-module map <m>\hat{g}: F \longrightarrow B</m> that such that
                </p>
          
                <image source="2023_10_23_e2d6a27704be928b3deeg-111(1).jpg" width="30%"/>
                  
                <p>
                  commutes, by sending each basis element <m>b \in F</m> to any lift of <m>f \pi(b)</m> in <m>B</m> via <m>s</m>.
                  Now set <m>g:=\hat{g} h</m>, and note that
                  <me>
                    \begin{array}{rrr}
                    s g &amp; =s \hat{g} h &amp; \text { by definition } \\
                    &amp; =f \pi h &amp; \text { by commutativity } \\
                    &amp; =f &amp; \text { since } \pi h=\mathrm{id}_{P},
                    \end{array}
                  </me>
                  so <m>g</m> is a lift of <m>s</m> by <m>f</m>.
                </p>
              </proof>
            </theorem>
      
            <p>
              We have seen that free modules are projective; what other modules are projective?
            </p>

            <definition xml:id="def-4.7"><title>Direct Summand</title>
              <statement>
                <p>
                  An <m>R</m>-module <m>M</m> is a <em>direct summand</em> of an <m>R</m>-module <m>N</m> if there exists an <m>R</m>-module <m>A</m> such that <m>A \oplus M \cong N</m>.
                  <idx><h>direct summand</h></idx>
                </p>
              </statement>
            </definition>

            <remark>
              <p>
                Remark 4.8. 
                Saying that <m>M</m> is a direct summand of <m>N</m> is equivalent to giving a splitting <m>\pi</m> of the inclusion map <m>i: M \hookrightarrow N</m>, meaning that <m>\pi i=\mathrm{id}_{N}</m>. 
                As we have argued in <xref ref="lem-2.19"/>, such a splitting <m>\pi</m> gives
                <me>N=\operatorname{im} i \oplus \operatorname{ker} \pi</me>
              </p>
        
              <p>
                Essentially repeating the argument we used in <xref ref="lem-2.19"/>, every element in <m>N</m> can be written as
                <me>n=(n-i \pi(n))+i \pi(n)</me>
                where <m>i \pi(n) \in \operatorname{im} i</m> and <m>n-i \pi(n) \in \operatorname{ker} \pi</m>, and <m>\operatorname{ker} \pi \cap \operatorname{im} i=0</m> because if <m>i(a) \in \operatorname{ker} \pi</m> then <m>a=\pi i(a)=0</m>.
              </p>
        
              <p>
                Note that when we are dealing with graded modules over a graded ring, the kernels and images of graded maps are graded modules, and the equality <m>N=\operatorname{im} i \oplus \operatorname{ker} \pi</m> is a graded direct sum of graded modules.
              </p>
            </remark>

            <theorem xml:id="thm-4.9"><title>Projective iff Direct Summand of Free Module</title>
              <statement>
                <p>
                  An <m>R</m>-module is projective <m>P</m> if and only if <m>P</m> is a direct summand of a free <m>R</m>-module. 
                  In particular, a finitely generated <m>R</m>-module <m>P</m> is projective if and only if <m>P</m> is a direct summand of <m>R^{n}</m> for some <m>n</m>.
                </p>
              </statement>

              <proof>
                <p>
                  <m>(\Rightarrow)</m> 
                  Let <m>P</m> be a projective module, and fix a free module <m>F</m> surjecting onto <m>P</m>. 
                  If <m>P</m> is finitely generated, we can take <m>F=R^{n}</m> for some <m>n</m>. 
                  The short exact sequence
                  <me>0 \longrightarrow \operatorname{ker} \pi \longrightarrow F \stackrel{\pi}{\longrightarrow} P \longrightarrow 0</me>
                  must split by <xref ref="thm-4.6"/>, so <m>P</m> is a direct summand of <m>F</m>.
                </p>
          
                <p>
                  <m>(\Leftarrow)</m> 
                  Now suppose <m>P</m> is a direct summand of a free module <m>F</m>. 
                  In particular, we have an inclusion map <m>i: P \longrightarrow F</m> that splits, so it comes together with a projection map <m>\pi: F \longrightarrow P</m> such that <m>\pi i=\operatorname{id}_{P}</m>. 
                  Given any diagram
                </p>
          
                <image source="2023_10_23_e2d6a27704be928b3deeg-112(1).jpg" width="30%"/>
                  
                <p>
                  we can define an <m>R</m>-module homomorphism <m>h</m> such that <m>s h=f \pi</m>, so that the following diagram commutes:
                </p>
          
                <image source="2023_10_23_e2d6a27704be928b3deeg-112.jpg" width="30%"/>
          
                <p>
                  Setting <m>g:=h i</m>, we do indeed obtain <m>s g=f</m>, since
                  <me>
                    \begin{array}{rlrl}
                    s g &amp; =s h i &amp; \text { by definition } \\
                    &amp; =f \pi i &amp; &amp; \text { because } s h=f \pi \\
                    &amp; =f &amp; &amp; \text { since } \pi i=\mathrm{id}_{P} \cdot \square
                    \end{array}
                  </me>
                </p>
              </proof>
            </theorem>

            <remark>
              <p>
                Remark 4.10. 
                While every module <m>M</m> is a quotient of a free module <m>F</m>, so that we always have a surjection <m>\pi: F \rightarrow M</m>, not every module embeds into a free module; 
                and even if <m>M</m> is a submodule of some free module <m>F</m>, the inclusion map <m>M \subseteq F</m> is not necessarily split. 
                On the other hand, as we showed in <xref ref="thm-4.9"/> that <m>M</m> is projective if and only if we can write it as a quotient of a free module <m>F</m>, say <m>\pi: F \rightarrow M</m>, and <m>\pi</m> splits, so that in fact <m>M</m> embeds into <m>F</m> and that map splits.
              </p>
            </remark>

            <corollary xml:id="cor-4.11">
              <statement>
                <p>
                  Let <m>R</m> be any ring.
                  <ol>
                    <li>
                      <p>
                        Every direct summand of a projective module is projective.
                      </p>
                    </li>
          
                    <li>
                      <p>
                        Every direct sum of projective modules is projective.
                      </p>
                    </li>
                  </ol>
                </p>
              </statement>

              <proof>
                <p>
                  <ol>
                    <li>
                      <p>
                        Suppose <m>M \oplus A \cong P</m> for some projective module <m>P</m>. 
                        By <xref ref="thm-4.9"/>, there exists a free <m>R</m>-module <m>F</m> and an <m>R</m>-module <m>B</m> such that <m>P \oplus B \cong F</m>. 
                        Then <m>M \oplus A \oplus B \cong P \oplus B \cong F</m>, and by <xref ref="thm-4.9"/> this implies <m>M</m> is projective.
                      </p>
                    </li>
          
                    <li>
                      <p>
                        Let <m>\left\{P_{i}\right\}_{i \in I}</m> be a family of projective modules. 
                        By <xref ref="thm-4.9"/>, there exist free modules <m>F_{i}</m> such that each <m>P_{i}</m> is a direct summand of <m>F_{i}</m>. 
                        Therefore, <m>\oplus P_{i}</m> is a direct summand of <m>\oplus_{i} F_{i}</m>, which is also free. 
                        By <xref ref="thm-4.9"/>, this implies that <m>\oplus P_{i}</m> is projective.
                      </p>
                    </li>
                  </ol>
                </p>
              </proof>
            </corollary>

            <p>
              We are finally ready to give examples showing that projective modules are not necessarily free.
            </p>

            <example><title>Projective but not Free Module</title>
              <p>
                Example 4.12. 
                The ring <m>R=\mathbb{Z} /(6)</m> can be written as a direct sum of the ideals
                <me>I=(2) \text { and } J=(3)</me>
              </p>
        
              <p>
                Indeed, <m>R=I+J</m> and <m>I \cap J=0</m>, so <m>R=I \oplus J</m>. 
                By <xref ref="cor-4.11"/>, <m>I</m> and <m>J</m> are projective <m>R</m>-modules. 
                However, <m>I</m> and <m>J</m> are not free. 
                This can be explained numerically: every finitely generated free <m>R</m>-module is of the form <m>R^{n}</m>, so it has <m>6^{n}</m> elements for some <m>n</m>, while <m>I</m> and <m>J</m> have <m>3</m> and <m>2</m> elements respectively.
              </p>
            </example>
      
            <p>
              Finally, to emphasize its importance we record here an easy result that we have used repeatedly at this point, and which will be very important later on.
            </p>

            <lemma xml:id="lem-4.13">
              <statement>
                <p>
                  For every <m>R</m>-module <m>M</m>, there exists a free module <m>F</m> surjecting onto <m>M</m>. 
                  If <m>M</m> is finitely generated, we can take <m>F</m> to be finitely generated.
                </p>
              </statement>
            </lemma>
      
            <p>
              We will often need only a weaker version of this: that every module is a quotient of a projective module.
            </p>

          </subsection>

          <outcomes>
            <ul>
              <li>
                <p>
                  Projective modules are exactly the modules that make <m>\operatorname{Hom}_{R}(P,-)</m> exact.
                </p>
              </li>

              <li>
                <p>
                  Here are other equivalent characterizations of a projective module <m>P</m>:
                  <ol>
                    <li>
                      <p>
                        Given any surjective <m>R</m>-module homomorphism <m>s: A \rightarrow B</m> and any <m>R</m>-module homomorphism <m>f: P \rightarrow B</m>, there exists an <m>R</m>-module homomorphism <m>g</m> such that the diagram
                      </p>
                      <image source="2023_10_23_e2d6a27704be928b3deeg-109(1).jpg" width="30%"/>
                      <p>
                        commutes.
                      </p>
                    </li>

                    <li>
                      <p>
                        <m>P</m> is the direct summand of a free module
                      </p>
                    </li>

                    <li>
                      <p>
                        Every short exact sequence
                        <me>0 \longrightarrow A \longrightarrow B \longrightarrow P \longrightarrow 0</me>
                        splits.
                      </p>
                    </li>
                  </ol>
                </p>
              </li>

              <li>
                <p>
                  Free modules are projective. 
                  Projective modules are free in commutative rings that are either local or graded.
                </p>
              </li>

              <li>
                <p>
                  For every module <m>M</m>, there exists a free module <m>F</m> surjecting into <m>M</m>.
                </p>
              </li>
            </ul>
          </outcomes>

        </section>

        <section xml:id="sec-injective"><title>Injective Modules</title>

          <objectives>
            <ul>
              <li>
                
              </li>
            </ul>
          </objectives>

          <subsection xml:id="subsec-injective"><title>Definition and Baer's Criterion</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>
            
            <p>
              Injective modules are dual to projectives.
            </p>

            <definition xml:id="def-4.14"><title>Injective Module</title>
              <statement>
                <p>
                  An <m>R</m>-module <m>I</m> is <em>injective</em> if given an injective <m>R</m>-module homomorphism <m>i: A \longrightarrow B</m> and an <m>R</m>-module homomorphism <m>f: A \longrightarrow I</m>, there exist an <m>R</m>-module homomorphism <m>g</m> such that
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-114.jpg" width="30%"/>
                <p>
                  commutes.
                </p>
              </statement>
            </definition>
      
            <p>
              These are precisely the modules <m>I</m> such that <m>\operatorname{Hom}_{R}(-, I)</m> is exact.
            </p>

            <theorem xml:id="thm-4.15">
              <statement>
                <p>
                  An <m>R</m>-module <m>I</m> is injective if and only if <m>\operatorname{Hom}_{R}(-, I)</m> is exact, meaning that for every short exact sequence
                  <me>0 \longrightarrow A \stackrel{i}{\longrightarrow} B \stackrel{p}{\longrightarrow} C \longrightarrow 0</me>
                  we get an exact sequence
                  <me>0 \longrightarrow \operatorname{Hom}_{R}(C, I) \stackrel{p^{*}}{\longrightarrow} \operatorname{Hom}_{R}(B, I) \stackrel{i^{*}}{\longrightarrow} \operatorname{Hom}_{R}(A, I) \longrightarrow 0</me>
                </p>
              </statement>

              <proof>
                <p>
                  By <xref ref="thm-3.14"/>, <m>\operatorname{Hom}_{R}(-, I)</m> is left exact, so for any short exact sequence
                  <me>0 \longrightarrow A \stackrel{i}{\longrightarrow} B \stackrel{p}{\longrightarrow} C \longrightarrow 0</me>
                  we get an exact sequence
                  <me>0 \longrightarrow \operatorname{Hom}_{R}(C, I) \stackrel{p^{*}}{\longrightarrow} \operatorname{Hom}_{R}(B, I) \stackrel{i^{*}}{\longrightarrow} \operatorname{Hom}_{R}(A, I)</me>
                </p>
          
                <p>
                  So the content of the theorem is that <m>I</m> is injective if and only if for every injective <m>R</m>-module homomorphism <m>i: A \longrightarrow B</m>, the induced map <m>i^{*}</m> is surjective. 
                  Now notice that <m>i^{*}</m> is surjective if and only if every <m>f \in \operatorname{Hom}_{R}(A, I)</m> lifts to some <m>g \in \operatorname{Hom}_{R}(B, I)</m>, meaning
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-114(1).jpg" width="30%"/>    
                <p>
                  commutes. 
                  That is precisely what we want for <m>I</m> to be injective.
                </p>
              </proof>
            </theorem>
      
            <p>
              Giving examples of injective modules is much harder than giving examples of projective modules, but we will see some examples later. 
              First, we prove some properties of injective modules.
            </p>
      
            <p>
              The class of injectives modules is closed for products and finite direct sums.
            </p>

            <lemma xml:id="lem-4.16">
              <statement>
                <p>
                  Given any family <m>\left\{M_{i}\right\}_{i \in I}</m> of injective modules, <m>\prod_{i \in I} M_{i}</m> is injective.
                </p>
              </statement>

              <proof>
                <p>
                  Let <m>\pi_{j}: \prod_{i \in I} M_{i} \longrightarrow M_{j}</m> be the projection onto the <m>j</m> th factor. 
                  Given any diagram
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-115(5).jpg" width="30%"/>
                <p>
                  the fact that <m>M_{i}</m> is injective gives us <m>R</m>-module homomorphisms <m>g_{i}</m> such that
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-115(2).jpg" width="30%"/>
                <p>
                  commutes for each <m>i</m>. Now the <m>R</m>-module homomorphism
                  <me>
                    \begin{gathered}
                    B \stackrel{g}{\longrightarrow} \prod_{i \in I} M_{i} \\
                    b \longmapsto\left(g_{i}(b)\right)
                    \end{gathered}
                  </me>
                  makes the diagram
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-115(3).jpg" width="30%"/>
                <p>
                  commute, so <m>\prod_{i \in I} M_{i}</m> is injective.
                </p>
              </proof>
            </lemma>

            <lemma xml:id="lem-4.17">
              <statement>
                <p>
                  If <m>M \oplus N=E</m> is an injective <m>R</m>-module, then so are <m>M</m> and <m>N</m>.
                </p>
              </statement>

              <proof>
                <p>
                  Any diagram
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-115(4).jpg" width="30%"/>
                <p>
                  can be extended to a map <m>A \longrightarrow E</m> by composing <m>f</m> with the inclusion of the first factor. 
                  Since <m>E</m> is injective, there exists <m>h</m> such that
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-115.jpg" width="30%"/>
                <p>
                  commutes. 
                  Let <m>\pi: E \longrightarrow M</m> be the projection onto <m>M</m>, so that <m>\pi j=\mathrm{id}_{M}</m>. 
                  Now if we set <m>g:=\pi h</m>,
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-115(1).jpg" width="30%"/>
                <p>
                  <me>
                    \begin{aligned}
                    g i &amp; =\pi h i &amp; \text { by definition } \\
                    &amp; =\pi j f &amp; \text { by commutativity } \\
                    &amp; =f &amp; \text { because } \pi j=\mathrm{id}_{M}
                    \end{aligned}</me>
                </p>
              </proof>
            </lemma>

            <theorem xml:id="thm-4.18"><title>Baer Criterion</title>
              <statement>
                <p>
                  An <m>R</m>-module <m>E</m> is injective if and only if every <m>R</m>-module homomorphism <m>I \longrightarrow E</m> from an ideal <m>I</m> in <m>R</m> can be extended to the whole ring, meaning that there exists <m>g</m> making the diagram
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-116(1).jpg" width="30%"/>
                <p>
                  commute.
                </p>
              </statement>

              <proof>
                <p>
                  On the one hand, if <m>E</m> is injective then our condition is simply a special case of the definition of injective module. 
                  On the other hand, suppose that this condition holds, and consider any diagram
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-116.jpg" width="30%"/>
                <p>
                  To simplify notation, let's assume our map <m>M \longrightarrow N</m> is indeed the inclusion of the submodule <m>M</m>, so we can write <m>m \in N</m> for the image of <m>m</m> in <m>N</m>. 
                  Consider the set
                  <me>X:=\{(A, g) \mid A \text { is a submodule of } N, M \subseteq A \subseteq N \text {, and } g \text { extends } f\}</me>
                </p>
          
                <p>
                  First, notice <m>X</m> is nonempty, since <m>(M, f) \in X</m>. 
                  Moreover, we can partially order <m>X</m> by setting <m>(A, g) \leqslant(B, h)</m> if <m>A \subseteq B</m> and <m>\left.h\right|_{A}=g</m>. 
                  So we have a nonempty partially ordered set; let's show we can apply Zorn's Lemma to it.
                </p>
          
                <p>
                  Given a chain in <m>X</m>, meaning a sequence
                  <me>\left(A_{1}, g_{1}\right) \leqslant\left(A_{2}, g_{2}\right) \leqslant \cdots</me>
                  of nested submodules <m>A_{1} \subseteq A_{2} \subseteq \cdots</m> and maps <m>g_{i}</m> that extend all <m>g_{j}</m> with <m>j \leqslant i</m>, let <m>A:=\bigcup_{i} A_{i}</m>, and define
                  <me>
                    \begin{aligned}
                    &amp; A \longrightarrow g \\
                    &amp; a \longrightarrow g_{i}(a) \text { if } a \in A_{i} .
                    \end{aligned}
                  </me>
                </p>
          
                <p>
                  Since all the <m>g_{i}</m> are homomorphisms of <m>R</m>-modules, this map <m>g</m> is indeed a map of <m>R</m>-modules. 
                  Moreover, <m>g</m> is well-defined, since the <m>g_{i}(a)=g_{j}(a)</m> whenever <m>a \in A_{i} \cap A_{j}</m>. 
                  By construction, this map extends all the <m>g_{i}</m>, so we conclude that <m>(A, g)</m> is an upper bound for our chain. 
                  Moreover, <m>M \subseteq A \subseteq N</m> follows immediately from our construction, and since each <m>g_{i}</m> extends <m>f</m>, so does <m>g</m>. 
                  We conclude that <m>(A, g) \in X</m>, and more generally that any chain in <m>X</m> has an upper bound in <m>X</m>. 
                  So Zorn's Lemma applies.
                </p>
          
                <p>
                  By Zorn's Lemma, <m>X</m> has a maximal element, say <m>(A, g)</m>. 
                  We claim that <m>A=N</m>. 
                  Suppose not, and let <m>n \in N</m> be an element not in <m>A</m>. One can check that
                  <me>I:=\{r \in R \mid r n \in A\}</me>
                  is an ideal in <m>R</m>, and that
                  <me>
                    \begin{aligned}
                    &amp; I \stackrel{h}{\longrightarrow} E \\
                    &amp; r \longrightarrow g(r n)
                    \end{aligned}
                  </me>
                  is an <m>R</m>-module homomorphism.
                </p>
          
                <p>
                  By assumption, we can extend <m>h</m> to an <m>R</m>-module homomorphism <m>R \longrightarrow E</m>, which we will write as <m>h</m> as well. 
                  Now the <m>R</m>-module homomorphism
                  <me>
                    \begin{aligned}
                    &amp; A+R n \longrightarrow E \\
                    &amp; a+r n \longrightarrow g(a)+h(r)
                    \end{aligned}
                  </me>
                  is well-defined by construction, since any <m>r n \in A</m> satisfies <m>g(r n)=h(r)</m>, and if <m>r n=r^{\prime} n</m> then <m>h(r)=r n=r^{\prime} n=h\left(r^{\prime}\right)</m>. 
                  Finally, this map agrees with <m>g</m> on <m>A</m>, and thus it agrees with <m>f</m> on <m>M</m>, so <m>(A+R n, \varphi) \in X</m> and <m>(A, g) \leqslant(A+R n, \varphi)</m>. 
                  By the maximality of <m>(A, g)</m>, we conclude that <m>A+R n=A</m>, and thus <m>n \in A</m>, which is a contradiction. 
                  We conclude that <m>A=N</m>. 
                  Therefore, <m>g</m> makes the diagram
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-117(1).jpg" width="30%"/>
                <p>
                  commute.
                </p>
              </proof>
            </theorem>

          </subsection>

          <subsection xml:id="subsec-divisible"><title>Divisible Modules</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>
            
            <p>
              It is very easy to see that every <m>R</m>-module is a quotient of a free module. 
              The dual statement is true as well, but it is a little more delicate.
            </p>

            <definition xml:id="def-4.21"><title>Divisible Module</title>
              <statement>
                <p>
                  An <m>R</m>-module <m>D</m> is <em>divisible</em> if for every nonzero <m>r \in R</m> and every <m>d \in D</m> there exists <m>b \in D</m> such that <m>r b=d</m>.
                </p>
              </statement>
            </definition>

            <remark>
              <p>
                Remark 4.22. 
                Given <m>r \in R</m>, and an <m>R</m>-module <m>M</m>, the multiplication by <m>r</m> map <m>M \stackrel{\cdot r}{\longrightarrow} M</m> is an <m>R</m>-module homomorphism. 
                The module <m>M</m> is divisible if and only if multiplication by <m>r</m> is surjective for all nonzero <m>r \in R</m>.
              </p>
            </remark>

            <example><title>Divisible Modules</title>
              <statement>
                <p>
                  The set of rational numbers <m>\Q</m>, considered as a module over the ring of integers <m>\Z</m>, is a divisible module. 
                  This is because for any nonzero integer <m>n</m>, you can find a rational number <m>q = \frac 1n</m> such that <m>nq</m> is still a rational number.
                </p>
              </statement>
            </example>

            <lemma xml:id="lem-4.23"><title>Divisible Modules Closed Under Quotients</title>
              <statement>
                <p>
                  Any quotient of a divisible module is also divisible.
                </p>
              </statement>

              <proof>
                <p>
                  Let <m>D</m> be a divisible <m>R</m>-module and <m>E</m> be a submodule of <m>D</m>. 
                  Let <m>r \in R</m> and <m>d+E \in</m> <m>D / E</m>. 
                  By assumption, there exists <m>a \in D</m> such that <m>r a=d</m>. 
                  The image <m>a+E</m> of <m>a</m> in <m>D / E</m> is still a solution to <m>r(a+E)=d+D</m>, so indeed <m>E</m> is divisible.
                </p>
              </proof>
            </lemma>

            <theorem xml:id="thm-divisible-cps"><title>Closure Properties of Divisible Modules</title>
              <statement>
                <p>
                  Divisible modules are closed under taking submodules, quotients, direct sums, and localizations.
                </p>
              </statement>
            </theorem>

            <lemma xml:id="lem-4.24"><title>Injective Modules Divisible in Domains</title>
              <statement>
                <p>
                  Over a domain, every injective module is divisible.
                </p>
              </statement>

              <proof>
                <p>
                  Suppose that <m>E</m> is an injective <m>R</m>-module, where <m>R</m> is a domain. 
                  Fix <m>r \in R</m> and <m>a \in E</m>. Since <m>R</m> is a domain, we have <m>s r=s^{\prime} r \Rightarrow s=s^{\prime}</m> for any <m>s, s^{\prime}, r \in R</m>. 
                  In particular, each element in <m>(r)</m> can be written uniquely as <m>s r</m> for some <m>s \in R</m>. 
                  In particular, the map of <m>R</m>-modules
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-119.jpg" width="30%"/>
                <p>
                  is well-defined. 
                  Since <m>E</m> is injective, we can extend this to a homomorphism <m>f: R \longrightarrow E</m>. 
                  Finally, <m>f(1) \in E</m> is an element such that <m>e=f(r)=r f(1)</m>, and <m>E</m> is divisible.
                </p>
              </proof>
            </lemma>

            <p>
              This not true in general if we do not assume <m>R</m> is a domain.
            </p>

            <example><title>Injective but not Divisible Module</title>
              <p>
                Example 4.25. 
                Let <m>k</m> be a field and <m>R=k[x] /\left(x^{2}\right)</m>. 
                On the one hand, <m>R</m> is not a divisible <m>R</m>-module, since there is no <m>y \in R</m> such that <m>x y=1</m>. 
                On the other hand, <m>R</m> is actually an injective module over itself, although we do not have the tools to justify that this is indeed an injective <m>R</m>-module. <m>{ }^{1}</m>
              </p>
            </example>
      
            <p>
              The converse of <xref ref="lem-4.24"/> does not hold in general, and quotients of injective modules are not necessarily injective.
            </p>

            <exercise><title>Injective Modules not Closed Under Quotients</title>
              <p>
                Exercise 57. 
                Let <m>R=k[x, y]</m>, where <m>k</m> is a field, let <m>Q=\operatorname{frac}(R)</m> be the fraction field of <m>R</m>. 
                The <m>R</m>-module <m>M=Q / R</m> is divisible but not injective.
              </p>
            </exercise>
      
            <p>
              But the converse of <xref ref="lem-4.24"/> does hold for some special classes of rings.
            </p>

            <theorem xml:id="lem-4.26"><title>Injective iff Divisible in PID</title>
              <statement>
                <p>
                  Let <m>R</m> be a principal ideal domain. 
                  An <m>R</m>-module <m>E</m> is injective if and only <m>E</m> it is divisible.
                </p>
              </statement>

              <proof>
                <p>
                  Given <xref ref="lem-4.24"/>, we only need to show that divisible modules are injective. 
                  By Baer's Criterion, we only need to show that any map from an ideal to <m>E</m> can be extended to the whole ring. 
                  So let <m>E</m> be a divisible <m>R</m>-module, and consider any map <m>I \longrightarrow E</m> from an ideal <m>I</m> to <m>E</m>. 
                  If <m>I=0</m>, we could extend our map by taking the <m>0</m> map from <m>R</m> to <m>E</m>, so we might as well assume that <m>I \neq 0</m>. 
                  By assumption, <m>I=(a)</m> for some <m>a \in R</m>, and since <m>E</m> is divisible, there exists <m>e \in E</m> such that <m>f(a)=a e</m>. 
                  Now consider the multiplication by <m>r</m> map,
                  <me>
                    \begin{aligned}
                    &amp; R \longrightarrow g \\
                    &amp; r \longrightarrow r e .
                    \end{aligned}
                  </me>
                  For every <m>r \in R, g(r a)=r a e=r f(a)=f(r a)</m>, so <m>g</m> extends <m>f</m>. 
                  Therefore, by Theorem 4.18, <m>E</m> is injective.
                </p>
              </proof>
            </theorem>

            <corollary xml:id="lem-4.27"><title>Injectives Closed Under Quotients in PIDs</title>
              <statement>
                <p>
                  Over a principal ideal domain, quotients of injective modules are injective.
                </p>
              </statement>

              <proof>
                <p>
                  If <m>E</m> is injective, it is also divisible, by <xref ref="lem-4.24"/>. Given any submodule <m>D \subseteq E</m>, any <m>e \in E</m>, and a nonzero <m>r \in R</m>, there exists <m>y \in E</m> such that <m>r y=e</m>, and so this also holds in <m>E / D</m>. 
                  Then <m>E / D</m> is divisible, and thus injective by <xref ref="lem-4.26"/>.  
                  <fn>Using fancy words you might learn in Commutative Algebra II, this ring <m>R</m> is an example of a complete intersection, which is a subclass of Gorenstein rings. Moreover, <m>\operatorname{dim} R=0</m> - this is something you'd learn about in Commutative Algebra II. Now it turns out (and this is a nontrivial fact) that Gorenstein rings of dimension 0 are injective modules over themselves.</fn>
                </p>
              </proof>
            </corollary>

            <p>
              Given an injective abelian group, we can always use it to construct an injective <m>R</m>-module over our favorite ring <m>R</m>.
            </p>

            <lemma xml:id="lem-4.28">
              <statement>
                <p>
                  Given an injective abelian group <m>D</m> and a ring <m>R, \operatorname{Hom}_{\mathbb{Z}}(R, D)</m> is an injective <m>R</m>-module.
                </p>
              </statement>

              <proof>
                <p>
                  Let <m>E:=\operatorname{Hom}_{\mathbb{Z}}(R, D)</m>. 
                  This abelian group <m>E</m> is an <m>R</m>-module, via
                  <me>r \cdot f:=(a \mapsto f(r a))</me>
                </p>
          
                <p>
                  We claim that <m>E</m> is actually an injective <m>R</m>-module. 
                  By <xref ref="thm-4.15"/>, it is sufficient to prove that <m>\operatorname{Hom}_{R}\left(-, \operatorname{Hom}_{\mathbb{Z}}(R, D)\right)</m> is an exact functor. 
                  By <xref ref="cor-3.61"/>, <m>\operatorname{Hom}_{R}\left(-, \operatorname{Hom}_{\mathbb{Z}}(R, D)\right)</m> is naturally isomorphic to <m>\operatorname{Hom}_{\mathbb{Z}}\left(-\otimes_{\mathbb{Z}} R, D\right)</m>.
                  This last functor is the composition of
                  <me>\operatorname{Hom}_{\mathbb{Z}}\left(-\otimes_{\mathbb{Z}} R, D\right)=\operatorname{Hom}_{\mathbb{Z}}(-, D) \circ\left(-\otimes_{\mathbb{Z}} R\right)</me>
                </p>
          
                <p>
                  On the one hand, <m>-\otimes_{\mathbb{Z}} R</m> is naturally isomorphic to the identity on <m>R</m>-Mod, by <xref ref="lem-3.40"/>, so it is exact. 
                  On the other hand, <m>D</m> is an injective <m>\mathbb{Z}</m>-module, so <m>\operatorname{Hom}_{\mathbb{Z}}(-, D)</m> is exact by <xref ref="thm-4.15"/>. 
                  The composition of exact functors is exact, and thus <m>\operatorname{Hom}_{R}\left(-, \operatorname{Hom}_{\mathbb{Z}}(R, D)\right)</m> is exact.
                </p>
              </proof>
            </lemma>

            <example>
              <p>
                Example 4.29. 
                Since <m>\mathbb{Q}</m> is a divisible abelian group, by <xref ref="lem-4.28"/> for any ring <m>R</m> the <m>R</m>-module <m>\operatorname{Hom}_{\mathbb{Z}}(R, \mathbb{Q})</m> is injective.
              </p>
            </example>

          </subsection>

          <subsection xml:id="subsec-inject-embed"><title>Every Module Embeds into an Injective Module</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>

            <p>
              When we talked about projective modules, we showed that every module is a quotient of a projective - in fact, every module is a quotient of a free module. 
              The dual statement is true as well: that every module embeds into an injective module. 
              We will soon see that these two statements are extremely important.
            </p>
      
            <p>
              While the statement about projectives is relatively simple - it's essentially a consequence of the universal property of free modules - the fact about injectives is a lot more delicate; 
              the work we just did on divisible modules was precisely so we could show this deep and important fact.
            </p>
      
            <p>
              First, we show that every abelian group can be embedded into an injective abelian group.
            </p>

            <lemma xml:id="lem-4.30">
              <statement>
                <p>
                  Every abelian group <m>M</m> is a submodule of some injective abelian group.
                </p>
              </statement>

              <proof>
                <p>
                  On the one hand, <m>M</m> is a quotient of some free abelian group, say <m>M \cong\left(\oplus_{i} \mathbb{Z}\right) / K</m>.
                  Now <m>\mathbb{Z}</m> embeds in <m>\mathbb{Q}</m>, and thus <m>M</m> embeds into a quotient of <m>\oplus_{i} \mathbb{Q}</m>. 
                  By Example 4.20, <m>\mathbb{Q}</m> is an injective abelian group, and by Corollary <m>4.19, \oplus_{i} \mathbb{Q}</m> is an injective abelian group, since <m>\mathbb{Z}</m> is a noetherian ring. 
                  By <xref ref="lem-4.27"/>, any quotient of <m>\oplus_{i} \mathbb{Q}</m> is also injective, so we have shown that <m>M</m> embeds into an injective abelian group, say <m>D</m>.
                </p>
          
                <p>
                  In fact, the proof above can be repeated over any PID: if <m>R</m> is a PID, we can show that any <m>R</m>-module <m>M</m> embeds into an injective module, and in fact <m>M</m> embeds into some number of copies of the fraction field <m>Q</m>.
                </p>
              </proof>
            </lemma>
      
            <p>
              We can finally show that over any ring, every module can be embedded into an injective module.
            </p>

            <theorem xml:id="thm-4.31">
              <statement>
                <p>
                  Every <m>R</m>-module <m>M</m> is a submodule of some injective <m>R</m>-module.
                </p>
              </statement>

              <proof>
                <p>
                  First, by <xref ref="lem-4.30"/> we can view <m>M</m> as a subgroup of some injective abelian group <m>D</m>. 
                  Let <m>i: M \longrightarrow D</m> be the inclusion map and <m>E:=\operatorname{Hom}_{\mathbb{Z}}(R, D)</m>.
                </p>
          
                <p>
                  By <xref ref="lem-4.28"/>, <m>E</m> is an injective <m>R</m>-module. 
                  Since Hom is left exact, by <xref ref="thm-3.14"/>, <m>\operatorname{Hom}_{\mathbb{Z}}(R,-)</m> preserves the inclusion <m>I</m>, so we have an inclusion <m>\operatorname{Hom}_{\mathbb{Z}}(R, M) \subseteq \operatorname{Hom}_{\mathbb{Z}}(R, D)</m>. 
                  Now consider the map
                  <me>
                    \begin{aligned}
                    &amp; M \stackrel{\psi}{\longrightarrow} \operatorname{Hom}_{\mathbb{Z}}(R, M) \\
                    &amp; m \longrightarrow(r \mapsto r m) .
                    \end{aligned}
                  </me>
                </p>
          
                <p>
                  This is an <m>R</m>-module homomorphism:
                  <ul>
                    <li>
                      <p>
                        Given <m>a, b \in M</m>,
                        <me>\psi(a+b)(r)=r(a+b)=r a+r b=\psi(a)(r)+\psi(b)(r)</me>
                        so <m>\psi(a+b)=\psi(a)+\psi(b)</m>.
                      </p>
                    </li>
          
                    <li>
                      <p>
                        Given <m>r \in R, m \in M</m>, and <m>s \in R</m>,
                        <me>\psi(r m)(s)=s(r m)=r(s m)=r \psi(m)(s),</me>
                        so <m>\psi(r m)=r \psi(m)</m>.
                      </p>
                    </li>
                  </ul>
                </p>
          
                <p>
                  Moreover, if <m>\psi(m)=0</m> then <m>m=\psi(m)(1)=0</m>. 
                  So <m>\psi</m> is injective, and thus composing <m>\psi</m> with our previous inclusion <m>\operatorname{Hom}_{\mathbb{Z}}(R, M) \subseteq \operatorname{Hom}_{\mathbb{Z}}(R, D)</m> gives us an inclusion <m>\varphi</m> of <m>M</m> into the injective <m>R</m>-module <m>\operatorname{Hom}_{\mathbb{Z}}(R, D)</m>. 
                  However, the inclusion <m>\operatorname{Hom}_{\mathbb{Z}}(R, M) \subseteq \operatorname{Hom}_{\mathbb{Z}}(R, D)</m> is a priori only a map of abelian groups, so we should check that <m>\varphi</m> is indeed <m>R</m>-linear. 
                  In order to do this, we need to be careful (at least in the case when <m>R</m> is not commutative) with how we defined the left <m>R</m>-module structure on <m>\operatorname{Hom}_{\mathbb{Z}}(R, D)</m> in Exercise 56: 
                  this is a situation where we view <m>R</m> as a <m>(\mathbb{Z}, R)</m>-bimodule and <m>D</m> as a left <m>\mathbb{Z}</m>-module, so <m>\operatorname{Hom}_{\mathbb{Z}}(R, D)</m> is a left <m>R</m>-module via
                  <me>r \cdot f \text { is the } R \text {-map given by }(r \cdot f)(a)=f(a r) \text {. }</me>
                </p>
          
                <p>
                  The map we need to show is <m>R</m>-linear is
                  <me>
                    \begin{aligned}
                    &amp; M \stackrel{\varphi}{\longrightarrow} \operatorname{Hom}_{\mathbb{Z}}(R, D) \\
                    &amp; m \longmapsto \varphi_{m}=(r \mapsto i(r m)) .
                    \end{aligned}
                  </me>
                  Regarding <m>i</m> as a simple inclusion, <m>i(m)</m> simply views the element <m>m</m> as an element of <m>D</m>; 
                  to simplify notation, we drop the <m>i</m> : so for each <m>m \in M, \varphi(m)</m> is the map <m>\varphi_{m}: R \longrightarrow D</m> given by
                  <me>\varphi_{m}(r)=r m</me>
                  For every <m>r \in R, m \in M</m>, and <m>s \in R</m>,
                </p>
          
                <p>
                  <me>
                    \begin{array}{rrr}
                    \varphi_{r m}(s) &amp; =s(r m) &amp; \text { by definition } \\
                    &amp; =(s r) m &amp; \\
                    &amp; =\varphi_{m}(s r) &amp; \text { using the module axioms } \\
                    &amp; =r \varphi_{m}(s) &amp; \text { by definition } \\
                    &amp; &amp; \text { by defition of the left } R \text {-module structure on } \operatorname{Hom}_{\mathbb{Z}}(R, D)
                    \end{array}
                  </me>
                  so <m>\varphi(r m)=r \varphi(m)</m>. 
                  This shows that <m>\varphi</m> is an inclusion of <m>R</m>-modules.
                </p>
              </proof>
            </theorem>

            <p>
              And finally, just like we did for projectives, we can characterize injectives in terms of split short exact sequences.
            </p>

            <theorem xml:id="thm-4.32">
              <statement>
                <p>
                  An <m>R</m>-module <m>I</m> is injective if and only if every short exact sequence
                  <me>0 \longrightarrow I \longrightarrow B \longrightarrow C \longrightarrow 0</me>
                  splits.
                </p>
              </statement>

              <proof>
                <p>
                  Let <m>I</m> be an injective <m>R</m>-module, and consider any short exact sequence
                  <me>0 \longrightarrow I \stackrel{i}{\longrightarrow} B \stackrel{p}{\longrightarrow} C \longrightarrow 0</me>
                  Since <m>I</m> is injective, there exists a map <m>g</m> making
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-122(1).jpg" width="30%"/>
                <p>
                  commute, and such a <m>g</m> gives a splitting for our short exact sequence.
                </p>
          
                <p>
                  Conversely, suppose that every short exact sequence <m>0 \longrightarrow I \longrightarrow B \longrightarrow C \longrightarrow 0</m> splits, and consider a diagram
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-122.jpg" width="30%"/>
                <p>
                  By <xref ref="thm-4.31"/>, <m>I</m> embeds into some injective <m>R</m>-module <m>E</m>, say by the inclusion <m>j</m>. 
                  By assumption, the short exact sequence
                  <me>0 \longrightarrow I \stackrel{j}{\longrightarrow} E \longrightarrow \text { coker } j \longrightarrow 0</me>
                  splits, so there exists a map <m>q: E \longrightarrow I</m> such that <m>q i=\mathrm{id}_{I}</m>. 
                  Since <m>E</m> is injective, we can lift <m>i</m> through <m>j f</m>, obtaining an <m>R</m>-module homomorphism <m>\ell</m> such that
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-122(2).jpg" width="30%"/>
                <p>
                  commutes. Now <m>g:=q \ell</m> satisfies
                  <me>
                    \begin{array}{rlr}
                    g i &amp; =q \ell i &amp; \text { by definition } \\
                    &amp; =q j f &amp; \text { by commutativity } \\
                    &amp; =f &amp; \text { since } q j=\mathrm{id}_{I},
                    \end{array}
                  </me>
                </p>
                <image source="2023_10_23_e2d6a27704be928b3deeg-123.jpg" width="30%"/>
                <p>
                  commutes.
                </p>
              </proof>
            </theorem>

            <p>
              Before we move on from injective modules, let us say a word about how the story continues. 
              The next chapter is quite beautiful, and it is a shame we have no time to discuss it in detail this semester.
            </p>
      
            <p>
              We proved above that every module <m>M</m> is a submodule of some injective module. 
              One can even do better and talk about the smallest injective module that <m>M</m> embeds in; 
              this is called the injective hull <m>E(M)</m> of <m>M</m>. 
              One could describe <m>E(M)</m> by saying that it is the intersection of all the injective modules that contain <m>M</m>, but this is not a very practical description. 
              Injective hulls can also be described through the theory of essential extensions, a topic which we do not have time to discuss this semester. 
              We leave the definition here just for fun, but we do not have the time to talk about it at length.
            </p>

            <definition xml:id="def-4.33">
              <statement>
                <p>
                  Let <m>M \subseteq E</m>. We say <m>E</m> is an <em>essential extension</em> of <m>M</m> if every nonzero submodule <m>N \subseteq E</m> intersects <m>M</m> nontrivially, meaning <m>E \cap M \neq 0</m>. 
                  More generally, an injective map <m>\alpha: M \longrightarrow E</m> is an essential extension if <m>\alpha(M) \subseteq E</m> is an essential extension in the sense above.
                </p>
              </statement>
            </definition>
      
            <p>
              One then shows that an <m>R</m>-module <m>M</m> is injective if and only if it has no proper essential extensions <m>E \supseteq M</m>. 
              This proves that a maximal essential extension <m>E</m> of <m>M</m> is injective, and that there are no other injective modules <m>I</m> with of <m>M \subseteq I \subseteq E</m>. 
              Moreover, one can show that any two maximal essential extension of <m>M</m> are isomorphic - and thus we can talk about the maximal essential extension of <m>M</m>, up to isomorphism, which is
            </p>
      
            <p>
              But the theory of injectives, and injective hulls in particular, is much more complicated than the theory of projectives. 
              When <m>M</m> is a finitely generated module, we can always find a finitely generated projective (even free!) module surjecting onto <m>M</m>; 
              in contrast, the injective hull <m>E(M)</m> might not be finitely generated - in fact, <m>E(M)</m> is typically not finitely generated even when <m>M</m> is cyclic.
            </p>
      
            <p>
              The story of the structure of injective modules then continues in a beautiful way. 
              Over a noetherian ring, it turns out that every injective module can be decomposed into a direct sum of injective modules of the form <m>E(R / P)</m>, where <m>P</m> is a prime ideal in <m>R</m>. 
              Moreover, the injective modules <m>E(R / P)</m> are the indecomposable injective modules, so the basic building blocks of injective modules. 
              One can in fact compute the injective hull of any finitely generated <m>R</m>-module very explicitly. 
              A lot of this was proved in Eben Matlis' beautiful PhD thesis [Mat58], but sadly we do not have time for the details this semester. 
              The details, however, are very important, for example to develop the theory of local cohomology - a topic which we will briefly mention later on.
            </p>

          </subsection>

          <outcomes>
            <ul>
              <li>
                <p>
                  Injective modules make <m>\operatorname{Hom}_{R}(-, I)</m> exact. 
                </p>
              </li>

              <li>
                <p>
                  The Baer Criterion tells us that a module <m>E</m> is injective if and only if a map from an ideal to <m>E</m> can be extended to all of <m>R</m>.
                </p>
              </li>

              <li>
                <p>
                  In a domain injective modules are divisible and in a PID divisible modules are injective.
                </p>
              </li>

              <li>
                <p>
                  Every <m>R</m>-module is a submodule of an injective module.
                </p>
              </li>
            </ul>
          </outcomes>
          
        </section>

        <section xml:id="sec-flat"><title>Flat Modules</title>

          <objectives>
            <ul>
              <li>
                
              </li>
            </ul>
          </objectives>

          <subsection xml:id="subsec-flat"><title>Definition</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>
          
            <p>
              Finally, we turn to the modules that make the tensor product exact.
            </p>

            <definition xml:id="def-4.34"><title>Flat Module</title>
              <statement>
                <p>
                  An <m>R</m>-module <m>M</m> is said to be <em>flat</em> if <m>M \otimes_{R}-</m> is an exact functor.
                </p>
              </statement>
            </definition>

            <remark>
              <p>
                Remark 4.35. 
                By <xref ref="thm-3.47"/>, <m>M \otimes_{R}</m> - is right exact. 
                Therefore, <m>M</m> is flat if and only if for every injective <m>R</m>-module map <m>i: A \longrightarrow B</m>,
                <me>M \otimes_{R} A \stackrel{1 \otimes i}{\longrightarrow} M \otimes_{R} B \quad \text { is injective. }</me>
              </p>
            </remark>

            <lemma xml:id="lem-4.36"><title>Direct Summands of Flat Modules are Flat</title>
              <statement>
                <p>
                  Given a family of <m>R</m>-modules <m>\left\{M_{i}\right\}_{i \in I}</m>, the direct sum <m>\oplus_{i} M_{i}</m> is flat if and only if every <m>M_{i}</m> is flat. 
                  In particular, direct summands of flat modules are flat.
                </p>
              </statement>

              <proof>
                <p>
                  Given a family of <m>R</m>-module homomorphisms <m>f_{i}: M_{i} \longrightarrow N_{i}</m>, there is an <m>R</m>-module homomorphism
                  <me>
                    \begin{array}{r}
                    \bigoplus_{i \in I} M_{i} \stackrel{\left(f_{i}\right)_{i \in I}}{\longmapsto} \bigoplus_{i \in I} N_{i} \\
                    \quad\left(m_{i}\right) \longmapsto
                    \end{array}
                  </me>
                  which is injective if and only if every <m>f_{i}</m> is injective.
                </p>
          
                <p>
                  Let <m>f: A \longrightarrow B</m> be an injective <m>R</m>-module homomorphism. 
                  There is a commutative diagram
                  <me>
                    \begin{aligned}
                    &amp; \left(\bigoplus_{i \in I} M_{i}\right) \otimes_{R} A \stackrel{\cong}{\longrightarrow} \bigoplus_{i \in I} M_{i} \otimes_{R} A \\
                    &amp; \varphi:=1 \otimes f \downarrow \\
                    &amp; \left(\bigoplus_{i \in I} M_{i}\right) \otimes_{R} B \stackrel{\downarrow}{\cong} \cong \bigoplus_{i \in I} M_{i} \otimes_{R} B
                    \end{aligned}
                  </me>
                  where the horizontal maps are the isomorphisms from <xref ref="thm-3.41"/>. 
                  In particular, <m>\varphi</m> is injective if and only if <m>\psi</m> is injective. 
                  Moreover, <m>\psi</m> is injective if and only if each component is injective, meaning <m>1 \otimes f: M_{i} \otimes A \longrightarrow M_{i} \otimes B</m> is injective for all <m>i</m>.
                </p>
          
                <p>
                  On the one hand, <m>\bigoplus_{i \in I} M_{i}</m> is flat if and only if for every injective map <m>f</m>, the corresponding <m>\phi</m> is injective. 
                  On the other hand, all the <m>M_{i}</m> are flat if and only if for every injective map <m>f, 1 \otimes f: M_{i} \otimes A \longrightarrow M_{i} \otimes B</m> is injective for all <m>i</m>, or equivalently, as explained above, if <m>\psi</m> is injective for any given injective map <m>f</m>. 
                  This translates into the equivalence we want to show.
                </p>
              </proof>
            </lemma>
      
            <p>
              All projectives are flat.
            </p>
      
            <theorem xml:id="thm-4.37"><title>Every Projective Module is Flat</title>
              <statement>
                <p>
                  Let <m>R</m> be any ring. Every projective <m>R</m>-module is flat.
                </p>
              </statement>

              <proof>
                <p>
                  First, recall that <m>R \otimes_{R}-</m> is naturally isomorphic to the identity functor, by Lemma 3.40, and thus exact (see Remark 3.11). 
                  This shows that <m>R</m> is flat, and thus any free module, being a direct sum of copies of <m>R</m>, must also be flat by <xref ref="lem-4.36"/>. 
                  Finally, every projective module is a direct summand of a free module, by <xref ref="thm-4.9"/>. 
                  Direct summands of flat modules are flat, by <xref ref="lem-4.36"/>, so every projective module is flat.
                </p>
              </proof>
            </theorem>
      
            <p>
              We can test whether a given module if flat by looking at the finitely generated submodules.
            </p>

            <theorem xml:id="thm-4.38"><title>Flatness and Finitely Generated Submodules</title>
              <statement>
                <p>
                  If every finitely generated submodule of <m>M</m> is flat, then <m>M</m> is flat.
                </p>
              </statement>

              <proof>
                <p>
                  Let <m>i: A \longrightarrow B</m> be an injective map of <m>R</m>-modules. 
                  We want to show that
                  <me>M \otimes_{R} A \stackrel{1 \otimes i}{\longrightarrow} M \otimes_{R} B</me>
                  is injective. 
                  Suppose that <m>u \in \operatorname{ker}\left(1_{M} \otimes i\right)</m>. 
                  We are going to construct a finitely generated submodule <m>N \subseteq M</m>, with <m>j: N \rightarrow M</m> the inclusion, and an element <m>v \in N \otimes_{R} A</m> such that <m>v \in \operatorname{ker}\left(1_{N} \otimes i\right)</m> and <m>u=\left(j \otimes 1_{A}\right)(v)</m>. 
                  Once we do that, our submodule <m>N</m> is finitely generated, and thus flat by assumption, so <m>1_{N} \otimes i</m> is injective; therefore, <m>v=0</m> and thus we must have <m>u=0</m>. 
                  Therefore, <m>1_{M} \otimes i</m> is injective, and we conclude that <m>M</m> is flat.
                </p>
          
                <p>
                  Let's say that <m>u=m_{1} \otimes a_{1}+\cdots+m_{n} \otimes a_{n}</m>.
                  In <xref ref="thm-3.22"/>, we constructed the tensor product <m>M \otimes_{R} B</m> as a quotient of the free module <m>F</m> on <m>M \times B</m> by the submodule <m>S</m> with all the necessary relations we need to impose. 
                  This gives us a short exact sequence
                  <me>0 \longrightarrow S \longrightarrow F \stackrel{\pi}{\longrightarrow} M \otimes_{R} B \longrightarrow 0</me>
                  The fact that <m>m_{1} \otimes i\left(a_{1}\right)+\cdots+m_{n} \otimes i\left(a_{n}\right)=0</m> means we can rewrite this element as <m>\pi(s)</m> for some <m>s \in S</m>. 
                  This element <m>s</m> is a linear combination of elements of finitely many <m>(m, b) \in M \times B</m>. 
                  Let <m>c_{1}, \ldots, c_{t}</m> be all the <m>M</m>-coordinates of those elements.
                </p>
          
                <p>
                  Now we take <m>N</m> to be the finitely generated submodule of <m>M</m> generated by <m>m_{1}, \ldots, m_{n}</m> and <m>c_{1}, \ldots, c_{t}</m>, and <m>v=m_{1} \otimes a_{1}+\cdots+m_{n} \otimes a_{n} \in N \otimes A</m>. 
                  Now
                  <me>\left(j \otimes 1_{A}\right)(v)=\left(j \otimes 1_{A}\right)\left(m_{1} \otimes a_{1}+\cdots+m_{n} \otimes a_{n}\right)=m_{1} \otimes a_{1}+\cdots+m_{n} \otimes a_{n} \in M \otimes_{R} A,</me>
                  and
                  <me>\left(1_{N} \otimes i\right)(v)=\left(1_{N} \otimes i\right)\left(m_{1} \otimes a_{1}+\cdots+m_{n} \otimes a_{n}\right)=m_{1} \otimes i\left(a_{1}\right)+\cdots+m_{n} \otimes i\left(a_{n}\right)=0</me>
                  as desired.
                </p>
              </proof>
            </theorem>

            <p>
              The reason we needed to add in these extra elements <m>n_{i}</m> is that a priori <m>N \otimes B</m> is not necessarily a submodule of <m>M \otimes B</m>, so we do not necessarily have <m>m_{1} \otimes i\left(a_{1}\right)+\cdots+m_{n} \otimes i\left(a_{n}\right)=0</m> in <m>\left(R m_{1}+\cdots+R m_{n}\right) \otimes B</m> without adding in all relations that make it true.
            </p>

          </subsection>

          <subsection xml:id="subsec-torsion"><title>Torsion Submodules</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>

            <definition xml:id="def-4.39"><title>Torsion Submodule</title>
              <statement>
                <p>
                  Let <m>R</m> be a domain and <m>M</m> be an <m>R</m>-module. 
                  The <em>torsion submodule</em> of <m>M</m> is
                  <me>T(M):=\{m \in M \mid r m=0 \text { for some regular element } r \in R\}</me>
                  The elements of <m>T(M)</m> are called <em>torsion elements</em>, and we say that <m>M</m> is <em>torsion</em> if <m>T(M)=M</m>. 
                  Finally, <m>M</m> is <em>torsion free</em> if <m>T(M)=0</m>.
                </p>
              </statement>
            </definition>

            <theorem xml:id="thm-torsion-free-cps"><title>Closure Properties of Torsion Free Modules</title>
              <statement>
                <p>
                  Torsion free modules are closed under taking submodules, quotients, direct sums, and localizations.
                </p>
              </statement>
            </theorem>
            
            <lemma xml:id="lem-4.40"><title>Flat Implies Torision Free in Domains</title>
              <statement>
                <p>
                  If <m>R</m> is a domain and <m>M</m> is a flat <m>R</m>-module, then <m>M</m> is torsion free.
                </p>
              </statement>

              <proof>
                <p>
                  Let <m>Q=\operatorname{frac}(R)</m> be the fraction field of <m>R</m>, which is a torsion free <m>R</m>-module.
                  Now <m>M \otimes_{R} Q</m> is a <m>Q</m>-vector space, so isomorphic to a direct sum of copies of <m>Q</m>. 
                  In particular, <m>M \otimes_{R} Q</m> is torsion free as an <m>R</m>-module. 
                  Since <m>M</m> is flat, the inclusion <m>R \subseteq Q</m> induces an injective <m>R</m>-module map
                  <me>0 \longrightarrow M \otimes_{R} R \longrightarrow M \otimes_{R} Q</me>
                  and since <m>M \cong M \otimes_{R} R</m>, by <xref ref="lem-3.40"/>, we conclude that <m>M</m> is isomorphic to a submodule of <m>M \otimes_{R} Q</m>. 
                  By <xref ref="thm-torsion-free-cps"/>, submodules of torsion free modules are also torsion free, so <m>M</m> is torsion free.
                </p>
              </proof>
            </lemma>

            <p>
              In general, the converse does not hold.
            </p>

            <example><title>Torsion Free but not Flat Module</title>
              <p>
                Example 4.41. 
                Let <m>k</m> be a field and <m>R=k[x, y]</m>. 
                Consider the ideal <m>\mathfrak{m}=(x, y)</m>. 
                This is a submodule of the torsion free module <m>R</m>, and thus torsion free by <xref ref="thm-torsion-free-cps"/>. 
                However, it is not flat. 
                For example, when we apply <m>R / \mathfrak{m} \otimes_{R}-</m> to the inclusion <m>\mathfrak{m} \subseteq R</m> we obtain a map of <m>R / \mathfrak{m}</m>-vector spaces
                <me>\mathfrak{m} / \mathfrak{m}^{2} \longrightarrow R / \mathfrak{m}</me>
              </p>
        
              <p>
                This map cannot possibly be injective: <m>\mathfrak{m} / \mathfrak{m}^{2}</m> is a <m>2</m>-dimensional <m>R / \mathfrak{m}</m>-vector space, while <m>R / \mathfrak{m}</m> is <m>1</m>-dimensional.
              </p>
            </example>
      
            <p>
              The converse does hold over a PID.
            </p>

            <theorem xml:id="lem-4.42"><title>Flat iff Torsion Free in PID</title>
              <statement>
                <p>
                  If <m>R</m> is a principal ideal domain, an <m>R</m>-module <m>M</m> is flat if and only if it is torsion free.
                </p>
              </statement>

              <proof>
                <p>
                  <m>(\Rightarrow)</m> This is just a special case of <xref ref="lem-4.40"/>.
                </p>
          
                <p>
                  <m>(\Leftarrow)</m> Suppose <m>M</m> is a torsion free finitely generated <m>R</m>-module. 
                  The structure theorem for PIDs says that <m>M</m> must be isomorphic to a direct sum of copies of cyclic modules. 
                  The cyclic module <m>R / I</m> has torsion (all the elements are killed by <m>I</m> ) unless <m>I=0</m>. 
                  Therefore, <m>M</m> must be isomorphic to a direct sum of copies of <m>R</m>, and thus free. 
                  By <xref ref="thm-4.3"/>, <m>M</m> is projective, and by <xref ref="thm-4.37"/> projectives are flat, so <m>M</m> is flat.
                </p>
          
                <p>
                  Now let <m>M</m> be any torsion free <m>R</m>-module. 
                  All of the finitely generated submodules of <m>R</m> are also torsion free by <xref ref="thm-torsion-free-cps"/>, and thus flat by what we have shown so far. 
                  By <xref ref="thm-4.38"/>, <m>M</m> must be flat.
                </p>
              </proof>
            </theorem>

            <p>
              Not all flat modules are projective.
            </p>

            <example><title>Flat but not Projective Module</title>
              <p>
                Example 4.43. 
                The <m>\mathbb{Z}</m>-module <m>\mathbb{Q}</m> is torsion free and thus flat, by <xref ref="lem-4.42"/>. 
                However, <m>\mathbb{Q}</m> is not a projective <m>\mathbb{Z}</m>-module. 
                Suppose by contradiction, that <m>\mathbb{Q}</m> is a projective <m>\mathbb{Z}</m>-module. 
                By <xref ref="thm-4.9"/>, <m>\mathbb{Q}</m> must be a direct summand of a free module, say <m>F=\bigoplus_{I} \mathbb{Z}</m>. 
                Consider the inclusion <m>\iota: \mathbb{Q} \hookrightarrow F</m>, and pick <m>i \in I</m> such that the image of <m>\mathbb{Q}</m> contains some element with a nonzero entry in the <m>i</m> component. 
                Now consider the projection <m>\pi: F \longrightarrow \mathbb{Z}</m> onto the <m>i</m> th factor. 
                By assumption, the composition <m>\pi i: \mathbb{Q} \longrightarrow \mathbb{Z}</m> is nonzero. 
                However, there are no nontrivial abelian group homomorphisms <m>\mathbb{Q} \longrightarrow \mathbb{Z}</m>, contradicting the fact that <m>\pi i</m> is nonzero. 
                We conclude that <m>\mathbb{Q}</m> is not projective.
              </p>
            </example>

            <p>
              However, for finitely generated modules over a commutative noetherian local ring, every flat module is free, and thus flat, projective, and free all coincide. 
              However, to prove that we need a little bit of commutative algebra, which we introduce in the next section.
            </p>
    
            <p>
              Finally, here is a very important example: localization is flat.
            </p>

            <theorem xml:id="thm-4.44"><title>Flatness of Localization</title>
              <statement>
                <p>
                  Let <m>R</m> be a commutative ring, and <m>W \ni 1</m> a multiplicative subset of <m>R</m>. 
                  Then <m>W^{-1} R</m> is flat over <m>R</m>.
                </p>
              </statement>

              <proof>
                <p>
                  By <xref ref="thm-3.57"/>, tensoring with <m>W^{-1} R</m> is localizing at <m>W</m>. 
                  But localization is exact, so tensoring with <m>W^{-1} R</m> is exact, and thus <m>W^{-1} R</m> is a flat <m>R</m>-module.
                </p>
              </proof>
            </theorem>

            <example>
              <p>
                If <m>R</m> is a domain then its fraction field <m>Q</m> is a flat module.
              </p>
            </example>

          </subsection>

          <outcomes>
            <ul>
              <li>
                <p>

                </p>
              </li>
            </ul>
          </outcomes>
    
        </section>
    
        <section xml:id="commutative-local-rings"><title>Commutative Local Rings</title>
    
          <p>
            We have shown that
            <me>\text { Free } \Longrightarrow \text { projective } \Longrightarrow \text { flat. }</me>
          </p>
    
          <p>
            Over a local ring, these three notions actually coincide. 
            To show this, we need a little bit of commutative algebra. 
            First, some notation: when <m>R</m> is a local ring, meaning <m>R</m> has a unique maximal ideal <m>\mathfrak{m}</m>, we write <m>(R, \mathfrak{m})</m> to denote the ring <m>R</m> and its maximal ideal. 
            Now note that for any <m>R</m>-module <m>M</m>, the module <m>M / \mathfrak{m} M</m> is annihilated by <m>\mathfrak{m}</m>, so it is also a module over a ring <m>R / \mathfrak{m}</m>, which is a field.
          </p>
    
          <p>
            The following is a classical result in commutative algebra, known by some as Nakayama's Lemma. 
            As noted in [Mat89, page 8], Nakayama himself claimed that this should be attributed to Krull and Azumaya, but it's not clear which of the three actually had the commutative ring statement first. 
            So some authors (eg, Matsumura) prefer to refer to it as NAK. 
            There are actually a range of statements, rather than just one, that go under the banner of Nakayama's Lemma a.k.a. NAK.
          </p>
    
          <p>
            Theorem <m>4.45(\mathrm{NAK})</m>. Let <m>(R, \mathfrak{m}, k)</m> be a local ring, and <m>M</m> be a finitely generated module. If <m>M=\mathfrak{m} M</m>, then <m>M=0</m>.
          </p>
    
          <p>
            The theorem above is the theorem most commonly referred to as NAK. 
            The proof involves only elementary tools, and a fun linear algebra-inspired trick called the Determinantal Trick. 
            While we will not include the details here, they can be found in any standard Commutative Algebra book. 
            We will however use this result to prove another statement that is also commonly referred to as NAK, which allows us to talk about minimal generating sets for finitely generated modules over local rings.
          </p>
    
          <p>
            Remark 4.46. 
            Let <m>R</m> be any commutative ring, and consider an <m>R</m>-module <m>M</m> and an ideal <m>I</m>. 
            If <m>I M=0</m>, meaning that <m>a m=0</m> for all <m>a \in I</m> and all <m>m \in M</m>, then <m>M</m> can be given the structure of an <m>R / I</m>-module, as follows: 
            for any <m>m \in M</m> and any <m>r \in R</m>,
            <me>(r+I) m=r m</me>
            The fact that <m>I</m> kills <m>M</m> is what makes this action well-defined. 
            The fact that <m>M</m> is actually an <m>R</m>-module under this action is a consequence of the fact that <m>M</m> is an <m>R</m>-module; 
            checking these details is routine, and we leave them as an exercise.
          </p>
    
          <p>
            Notice that the structure of <m>M</m> as an <m>R / I</m>-module is essentially the same as its structure as an <m>R</m>-module. 
            There are many properties of <m>M</m> as an <m>R</m>-module that pass onto its <m>R / I-</m> module structure, and typically such results are easy to check.
          </p>
    
          <p>
            Here is a special case of this: if <m>(R, \mathfrak{m})</m> is a commutative local ring, and <m>M</m> is an <m>R</m>-module, then the module <m>M / \mathfrak{m} M</m> is killed by <m>\mathfrak{m}</m>, and thus it is also a module over <m>R / \mathfrak{m}</m>. 
            Now notice that <m>R / \mathfrak{m}</m> is a field, so <m>M / \mathfrak{m} M</m> is actually a vector space over the field <m>R / \mathfrak{m}</m>.
          </p>
    
          <p>
            Theorem 4.47. 
            Let <m>(R, \mathfrak{m})</m> be a commutative local ring, and <m>M</m> be a finitely generated module. 
            For <m>m_{1}, \ldots, m_{s} \in M</m>,
            <me>m_{1}, \ldots, m_{s} \text { generate } M \Longleftrightarrow \overline{m_{1}}, \ldots, \overline{m_{s}} \text { generate } M / \mathfrak{m} M</me>
            Thus, any generating set for <m>M</m> consists of at least <m>\operatorname{dim}_{k}(M / \mathfrak{m} M)</m> elements.
          </p>
    
          <p>
            Proof. The implication <m>(\Rightarrow)</m> is clear. For <m>(\Leftarrow)</m>, given <m>m_{1}, \ldots, m_{s} \in M</m> such that <m>\overline{m_{1}}, \ldots, \overline{m_{s}}</m> generate <m>M / \mathfrak{m} M</m>, consider
          </p>
    
          <p>
            <me>N:=R m_{1}+\cdots+R m_{s} \subseteq M</me>
          </p>
    
          <p>
            Since <m>M / \mathfrak{m} M</m> is generated by the image of <m>N</m>, we have <m>M=N+\mathfrak{m} M</m>. By taking the quotient by <m>N</m>, we see that
          </p>
    
          <p>
            <me>M / N=(N+\mathfrak{m} M) / N=\mathfrak{m}(M / N)</me>
          </p>
    
          <p>
            By Theorem 4.45, <m>M / N=0</m> and thus <m>M=N</m>.
          </p>
    
          <p>
            As we mentioned above, this allows us to talk about minimal generating sets.
          </p>
    
          <p>
            Definition 4.48. Let <m>(R, \mathfrak{m})</m> be a local ring, and <m>M</m> a finitely generated module. A set of elements <m>\left\{m_{1}, \ldots, m_{t}\right\}</m> is a minimal generating set of <m>M</m> if the images of <m>m_{1}, \ldots, m_{t}</m> form a basis for the <m>R / \mathfrak{m}</m> vector space <m>M / \mathfrak{m} M</m>.
          </p>
    
          <p>
            Note that every finitely generated module over a local ring has a minimal generating set, that every minimal generating set has the same number of elements, and that any set of generators for <m>M</m> contains a minimal generating set, all thanks to plain old linear algebra. In particular, we can now define the following:
          </p>
    
          <p>
            Definition 4.49. Let <m>M</m> be a finitely generated module over a commutative local ring <m>(R, \mathfrak{m})</m>. The minimal number of generators of <m>M</m>, denoted <m>\mu(M)</m>,, is the number of elements in any minimal generating set for <m>M</m>.
          </p>
    
          <p>
            We now have all the key commutative algebra ingredients needed to show that for finitely generated modules over a noetherian local ring, projective <m>=</m> free. However, the proof follows more easily with one more homological tool we haven't developed yet, so we will hold off on proving this for now - in fact, you will soon be able to prove it easily, so this will be in the next problem set.
          </p>
    
          <p>
            Exercise 58. Let <m>(R, \mathfrak{m})</m> be a commutative local ring, and let <m>M</m> be a finitely presented module. Then
          </p>
    
          <p>
            <me>M \text { is flat } \Longleftrightarrow M \text { is projective } \Longleftrightarrow M \text { is free. }</me>
          </p>
    
          <p>
            Kaplansky [Kap58] showed that this holds even for modules that are not necessarily finitely presented, but generated by countably many elements.
          </p>
    
          <p>
            Definition 4.50. An <m>R</m>-module <m>M</m> is locally free if <m>M_{P}</m> is free for every prime ideal <m>P</m>.
          </p>
    
          <p>
            Exercise 59. Let <m>R</m> be a commutative ring, <m>M</m> and <m>N</m> be <m>R</m>-modules, and <m>P</m> be a prime ideal. Show that
          </p>
    
          <p>
            <me>\left(M \otimes_{R} N\right)_{P} \cong M_{P} \otimes_{R_{P}} N_{P}</me>
          </p>
    
          <p>
            Exercise 60. Let <m>R</m> be a commutative ring, <m>P</m> be a prime ideal, and <m>M</m> be an <m>R_{P}</m>-module. Let <m>N</m> be <m>M</m> as an <m>R</m>-module via restriction of scalars. Then as <m>R_{P}</m>-modules, we have an isomorphism
          </p>
    
          <p>
            <me>N_{P} \cong M</me>
          </p>
    
          <p>
            Exercise 61. Let <m>R</m> be a commutative ring. Show that a homomorphism of <m>R</m>-modules <m>f: M \rightarrow N</m> is surjective if and only if <m>f_{P}</m> is surjective for all primes <m>P</m>.
          </p>

          <exercise xml:id="exe-62">
            <p>
              Exercise 62. Let <m>R</m> be a noetherian ring, <m>W</m> be a multiplicative set, <m>M</m> be a finitely generated <m>R</m>-module, and <m>N</m> an arbitrary <m>R</m>-module. Show that
            </p>
      
            <p>
              <me>\operatorname{Hom}_{W^{-1} R}\left(W^{-1} M, W^{-1} N\right) \cong W^{-1} \operatorname{Hom}_{R}(M, N) \text {. }</me>
            </p>
      
            <p>
              In particular, if <m>P</m> is prime,
            </p>
      
            <p>
              <me>\operatorname{Hom}_{R_{P}}\left(M_{P}, N_{P}\right) \cong \operatorname{Hom}_{R}(M, N)_{P}</me>
            </p>
          </exercise>
    
          
    
          <p>
            Theorem 4.51. Let <m>R</m> be a commutative noetherian ring and let <m>M</m> be a finitely presented <m>R</m>-module. Then
          </p>
    
          <p>
            <me>M \text { is projective } \Longleftrightarrow M \text { is flat } \Longleftrightarrow M \text { is locally free. }</me>
          </p>
    
          <p>
            Proof. We already know that projectives are flat, by Theorem 4.37.
          </p>
    
          <p>
            Suppose <m>M</m> is flat. We claim that <m>M_{P}</m> is flat for every prime ideal <m>P</m>. First, note that <m>M_{P} \cong R_{P} \otimes_{R} M</m>, by Theorem 3.57; moreover, <m>R_{P}</m> is a flat <m>R</m>-module by Exercise 53 . Note moreover that any <m>R_{P}</m>-module can also be viewed as an <m>R</m>-module by extension of scalars along the canonical localization map. Now given any short exact sequence of <m>R_{P}</m>-modules, say
          </p>
    
          <p>
            <me>0 \longrightarrow A \longrightarrow B \longrightarrow C \longrightarrow 0</me>
          </p>
    
          <p>
            tensoring with <m>M_{P}</m> over <m>R_{P}</m> can be done in two steps: first we view this as a short exact sequence of <m>R</m>-modules, and tensor with <m>M</m>, but <m>M</m> is a flat <m>R</m>-module, so
          </p>
    
          <p>
            <me>0 \longrightarrow A \otimes_{R} M \longrightarrow B \otimes_{R} M \longrightarrow C \otimes_{R} M \longrightarrow 0</me>
          </p>
    
          <p>
            is exact. Then we tensor with <m>R_{P}</m>, but this is also flat <m>R</m>-module, so we get a short exact sequence again:
          </p>
    
          <p>
            <me>0 \longrightarrow\left(A \otimes_{R} M\right) \otimes_{R} R_{P} \longrightarrow\left(B \otimes_{R} M\right) \otimes_{R} R_{P} \longrightarrow\left(C \otimes_{R} M\right) \otimes_{R} R_{P} \longrightarrow 0</me>
          </p>
    
          <p>
            By Theorem 3.57 and Exercise 59, for each <m>R_{P}</m>-module <m>X</m> we have
          </p>
    
          <p>
            <me>\left(X \otimes_{R} M\right) \otimes_{R} R_{P} \cong\left(X \otimes_{R} M\right)_{P} \cong X_{P} \otimes_{R_{P}} M_{P}</me>
          </p>
    
          <p>
            But <m>X_{P} \cong X</m>, by ??, so we conclude that
          </p>
    
          <p>
            <me>\left(X \otimes_{R} M\right) \otimes_{R} R_{P} \cong X \otimes_{R_{P}} M_{P}</me>
          </p>
    
          <p>
            Thus
          </p>
    
          <p>
            <me>0 \longrightarrow A \otimes_{R_{P}} M_{P} \longrightarrow B \otimes_{R_{P}} M_{P} \longrightarrow C \otimes_{R_{P}} M_{P} \longrightarrow 0</me>
          </p>
    
          <p>
            is exact, and <m>M_{P}</m> is a flat <m>R_{P}</m>-module.
          </p>
    
          <p>
            So whenever <m>M</m> is flat, <m>M_{P}</m> is a flat <m>R_{P}</m>-module for all primes <m>P</m>. By Exercise <m>58, M_{P}</m> must be free over <m>R_{P}</m> for all primes <m>P</m>, that is, <m>M</m> is locally free.
          </p>
    
          <p>
            Finally, suppose that <m>M</m> is locally free. We want to show that <m>M</m> is projective. So by Theorem 4.4, we need to show that for all surjective <m>R</m>-module maps <m>f: A \rightarrow B</m>, the map <m>f_{*}: \operatorname{Hom}_{R}(M, A) \rightarrow \operatorname{Hom}_{R}(M, B)</m> is surjective. By Exercise 61 , it is enough to show that <m>f_{P}</m> is surjective for all primes <m>P</m>. By Exercise 62,
          </p>
    
          <p>
            <me>\operatorname{Hom}_{R_{P}}\left(M_{P}, A_{P}\right) \cong \operatorname{Hom}_{R}(M, A)_{P} \quad \text { and } \quad \operatorname{Hom}_{R_{P}}\left(M_{P}, B_{P}\right) \cong \operatorname{Hom}_{R}(M, B)_{P}</me>
          </p>
    
          <p>
            and
          </p>
    
          <p>
            <me>\left(f_{*}\right)_{P}=\left(f_{P}\right)_{*}: \operatorname{Hom}_{R_{P}}\left(M_{P}, A_{P}\right) \rightarrow \operatorname{Hom}_{R_{P}}\left(M_{P}, B_{P}\right) .</me>
          </p>
    
          <p>
            But <m>M_{P}</m> i free, and thus projective by Theorem 4.3, so <m>\left(f_{P}\right)_{*}</m> is surjective. Since this holds for all <m>P</m>, by Exercise 61 we conclude that <m>f_{*}</m> is surjective, and thus <m>M</m> is projective.
          </p>
    
          <p>
            Note that the noetherianity assumption is just so that finitely generated implies finitely presented; the statement is also true for a general commutative ring if instead of finitely generated modules we take finitely presented.
          </p>

          <outcomes>
            <ul>
              <li>
                <p>

                </p>
              </li>

              <li>
                <p>
                 
                </p>
              </li>

              <li>
                <p>

                </p>
              </li>

              <li>
                <p>

                </p>
              </li>
            </ul>
          </outcomes>

        </section>
        
      </chapter>

      <chapter xml:id="ch-resolutions"><title>Resolutions</title>

        <section xml:id="sec-proj-res"><title>Projective Resolutions</title>

          <objectives>
            <ul>
              <li>
                
              </li>
            </ul>
          </objectives>

          <subsection xml:id="subsec-proj-res-def"><title>Definition, Existence, Examples</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>
            
            <p>
              To describe an <m>R</m>-module <m>M</m>, we need to know a set of generators and the relations among those generators. 
              If we continue that process, and ask for relations among the relations (treating the relations as generators for the module of relations), and relations among the relations among the relations, and so on, we construct what is known as a free resolution for <m>M</m>. 
              Free resolutions play a key role in many important constructions, and encode a lot of interesting information about our module. 
              For example, if the module came from some geometric setting, geometric information about the module gets reflected in the free resolution. 
              Studying the resolutions of all finitely generated modules over a ring <m>R</m> also tells us important information about the ring itself, and its singularities.
            </p>
        
            <p>
              In this chapter we will introduce free resolutions, and more generally projective resolutions, as well as their injective counterpart. 
              We will also study free resolutions in a bit more detail over commutative local noetherian rings, and the graded analogue. 
              For more details on the basics of graded free resolutions, we recommend Irena Peeva's excellent book [Pee11].
            </p>

            <definition xml:id="def-5.1"><title>Projective Resolution</title>
              <statement>
                <p>
                  Let <m>M</m> be an <m>R</m>-module. 
                  A <em>projective resolution</em> is a complex
                </p>
          
                <image source="2023_11_20_24b20e755a5fa2ec338dg-01.jpg"/>
                  
                <p>
                  where all the <m>P_{i}</m> are projective, <m>\mathrm{H}_{0}(C)=M</m>, and <m>\mathrm{H}_{i}(C)=0</m> for all <m>i \neq 0</m>. 
                  We may also write a projective resolution for <m>M</m> as an exact sequence
                  <me>\cdots \underset{\substack{\mathrm{n} \\ \cdots}}{\longrightarrow} \longrightarrow \underset{\substack{1 \\ 1}}{\longrightarrow} P_{0} \longrightarrow M \longrightarrow 0</me>
                  where all the modules <m>P_{i}</m> are projective. 
                  The resolution is <em>free</em> if all the <m>P_{i}</m> are free.
                </p>
              </statement>
            </definition>

            <p>
              You will find both these definitions in the literature, often indicating the second option as an abuse of notation. 
              We will be a bit sloppy and consider both equivalently, since at the end of the day they contain the same information. 
              One often uses the word acyclic to refer to a complex that is exact everywhere except at homological degree <m>0</m>; 
              but we caution the reader that some authors use the word acyclic to refer to exact complexes. 
              For that reason, we will avoid the word acyclic altogether.
            </p>

            <theorem xml:id="thm-5.2"><title>Every Module has a Free Resolution</title>
              <statement>
                <p>
                  Every <m>R</m>-module has a free resolution, and thus it has a projective resolution.
                </p>
              </statement>

              <proof>
                <p>
                  Let <m>M</m> be an <m>R</m>-module. 
                  We are going to construct a projective resolution quite explicitly. 
                  The first step is to find a projective module <m>P_{0}</m> that surjects onto <m>M</m>. 
                  In fact, we can find a free module surjecting onto <m>M</m>, by <xref ref="lem-4.13"/>.
                  Now consider the kernel of that projection, say
                  <me>0 \longrightarrow K_{0} \stackrel{i_{0}}{\longrightarrow} P_{0} \stackrel{\pi_{0}}{\longrightarrow} M \longrightarrow 0</me>
                  Set <m>\partial_{0}:=\pi_{0}</m>. 
                  There exists a free module <m>P_{1}</m> surjecting onto <m>K_{0}</m>, again by <xref ref="lem-4.13"/>.
                  Now the map <m>\partial_{1}=i_{0} \pi_{1}</m> satisfies <m>\operatorname{im} \partial_{1}=K_{0}=\operatorname{ker} \partial_{0}</m>.
                </p>

                <image source="2023_11_20_24b20e755a5fa2ec338dg-02.jpg"/>

                <p>
                  Now the process continues analougously. 
                  We find a free module <m>P_{2}</m> surjecting onto <m>K_{1}:=</m> ker <m>\partial_{1}</m>, and set
                </p>

                <image source="2023_11_20_24b20e755a5fa2ec338dg-02(1).jpg"/>

                <p>
                  At each stage, <m>\pi_{i}: P_{i} \rightarrow K_{i} 1</m> is a surjective map, <m>K_{i}:=</m> ker <m>\partial_{i}, i_{i}</m> is the inclusion of the kernel of <m>\partial_{i}</m> into <m>P_{i}</m>, and we get short exact sequences
                  <me>0 \longrightarrow K_{n+1} \stackrel{i_{n} \quad 1}{\longrightarrow} P_{n+1} \stackrel{\pi_{n} \stackrel{1}{\longrightarrow}}{\longrightarrow} K_{n} \longrightarrow 0</me>
                  In fact, <m>\operatorname{im}\left(i_{n+1}\right)=\operatorname{ker} \partial_{n+1}=\operatorname{ker}\left(i_{n} \pi_{n+1}\right)=\operatorname{ker} \pi_{n+1}</m>. 
                  We can continue this process for as long as <m>P_{n} \neq 0</m>, and the resulting sequence will be a projective resolution for <m>M</m>.
                </p>
              </proof>
            </theorem>
      
            <p>
              A free resolution
              <me>\cdots \longrightarrow F_{2} \longrightarrow F_{1} \longrightarrow F_{0} \longrightarrow M</me>
              gives us a detailed description of our module <m>M</m>:

              <ul>
                <li>
                  <p>
                    <m>F_{0}</m> gives us generators for <m>M</m>.
                  </p>
                </li>

                <li>
                  <p>
                    <m>F_{1}</m> gives us generators for all the relations among our generators for <m>M</m>.
                  </p>
                </li>

                <li>
                  <p>
                    The next module describes the relations among the relations among our generators. And so on.
                  </p>
                </li>
              </ul>
            </p>

            <definition xml:id="def-5.3"><title>Length of Projective Resolution</title>
              <statement>
                <p>
                  If <m>P</m> is a projective resolution of <m>M</m>, we say that <m>P</m> has length <m>d</m> if <m>P_{n}=0</m> for all <m>n&gt;d</m> and <m>P_{d} \neq 0</m>. 
                  If no such <m>d</m> exists, we say that <m>P</m> has infinite length. 
                  If <m>M</m> has no finite projective resolution, we say that <m>M</m> has infinite projective dimension; otherwise, the projective dimension of <m>M</m> is the smallest length of a projective resolution.
                </p>
              </statement>
            </definition>

            <remark xml:id="rem-5.4"><title>Projective Dimension <m>0</m> iff Projective</title>
              <p>
                A module <m>M</m> has <m>\operatorname{pdim}(M)=0</m> if and only <m>M</m> is projective. 
                Indeed, note that if <m>M</m> is projective, then
                <me>
                  0 \underset{0}{M} M \longrightarrow M \longrightarrow 0
                </me>
                is a projective resolution of <m>M</m>. On the other hand, if <m>M</m> has a projective resolution
                <me>
                  0 \longrightarrow \underset{0}{P} P \longrightarrow M \longrightarrow 0
                </me>
                then exactness tells us that <m>P \cong M</m>.
              </p>
            </remark>

            <example xml:id="ex-5.5"><title>Projective Resolution for <m>\mathbb{Z} / 2</m> over <m>\mathbb{Z}</m></title>
              <p>
                Let us construct a free resolution for <m>\mathbb{Z} / 2</m> over <m>\mathbb{Z}</m>. 
                First, since <m>\mathbb{Z} / 2</m> has only one generator, we can start with the canonical surjection <m>\pi: \mathbb{Z} \rightarrow \mathbb{Z} / 2</m>.
                Note that <m>\operatorname{ker} \pi=(2)</m> is generated by just one element again, so we can take
                <me>
                  \mathbb{Z} \stackrel{2}{\longrightarrow} \mathbb{Z} \stackrel{\pi}{\longrightarrow} \mathbb{Z} / 2
                </me>
                But now the map <m>\mathbb{Z} \stackrel{2}{\rightarrow} \mathbb{Z}</m> is injective, so we are done, and
                <me>
                  0 \longrightarrow \mathbb{Z} \stackrel{2}{\longrightarrow} \mathbb{Z} \longrightarrow \mathbb{Z} / 2 \longrightarrow 0
                </me>
                is a free resolution for <m>\mathbb{Z} / 2</m>. 
                This shows that <m>\operatorname{pdim}(\mathbb{Z} / 2) \leqslant 1</m>. 
                Also, <m>\mathbb{Z} / 2</m> is not projective: we showed in <xref ref="ex-3.15"/> that <m>\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} / 2, \quad)</m> is not exact. 
                Thus <m>\operatorname{pdim}(\mathbb{Z} / 2)=1</m>.
              </p>
            </example>

            <example xml:id="ex-5.6"><title>Projective Resolution for <m>k</m> over <m>k[x] /\left(x^{3}\right)</m></title>
              <p>
                Consider a field <m>k</m> and <m>R=k[x] /\left(x^{3}\right)</m>. 
                Let us construct a free resolution for <m>M=R /(x)</m>. 
                We can start with the canonical surjection <m>R \rightarrow M</m>; 
                the kernel is <m>(x)</m>, which is cyclic, so our resolution begins with
                <me>
                  R \stackrel{x}{\longrightarrow} R \longrightarrow M
                </me>
                Now the kernel of <m>R \stackrel{x}{\rightarrow} R</m> is <m>\left(x^{2}\right)</m>, which is again cyclic. 
                Our resolution continues with
                <me>
                  R \stackrel{x^{2}}{\longrightarrow} R \stackrel{x}{\longrightarrow} R \longrightarrow M
                </me>
                Next, we need to compute the kernel of multiplication by <m>x^{2}</m>; 
                but that is <m>(x)</m>, a cyclic module, and the next step in the resolution is
                <me>
                  R \stackrel{x}{\longrightarrow} R \stackrel{x^{2}}{\longrightarrow} R \stackrel{x}{\longrightarrow} R \longrightarrow M .
                </me>
                But now we have a repeating pattern! Our two-periodic resolution goes on forever:
                <me>
                  \cdots \longrightarrow R \stackrel{x^{2}}{\longrightarrow} R \stackrel{x}{\longrightarrow} R \stackrel{x^{2}}{\longrightarrow} R \stackrel{x}{\longrightarrow} R \longrightarrow M
                </me>
                In fact, it turns out that <m>\operatorname{pdim}(M)=\infty</m>. 
                But to really justify that, we need to understand that this is a <em>minimal</em> free resolution.
              </p>
            </example>

          </subsection>

          <subsection xml:id="subsec-grading"><title>A Brief Introduction to Graded Modules</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>

            <p>
              To talk about minimal free resolutions we need some reasonable conditions to hold. 
              For the rest of the section, all rings will be commutative, and in fact we will be focusing on two types of rings: 
              commutative local rings or <m>\mathbb{N}</m>-graded algebras over fields.
            </p>

            <example xml:id="ex-grading">
              <statement>
                <p>
                  When <m>k</m> is a field, the polynomial ring <m>R=k\left[x_{1}, \ldots, x_{n}\right]</m> can be given an <m>\mathbb{N}</m>-grading by setting <m>\operatorname{deg}\left(x_{i}\right)=d_{i}</m> for some <m>d_{i} \in \mathbb{N}</m>. 
                  The most common <m>\mathbb{N}</m>-grading, also known as the standard grading, is the one where we declare <m>\operatorname{deg}\left(x_{i}\right)=1</m> for all <m>i</m>. 
                  Once we declare the degrees of the variables, we can extend that grading to all monomials as follows:
                  <me> 
                    \operatorname{deg}\left(x_{1}^{a_{1}} \cdots x_{n}^{a_{n}}\right)=a_{1} d_{1}+\cdots+a_{n} d_{n}
                  </me>
                </p>
              </statement>
            </example>

            <definition xml:id="def-homogeneous-elements">
              <statement>
                <p>
                  A homogeneous element in <m>R</m> is any <m>k</m>-linear combination of monomials of the same degree. 
                  We write <m>R_{i}</m> for the set of all homogeneous elements of degree <m>i</m>, which is an abelian group under addition, and note that
                  <me>
                    R=\bigoplus_{i} R_{i}
                  </me>
                  Note also that <m>R_{i} R_{j} \subseteq R_{i+j}</m> for all <m>i</m> and <m>j</m>. 
                </p>
              </statement>
            </definition>
      
            <p>
              More generally, a <em>graded ring</em> is any ring that can be decomposed in pieces of this form, meaning that
              <me>
                R=\bigoplus_{i} R_{i} \quad \text { and } \quad R_{i} R_{j}=R_{i+j}
              </me>
              The elements in <m>R_{i}</m> are called homogeneous elements of degree <m>i</m>. 
              Similarly, a <em>graded</em> <m>R</m>-<em>module</em> is a module such that
              <me>
                M=\bigoplus_{i} M_{i} \quad \text { and } \quad R_{i} M_{j}=M_{i+j}
              </me>
            </p>
      
            <p>
              A homomorphism of graded <m>R</m>-modules <m>\varphi: M \rightarrow N</m> that such that <m>\varphi\left(M_{i}\right) \subseteq N_{i+d}</m> for all <m>i</m> is a <em>graded map</em> of degree <m>d</m>. 
              Any graded map can be thought of as a map of degree <m>0</m> by shifting degrees. 
              We write <m>M(d)</m> for the graded <m>R</m>-module with <m>M(d)_{i}=M_{i} d</m>.
            </p>
      
            <p>
              When <m>R=k\left[x_{1}, \ldots, x_{n}\right]</m> is standard graded,
              <me>
                R_{i}=\bigoplus_{a_{1}+\cdots+a_{n}=i} x_{1}^{a_{1}} \cdots x_{n}^{a_{n}}
              </me>
            </p>
      
            <p>
              Note here that <m>0</m> can be though of as a homogeneous element of any degree; one sometimes declares <m>\operatorname{deg}(0)=\infty</m>. 
              An ideal <m>I</m> in <m>R</m> is a <em>homogeneous ideal</em> if it can be generated by homogeneous elements; 
              one can show that this is equivalent to
              <me>I=\bigoplus_{i}\left(I \cap R_{i}\right)</me>
            </p>
      
            <p>
              Finally, whenever <m>I</m> itself is homogeneous, the grading on <m>R</m> passes onto <m>R / I</m>, with
              <me>(R / I)_{i}=R_{i} / I_{i}</me>
            </p>
      
            <p>
              We will be concerned with finitely generated <m>\mathbb{N}</m>-graded <m>k</m>-algebras <m>R</m> with <m>R_{0}=k</m>, which are of the form <m>R=k\left[x_{1}, \ldots, x_{n}\right] / I</m> for some homogeneous ideal <m>I</m>. One nice feature of such rings is that while there might be many maximal ideals, there is only one homogeneous maximal ideal, which is given by
            </p>
      
            <p>
              <me>R_{+}:=\bigoplus_{i&gt;0} R_{i}</me>
            </p>
      
            <p>
              In many ways, the behavior of such a graded ring and its unique homogeneous maximal ideal <m>R_{+}</m>is an analogue to the behavior of a local ring <m>R</m> and its unique maximal ideal ideal , though one always needs to provide a separate proof for the graded and local versions.
            </p>

          </subsection>

          <subsection xml:id="subsec-unique-minimal"><title>Uniqueness of Minimal Projective Resolutions</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>

            <definition xml:id="def-5.7"><title>Minimal Complex</title>
              <statement>
                <p>
                  Let <m>(R, \fm)</m> be either a commutative local ring or a commutative <m>\mathbb{N}</m>-graded <m>k</m>-algebra with <m>R_{0}=k</m> and homogeneous maximal ideal <m>\fm=R_{+}</m>. 
                  A complex
                  <me>\cdots \longrightarrow F_{2} \stackrel{\partial_{2}}{\longrightarrow} F_{1} \stackrel{\partial_{1}}{\longrightarrow} F_{0} \longrightarrow \cdots</me>
                  is minimal if  <m>\im\partial_{n+1} \subseteq \fm F_{n}</m> for all <m>n</m>.
                </p>
              </statement>
            </definition>

            <remark xml:id="rem-5.8">
              <p>
                Remark 5.8. 
                A complex <m>(F, \partial)</m> is minimal if and only if the differentials in the complex <m>F \otimes_{R} R /\fm</m> are all identically <m>0</m>. 
                If all the <m>F_{i}</m> are free, fix a basis for each <m>F_{i}</m>. 
                The differentials <m>\partial_{i}</m> can be represented by matrices, though possibly infinite. 
                We will be primarily interested in the case of finitely generated modules over noetherian rings, which are finitely presented, so all the <m>F_{i}</m> are finitely generated as well, and each <m>\partial_{i}</m> corresponds to some finite matrix. 
                In this case, our complex is minimal if and only if all the entries in the matrices representing <m>\partial_{i}</m> are in <m>\fm</m>, whatever our chosen bases are.
              </p>
            </remark>

            <lemma xml:id="lem-5.9">
              <statement>
                <p>
                  Let <m>R</m> be a commutative ring. 
                  Suppose <m>(R, \quad)</m> is either a local ring or an <m>\mathbb{N}</m> graded <m>k</m>-algebra with <m>R_{0}=k</m> and homogeneous maximal ideal <m>=R_{+}</m>. Let <m>M</m> be a finitely generated (graded) <m>R</m>-module. 
                  A free resolution
                  <me>
                    F=\cdots \longrightarrow F_{2} \stackrel{\partial_{2}}{\longrightarrow} F_{1} \stackrel{\partial_{1}}{\longrightarrow} F_{0}
                  </me>
                  for <m>M</m> is a minimal complex if and only if for all <m>n</m> the module <m>F_{n}</m> is the free module on a minimal set of generators for  <m>\ker\partial_{n} 1</m>, which in the graded case must be homogeneous.
                </p>
              </statement>

              <proof>
                <p>
                  Suppose there exists an <m>n</m> such that <m>F_{n}</m> is the free module on some non-minimal set of generators <m>m_{1}, \ldots, m_{s}</m> for <m>K_{n} 1:=\operatorname{ker} \partial_{n}{ }_{1}</m>; 
                  so there is a basis <m>e_{1}, \ldots, e_{s}</m> for <m>F_{n}</m> such that <m>\partial_{n}\left(e_{i}\right)=m_{i}</m>, and the images of <m>m_{1}, \ldots, m_{s}</m> in the vector space <m>K_{n} 1 / \fm K_{n} 1</m> are linearly dependent. 
                  Then there exists <m>r_{1}, \ldots, r_{s} \in R</m>, not all in <m>\fm</m>, such that <m>r_{1} m_{1}+\cdots+r_{s} m_{s}=0</m> in <m>R</m>. In the graded case, we can take all these coefficients <m>r_{i}</m> to be homogeneous. 
                  At least one of these coefficients is not in <m>\fm</m>, and thus it must be invertible, 
                  <fn>In the graded case, homogeneous elements not in <m>\fm</m> are nonzero elements in <m>R=k</m>, and thus invertible.</fn>
                  so we can multiply by its inverse. 
                  So perhaps after reordering our elements, we get
                  <me>
                    m_{s}=r_{1} m_{1}+\cdots+r_{s}{ }_{1} m_{s} 1.
                  </me>
                </p>
          
                <p>
                  Then
                  <me>
                    e_{s} \quad r_{1} e_{1} \quad \cdots \quad r_{s \quad 1} e_{s}{ }_{1} \in \operatorname{ker} \partial_{n}=\operatorname{im} \partial_{n+1}
                  </me>
                  is not in <m>\fm F_{n}</m>, so <m>\im \partial_{n+1}\not\in\fm F_{n}</m>.
                </p>
          
                <p>
                  Now suppose that im <m>\partial_{n+1}\not\in\fm F_{n}</m> for some <m>n</m>. 
                  Let <m>e_{1}, \ldots, e_{s}</m> be a basis for <m>F_{n}</m>, so that <m>\partial_{n}\left(e_{1}\right), \ldots, \partial\left(e_{s}\right)</m> form a generating set for <m>K_{n} \quad 1:=\operatorname{ker} \partial_{n} \quad</m>. 
                  By assumption, <m>\operatorname{ker} \partial_{n}=\operatorname{im} \partial_{n+1}</m> contains some (homogeneous, in the graded case) element that is not in <m>\fm F_{n}</m>. 
                  So there is an element <m>r_{1} e_{1}+\cdots+r_{s} e_{s} \in \operatorname{ker} \partial_{n}</m> not in <m>\fm F_{n}</m>. 
                  In particular, some <m>r_{i} \notin \fm</m>, which we can assume without loss of generality to be <m>r_{1}</m>. 
                  Multiplying by the inverse of <m>r_{1}</m>, we get some <m>c_{i} \in R</m> such that
                  <me>
                    e_{1} \quad c_{2} e_{2} \quad \cdots \quad c_{s} e_{s} \in \operatorname{ker} \partial_{n}
                  </me>
                  so
                  <me>
                    \partial_{n}\left(e_{1}\right)=c_{2} \partial_{n}\left(e_{2}\right)+\cdots+c_{s} \partial_{n}\left(e_{s}\right).
                  </me>
                  This is a nontrivial relation among our chosen set of generators of <m>K_{n}</m>, which must then be non-minimal.
                </p>
              </proof>
            </lemma>      
      
            <p>
              So to construct a minimal free resolution of <m>M</m>, we simply take as few generators as possible in each step. 
              Ultimately, we can talk about <em>the</em> minimal free resolution of <m>M</m>. 
              To show that, we need some definitions and a lemma.
            </p>

            <definition xml:id="def-5.10"><title>Direct Sum of Complexes</title>
              <statement>
                <p>
                  Let <m>(F, \partial)</m> and <m>(G, \delta)</m> be complexes of <m>R</m>-modules. 
                  The <em>direct sum</em> of <m>F</m> and <m>G</m> is the complex of <m>R</m>-modules <m>F \oplus G</m> that has <m>(F \oplus G)_{n}=F_{n} \oplus G_{n}</m>, with differentials given by
                  <me>\begin{gathered}
                  F_{n+1} \stackrel{\partial_{n 1}}{\longrightarrow} F_{n} \\
                  \oplus \\
                  G_{n+1} \underset{\delta_{n 1}}{\longrightarrow} G_{n}
                  \end{gathered}</me>
                </p>
          
                <p>
                  together with the complex maps <m>F \rightarrow F \oplus G</m> and <m>G \rightarrow F \oplus G</m> given by the corresponding inclusion in each homological degree.
                </p>
              </statement>
            </definition>

            <exercise xml:id="exe-67">
              <p>
                Exercise 67. 
                Show that the direct sum of complexes is the coproduct in the category <m>\mathrm{Ch}(R)</m>.
              </p>
            </exercise>

            <proposition xml:id="rem-5.11">
              <statement>
                <p>
                  The homology of a direct sum is the direct sum of the homologies.
                </p>
              </statement>

              <proof>
                <p>
                  Notice 
                  <me>
                    \left(\partial_{n}, \delta_{n}\right)(a, b)=(0,0) \Longleftrightarrow \partial_{n}(a)=0 \text { and } \delta_{n}(b)=0 \text {, }
                  </me>
                  and
                  <me>
                    (a, b) \in \operatorname{im}\left(\partial_{n}, \delta_{n}\right) \text { if and only if } a \in \operatorname{im} \partial_{n} \text { and } b \in \operatorname{im} \partial_{n}
                  </me>
                  Thus
                  <me>
                    \mathrm{H}_{n}(F \oplus G)=\frac{\operatorname{ker}\left(\partial_{n}, \delta_{n}\right)}{\operatorname{im}\left(\partial_{n+1}, \delta_{n+1}\right)}=\frac{\operatorname{ker} \partial_{n}}{\operatorname{im} \partial_{n+1}} \oplus \frac{\operatorname{ker} \delta_{n}}{\operatorname{im} \delta_{n+1}}=\mathrm{H}_{n}(F) \oplus \mathrm{H}_{n}(G)
                  </me>
                </p>
              </proof>
            </proposition>

            <remark>
              <p>
                More generally, this is true because <em>Ch(R)</em> is an abelian category, where all additive functors preserve direct sums.
              </p>
            </remark>

            <remark xml:id="rem-5.12"><title>Direct Summands in <m>Ch(R)</m></title>
              <p>
                Suppose that <m>C</m> is a subcomplex of <m>D</m>, and that we know that each <m>C_{n}</m> is a direct summand of <m>D_{n}</m>, say by <m>D_{n}=C_{n} \oplus B_{n}</m>. 
                In order for <m>C</m> to be a free summand of <m>D</m>, we also need that the differentials of <m>D</m> behave well with <m>C</m>: 
                for each <m>n</m>, we need to check that <m>\partial_{n}\left(B_{n}\right) \subseteq B_{n} \quad 1</m> and <m>\partial_{n}\left(C_{n}\right) \subseteq C_{n} 1</m>. 
                This does not always hold.
              </p>
            </remark>

            <definition xml:id="def-5.13"><title>Trivial Complex</title>
              <statement>
                <p>
                  A complex <m>C</m> of <m>R</m>-modules is <em>trivial</em> if it is a direct sum of complexes of the form
                  <me>
                    \cdots \longrightarrow 0 \longrightarrow R \stackrel{1}{\longrightarrow} R \longrightarrow 0 \longrightarrow \cdots
                  </me>
                </p>
              </statement>
            </definition>

            <example xml:id="ex-5.14"><title>Trival Complex</title>
              <p>
                The complex
                <me>
                  0 \longrightarrow R \stackrel{\left(\begin{array}{l}
                  1 \\
                  0
                  \end{array}\right)}{\longrightarrow} R^{2} \stackrel{0 \quad 1}{\longrightarrow} R \longrightarrow 0 \quad \begin{array}{r}
                  0 \longrightarrow R \stackrel{1}{\longrightarrow} R \longrightarrow 0 \\
                  0 \longrightarrow R \stackrel{1}{\longrightarrow} R \longrightarrow 0
                  \end{array}
                </me>
                is trivial.
              </p>
            </example>

            <remark xml:id="rem-5.15"><title>Trivial Complexes are Exact</title>
              <p>
                Trivial complexes are exact: they are the direct sums of exact complexes, and by <xref ref="rem-5.11"/> taking homology commutes with direct sums.
              </p>  
            </remark>
      
            <lemma xml:id="lem-5.16">
              <statement>
                <p>
                  Let <m>(R, \fm)</m> be either a commutative local ring or a commutative <m>\mathbb{N}</m>-graded <m>k</m>-algebra with <m>R_{0}=k</m> and homogeneous maximal ideal <m>\fm=R_{+}</m>. 
                  Every (graded) complex
                  <me>
                    \cdots \longrightarrow T_{2} \stackrel{\partial_{2}}{\longrightarrow} T_{1} \stackrel{\partial_{1}}{\longrightarrow} T_{0} \longrightarrow 0
                  </me>
                  of finitely generated (graded) free <m>R</m>-modules that is exact everywhere must be trivial.
                </p>
              </statement>

              <proof>
                <p>
                  Since <m>T_{0}</m> is projective, <xref ref="thm-4.6"/> says that the short exact sequence
                  <me>
                    0 \longrightarrow \operatorname{ker} \partial_{1} \longrightarrow T_{1} \stackrel{\partial_{1}}{\longrightarrow} T_{0} \longrightarrow 0
                  </me>
                  splits, so <m>T_{1} \cong \operatorname{ker} \partial_{1} \oplus T_{0}</m>. 
                  In fact, <m>\partial_{1}</m> is the canonical projection map <m>T_{0} \oplus \operatorname{ker} \partial_{1} \rightarrow T_{0}</m>, and our original exact sequence breaks off as
                  <me>
                    \begin{aligned}
                      \cdots \longrightarrow 
                      &amp; T_{2} \stackrel{\partial_{2}}{\longrightarrow} \operatorname{ker} \partial_{1} \longrightarrow 0 \\
                      &amp; \oplus \\
                      0 \longrightarrow 
                      &amp; T_{0} \stackrel{1}{\longrightarrow} T_{0} \longrightarrow 0
                    \end{aligned}
                  </me>
                </p>
          
                <p>
                  In particular, since <m>0 \longrightarrow T_{0} \stackrel{1}{\longrightarrow} T_{0} \longrightarrow 0</m> is trivial and homology commutes with taking direct sums of complexes, by <xref ref="rem-5.11"/>, we conclude that
                  <me>
                    \cdots \longrightarrow T_{2} \stackrel{\partial_{2}}{\longrightarrow} \operatorname{ker} \partial_{1} \longrightarrow 0
                  </me>
                  is also exact everywhere. 
                  In particular, we have also shown that ker <m>\partial_{1}</m> is a (graded) direct summand of the (graded) free <m>R</m>-module <m>T_{1}</m>. 
                  In the local case, <m>\ker\partial_{1}</m> is a projective by <xref ref="thm-4.9"/>, and thus free by <xref ref="exe-62"/>. 
                </p>

                  <p>
                  In the graded setting, ?? says that ker <m>\partial_{1}</m> is free. 
                  So we are back at our original situation, and we can repeat the same argument repeatedly to show that our complex breaks off as the direct sum of the trivial complexes
                  <me>
                    0 \longrightarrow \operatorname{ker} \partial_{n} \stackrel{1}{\longrightarrow} \operatorname{ker} \partial_{n} \longrightarrow 0
                  </me>
                  and must therefore be trivial.
                </p>
              </proof>
            </lemma>

            <theorem xml:id="thm-5.17">
              <statement>
                <p>
                  Let
                  <me>
                    P=\cdots \longrightarrow P_{n} \longrightarrow \cdots P_{1} \stackrel{\partial_{1}}{\longrightarrow} P_{0} \stackrel{\partial_{0}}{\longrightarrow} M \longrightarrow 0
                  </me>
                  be a complex of projective <m>R</m>-modules, and let
                  <me>
                    C=\cdots \longrightarrow C_{n} \longrightarrow \cdots C_{1} \stackrel{\delta_{1}}{\longrightarrow} C_{0} \stackrel{\delta_{0}}{\longrightarrow} N \longrightarrow 0
                  </me>
                  be an exact complex. 
                  Every <m>R</m>-module map <m>f: M \rightarrow N</m> lifts to a map of complexes <m>\varphi: P \rightarrow C</m>, and any two such lifts are homotopic.
                </p>
          
                <p>
                  Moreover, if <m>R</m> is a commutative graded <m>k</m>-algebra, <m>M</m> and <m>N</m> are finitely generated graded <m>R</m>-modules, <m>P_{n}</m> and <m>C_{n}</m> are finitely generated graded <m>R</m>-modules, and <m>f</m> is a degree-preserving homomorphism, then the induced map of complexes is made out of degree-preserving <m>R</m> module maps.
                </p>
              </statement>

              <proof>
                <p>
                  Since <m>P_{0}</m> is projective and <m>\delta_{0}</m> is surjective, there exists an <m>R</m>-module homomorphism <m>\varphi_{0}</m> such that
                </p>
        
                <image source="2023_11_20_24b20e755a5fa2ec338dg-08.jpg"/>
          
                <p>
                  commutes. 
                  Notice in fact that
                  <me>
                    \begin{aligned}
                      \delta_{0} \varphi_{0}\left(\operatorname{im} \partial_{1}\right) &amp; \subseteq \delta_{0} \varphi_{0}\left(\operatorname{ker} \partial_{0}\right) &amp; &amp; \text { because } P \text { is a complex } \\
                      &amp; =f \partial_{0}\left(\operatorname{ker} \partial_{0}\right) &amp; &amp; \text { by commutativity of the square above } \\
                      &amp; =0, &amp; &amp;
                    \end{aligned}
                  </me>
                  so <m>\varphi_{0}\left(\operatorname{im} \partial_{1}\right) \subseteq \operatorname{ker} \delta_{0}=\operatorname{im} \delta_{1}</m>. 
                  In the graded case, note that we can define <m>\varphi_{0}</m> by sending the elements <m>b_{i}</m> in a homogeneous basis of <m>P_{0}</m> to homogeneous <m>c_{i} \in C_{0}</m> such that <m>\delta_{0}\left(c_{i}\right)=f \partial_{0}\left(b_{i}\right)</m>.
                </p>
          
                <p>
                  We now proceed by induction. 
                  Suppose we have constructed <m>P_{n}{ }_{1} \stackrel{\varphi_{n}}{\rightarrow} \rightarrow C_{n}{ }_{1}</m> such that <m>\varphi_{n} \quad\left(\operatorname{im} \partial_{n}\right) \subseteq \operatorname{im} \delta_{n}</m>. 
                  Since <m>P_{n}</m> is projective, there exists a map <m>\varphi_{n}</m> such that
                </p>
          
                <image source="2023_11_20_24b20e755a5fa2ec338dg-08(1).jpg"/>
                  
                <p>
                  commutes. 
                  And again,
                </p>
          
                <p>
                  <me>
                    \begin{array}{rlr}
                      \delta_{n} \varphi_{n}\left(\operatorname{im} \partial_{n+1}\right) &amp; \subseteq \delta_{n} \varphi_{n}\left(\operatorname{ker} \partial_{n}\right) \\
                      &amp; =\varphi_{n}{ }_{1} \partial_{n}\left(\operatorname{ker} \partial_{n}\right) \\
                      &amp; =0,
                    \end{array} \quad \text { by commutativity of the square above }
                  </me>
                  so <m>\varphi_{n}\left(\operatorname{im} \partial_{n+1}\right) \subseteq \operatorname{ker} \delta_{n}=\operatorname{im} \delta_{n+1}</m>.
                </p>
          
                <p>
                  We can now inductively construct our map of complexes <m>\varphi</m> lifting <m>f</m>.
                </p>
          
                <p>
                  Now suppose we are given two such maps of complexes <m>P \rightarrow C</m> lifting <m>f</m>, say <m>\varphi</m> and <m>\psi</m>. 
                  Note that <m>\varphi \quad \psi</m> and 0 are two liftings of the zero map. 
                  We are going to show that any map lifting the zero map <m>M \rightarrow N</m> must be nullhomotopic, which will then imply that <m>\varphi</m> and <m>\psi</m> are homotopic as well (essentially via the same homotopy!).
                </p>
          
                <p>
                  So let <m>\varphi: P \rightarrow C</m> be a map of complexes lifting the zero map <m>M \rightarrow N</m>, so that the following commutes:
                </p>
          
                <image source="2023_11_20_24b20e755a5fa2ec338dg-09(2).jpg"/>
                  
                <p>
                  We will explicitly construct a nullhomotopy for <m>\varphi</m> by induction. 
                  First, set <m>h_{n}=0</m> for all <m>n&lt;0</m>. The commutativity of the rightmost square tells us that <m>\delta_{0} \varphi_{0}=0</m>, so
                  <me>
                    \operatorname{im} \varphi_{0} \subseteq \operatorname{ker} \delta_{0}=\operatorname{im} \delta_{1}
                  </me>
                </p>
          
                <p>
                  Since <m>P_{0}</m> is projective, there exists an <m>R</m>-module homomorphism <m>h_{0}</m> such that
                </p>
          
                <image source="2023_11_20_24b20e755a5fa2ec338dg-09(1).jpg"/>
                  
                <p>
                  commutes, and thus <m>\varphi_{0}=\delta_{1} h_{0}=\delta_{1} h_{0}+h_{1} \partial_{0}</m>. Notice also that
                  <me>
                    \begin{aligned}
                      &amp; \delta_{1}\left(\varphi_{1} \quad h_{0} \partial_{1}\right)=\varphi_{0} \partial_{1} \quad \delta_{1} h_{0} \partial_{1} \quad \text { because } \varphi \text { is a map of complexes } \\
                      &amp; =\left(\begin{array}{lll}
                      \varphi_{0} &amp; \delta_{1} h_{0}
                      \end{array}\right) \partial_{1} \quad \text { factoring } \\
                      &amp; =0 \quad \text { since } \varphi_{0}=\delta_{1} h_{0},
                    \end{aligned}
                  </me>
                  so <m>\operatorname{im}\left(\varphi_{1} \quad h_{0} \partial_{1}\right) \subseteq \operatorname{ker} \delta_{1}=\operatorname{im} \delta_{2}</m>.
                </p>
          
                <p>
                  Now assume that we have constructed maps <m>h_{0}, \ldots, h_{n}</m> such that <m>\varphi_{n}=h_{n}{ }_{1} \partial_{n}+\delta_{n+1} h_{n}</m> and <m>\operatorname{im}\left(\varphi_{n+1} \quad h_{n} \partial_{n+1}\right) \subseteq \operatorname{im} \delta_{n+2}</m>. 
                  Since <m>P_{n+1}</m> is projective, we can find a map <m>h_{n+1}</m> such that
                </p>
          
                <image source="2023_11_20_24b20e755a5fa2ec338dg-09.jpg"/>   
          
                <p>
                  commutes, so <m>\varphi_{n+1}=\delta_{n+2} h_{n+1}+h_{n} \partial_{n+1}</m>. 
                  Now
                  <me>
                    \begin{aligned}
                      &amp; \delta_{n+2}\left(\varphi_{n+2} \quad h_{n+1} \partial_{n+2}\right)=\varphi_{n+1} \partial_{n+2} \quad \delta_{n+2} h_{n+1} \partial_{n+2} \quad \text { since } \varphi \text { is a map of complexes } \\
                      &amp; =\left(\varphi_{n+1} \quad \delta_{n+2} h_{n+1}\right) \partial_{n+2} \\
                      &amp; =h_{n} \partial_{n+1} \partial_{n+2} \quad \text { by commutativity of the triangle above } \\
                      &amp; =0 \quad \text { since } \partial_{n+1} \partial_{n+2}=0 \text {. }
                    \end{aligned}
                  </me>
                </p>
          
                <p>
                  So we again obtain <m>\operatorname{im}\left(\varphi_{n+2} \quad h_{n+1} \partial_{n+2}\right) \subseteq \operatorname{ker} \delta_{n+1}=\operatorname{im} \delta_{n+2}</m>. 
                  By induction, this process allows us to construct our homotopy <m>h</m>.
                </p>
              </proof>
            </theorem>

            <theorem xml:id="thm-5.18"><title>Uniqueness of Minimal Free Resolutions</title>
              <statement>
                <p>
                  Let <m>(R, \fm)</m> be a commutative ring, either a local ring or a <m>\mathbb{N}</m>-graded graded <m>k</m>-algebra with <m>R_{0}=k</m> and homogeneous maximal ideal <m>\fm=R_{+}</m>. 
                  If <m>F</m> is a minimal free resolution of <m>M</m>, then any free resolution for <m>M</m> is isomorphic to a direct sum of <m>F</m> with a trivial complex. 
                  In particular, the minimal free resolution of <m>M</m> is unique up to isomorphism.
                </p>
              </statement>

              <proof>
                <p>
                  Suppose that <m>G</m> is another free resolution of <m>M</m>. 
                  By <xref ref="thm-5.17"/>, there are complex maps <m>\psi: G \rightarrow F</m> and <m>\varphi: F \rightarrow G</m> that lift the identity map on <m>M</m>. 
                  Then <m>\psi \varphi: F \rightarrow F</m> is a map of complexes that lifts the identity on <m>M</m>, and thus by <xref ref="thm-5.17"/> <m>\varphi \psi</m> must be homotopic to the identity on <m>F</m>. 
                  Let <m>h</m> be a homotopy between <m>\psi \varphi</m> and the identity, so that for all <m>n</m>,
                  <me>\text { id } \quad \psi_{n} \varphi_{n}=\partial_{n+1} h_{n}+h_{n}{ }_{1} \partial_{n}</me>
                  Since <m>F</m> is minimal, we have <m>\operatorname{im} \partial_{n} \subseteq \fm F_{n}</m> and <m>\operatorname{im} \partial_{n+1} \subseteq \fm F_{n}</m>, so <m>\operatorname{im}\left(\mathrm{id} \quad \psi_{n} \varphi_{n}\right) \subseteq \fm F_{n}</m> for all <m>n</m>. 
                  Our first goal will be to show that <m>\psi \varphi</m> is an isomorphism.
                </p>
          
                <p>
                  First we do the local case. 
                  Let <m>A</m> be the matrix representing <m>\psi_{n} \varphi_{n}</m> in some fixed basis for <m>F_{n}</m>, and note that  <m>\id\psi_{n} \varphi_{n}</m> is represented by <m>\Id-A</m>, so all the entries in  <m>\Id-A</m> must be in <m>\fm</m>. 
                  Our matrix <m>A</m> can be written as
                  <me>
                    A=\left(\begin{array}{cccc}
                      1+a_{11} &amp; a_{12} &amp; \ldots &amp; a_{1 s} \\
                      a_{21} &amp; 1+a_{22} &amp; \cdots &amp; a_{2 s} \\
                      &amp; \ddots &amp; &amp; \\
                      a_{s 1} &amp; \cdots &amp; a_{s s} 1 &amp; 1+a_{s s}
                    \end{array}\right)
                  </me>
                  for some <m>a_{i j} \in</m>, so that <m>\operatorname{det}(A)=1+a</m> for some <m>a \in</m>. 
                  In particular, <m>\operatorname{det}(A)</m> is invertible, and <m>\psi_{n} \varphi_{n}</m> is an isomorphism.
                </p>
          
                <p>
                  In the graded case, we have to be a bit more careful: not all elements that are not in are invertible, this is only true for homogeneous elements. 
                  First, we fix a basis of homogeneous elements <m>f_{1}, \ldots, f_{s}</m> for <m>F_{n}</m> with <m>\operatorname{deg}\left(f_{1}\right) \leqslant \operatorname{deg}\left(f_{2}\right) \leqslant \cdots \leqslant \operatorname{deg}\left(f_{s}\right)</m>, and set <m>\Phi:=</m> id <m>\psi_{n} \varphi_{n}</m>. 
                  Since our map <m>\Phi</m> is degree-preserving, <m>\Phi\left(f_{i}\right)</m> is homogeneous for each <m>i</m>, and so we can write <m>\Phi\left(f_{i}\right)</m> as a linear combination of our basis elements <m>f_{1}, \ldots, f_{s}</m> using only pieces of degree <m>\operatorname{deg}\left(\Phi\left(f_{i}\right)\right)</m>. 
                  We obtain a matrix <m>C=\left(c_{i j}\right)</m> such that <m>c_{i j} \neq 0 \Longrightarrow \operatorname{deg}\left(c_{i j}\right)=\operatorname{deg}\left(f_{j}\right) \operatorname{deg}\left(f_{i}\right)</m>, and <m>C</m> represents <m>\Phi</m>, meaning <m>\Phi\left(f_{i}\right)=c_{i 1} f_{1}+\cdots+c_{i s} f_{s}</m> for all <m>i</m>. 
                  Now all the entries of <m>C=\mathrm{Id} \quad A</m> must be in, so in particular we must have <m>a_{i i}=1</m> for all <m>i</m>. 
                  Moreover, since we chose our basis to have increasing degrees, <m>\operatorname{deg}\left(c_{i j}\right)=0</m> whenever <m>i&lt;j</m>. 
                  Since we must also have <m>c_{i j} \in \fm</m> whenever <m>i \neq j</m>, we conclude that <m>c_{i j}=0</m> for <m>i&lt;j</m>. 
                  We conclude that <m>A</m> is an upper triangular matrix. 
                  Finally, <m>\operatorname{det}(A)=a_{11} \cdots a_{s s}=1</m>, and <m>A</m> is invertible.
                </p>
          
                <p>
                  So we have shown in both cases that <m>\psi_{n} \varphi_{n}</m> is an isomorphism for all <m>n</m>. 
                  By <xref ref="exe-25"/>, <m>\psi \varphi</m> is in fact an isomorphism of complexes, so let <m>\xi: F \rightarrow F</m> be its inverse. 
                  Now we want to claim that <m>\varphi</m> splits as a map of complexes. 
                  Notice that
                  <me>
                    (\xi \psi) \varphi=\xi(\psi \varphi)=\mathrm{id}_{F}
                  </me>
                  so let us take <m>\xi \psi</m> to be our proposed splitting for <m>\varphi</m>.
                  Note that <m>(\xi \psi)_{n} \varphi_{n}=\operatorname{id}_{n}</m> implies that our map <m>\xi \psi</m> provides splittings for the <m>R</m>-module maps in each degree, by <xref ref="lem-2.19"/>, so <m>G_{n}=\varphi_{n}\left(F_{n}\right) \oplus \operatorname{ker}\left(\xi_{n} \psi_{n}\right)</m>. 
                  We just need to prove that this splitting holds as complexes, that is, that <m>G=\varphi(F) \oplus \operatorname{ker}(\xi \psi)</m> as complexes. 
                  So let <m>K:=\operatorname{ker}(\xi \psi)</m>, and denote the differential in <m>G</m> by <m>\delta</m>.
                  We need to check that <m>\delta(\varphi(F)) \subseteq \varphi(F)</m> and <m>\delta(K) \subseteq K</m>.
                </p>
          
                <p>
                  Since <m>\varphi</m> is a map of complexes, <m>\delta \varphi=\varphi \partial</m>, so we do get <m>\delta(\varphi(F)) \subseteq \varphi(F)</m>. 
                  Given <m>a \in K_{n+1}</m>, we can write <m>\delta_{n+1}(a)=\varphi(b)+c</m> for some <m>b \in F_{n}</m> and <m>K_{n}</m>, since <m>G_{n}=\varphi\left(F_{n}\right) \oplus K_{n}</m>. 
                  Then
                  <me>
                    \begin{aligned}
                      b &amp; =\operatorname{id}(b) \\
                      &amp; =\xi_{n} \psi_{n} \varphi_{n}(b) \\
                      &amp; =\xi_{n} \psi_{n}\left(\varphi_{n}(b)+c\right) \\
                      &amp; =\xi_{n} \psi_{n} \delta_{n+1}(a) \\
                      &amp; =\xi_{n} \delta_{n+1} \psi_{n}(a) \\
                      &amp; =\delta_{n+1}\left(\xi_{n} \psi_{n}\right)(a) \\
                      &amp; =0
                    \end{aligned}
                  </me>
                  since <m>\xi_{n} \psi_{n}</m> is a splitting for <m>\varphi_{n}</m> since <m>c \in K_{n}</m> by assumption since <m>\psi</m> is a map of complexes since <m>\xi</m> is a map of complexes since <m>a \in K_{n}</m>.
                </p>
          
                <p>
                  We conclude that <m>\delta_{n+1}(a) \in K_{n}</m>, and <m>\delta(K) \subseteq K</m>.
                  We have now shown that <m>G \cong F \oplus K</m>.
                </p>
          
                <p>
                  Finally, we are going to show that <m>K</m> is a trivial complex. 
                  First, we claim that <m>K_{n}</m> is free for all <m>n</m>. 
                  We have already shown that <m>K_{n}</m> is a (graded) direct summand of a (graded) free module. 
                  In the local case, <xref ref="thm-4.9"/> says that <m>K_{n}</m> is projective, and then <xref ref="exe-62"/> says that <m>K_{n}</m> must in fact be free. 
                  In the graded setting, one can show that any graded module which is a direct sum of a finitely generated graded <m>R</m>-module is a graded free module. 
                  In both cases, <m>K_{n}</m> is free.
                </p>
          
                <p>
                  Since <m>G \cong F \oplus K</m>, we have <m>\mathrm{H}_{n}(G) \cong \mathrm{H}_{n}(F) \oplus \mathrm{H}_{n}(K)</m>. 
                  Since <m>F</m> and <m>G</m> are both (graded) free resolutions for <m>M</m>, they have the same homology: <m>\mathrm{H}_{n}(F)=\mathrm{H}_{n}(G)=0</m> for all <m>n \neq 0</m>, and <m>\mathrm{H}_{0}(F)=\mathrm{H}_{0}(G)=M</m>. 
                  We conclude that <m>K</m> is exact everywhere. 
                  Finally, <xref ref="lem-5.16"/> shows that <m>K</m> is trivial.
                </p>
              </proof>
            </theorem>

            <theorem xml:id="thm-5.19"><title>Horseshoe Lemma</title>
              <statement>
                <p>
                  Consider a short exact sequence of modules
                  <me>
                    0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0
                  </me>
                  Let <m>P</m> be a projective resolution of <m>A</m>, and <m>R</m> be a projective resolution of <m>C</m>. 
                  There exists a projective resolution <m>Q</m> of <m>B</m> and maps of complexes <m>F</m> and <m>G</m> lifting <m>f</m> and <m>g</m> such that
                  <me>
                    0 \longrightarrow P \stackrel{F}{\longrightarrow} Q \stackrel{G}{\longrightarrow} R \longrightarrow 0
                  </me>
                  is a short exact sequence of complexes.
                </p>
              </statement>

              <proof>
                <p>
                  First, we need to introduce some general notation: given homomorphisms <m>f: M \rightarrow L</m> and <m>g: N \rightarrow L</m> with the same target, we will write <m>f \oplus g</m> for the homomorphism <m>M \oplus N \rightarrow L</m> given by <m>(f \oplus g)(m, n)=f(m)+g(n)</m>. 
                  Moreover, we will denote the differential of <m>P</m> by <m>\partial^{P}</m>, and the differential of <m>R</m> by <m>\partial^{R}</m>.
                </p>
          
                <p>
                  For each <m>n \geqslant 0</m>, set <m>Q_{n}:=P_{n} \oplus R_{n}</m>, and let <m>F_{n}: P_{n} \rightarrow Q_{n}</m> and <m>G_{n}: Q_{n} \rightarrow R_{n}</m> be the canonical projections. 
                  By <xref ref="cor-4.11"/>, <m>Q_{n}</m> is projective for all <m>n</m>. 
                  Moreover, we get short exact sequences
                  <me>
                    0 \longrightarrow P_{n} \stackrel{F_{n}}{\longrightarrow} Q_{n} \stackrel{G_{n}}{\longrightarrow} R_{n} \longrightarrow 0
                  </me>
                  for all <m>n</m>. 
                  We will construct the missing differentials <m>\partial^{Q}</m> inductively.
                </p>
          
                <p>
                  Since <m>R_{0}</m> is projective and <m>g</m> is surjective, there exists <m>\gamma</m> such that
                </p>
          
                <image source="2023_11_20_24b20e755a5fa2ec338dg-12(2).jpg"/>
          
                <p>
                  commutes. 
                  Set <m>\partial_{0}^{Q}:=\left(f \partial_{0}^{P}\right) \oplus \gamma</m>. 
                  The universal property of the coproduct guarantees that
                </p>
          
                <image source="2023_11_20_24b20e755a5fa2ec338dg-12.jpg"/>
                  
                <p>
                  commutes. 
                  By the <xref text="title" ref="five-lemma"/>, <m>\partial_{0}^{Q}</m> is surjective. 
                  By the <xref text="title" ref="thm-2.26"/>,
                  <me>
                    \operatorname{ker} \partial_{0}^{P} \longrightarrow \operatorname{ker} \partial_{0}^{Q} \longrightarrow \operatorname{ker} \partial_{0}^{R}
                  </me>
                  is exact. 
                  We then proceed by induction, and at each step we apply the base case to
                </p>
          
                <image source="2023_11_20_24b20e755a5fa2ec338dg-12(1).jpg"/>
                  
                <p>
                  where the vertical arrows are surjective because <m>P</m> and <m>R</m> are projective resolutions and thus exact. 
                  Notice that by construction, the image of <m>\partial_{n+1}^{Q}</m> is contained in <m>\operatorname{ker} \partial_{n}^{Q}</m>, which guarantees that <m>\partial</m> is a differential.
                </p>
          
                <p>
                  This inductive process allows us to build a complex of projectives <m>Q</m> and a short exact sequence of complexes
                  <me>
                    0 \longrightarrow P \stackrel{F}{\longrightarrow} Q \stackrel{G}{\longrightarrow} R \longrightarrow 0 .
                  </me>
                  Applying the <xref text="title" ref="thm-2.28"/>, we get exact sequences
                  <me>
                    0=\mathrm{H}_{n}(P) \rightarrow \mathrm{H}_{n}(Q) \longrightarrow \mathrm{H}_{n}(R)=0
                  </me>
                  for all <m>n \geqslant 1</m>, and thus <m>\mathrm{H}_{n}(Q)=0</m>. 
                  Moreover, we constructed <m>\delta_{0}^{Q}</m> so that
                  <me>
                    Q_{1} \stackrel{\delta_{1}}{\longrightarrow} Q_{0} \longrightarrow B
                  </me>
                  is exact, and thus <m>\mathrm{H}_{0}(Q)=B</m>. We conclude that <m>Q</m> is a projective resolution of <m>B</m>.
                </p>
              </proof>
            </theorem>

            <remark>
              <p>
                why its called that
              </p>
            </remark>

          </subsection>

          <subsection xml:id="subsec-syzygy-betti"><title>Syzygys and Betti Numbers</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>
            
            <p>
              Now that we know that minimal free resolutions exist and are unique (in the local and graded settings), we will take the rest of this section to briefly discuss how minimal free resolutions contain a lot of important information about our modules. For example, we want to keep track of the kernels of the differentials in a minimal free resolution.
            </p>

            <definition xml:id="def-5.20"><title>Syzygy</title>
              <statement>
                <p>
                  Let <m>(R, \fm)</m> be a commutative ring, either a local ring or an <m>\mathbb{N}</m>-graded <m>k</m>-algebra with <m>R_{0}=k</m> and homogeneous maximal ideal <m>\fm=R_{+}</m>. 
                  Let <m>F</m> be a minimal free resolution for the finitely generated (graded) <m>R</m>-module <m>M</m>. 
                  For each <m>n \geqslant 1</m>, the submodule
                  <me>
                    \Omega_{n}(M):=\operatorname{im} \partial_{n}=\operatorname{ker} \partial_{n} 1
                  </me>
                  is the <m>n</m>th <em>syzygy</em> of <m>M</m>.
                </p>
              </statement>
            </definition>

            <remark xml:id="rem-5.21">
              <p>
                For each <m>n</m>, we have a short exact sequence
                <me>
                  0 \longrightarrow \operatorname{ker} \partial_{n} \longrightarrow F_{n} \longrightarrow \operatorname{im} \partial_{n} \longrightarrow 0
                </me>
                But <m>\ker\partial_{n}=\Omega_{n}(M)</m> and <m>\operatorname{im} \partial_{n}=\Omega_{n}{ }_{1}(M)</m>, so we get a short exact sequence
                <me>
                  0 \longrightarrow \Omega_{n}(M) \longrightarrow F_{n} \longrightarrow \Omega_{n}{ }_{1}(M) \longrightarrow 0
                </me>
              </p>
            </remark>

            <p>
              Syzygies are indeed well-defined up to isomorphism.
            </p>

            <proposition xml:id="rem-5.22"><title>Syzygy's Are Well-Defined</title>
              <statement>
                <p>
                  Syzygies are indeed well-defined up to isomorphism.
                </p>
              </statement>
              <proof>
                <p>
                  Suppose that <m>F</m> and <m>G</m> are two minimal free resolutions for <m>M</m>. 
                  By <xref ref="thm-5.18"/>, there exists an isomorphism between <m>F</m> and <m>G</m>, say <m>\varphi</m>. 
                  Since <m>\varphi</m> is a map of complexes, <m>\varphi \partial^{F}=\partial^{G} \varphi</m>, and thus <m>\varphi</m> must send elements in ker <m>\partial^{F}</m> into elements in <m>\ker\partial^{G}</m>. 
                  Similarly, an inverse <m>\psi</m> to <m>\varphi</m> sends ker <m>\partial^{G}</m> into ker <m>\partial^{F}</m>. 
                  In each homological degree, the induced maps <m>\operatorname{ker} \partial_{n}^{F} \rightarrow \operatorname{ker} \partial_{n}^{G}</m> and <m>\operatorname{ker} \partial_{n}^{F} \rightarrow \operatorname{ker} \partial_{n}^{G}</m> are inverse, and thus isomorphisms. 
                  In the graded case, one can show that we obtain graded isomorphisms, so that the graded syzygies are also well-defined up to isomorphism.
                </p>
              </proof>
            </proposition>
      
            <p>
              The number of generators in each homological degree is also an important invariant.
            </p>

            <definition xml:id="def-5.23"><title>Betti Number</title>
              <statement>
                <p>
                  Let <m>(R, \fm)</m> be a commutative ring, either a local ring or an <m>\mathbb{N}</m>-graded <m>k</m>-algebra with <m>R_{0}=k</m> and homogeneous maximal ideal <m>\fm=R_{+}</m>. 
                  Let <m>F</m> be a minimal free resolution for the finitely generated (graded) <m>R</m>-module <m>M</m>. 
                  The <m>n</m>th betti number of <m>M</m> is
                  <me>
                    \beta_{i}(M):=\operatorname{rank} F_{i}=\mu\left(F_{i}\right)
                  </me>
                </p>
              </statement>
            </definition>
      
            <p>
              In the graded case, we can also talk about <em>graded</em> betti numbers.
               When <m>M</m> is a graded module, we can write a resolution that keeps track of the grading.
            </p>

            <definition xml:id="def-5.24"><title>Betti Table</title>
              <statement>
                <p>
                  Let <m>R</m> be a commutative <m>\mathbb{N}</m>-graded graded <m>k</m>-algebra with <m>R_{0}=k</m> and homogeneous maximal ideal <m>=R_{+}</m>. 
                  Let <m>M</m> be a graded <m>R</m>-module. The <m>(i, j)</m> th betti number of <m>M, \beta_{i j}(M)</m>, counts the number of generators of <m>F_{i}</m> in degree <m>j</m>. 
                  We often collect the betti numbers of a module in its <em>betti table</em>:
                </p>
          
                  <tabular>
                  <row header="yes">
                    <cell halign="right"><m>\beta(M)</m></cell>
                    <cell halign="center">0</cell>
                    <cell halign="center">1</cell>
                    <cell halign="center">2</cell>
                    <cell halign="center"><m>\cdots</m></cell>
                  </row>
                  <row>
                    <cell halign="right">0</cell>
                    <cell halign="center"><m>\beta_{00}(M)</m></cell>
                    <cell halign="center"><m>\beta_{01}(M)</m></cell>
                    <cell halign="center"><m>\beta_{02}(M)</m></cell>
                    <cell halign="center"></cell>
                  </row>
                  <row>
                    <cell halign="right">1</cell>
                    <cell halign="center"><m>\beta_{11}(M)</m></cell>
                    <cell halign="center"><m>\beta_{12}(M)</m></cell>
                    <cell halign="center"><m>\beta_{13}(M)</m></cell>
                    <cell halign="center"></cell>
                  </row>
                  <row>
                    <cell halign="right">2</cell>
                    <cell halign="center"><m>\beta_{22}(M)</m></cell>
                    <cell halign="center"><m>\beta_{23}(M)</m></cell>
                    <cell halign="center"></cell>
                    <cell halign="center"></cell>
                  </row>
                  <row>
                    <cell halign="right"><m>\vdots</m></cell>
                    <cell halign="center"></cell>
                    <cell halign="center"></cell>
                    <cell halign="center"><m>\ddots</m></cell>
                    <cell halign="center"></cell>
                  </row>
                  </tabular>
            
              </statement>
            </definition>
      
            <p>
              By convention, the entry corresponding to <m>(i, j)</m> in the betti table of <m>M</m> contains <m>\beta_{i, i+j}(M)</m>, and <m>\operatorname{not} \beta_{i j}(M)</m>. 
              This is how Macaulay2 displays betti tables.
            </p>

            <example xml:id="ex-5.25">
              <p>
                Let <m>R=k[x, y, z]</m> and <m>M=R /(x y, x z, y z)</m>. 
                The minimal free resolution for <m>M</m> is
                <me>
                  \left.0 \longrightarrow R^{2} \stackrel{\left(\begin{array}{cc}
                z &amp; 0 \\
                y &amp; y \\
                0 &amp; x
                \end{array}\right)}{\longrightarrow} R^{3} \longrightarrow x y \quad x z \quad y z\right) \quad R \longrightarrow M \text {. }
              </me>
              </p>
        
              <p>
                From this minimal resolution, we can read the betti numbers of <m>M</m> :
                <ul>
                  <li>
                    <p>
                      <m>\beta_{0}(M)=1</m>, since <m>M</m> is a cyclic module;
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>\beta_{1}(M)=3</m>, and these three quadratic generators live in degree 2;
                    </p>
                  </li>

                  <li>
                    <p>
                      <m>\beta_{2}(M)=2</m>, and these represent linear syzygies on quadrics, and thus live in degree 3 .
                    </p>
                  </li>
                </ul>
              </p>
        
              <p>
                To write a graded free resolution for <m>M</m>, we choose all maps to have degree <m>0</m>, so that the graded free modules in each degree are sums of copies of shifts of <m>R</m>. 
                Here is the graded free resolution of <m>M</m>:
                <me>
                  0 \longrightarrow R(3)^{2} \stackrel{\left(\begin{array}{cc}
                  z &amp; 0 \\
                  y &amp; y \\
                  0 &amp; x
                  \end{array}\right)}{\longrightarrow} R(2)^{3} \longrightarrow x \longrightarrow \text {. }
                </me>
              </p>
        
              <p>
                Notice that the graded shifts in lower homological degrees affect all the higher homological degrees as well. 
                For example, when we write the map in degree <m>2</m>, we only need to shift the degree of each generator by <m>1</m>, but since our map now lands on <m>R(2)^{3}</m>, we have to bump up degrees from <m>2</m> to <m>3</m>, and write <m>R(3)^{2}</m>. 
                The graded betti number <m>\beta_{i j}(M)</m> of <m>M</m> counts the number of copies of <m>R(j)</m> in homological degree <m>i</m> in our resolution. 
                So we have
                <me>
                  \beta_{00}=1, \beta_{12}=3 \text {, and } \beta_{23}=2 \text {. }
                </me>
              </p>
        
              <p>
                We can collect the graded betti numbers of <m>M</m> in its betti table:
              </p>
                    
                <tabular>
                <row header="yes">
                  <cell halign="right"><m>\beta(M)</m></cell>
                  <cell halign="left">0</cell>
                  <cell halign="left">1</cell>
                  <cell halign="left">2</cell>
                  <cell halign="left"></cell>
                </row>
                <row>
                  <cell halign="right">0</cell>
                  <cell halign="left">1</cell>
                  <cell halign="left"></cell>
                  <cell halign="left"></cell>
                  <cell halign="left"></cell>
                </row>
                <row>
                  <cell halign="right">1</cell>
                  <cell halign="left"></cell>
                  <cell halign="left">3</cell>
                  <cell halign="left">2</cell>
                  <cell halign="left"></cell>
                </row>
                </tabular>
              
            </example>

            <example xml:id="ex-5.26">
              <p>
                Let <m>k</m> be a field, <m>R=k[x, y]</m>, and consider the ideal
                <me>
                  I=\left(x^{2}, x y, y^{3}\right)
                </me>
                which has two generators of degree <m>2</m> and one of degree <m>3</m>, so there are graded betti numbers <m>\beta_{12}</m> and <m>\beta_{13}</m>. 
                The minimal free resolution for <m>R / I</m> is
                <me>
                  \begin{aligned}
                  &amp; 0 \longrightarrow \underset{R()^{1}}{R} \stackrel{(3)^{1}}{\left(\begin{array}{cc}
                  y &amp; 0 \\
                  x &amp; y^{2} \\
                  0 &amp; x
                  \end{array}\right)} \underset{\bigoplus^{2}}{\longrightarrow} \stackrel{\left.x^{2} \quad x y y^{3}\right)}{\longrightarrow} R \longrightarrow R / I . \\
                  &amp; R(3)^{1} \\
                  &amp; \beta_{23}(R / I)=1 \beta_{12}(R / I)=2 \\
                  &amp; \beta_{24}(R / I)=1 \beta_{13}(R / I)=1
                  \end{aligned}
                </me>
              </p>
        
              <p>
                So the betti table of <m>R / I</m> is
              </p>
            </example>
      
            <p>
              In fact, even if all we know is the betti numbers of <m>M</m>, there is lots of information to we can extract about <m>M</m>. 
              For more about the beautiful theory of free resolutions and syzygies, see [Eis05]. 
              For a detailed treatment of graded free resolutions, see [Pee11].
            </p>

          </subsection>

          <outcomes>
            <ul>
              <li>
                <p>

                </p>
              </li>
            </ul>
          </outcomes>
          
        </section>

        <section xml:id="sec-inj-res"><title>Injective Resolutions</title>

          <p>
            Injective resolutions are analogous to projective resolutions, but now we want to approximate our module <m>M</m> by injectives.
          </p>

          <definition xml:id="def-5.27"><title>Injective Resolution</title>
            <statement>
              <p>
                Let <m>M</m> be an <m>R</m>-module. 
                An <em>injective resolution</em> of <m>M</m> is a complex
                <me>
                  E=0 \longrightarrow E_{0} \longrightarrow E_{1} \longrightarrow E_{2} \longrightarrow \cdots
                </me>
                with <m>\mathrm{H}_{0}(E)=M</m> and <m>\mathrm{H}_{n}(E)=0</m> for all <m>n \neq 0</m>. 
                We may abuse notation and instead say that an injective resolution of <m>M</m> is an exact sequence
                <me>
                  0 \longrightarrow M \longrightarrow E_{0} \longrightarrow E_{1} \longrightarrow E_{2} \longrightarrow \cdots .
                </me>
              </p>
            </statement>
          </definition>

          <remark xml:id="rem-5.28">
            <p>
              This is the first example we have encountered where we have a <em>cocomplex</em> rather than a complex. 
              Its homology should technically be referred to as <em>cohomology</em>, and written with superscripts:
            </p>
          </remark>

          <p>
            We can construct injective resolutions in a similar fashion to how we constructed projective resolutions.
          </p>

          <theorem xml:id="thm-5.29"><title>Every Module has an Injective Resolution</title>
            <statement>
              <p>
                Every <m>R</m>-module <m>M</m> has an injective resolution.
              </p>
            </statement>

            <proof>
              <p>
                By <xref ref="thm-4.31"/>, every <m>R</m>-module embeds into an injective module. 
                So we start by taking an injective <m>R</m>-module <m>E_{0}</m> containing <m>M</m>, and look at the cokernel of the inclusion:
                <me>
                  0 \longrightarrow M \stackrel{i_{0}}{\longrightarrow} E_{0} \stackrel{\pi_{0}}{\longrightarrow} \text { coker } i_{0} \longrightarrow 0 \text {. }
                </me>
                Now coker <m>i_{0}</m> includes in some other injective module <m>E_{1}</m>.
              </p>

              <image source="2023_11_20_24b20e755a5fa2ec338dg-15.jpg"/>
              <p>

                Take <m>\partial_{0}:=i_{1} \pi_{0}</m>. 
                Since <m>i_{1}</m> is injective,
              </p>
        
              <p>
                <me>
                  \operatorname{ker} \partial_{0}=\operatorname{ker}\left(i_{1} \pi_{0}\right)=\operatorname{ker} \pi_{0}=\operatorname{im} i_{0}
                </me>
              </p>
        
              <p>
                Notice also that coker <m>i_{0}=\operatorname{im} \partial_{0}=\operatorname{ker}\left(E_{1} \rightarrow \operatorname{coker} \partial_{0}\right)</m>. 
                So we can now we continue in a similar fashion, by finding an injective module <m>E_{2}</m> that coker <m>\partial_{0}</m> embeds into.
              </p>
        
              <image source="2023_11_20_24b20e755a5fa2ec338dg-16.jpg"/>
                
              <p>
                By construction and since <m>i_{2}</m> is injective, <m>\operatorname{ker} \partial_{1}=\operatorname{im} \partial_{0}</m>, and our complex is exact at <m>E_{1}</m>. 
                The process continues analogously.
              </p>
            </proof>
          </theorem>
          
          <p>
            We can again define a minimal injective resolution for <m>M</m> as one where at each step we take the smallest injective module that coker <m>i_{n}</m> embeds into; 
            this is called the <em>injective hull</em> of <m>M</m>. 
            Perhaps unsurprisingly, one can show that the minimal injective resolution of a finitely generated module over a local ring is unique up to isomorphism. 
            The analogues to the betti numbers are called <em>Bass numbers</em>, although now there are some major differences. 
            When we construct a minimal free resolution, we have only to count copies of <m>R</m> in each homological degree, while there are many different building clocks for injective modules - the injective hulls of <m>R / P</m>, where <m>P</m> ranges over the prime ideals in <m>R</m>. 
            So for each homological degree <m>i</m>, we get one bass number for each prime ideal <m>P</m>.
          </p>

          <example xml:id="ex-5.30">
            <p>
              Let's construct a minimal free resolution for the abelian group <m>\mathbb{Z}</m>. 
              We start by including <m>\mathbb{Z}</m> in <m>\mathbb{Q}</m>, and then note that the cokernel <m>\mathbb{Q} / \mathbb{Z}</m> is actually injective, by <xref ref="lem-4.26"/> and <xref ref="lem-4.23"/>. 
              So <m>\mathbb{Q} / \mathbb{Z}</m> embeds in itself, and our resolution stops there. So the short exact sequence
              <me>
                0 \longrightarrow \mathbb{Z} \longrightarrow \mathbb{Q} \longrightarrow \mathbb{Q} / \mathbb{Z} \longrightarrow 0
              </me>
              is in fact a minimal injective resolution for <m>\mathbb{Z}</m>.
            </p>
          </example>
          
        </section>
        
      </chapter>

      <chapter xml:id="ch-derived-functors"><title>Derived Functors</title>

        <section xml:id="sec-construction"><title>The General Construction</title>

          <objectives>
            <ul>
              <li>
                
              </li>
            </ul>
          </objectives>

          <subsection xml:id="subsec-derived"><title>Making Sure Derived Functors Make Sense</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>
            
            <p>
              While Hom and tensor are not exact functors, we can measure their lack of exactness using their derived functors Ext and Tor. 
              These are the poster child examples of what are called derived functors, which can be constructed over any abelian category provided we have enough projective or injective objects. 
              In this chapter, we will construct derived functors over <m>R</m>-Mod (which does have enough injectives and enough projectives), and then later we will discuss the general construction.
            </p>
  
            <p>
              We start with the general construction of derived functors, although we will soon focus on concrete examples, most importantly Ext and Tor, the derived functors of hom and tensor.
            </p>
  
            <definition xml:id="def-6.1">
              <statement>
                <p>
                  Definition 6.1 (Derived functors). 
                  Let <m>F: R</m>-Mod <m>\rightarrow S</m>-Mod be a covariant right exact functor. 
                  The left derived functors of <m>F</m> are a sequence of functors
                  <me>L_{i} F: R \text {-Mod } \rightarrow S \text {-Mod, for } i \geqslant 0</me>
                  defined as follows:
                </p>
          
                <p>
                  For each <m>R</m>-module <m>A</m>, fix a projective resolution <m>P</m> of <m>A</m>, and set
                  <me>L_{i} F(A):=\mathrm{H}_{i}(F(P))</me>
                  Given a <m>R</m>-module homomorphism <m>f: A \rightarrow B</m>, fix projective resolutions <m>P</m> of <m>A</m> and <m>Q</m> of <m>B</m>, and a map of complexes <m>\varphi: P \rightarrow Q</m> lifting <m>f</m>. 
                  Then
                  <me>L_{i} F(f):=\mathrm{H}_{i}(F(\varphi))</me>
                </p>
          
                <p>
                  Let <m>F: R</m>-Mod <m>\rightarrow S</m>-Mod be a covariant left exact functor. 
                  The right derived functors of <m>F</m> are a sequence of functors
                  <me>R^{i} F: R \text {-Mod } \rightarrow S \text {-Mod, for } i \geqslant 0</me>
                  defined as follows:
                </p>
          
                <p>
                  For each <m>R</m>-module <m>A</m>, fix an injective resolution <m>E</m> of <m>A</m>, and set
                  <me>R^{i} F(A):=\mathrm{H}^{i}(F(E))</me>
                  Given an <m>R</m>-module homomorphism <m>f: A \rightarrow B</m>, fix injective resolutions <m>E</m> of <m>A</m> and <m>I</m> of <m>B</m>, and a map of complexes <m>\varphi: P \rightarrow Q</m> extending <m>f</m>.
                  Then
                  <me>R^{i} F(f):=\mathrm{H}^{i}(F(\varphi))</me>
                </p>
          
                <p>
                  Let <m>F: R</m>-Mod <m>\rightarrow S</m>-Mod be a contravariant left exact functor. 
                  The right derived functors of <m>F</m> are a sequence of functors
                  <me>R^{i} F: R \text {-Mod } \rightarrow S \text {-Mod, for } i \geqslant 0</me>
                  defined as follows:
                </p>
          
                <p>
                  For each <m>R</m>-module <m>A</m>, fix a projective resolution <m>P</m> of <m>A</m>, and set
                  <me>R^{i} F(A):=\mathrm{H}^{i}(F(P))</me>
                  Given an <m>R</m>-module homomorphism <m>f: A \rightarrow B</m>, fix projective resolutions <m>P</m> for <m>A</m> and <m>Q</m> for <m>B</m>, and a map of complexes <m>\varphi: P \rightarrow Q</m> extending <m>f</m>. 
                  Then
                  <me>R^{i} F(f):=\mathrm{H}^{i}(F(\varphi))</me>
                </p>
          
                <p>
                  Finally, let <m>F: R</m>-Mod <m>\rightarrow S</m>-Mod be a contravariant right exact functor. 
                  The left derived functors of <m>F</m> are a sequence of functors
                  <me>L_{i} F: R \text {-Mod } \rightarrow S \text {-Mod, for } i \geqslant 0</me>
                  defined as follows:
                </p>
          
                <p>
                  For each object <m>A</m> in <m>\mathcal{A}</m>, fix an injective resolution <m>E</m> of <m>A</m>, and set
                  <me>L_{i} F(A):=\mathrm{H}_{i}(F(E))</me>
                  Given an arrow <m>A \stackrel{f}{\rightarrow} B</m>, fix injective resolutions <m>A \rightarrow E</m> and <m>B \rightarrow I</m>, and a map of complexes <m>E \stackrel{\varphi}{\rightarrow} I</m> extending <m>f</m>. 
                  Then
                  <me>L_{i} F(f):=\mathrm{H}_{i}(F(\varphi))</me>
                </p>
              </statement>
            </definition>
      
            <p>
              It is not clear a priori that this construction is well-defined, but we will soon show that is indeed the case.
            </p>
  
            <remark>
              <p>
                Remark 6.2. 
                If <m>F</m> is exact, then <m>\mathrm{H}_{i}(F(C))=F\left(\mathrm{H}_{i}(C)\right)</m>, so <m>L_{i} F=0</m> for all <m>i&gt;0</m>.
              </p>
            </remark>
  
            <remark>
              <p>
                Remark 6.3. 
                If <m>P</m> is projective, then <m>0 \rightarrow P \rightarrow 0</m> is a projective resolution of <m>P</m>, and thus <m>L_{i} F(P)=0</m> for all <m>i&gt;0</m>.
                Similarly, if <m>E</m> is injective then <m>R^{i} F(E)=0</m>.
              </p>
            </remark>
  
            <proposition xml:id="prop-6.4">
              <statement>
                <p>
                  Proposition 6.4. 
                  Let <m>F: R \operatorname{Mod} \rightarrow S</m> Mod be a covariant right exact functor.
                  <ol>
                    <li>
                      <p>
                        <m>L_{i} F(A)</m> is well-de ned up to isomorphism for every object <m>A</m>.
                      </p>
                    </li>
  
                    <li>
                      <p>
                        <m>L_{i} F(f)</m> is well-de ned for every arrow <m>f</m>.
                      </p>
                    </li>
  
                    <li>
                      <p>
                        <m>L_{i} F</m> is an additive functor for each <m>i</m>.
                      </p>
                    </li>
  
                    <li>
                      <p>
                        <m>L_{0} F=F</m>.
                      </p>
                    </li>
                  </ol>
                </p>
              </statement>
  
              <proof>
                <p>
                  <ol>
                    <li>
                      <p>
                        Let <m>P</m> and <m>Q</m> be projective resolutions of <m>A</m>. 
                        Theorem 5.17 gives us maps of complexes <m>\varphi: P \rightarrow Q</m> and <m>\psi: Q \rightarrow P</m> such that <m>\varphi \psi</m> is homotopic to <m>1_{Q}</m> and <m>\psi \varphi</m> is homotopic to <m>1_{P}</m>. 
                        Additive functors preserve homotopies, by Remark 7.35, so <m>F(\varphi) F(\psi)</m> and <m>F(\psi) F(\varphi)</m> are homotopic to the corresponding identity maps. 
                        Homotopic maps induce the same map in homology, by Lemma 2.9. 
                        Therefore, <m>F(\varphi)</m> and <m>F(\psi)</m> induce isomorphisms in homology.
                      </p>
                    </li>
  
                    <li>
                      <p>
                        Fix projective resolutions <m>P</m> and <m>Q</m> of <m>M</m> and <m>N</m>. 
                        Any two lifts <m>\varphi</m> and <m>\psi</m> of <m>f: M \rightarrow N</m> to <m>P \rightarrow Q</m> are homotopic, by Theorem 5.17. 
                        Additive functors preserve homotopies, by Remark 7.35, so <m>F(\varphi)</m> and <m>F(\psi)</m> are homotopic. 
                        Homotopic maps induce the same map in homology, by Lemma 2.9, so <m>L_{i} F(\varphi)=L_{i} F(\psi)</m> for each <m>i</m>.
                      </p>
                    </li>
  
                    <li>
                      <p>
                        Given an arrow <m>f</m>, fix a lift <m>\varphi</m> of <m>f</m> to projective resolutions of the source and target, which exists by Theorem 5.17.
                        Since <m>F</m> is an additive functor, <m>\mathrm{H}_{i}(F(\varphi))</m> is a homomorphism for each <m>i</m>, and thus <m>L_{i} F(f)</m> is a homomorphism between the corresponding Hom-groups, which as we have seen is independent of our choice of <m>\varphi</m>.
                      </p>
                    </li>
  
                    <li>
                      <p>
                        Let <m>A</m> be any <m>R</m>-module and <m>P</m> be a projective resolution of <m>A</m>. 
                        Since <m>P</m> is right exact, and
                        <me>P_{1} \longrightarrow P_{0} \longrightarrow A \longrightarrow 0</me>
                        is exact, then so is
                        <me>F\left(P_{1}\right) \longrightarrow F\left(P_{0}\right) \longrightarrow F(A) \longrightarrow 0</me>
                      </p>
                
                      <p>
                        We claim that <m>\mathrm{H}_{0}(F(P))=F(A)</m>. 
                        The last sequence above says that
                        <me>F(A)=\operatorname{coker}\left(F\left(P_{1}\right) \rightarrow F\left(P_{0}\right)\right),</me>
                        and <m>\mathrm{H}_{0}(F(P))=F\left(P_{0}\right) / \operatorname{im}\left(F\left(P_{1}\right) \rightarrow F\left(P_{0}\right)\right)=\operatorname{coker}\left(F\left(P_{1}\right) \rightarrow F\left(P_{0}\right)\right)</m>.
                      </p>
                    </li>
                  </ol>
                </p>
              </proof>
            </proposition>
  
            <exercise>
              <p>
                Exercise 68. 
                Show that the following holds for every covariant left exact functor <m>F</m> :
                <ol>
                  <li>
                    <p>
                      <m>R^{i} F(A)</m> is well-defined up to isomorphism.
                    </p>
                  </li>
  
                  <li>
                    <p>
                      <m>R^{i} F(f)</m> is well-defined for every arrow <m>f</m>.
                    </p>
                  </li>
  
                  <li>
                    <p>
                      <m>R^{i} F(f)</m> is an additive functor for every <m>i</m>.
                    </p>
                  </li>
  
                  <li>
                    <p>
                      <m>R^{0} F=F</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </exercise>

          </subsection>

          <subsection xml:id="subsec-forcing-exactness"><title>Forcing Exactness</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>

            <p>
              And now we are ready to prove the most important result about derived functors: they fix the lack of exactness of the functor we are deriving, by inducing a long exact sequence in homology from any given short exact sequence.
            </p>
  
            <theorem xml:id="thm-6.5">
              <statement>
                <p>
                  Theorem 6.5. 
                  Let <m>F</m> a right exact covariant functor. 
                  Any short exact sequence
                  <me>0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0</me>
                  induces a natural long exact sequence
                  <me>\cdots \longrightarrow L_{2} F(C) \longrightarrow L_{1} F(A) \longrightarrow L_{1} F(B) \longrightarrow L_{1} F(C) \longrightarrow F(A) \longrightarrow F(B) \longrightarrow F(C) \longrightarrow 0</me>
                </p>
          
                <p>
                  Similarly, if <m>F</m> is a left exact covariant functor, we obtain a long exact sequence
                  <me>0 \longrightarrow F(A) \longrightarrow F(B) \longrightarrow F(C) \longrightarrow R^{1} F(A) \longrightarrow R^{1} F(B) \longrightarrow R^{1} F(C) \longrightarrow R^{2} F(A) \longrightarrow \cdots</me>
                </p>
          
                <p>
                  If <m>F</m> is a contravariant left exact functor, we obtain a natural long exact sequence
                  <me>0 \longrightarrow F(C) \longrightarrow F(B) \longrightarrow F(A) \longrightarrow R^{1} F(C) \longrightarrow R^{1} F(B) \longrightarrow R^{1} F(A) \longrightarrow R^{2} F(C) \longrightarrow \cdots</me>
                </p>
              </statement>
  
              <proof>
                <p>
                  We give a proof for the case of right exact functors, and the remaining cases follow by duality. 
                  We start by fixing projective resolutions <m>P</m> of <m>A</m> and <m>R</m> of <m>C</m>.
                   By Theorem 7.58, we can choose a projective resolution <m>Q</m> of <m>B</m> and lifts of <m>f</m> and <m>g</m> such that
                  <me>0 \longrightarrow P \longrightarrow Q \longrightarrow R \longrightarrow 0</me>
                  is a short exact sequence of complexes. 
                  By Proposition 6.4, <m>L_{i} F</m> does not depend on the choice of resolution, so we can compute <m>L_{i} F(A), L_{i} F(B)</m>, and <m>L_{i} F(C)</m> from <m>P, Q</m>, and <m>R</m>. 
                  Now notice that for each <m>n, R_{n}</m> is projective, so
                  <me>0 \longrightarrow P_{n} \longrightarrow Q_{n} \longrightarrow R_{n} \longrightarrow 0</me>
                  is a split short exact sequence. 
                  Now additive functors preserve split short exact sequences, by Exercise 94, so
                  <me>0 \longrightarrow F\left(P_{n}\right) \longrightarrow F\left(Q_{n}\right) \longrightarrow F\left(R_{n}\right) \longrightarrow 0</me>
                  is a short exact sequence for all <m>n</m>. 
                  Then
                  <me>0 \longrightarrow F(P) \longrightarrow F(Q) \longrightarrow F(R) \longrightarrow 0</me>
                  is a short exact sequence of complexes. 
                  Note, however, that this sequence is not necessarily split anymore, since the splittings at each level do not necessarily assemble into a map of complexes. 
                  The Long Exact Sequence in homology now gives us the long exact sequence we desire.
                </p>
          
                <p>
                  There were many choices along the way. 
                  First, we chose resolutions <m>P, Q</m>, and <m>R</m>, and lifts of <m>f</m> and <m>g</m>. 
                  We have shown our computations of <m>L_{i} F(\quad)</m> are independent of these choices. 
                  We should check, however, that the resulting connecting arrows are natural transformations that do not depend on our choice of lifts.
                  Once a lift is fixed, we know we already have naturality from the Snake Lemma or the Long Exact Sequence in homology.
                  It remains to check naturality. 
                  What is left to check is that given a commutative diagram with exact rows
                </p>
        
                <image source="2023_11_27_3974d73438430121205eg-05(2).jpg"/>
                  
                <p>
                  and chosen lifts of the original short exact sequences to projective resolutions, there are maps of complexes such that
                </p>
          
                <image source="2023_11_27_3974d73438430121205eg-05.jpg"/>
          
                <p>
                  commutes. 
                  Our derived functors <m>L_{i} F</m> will preserve these maps of complexes and the commutativity of the diagram above, so we get commutative diagrams
                </p>
          
                <image source="2023_11_27_3974d73438430121205eg-05(3).jpg"/>
          
                <p>
                  for each <m>i</m>. 
                  First, notice that we know that <m>a, b</m>, and <m>c</m> can be lifted to maps of complexes by Theorem 5.17, and that any two lifts of each <m>a, b</m>, or <m>c</m> are unique up to homotopy. 
                  So let's start by fixing lifts of <m>a</m> and <m>\gamma</m> of <m>c</m>, and we will construct an appropriate lift <m>\beta</m> of <m>b</m>. 
                  Since the short exact sequences
                  <me>0 \longrightarrow P_{n} \longrightarrow Q_{n} \longrightarrow R_{n} \longrightarrow 0</me>
                </p>
          
                <p>
                  split for each <m>n</m>, we might as well assume that <m>Q_{n}=P_{n} \oplus R_{n}</m> and that the arrows <m>P \rightarrow Q</m> and <m>Q \rightarrow R</m> are given by the canonical arrows to and from the product <m>\equiv</m> coproduct in each homological degree. 
                  We cannot, however, assume <m>Q=P \oplus R</m> as complexes, only that <m>Q_{n}=P_{n} \oplus R_{n}</m> in each homological degree <m>n</m>. 
                  The commutativity of
                </p>
        
                <image source="2023_11_27_3974d73438430121205eg-05(1).jpg"/>
                  
                <p>
                  does imply that <m>\partial^{Q}(P) \subseteq P</m>, so we can say that <m>\partial^{Q}</m> is of the form
                  <me>
                    \partial_{n}^{Q}=\left(\begin{array}{cc}
                    \partial_{n}^{P} &amp; \mu_{n} \\
                    0 &amp; \partial_{n}^{R}
                    \end{array}\right)
                  </me>
                  for each <m>n</m>. Since this is a differential, we have
                  <me>\left(\partial_{n}^{Q}\right)^{2}=0 \Longrightarrow \partial_{n}^{P}{ }_{1} \mu_{n}+\mu_{n}{ }_{1} \partial_{n}^{R}=0</me>
                </p>
          
                <p>
                  Similarly, all this applies to <m>\partial_{n}^{Q^{\prime}}</m>, which must be of the form
                  <me>
                    \partial_{n}^{Q^{\prime}}=\left(\begin{array}{cc}
                    \partial_{n}^{P^{\prime}} &amp; \mu_{n}^{\prime} \\
                    0 &amp; \partial_{n}^{R^{\prime}}
                    \end{array}\right)
                  </me>
                </p>
          
                <p>
                  We claim that we can define <m>\beta_{n}=\left(\begin{array}{cc}n &amp; \nu_{n} \\ 0 &amp; \gamma_{n}\end{array}\right)</m> for each <m>n</m> such that <m>\beta</m> is a map of complexes, meaning
                  <me>\partial_{n}^{Q^{\prime}} \beta_{n}=\beta_{n \quad 1} \partial_{n}^{Q}</me>
                </p>
          
                <p>
                  Writing the corresponding products of matrices, we must have
                </p>
          
                <image source="2023_11_27_3974d73438430121205eg-06(1).jpg"/>
                  
                <p>
                  The only nontrivial statement we want to guarantee is that <m>\partial_{n}^{P^{\prime}} \nu_{n}+\mu_{n}^{\prime} \gamma_{n}={ }_{n}{ }_{1} \mu_{n}+\nu_{n}{ }_{1} \partial_{n}^{R}</m>. 
                  We can solve this inductively for each <m>n</m>, and construct an appropriate <m>\nu_{n}</m> inductively. 
                  Given <m>\nu_{n}</m>, set
                  <me>{ }_{n}:={ }_{n}{ }_{1} \mu_{n}+\nu_{n}{ }_{1} \partial_{n}^{R} \quad \mu_{n}^{\prime} \gamma_{n}</me>
                </p>
          
                <p>
                  We want to construct <m>\nu_{n}</m> such that <m>R_{n} \stackrel{\nu_{n}}{\longrightarrow} P_{n}^{\prime} \quad</m> commutes, assuming we have constructed
                </p>
          
                <p>
                  <m>\nu_{n}</m> 1. First, we claim that <m>\partial_{n}^{P^{\prime}}{ }_{1}{ }_{n}=0</m>.
                </p>
          
                <image source="2023_11_27_3974d73438430121205eg-06(2).jpg"/>
                  
                <image source="2023_11_27_3974d73438430121205eg-06(3).jpg"/>
                  
                <p>
                  By induction,
                  <me>\partial_{n}^{P_{1} \nu_{n}{ }_{1}}+\mu_{n{ }_{1}}^{\prime} \gamma_{n}{ }_{1}={ }_{n}{ }_{2} \mu_{n \quad 1}+\nu_{n}{ }_{2} \partial_{n}^{R}{ }_{1}^{R} \text {. }</me>
                </p>
          
                <p>
                  Using this to replace <m>\partial_{n}^{P^{\prime}}{ }_{1} \nu_{n}{ }_{1}</m> in the equation above, we get
                </p>
          
                <image source="2023_11_27_3974d73438430121205eg-06.jpg"/>
          
                <p>
                  <me>
                    \begin{aligned}
                    &amp; ={ }_{n}{ }_{2}{ }_{2} \mu_{n}{ }_{1} \partial_{n}^{R}+\partial_{n}^{P^{\prime}{ }_{1}}{ }_{n}{ }_{1}{ }_{1} \mu_{n}+\nu_{n}{ }_{2} \partial_{n}{ }_{1}^{R} \partial_{n}^{R} \quad \mu_{n}^{\prime}{ }_{1}\left(\partial_{n}^{P^{\prime}} \gamma_{n}+\gamma_{n}{ }_{1} \partial_{n}^{R}\right) \\
                    &amp; ={ }_{n}{ }_{2} \partial_{n}{ }_{1}{ }_{1} \mu_{n}+\partial_{n}^{P^{\prime}{ }_{1}}{ }_{n}{ }_{1}{ }_{1} \mu_{n}+\nu_{n}{ }_{2} \partial_{n}{ }_{1}{ }_{1} \partial_{n}^{R} \quad \mu_{n}^{\prime}{ }_{1}\left(\partial_{n}^{P^{\prime}} \gamma_{n}+\gamma_{n}{ }_{1} \partial_{n}^{R}\right)
                    \end{aligned}
                  </me>
                </p>
          
                <p>
                  We showed above that <m>\partial_{n}^{P^{\prime}} \gamma_{n}+\gamma_{n}{ }_{1} \partial_{n}^{R}=0</m>. 
                  Moreover, <m>\partial_{n}^{R}{ }_{1} \partial_{n}^{R}=0</m>. 
                  We conclude that
                  <me>
                    \begin{array}{rlr}
                    \partial_{n{ }_{1}{ }_{n}}^{P^{\prime}} &amp; ={ }_{n}{ }_{2} \partial_{n}^{P}{ }_{1} \mu_{n}+\partial_{n}^{P_{1}}{ }_{1}{ }_{n}{ }_{1} \mu_{n} &amp; \\
                    &amp; ={ }_{n}{ }_{2} \partial_{n}^{P}{ }_{1} \mu_{n}+{ }_{n}{ }_{2} \partial_{n}^{P^{\prime}} \mu_{n} &amp; \text { since } \quad \text { is a map of complexes } \\
                    &amp; ={ }_{n}{ }_{2}\left(\partial_{n}^{P}{ }_{1} \mu_{n}+\partial_{n}^{P^{\prime}} \mu_{n}\right) &amp; \\
                    &amp; =0 &amp; \text { since } \partial_{n}^{P}{ }_{1} \mu_{n}+\partial_{n}^{P^{\prime}} \mu_{n}=0 .
                    \end{array}
                  </me>
                </p>
          
                <p>
                  So this concludes the proof that <m>\partial_{n}^{P^{\prime}}{ }_{1}{ }_{n}=0</m>. 
                  Therefore, <m>{ }_{n}</m> must factor through the <m>\operatorname{ker} \partial_{n}^{P^{\prime}}{ }_{1}</m> :
                </p>
          
                <image source="2023_11_27_3974d73438430121205eg-07(2).jpg"/>
          
                <p>
                  On the other hand, <m>P^{\prime}</m> is a resolution and thus exact, so <m>\operatorname{im} \partial_{n}=\operatorname{ker} \partial_{n} 1</m>, and <m>\partial_{n}</m> factors through <m>\operatorname{ker} \partial_{n}{ }_{1}</m> as
                </p>
          
                <image source="2023_11_27_3974d73438430121205eg-07(1).jpg"/>
                  
                <p>
                  via some epi <m>\varphi_{n}</m>. 
                  Finally, <m>R_{n}</m> is projective, so there exists <m>\nu_{n}</m> such that
                </p>
          
                <image source="2023_11_27_3974d73438430121205eg-07.jpg"/>
                  
                <p>
                  commutes - this was the <m>\nu_{n}</m> we were searching for.
                </p>
              </proof>
            </theorem>
  
            <theorem xml:id="thm-6.6">
              <statement>
                <p>
                  Let <m>T_{i}: R \operatorname{Mod} \rightarrow S</m> Mod be a sequence of additive covariant functors, and <m>F: R \operatorname{Mod} \rightarrow S</m> Mod a right exact functor. 
                  Suppose that the following hold:
                  <ol>
                    <li>
                      <p>
                        For every short exact sequence <m>0 \longrightarrow A \longrightarrow B \longrightarrow C \longrightarrow 0</m> in <m>R</m> Mod, we get a natural long exact sequence
                        <me>\cdots \longrightarrow T_{2}(C) \longrightarrow T_{1}(A) \longrightarrow T_{1}(B) \longrightarrow T_{1}(C) \longrightarrow T_{0}(A) \longrightarrow T_{0}(B) \longrightarrow T_{0}(C) \longrightarrow 0</me>
                      </p>
                    </li>
  
                    <li>
                      <p>
                        <m>T_{0}</m> is naturally isomorphic to <m>F</m>.
                      </p>
                    </li>
  
                    <li>
                      <p>
                        <m>T_{n}(P)=0</m> for every projective <m>P</m> and all <m>n \geqslant 1</m>.
                      </p>
                    </li>
                  </ol>
                  Then <m>T_{n}</m> is naturally isomorphic to <m>L_{n} F</m> for all <m>n \geqslant 0</m>.
                </p>
              </statement>
  
              <proof>
                <p>
                  We are going to show that <m>T_{n}</m> is naturally isomorphic to <m>L_{n} F</m> by all <m>n</m>. 
                  The statement for <m>n=0</m> is one of our assumptions. 
                  When <m>n=1</m>, fix an <m>R</m>-module <m>M</m>, and consider a short exact sequence
                  <me>0 \longrightarrow K \stackrel{f}{\longrightarrow} P \longrightarrow M \longrightarrow 0</me>
                  with <m>P</m> projective. 
                  By assumption (1), we get a long exact sequence on the <m>T_{i}</m>, and by (2), there exist isomorphisms <m>\tau_{0}</m> such that the following is a commutative diagram:
                </p>
          
                <image source="2023_11_27_3974d73438430121205eg-07(3).jpg"/>
          
                <p>
                  By <m>(3), T_{1}(P)=0</m>, and <m>L_{1} F(P)=0</m> by construction. 
                  The exactness of each row now implies that <m>\Delta_{1}</m> and <m>\delta_{1}</m> are both injective. 
                  Moreover,
                  <me>
                    \begin{array}{rlr}
                    F(f) \tau_{0}(K) \Delta_{1} &amp; =\tau_{0}(P) T_{0}(f) \Delta_{1} &amp; \text { by commutativity of the diagram } \\
                    &amp; =0 &amp; \text { since } T_{0}(f) \Delta_{1}=0 .
                    \end{array}
                  </me>
                  so the image of <m>\tau(k) \Delta_{1}</m> is contained in <m>\operatorname{ker} F(f)=\operatorname{im} \delta_{1}</m>. 
                  Define <m>\tau_{1}(M): T_{1}(M) \rightarrow L_{1} F(M)</m> as follows: 
                  we send each <m>a \in T_{1}(M)</m> to the unique <m>b \in L_{1} F(M)</m> such that <m>\delta_{1}(b)=\tau_{0}(K) \Delta_{1}(a)</m>. 
                  This is a homomorphism of <m>R</m>-modules because so are <m>\delta_{1}, \tau_{0}(K)</m>, and <m>\Delta_{1}</m>. 
                  Moreover, since <m>\tau_{0}(K)</m> is an isomorphism and <m>\Delta_{1}</m> is injective, the composition <m>\tau_{0}(K) \Delta_{1}</m> is injective. 
                  As a consequence, <m>\tau_{1}(M)</m> is injective. 
                  On the other hand, we claim that <m>\tau_{1}(M)</m> is also surjective. 
                  Given any <m>b \in L_{1} F(M)</m>, since <m>\tau_{0}(K)</m> is an isomorphism there exists <m>c \in T_{0}(K)</m> such that <m>\tau_{0}(K)(c)=\delta_{1}(b)</m>. 
                  Thus
                  <me>
                    \begin{array}{rlr}
                    \tau_{0}(P) T_{0}(f)(c) &amp; =F(f) \tau_{0}(K)(c) &amp; \text { by commutativity } \\
                    &amp; =F(f) \delta_{1}(b) &amp; \text { since } \tau_{0}(K)(c)=\delta_{1}(b) \\
                    &amp; =0 &amp; \text { since the bottom row is a complex }
                    \end{array}
                  </me>
                </p>
          
                <p>
                  Since <m>\tau_{0}(P)</m> is an iso, we must have <m>c \in \operatorname{ker}\left(T_{0}(f)\right)=\operatorname{im} \Delta_{1}</m>. 
                  Thus we can choose <m>a \in T_{1}(M)</m> such that <m>\Delta_{1}(a)=c</m>, which implies that <m>\tau_{1}(M)(a)=b</m>. 
                  Therefore, <m>\tau_{1}(M)</m> is an isomorphism.
                </p>
          
                <p>
                  This shows that <m>T_{1}(M) \cong L_{1} F(M)</m>. 
                  Now let <m>n \geqslant 1</m>, and consider the diagram with exact rows
                  <me>
                    \begin{gathered}
                    T_{n+1}(P) \longrightarrow T_{n+1}(M) \stackrel{\Delta_{n} 1}{\longrightarrow} T_{n}(K) \longrightarrow T_{n}(P) \\
                    L_{n+1} F(P) \longrightarrow L_{n+1} F(M) \underset{\delta_{n \quad 1}}{\longrightarrow} L_{n} F(K) \longrightarrow L_{n} F(P)
                    \end{gathered}
                  </me>
                </p>
          
                <p>
                  By (3), <m>T_{n+1}(P)=0=T_{n}(P)</m>, and by construction <m>L_{n+1} F(P)=0=L_{n} F(P)</m>. 
                  Therefore, <m>\Delta_{n+1}</m> and <m>\delta_{n+1}</m> are isomorphisms. 
                  Since <m>\tau_{n}(K)</m> is also an isomorphism, we conclude that <m>T_{n+1}(M) \cong L_{n+1} F(M)</m>. 
                  Therefore, <m>T_{n}(M) \cong L_{n} F(M)</m> for all <m>n</m>.
                </p>
          
                <p>
                  It remains to show that these isomorphisms are natural, that is, that any <m>R</m>-module map <m>f: M \rightarrow N</m> gives rise to commutative diagrams
                </p>
          
                <image source="2023_11_27_3974d73438430121205eg-08.jpg"/>
                  
                <p>
                  We will prove this by induction on <m>i</m>. 
                  First, note that the commutativity of the square holds for <m>i=0</m> by (2). 
                  Let <m>i \geqslant 1</m>. 
                  Fix projectives <m>P</m> and <m>Q</m> and short exact sequences
                  <me>0 \longrightarrow K \longrightarrow P \longrightarrow M \longrightarrow 0 \quad \text { and } \quad 0 \longrightarrow C \longrightarrow Q \longrightarrow N \longrightarrow</me>
                </p>
          
                <p>
                  Since <m>Q</m> is projective and <m>Q \rightarrow N</m> is surjective, <m>f</m> lifts to a map <m>g: P \rightarrow Q</m>.
                  Moreover, an argument similar to the one we used above shows that we can define a map <m>h</m> giving a commutative diagram
                </p>
          
                <image source="2023_11_27_3974d73438430121205eg-09.jpg"/>
                  
                <p>
                  Now consider the following diagram:
                </p>
          
                <image source="2023_11_27_3974d73438430121205eg-09(1).jpg"/>
                  
                <p>
                  The big square and (1) commute by definition of <m>\tau_{i}</m>.
                </p>
          
                <p>
                  The square (3) commutes because we assumed in (1) that <m>T_{i}</m> gives rise to long exact sequences which are natural.
                </p>
          
                <p>
                  The square (5) commutes because <m>L_{i} F</m> gives rise to natural long exact sequences, by Theorem 6.5.
                </p>
          
                <p>
                  The square (4) commutes by induction hypothesis.
                </p>
          
                <p>
                  Our goal is to show that (2) commutes. 
                  First, we claim that
                  <me>\delta_{i} \circ \tau_{i}(N) \circ T_{i}(f)=\delta_{i} \circ L_{i} F(f) \circ \tau_{i}(M)</me>
                  Indeed, using the commutativity of the various other parts of the diagram, we get
                  <me>
                    \begin{array}{rlr}
                    \delta_{i} \circ \tau_{i}(N) \circ T_{i}(f) &amp; =\tau_{i}{ }_{1}(C) \circ \Delta_{i} \circ T_{i}(f) &amp; \text { by commutativity of (1) } \\
                    &amp; =\tau_{i}{ }_{1}(C) \circ T_{i}{ }_{1}(h) \circ \Delta_{i} &amp; \text { by commutativity of (3) } \\
                    &amp; =L_{i}{ }_{1} F(h) \circ \tau_{i}{ }_{1}(K) \circ \Delta_{i} &amp; \text { by commutativity of (4) } \\
                    &amp; =L_{i}{ }_{1} F(h) \circ \delta_{i} \circ \tau_{i}(M) &amp; \text { by commutativity of the big square } \\
                    &amp; =\delta_{i} \circ L_{i} F(f) \circ \tau_{i}(M) &amp; \text { by commutativity of (5). }
                    \end{array}
                  </me>
                </p>
          
                <p>
                  On the other hand, the long exact sequence for <m>L_{i} F</m> from Theorem 6.5 says that
                  <me>L_{i} F(Q) \longrightarrow L_{i} F(N) \stackrel{\delta_{i}}{\longrightarrow} L_{i}{ }_{1} F(C)</me>
                  is exact, but since <m>i \geqslant 1</m> and <m>Q</m> is projective we have <m>L_{i} F(Q)=0</m> by Remark 6.3. 
                  But the exactness of
                  <me>0 \longrightarrow L_{i} F(N) \stackrel{\delta_{i}}{\longrightarrow} L_{i}{ }_{1} F(C)</me>
                  says that <m>\delta_{i}</m> is injective. 
                  Therefore,
                  <me>\delta_{i} \circ \tau_{i}(N) \circ T_{i}(f)=\delta_{i} \circ L_{i} F(f) \circ \tau_{i}(M) \Longrightarrow \tau_{i}(N) \circ T_{i}(f)=L_{i} F(f) \circ \tau_{i}(M),</me>
                  and 2 commutes, as desired.
                </p>
              </proof>
            </theorem>
  
            <p>
              There are versions of this theorem for the three remaining cases as well; we record one of them here:
            </p>
  
            <theorem xml:id="thm-6.7">
              <statement>
                <p>
                  Suppose <m>T_{i}: R \operatorname{Mod} \rightarrow S</m> Mod is a sequence of additive covariant functors and <m>F: R \operatorname{Mod} \rightarrow S</m> Mod a left exact functor such that
                  <ol>
                    <li>
                      <p>
                        For every short exact sequence <m>0 \longrightarrow A \longrightarrow B \longrightarrow C \longrightarrow</m> in <m>R</m> Mod, we get a long exact sequence
                        <me>0 \longrightarrow T_{0}(A) \longrightarrow T_{0}(B) \longrightarrow T_{0}(C) \longrightarrow T_{1}(A) \longrightarrow T_{1}(B) \longrightarrow T_{1}(C) \longrightarrow \cdots</me>
                      </p>
                    </li>
  
                    <li>
                      <p>
                        <m>T_{0}</m> is naturally isomorphic to <m>F</m>.
                      </p>
                    </li>
  
                    <li>
                      <p>
                        <m>T_{n}(E)=0</m> for every injective <m>E</m> and all <m>n \geqslant 1</m>.
                      </p>
                    </li>
                  </ol>
                  Then <m>T_{n}</m> is naturally isomorphic to <m>R^{n} F</m> for all <m>n</m>.
                </p>
              </statement>
            </theorem>
  
            <p>
              We leave the proof of this and the other two cases as an exercise.
            </p>
            
          </subsection>

          <outcomes>
            <ul>
              <li>
                <p>

                </p>
              </li>
            </ul>
          </outcomes>
          
        </section>

        <section xml:id="sec-ext-tor"><title>A First Look at <m>\Ext</m> and <m>\Tor</m></title>

          <objectives>
            <ul>
              <li>
                
              </li>
            </ul>
          </objectives>

          <subsection xml:id="subsec-double-complexes"><title>Double Complexes</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>

            <p>
              It's time to return to study some concrete examples of derived functors: Ext, the derived functor of Hom, and Tor, the derived functor of tensor. 
              Given two modules <m>M</m> and <m>N</m>, we may consider the derived functors of <m>M \otimes_{R}</m>, and then plug in <m>N</m>, or we may consider the derived functors of <m>\otimes_{R} N</m>, and plug in <m>M</m>; 
              it turns out that the two are naturally isomorphic, and this is the Tor functor:
              <me>\operatorname{Tor}_{i}^{R}(M, N):=L_{i}\left(M \otimes_{R}\right)(N) \cong L_{i}\left(\otimes_{R} N\right)(M)</me>
            </p>
      
            <p>
              More precisely, if <m>P</m> is a projective resolution of <m>M</m>, and <m>Q</m> is a projective resolution of <m>N</m>,
              <me>\operatorname{Tor}_{i}^{R}(M, N):=\mathrm{H}_{i}\left(P \otimes_{R} N\right) \cong \mathrm{H}_{i}\left(M \otimes_{R} Q\right) .</me>
            </p>
      
            <p>
              There are two Hom functors, each with its own derived functor: given <m>R</m>-modules <m>M</m> and <m>N</m>, we may take a projective resolution <m>P</m> of <m>M</m>, and compute <m>\mathrm{H}^{i}\left(\operatorname{Hom}_{R}(P, N)\right)</m>, or we could take an injective resolution <m>E</m> of <m>N</m>, and compute <m>\mathrm{H}^{i}\left(\operatorname{Hom}_{R}(M, E)\right)</m>. 
              It turns out these two completely different sounding constructions give us isomorphic <m>R</m>-modules:
              <me>
                \begin{aligned}
                \operatorname{Ext}_{R}^{i}(M, N) &amp; :=R^{i}\left(\operatorname { H o m } _ { R } ( M , \quad ) ( N ) \cong R ^ { i } \left(\operatorname{Hom}_{R}(, N)(M)\right.\right. \\
                &amp; \cong \mathrm{H}^{i}\left(\operatorname{Hom}_{R}(P, N)\right) \cong \mathrm{H}^{i}\left(\operatorname{Hom}_{R}(M, E)\right)
                \end{aligned}
              </me>
            </p>
      
            <p>
              To show that for each of Ext and Tor these two seemingly unrelated definitions agree, we will need some more tools.
            </p>
  
            <definition xml:id="def-6.8">
              <statement>
                <p>
                  The suspension or shift of a complex <m>C</m> is the complex <m>\Sigma C:=C[1]</m> with
                  <me>(\Sigma C)_{n}=C_{n} \quad \text { and } \quad \partial^{\Sigma C}=\partial^{C} \text {. }</me>
                </p>
          
                <p>
                  Given an integer <m>k</m>, the <m>k</m> th suspension of <m>C</m> is the complex
                  <me>\Sigma^{k} C:=\underbrace{\sum \cdots \Sigma}_{k \text { times }} C \quad \text { with } \partial^{\Sigma^{k} C}=(1)^{k} \partial^{C}</me>
                </p>
              </statement>
            </definition>
      
            <p>
              Note that there are two conventions in the literature, the other one being <m>(\Sigma C)_{n}=C_{n+1}</m>.
            </p>
  
            <definition xml:id="def-6.9">
              <statement>
                <p>
                  A (homological) double complex over the ring <m>R</m> is a family of <m>R</m>-modules <m>\left\{C_{p, q}\right\}_{p, q \in \mathbb{Z}}</m> together with homomorphisms of <m>R</m>-modules <m>d^{h}: C_{p, q} \rightarrow C_{p} \quad{ }_{1, q}</m> and <m>d^{v}: C_{p, q} \rightarrow</m> <m>C_{p, q} 1</m> satisfying
                </p>
          
                <image source="2023_11_27_3974d73438430121205eg-11.jpg"/>
                  
                <p>
                  <me>d^{h} d^{h}=0 \quad d^{v} d^{v}=0 \quad d^{h} d^{v}+d^{v} d^{h}=0</me>
                </p>
              </statement>
            </definition>
  
            <remark>
              <p>
                Remark 6.10. Note that if <m>C</m> is a double complex, then each row and each column is a complex: 
                if we fix <m>p, C_{p, \bullet}</m> is a complex with differential <m>d^{v}</m>; 
                if we fix <m>q, C_{\bullet, q}</m> is a complex with differential <m>d^{h}</m>.
              </p>
            </remark>
  
            <p>
              What we defined above is a homological double complex. 
              A cohomological double complex would have vertical and horizontal maps that go up in index, and we instead write <m>C^{p, q}</m> for the module in position <m>(p, q)</m>. Also, please note that there are different conventions in the literature for whether <m>p</m> refers to the row or column.
            </p>
  
            <definition xml:id="def-6.11">
              <statement>
                <p>
                  Given a double complex <m>C</m>, its total complex is the complex given by
                  <me>\operatorname{Tot}^{\oplus}(C)_{n}:=\bigoplus_{p+q=n} C_{p, q} \quad \text { with differential } d=d^{h}+d^{v}</me>
                </p>
          
                <p>
                  Similarly, the product total complex of <m>C</m> is given by
                  <me>\operatorname{Tot}^{\Pi}(C)_{n}:=\prod_{p+q=n} C_{p, q} \quad \text { with differential } d=d^{h}+d^{v}</me>
                </p>
              </statement>
            </definition>
  
            <remark>
              <p>
                Remark 6.12. Let <m>C</m> be a double complex with differentials <m>d^{v}</m> and <m>d^{h}</m>. Then
              </p>
        
              <p>
                <me>\left(d^{h}+d^{v}\right)\left(d^{h}+d^{v}\right)=\underbrace{d^{h} d^{h}}_{0}+\underbrace{d^{h} d^{v}+d^{v} d^{h}}_{0}+\underbrace{d^{v} d^{v}}_{0}=0</me>
              </p>
        
              <p>
                so <m>\left(\operatorname{Tot}^{\oplus}(C), d\right)</m> and <m>\left(\operatorname{Tot}^{\Pi}(C), d\right)</m> are indeed complexes.
              </p>
            </remark>
  
            <p>
              In order to prove our two definitions of Ext and Tor each agree, we will need two special double complexes: the tensor and the Hom double complex.
            </p>
  
            <definition xml:id="def-6.13">
              <statement>
                <p>
                  Definition 6.13. 
                  Let <m>R</m> be a ring and <m>C</m> and <m>D</m> be complexes of <m>R</m>-modules. 
                  The tensor product double complex of <m>C</m> and <m>D</m> is the double complex <m>C \otimes D</m> given by taking
                  <me>(C \otimes D)_{p, q}=C_{p} \otimes D_{q} \quad d^{h}=\partial^{C} \otimes_{R} 1_{D}, \quad \text { and } \quad d^{v}=(1)^{p} 1_{C} \otimes_{R} \partial^{D}</me>
                </p>
          
                <p>
                  We call the total complex of the tensor product double complex of <m>C</m> and <m>D</m> the tensor product of <m>C</m> and <m>D</m> in <m>\mathrm{Ch}(R)</m>, and denote it by <m>C \otimes D</m>.
                </p>
              </statement>
            </definition>
  
            <remark>
              <p>
                Remark 6.14. 
                The tensor product total complex has
                <me>\operatorname{Tot}^{\oplus}(C \otimes D)_{n}=\bigoplus_{p+q=n} C_{n} \otimes_{R} D_{n}</me>
                and differential
                <me>d(x \otimes y)=\partial(x) \otimes y+(1)^{p} x \otimes \partial(y)</me>
                for <m>x \in C_{p}</m> and <m>y \in D_{q}</m>.
              </p>
            </remark>
  
            <definition xml:id="def-6.15">
              <statement>
                <p>
                  Let <m>R</m> be a ring and <m>C</m> and <m>D</m> be complexes of <m>R</m>-modules. 
                  The Hom double complex of <m>C</m> and <m>D</m> is the double complex <m>\operatorname{Hom}(C, D)</m> given by
                  <me>(\operatorname{Hom}(C, D))_{p, q}:=\operatorname{Hom}_{R}\left(C_{p}, D_{q}\right)</me>
                  with differentials
                  <me>
                    \begin{array}{cr}
                    \operatorname{Hom}_{R}\left(C_{p}, D_{q}\right) \stackrel{d^{h}}{\longrightarrow} \operatorname{Hom}_{R}\left(C_{p}{ }_{1}, D_{q}\right) &amp; \text { and } \operatorname{Hom}_{R}\left(C_{p}, D_{q}\right) \stackrel{d^{v}}{\longrightarrow} \operatorname{Hom}_{R}\left(C_{p}, D_{q}{ }^{1}\right) . \\
                    f \stackrel{C}{ } \stackrel{f}{\longrightarrow}(1)^{p+q+1} \partial^{D} \circ f
                    \end{array}
                  </me>
                </p>
          
                <p>
                  We call the product total complex of the Hom double complex of <m>C</m> and <m>D</m> the (internal) Hom complex of <m>C</m> and <m>D</m>, and denote it by <m>\operatorname{Hom}(C, D)</m>.
                </p>
              </statement>
            </definition>
  
            <remark>
              <p>
                Remark 6.16. 
                The Hom complex of <m>C</m> and <m>D</m> is the complex
                <me>\operatorname{Hom}(C, D)_{n}=\prod_{p+q=n} \operatorname{Hom}_{R}\left(C_{p}, D_{q}\right)</me>
                with differential <m>d(f)=f \circ \partial^{C}+(1)^{p+q+1} \partial^{D} \circ f</m> for each <m>f \in \operatorname{Hom}_{R}\left(C_{p}, D_{q}\right)</m>.
              </p>
            </remark>
  
            <remark>
              <p>
                Remark 6.17. 
                Given <m>C</m> and <m>D</m> in <m>\mathrm{Ch}(R)</m>, what is a 0 -cycle in the Hom complex <m>\operatorname{Hom}(C, D)</m> ? A 0 -cycle is a sequence of maps of <m>R</m>-modules <m>f_{k}: C_{k} \rightarrow D_{k}</m> satisfying <m>f \partial^{C} \quad \partial^{D} f=0</m>, so the 0 -cycles are precisely the maps of complexes <m>C \rightarrow D</m>. 
                Similarly, a sequence of maps <m>f_{k}: C_{k} \rightarrow D_{k}</m> is a 0-boundary if there exists a sequence of maps <m>h_{k}: C_{k} \rightarrow D_{k+1}</m> such that <m>f_{k}=\partial^{D} h_{k}+h_{k}{ }_{1} \partial^{C}</m>. 
                In other words, a 0-boundary indicates a homotopy relation - if <m>f \quad g</m> is a 0-boundary, <m>f</m> and <m>g</m> are homotopic maps.
              </p>
            </remark>
  
            <definition xml:id="def-6.18">
              <statement>
                <p>
                  Let <m>f: C \rightarrow D</m> be a map of complexes. 
                  The cone of <m>f</m> is the complex cone <m>(f)</m> with cone <m>(f)_{n}=C_{n} \quad 1 \oplus D_{n}</m> and differential given by
                  <me>
                    \partial_{n}:=\left(\begin{array}{cc}
                    \partial_{C} &amp; 0 \\
                    f &amp; \partial_{D}
                    \end{array}\right): \begin{array}{cc}
                    C_{n} &amp; 1 \stackrel{\partial^{C}}{\longrightarrow} C_{n} \quad 2 \\
                    &amp; \oplus D_{n} \underset{\partial^{D}}{\longrightarrow} D_{n} \quad 1
                    \end{array}
                  </me>
                </p>
              </statement>
            </definition>
  
            <remark>
              <p>
                Remark 6.19. 
                There are different conventions for the sign in front of <m>f</m> in the definition of the differentials on the cone of <m>f</m>. 
                Weibel [Wei94] defines
                <me>
                  \partial_{n}:=\left(\begin{array}{cc}
                  \partial_{C} &amp; 0 \\
                  f &amp; \partial_{D}
                  \end{array}\right)
                </me>
                and some authors even write
                <me>
                  \partial_{n}:=\left(\begin{array}{cc}
                  \partial_{C} &amp; 0 \\
                  (1)^{n} f &amp; \partial_{D}
                  \end{array}\right)</me>
                </p>
            </remark>
  
            <p>
              All of these choices do make our proposed differential a differential (check it!). 
              The facts below about the mapping cone are all true up to sign whatever the sign convention we follow.
            </p>
  
            <exercise>
              <p>
                Exercise 69. 
                Let <m>f: C \rightarrow</m> be a map of complexes. 
                Show that giving a map of complexes cone <m>(f) \rightarrow E</m> is the same as giving a map of complexes <m>D \stackrel{g}{\rightarrow} E</m>, and a homotopy between <m>g f</m> and 0 .
              </p>
            </exercise>
  
            <exercise>
              <p>
                Exercise 70. 
                Let <m>f: A \rightarrow B</m> be a map of complexes. 
                Show that <m>f</m> is nullhomotopic if and only of <m>f</m> factors through the canonical map <m>A \rightarrow \operatorname{cone}\left(\operatorname{id}_{A}\right)</m>.
              </p>  
            </exercise>
  
            <remark>
              <p>
                Remark 6.20. 
                Given any map of complexes <m>C \stackrel{f}{\longrightarrow} D</m>, there is a short exact sequence
                <me>0 \longrightarrow D \longrightarrow \operatorname{cone}(f) \longrightarrow \Sigma^{1} C \longrightarrow 0</me>
                determined by the canonical arrows to and from the product <m>\equiv</m> coproduct. 
                The connecting arrows from the Snake Lemma
                <me>\mathrm{H}_{n \quad 1}(C)=\mathrm{H}_{n}\left(\Sigma{ }^{1} C\right) \stackrel{\delta}{\longrightarrow} \mathrm{H}_{n \quad 1}(D)</me>
                are exactly <m>\mathrm{H}_{n} \quad 1(f): \mathrm{H}_{n} \quad{ }_{1}(C) \rightarrow \mathrm{H}_{n} \quad{ }_{1}(D)</m> induced by <m>f</m>, so there is a long exact sequence
                <me>\cdots \longrightarrow \mathrm{H}_{n+1}(\operatorname{cone}(f)) \longrightarrow \mathrm{H}_{n}(C) \stackrel{\mathrm{H}_{n}(f)}{\longrightarrow} \mathrm{H}_{n}(D) \longrightarrow \mathrm{H}_{n}(\operatorname{cone}(f)) \longrightarrow \mathrm{H}_{n} \quad 1(C) \longrightarrow \cdots</me>
              </p>
        
              <p>
                As a consequence, <m>f</m> is a quasi-isomorphism if and only if cone <m>(f)</m> is exact.
              </p>
            </remark>
  
            <remark>
              <p>
                Remark 6.21. 
                Given a map of complexes <m>C \stackrel{f}{\longrightarrow} D</m>, we can construct a double complex from <m>f</m>, as follows:
              </p>
  
              <image source="2023_11_27_3974d73438430121205eg-14.jpg"/>
              
              <p>
                Note that <m>\operatorname{Tot}^{\oplus}(X)=\operatorname{cone}(f)</m>.
              </p>
            </remark>
      
            <p>
              Now that we have introduced all the tools we need, the last thing we need is a technical but very useful lemma.
            </p>
  
            <lemma xml:id="lem-6.22"><title>Acyclic Assembly Lemma</title>
              <statement>
                <p>
                  Let <m>C</m> be a double complex in <m>R</m> Mod.
                  <ol>
                    <li>
                      <p>
                        If <m>C</m> is an upper half plane double complex with exact rows, meaning <m>C_{p, q}=0</m> whenever <m>q&lt;0</m>, then <m>\operatorname{Tot}^{\oplus}(C)</m> is exact.
                      </p>
                    </li>
  
                    <li>
                      <p>
                        If <m>C</m> is a right half plane double complex with exact columns, meaning <m>C_{p, q}=0</m> whenever <m>p&lt;0</m>, then <m>\operatorname{Tot}^{\oplus}(C)</m> is exact.
                      </p>
                    </li>
  
                    <li>
                      <p>
                        If <m>C</m> is an upper half plane double complex with exact columns, meaning <m>C_{p, q}=0</m> whenever <m>q&lt;0</m>, then <m>\operatorname{Tot}^{\Pi}(C)</m> is exact.
                      </p>
                    </li>
  
                    <li>
                      <p>
                        If <m>C</m> is a right half plane double complex with exact rows, meaning <m>C_{p, q}=0</m> whenever <m>p&lt;0</m>, then <m>\operatorname{Tot}^{\Pi}(C)</m> is exact.
                      </p>
                    </li>
                  </ol>
                </p>
              </statement>
  
              <proof>
                <p>
                  Notice that <m>\mathrm{a} \Leftrightarrow \mathrm{b}</m> and <m>\mathrm{c} \Leftrightarrow \mathrm{d}</m> by switching the indexes. 
                  Moreover, we claim that it is sufficient to show <m>c</m>, since it implies <m>b</m>.
                </p>
          
                <p>
                  To show that <m>\mathrm{c}</m> implies <m>\mathrm{b}</m>, we need some notation. 
                  Given a double complex <m>C</m>, consider the <m>n</m>th truncation <m>\tau_{n}(C)</m> of <m>C</m> defined by
                  <me>\tau_{n}(C)_{p, q}:= \begin{cases}C_{p, q} &amp; \text { if } q&gt;n \\ \operatorname{ker}\left(C_{p, n} \stackrel{d^{v}}{\longrightarrow} C_{p, n} \quad 1\right) &amp; \text { if } q=n \\ 0 &amp; \text { if } q&lt;n\end{cases}</me>
                  The natural inclusion <m>\tau_{n}(C) \rightarrow C</m> induces an isomorphism in homology for <m>i \geqslant n</m>.
                </p>
          
                <p>
                  Suppose that <m>C</m> is a right half plane double complex with exact columns, and assume that <m>\mathrm{c}</m> holds. 
                  Then <m>\tau_{n}(C)</m> still has exact columns, so by c, <m>\operatorname{Tot} \Pi_{(}\left(\tau_{n}(C)\right)</m> is exact. 
                  On the other hand, notice that up to a vertical shift, <m>\tau_{n}(C)</m> is a first quadrant double complex, and for each fixed <m>m</m>, there are only finitely many values of <m>p</m> and <m>q</m> with <m>p+q=m</m> and such that <m>\tau_{n}(C)_{p, q} \neq 0</m>. 
                  Therefore, <m>\operatorname{Tot}^{\Pi}\left(\tau_{n}\left(C_{p, \bullet}\right)\right)=\operatorname{Tot}^{\oplus}\left(\tau_{n}\left(C_{p, \bullet}\right)\right)</m>, so <m>\operatorname{Tot}^{\oplus}\left(\tau_{n}\left(C_{p, \bullet}\right)\right)</m> is exact. 
                  We claim that this implies that <m>\operatorname{Tot}^{\oplus}(C)</m> is exact. 
                  One can make this precise by saying <m>\operatorname{Tot}^{\oplus}(C)=\operatorname{colim}_{n}\left(\operatorname{Tot}^{\oplus}(C)\right)</m>. 
                  The point is that any element <m>a \in Z_{k}\left(\operatorname{Tot}^{\oplus}(C)\right)</m>, when we write <m>a</m> explicitly as <m>a=\left(a_{p, q}\right) \in \oplus_{p+q=k} C_{p, q}</m> in terms of its coordinates in each <m>C_{p, q}</m>, only finitely many <m>a_{p, q}</m> are nonzero. 
                  Let <m>q</m> be the smallest such that <m>a_{p, q} \neq 0</m>, and fix any <m>n&lt;q</m>. 
                  Then
                  <me>a \in Z_{k}\left(\operatorname{Tot}^{\oplus}\left(\tau_{n}(C)\right)\right)=B_{k}\left(\operatorname{Tot}^{\oplus}\left(\tau_{n}(C)\right)\right) \subseteq B_{k}\left(\operatorname{Tot}^{\oplus}(C)\right)</me>
                </p>
          
                <p>
                  So <m>\operatorname{Tot}^{\oplus}(C)</m> is exact, and b holds.
                </p>
          
                <p>
                  All we have left to do is to show c, meaning that the product total complex of any upper half plane double complex <m>C</m> with exact columns is exact. 
                  We are going to show that <m>\mathrm{H}_{0}\left(\operatorname{Tot}^{\Pi}(C)\right)=0</m>, and the remaining homologies follow by shifting <m>C</m> left and right. 
                  Consider a 0 -cycle in <m>\operatorname{Tot}^{\Pi}(C)</m>, meaning a sequence of elements <m>c_{p} \in C_{p, p}</m> for each <m>p \geqslant 0</m> such that <m>c=\left(c_{p}\right) \in Z_{0}\left(\operatorname{Tot}^{\Pi}(C)\right)</m>. 
                  So
                  <me>d(c)=0 \Leftrightarrow d^{v}\left(c_{p}\right)+d^{h}\left(c_{p} 1\right)=0 \text { for all } p \text {. }</me>
                </p>
          
                <p>
                  We will construct <m>b_{p, p+1} \in C_{p, p+1}</m> for each <m>p</m> such that <m>d^{v}\left(b_{p, p+1}\right)+d^{h}\left(b_{p+1, p}\right)=c_{p}</m>, proving that <m>c \in B_{0}\left(\operatorname{Tot}^{\Pi}(C)\right)</m>.
                </p>
          
                <p>
                  Set <m>b_{1,0}=0 \in C_{1,0}</m> when <m>p=1</m>. Since <m>C_{0,1}=0</m>, we must have <m>d^{v}\left(c_{0}\right)=0 \in C_{0,1}</m>. 
                  We also assumed that the columns are exact, so in particular the 0th column is exact. 
                  We can then find <m>b_{0,1} \in C_{0,1}</m> such that <m>d^{v}\left(b_{0,1}\right)=c_{0}</m>, and thus <m>d^{v}\left(b_{0,1}\right)+d^{h}\left(b_{1,0}\right)=c_{0}</m>.
                </p>
          
                <p>
                  Now we proceed by induction. 
                  Suppose we have constructed <m>b_{s+1, s}</m> for <m>1 \leqslant s \leqslant p</m> with the desired property that <m>d^{v}\left(b_{s, s+1}\right)+d^{h}\left(b_{s+1, s}\right)=c_{s}</m> for all <m>s \leqslant p</m>. 
                  Then
                  <me>
                    \begin{aligned}
                      &amp; d^{v}\left(c_{p, p} \quad d^{h}\left(b_{p+1, p}\right)\right)=d^{v}\left(c_{p}\right)+d^{h} d^{v}\left(b_{p+1, p}\right) \quad \text { since } d^{v} d^{h}+d^{h} d^{v}=0 \\
                      &amp; \left.=d^{v}\left(c_{p}\right)+d^{h}\left(\begin{array}{lllll}
                      c_{p} &amp; 1 &amp; d^{h}\left(b_{p+2, p}\right. &amp; 1
                      \end{array}\right)\right) \quad \text { as } d^{v}\left(b_{p+1, p}\right)+d^{h}\left(\begin{array}{lll}
                      b_{p+2, p} &amp; 1
                      \end{array}\right)=c_{p} \quad 1 \\
                      &amp; =d^{v}\left(c_{p}\right)+d^{h}\left(\begin{array}{ll}
                      c_{p} &amp; 1
                      \end{array}\right) \quad d^{h} d^{h}\left(\begin{array}{lll}
                      b_{p+2, p} &amp; 1
                      \end{array}\right) \\
                      &amp; =d^{v}\left(c_{p}\right)+d^{h}\left(\begin{array}{ll}
                      c_{p} &amp; 1
                      \end{array}\right) \quad \text { since } d^{h} d^{h}=0 \\
                      &amp; =0 \text {. }
                    \end{aligned}
                  </me>
                </p>
          
                <p>
                  The last equality comes simply from the fact that <m>\left(d^{v}+d^{h}\right)(c)=0</m>. 
                  So we have shown that <m>d^{v}\left(c_{p, p} \quad d^{h}\left(b_{p+1, p}\right)\right)=0</m>. 
                  Since the columns are exact, we can find <m>b_{p, p+1} \in C_{p, p+1}</m> such that
                  <me>d^{v}\left(b_{p, p+1}\right)=c_{p, p} \quad d^{h}\left(b_{p+1, p}\right)</me>
                </p>
          
                <p>
                  Equivalently,
                  <me>d^{v}\left(b_{p, p+1}\right)+d^{h}\left(b_{p+1, p}\right)=c_{p, p}</me>
                </p>
              </proof>
            </lemma>
  
            <exercise>
              <p>
                Exercise 71. 
                Given a double complex <m>C</m> with <m>C_{p, q}=0</m> for all <m>p&lt;n</m>, the horizontal differentials <m>C_{n+1, q} \rightarrow C_{n, q}</m> induce a map of complexes
                <me>\operatorname{Tot}^{\oplus}\left(C_{&gt;n, \bullet}\right) \stackrel{\varphi}{\rightarrow} C_{n, \bullet}</me>
                where <m>C_{&gt;n, \bullet}</m> denotes the double complex we obtain from <m>C</m> by excluding the leftmost nonzero column, and <m>\operatorname{Tot}^{\oplus}(C) \cong \Sigma^{1} \operatorname{cone}(\varphi)</m>, or equivalently, <m>\Sigma \operatorname{Tot}^{\oplus}(C) \cong \operatorname{cone}(\varphi)</m>.
              </p>
            </exercise>
            
          </subsection>

          <subsection xml:id="subsec-balancing"><title>Balancing <m>\Tor</m> and <m>\Ext</m></title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>

            <p>
              We are finally ready to show that the two definitions of Tor coincide.
            </p>
  
            <theorem xml:id="thm-6.23">
              <statement>
                <p>
                  Theorem 6.23 (Balancing Tor). 
                  Let <m>M</m> and <m>N</m> be <m>R</m>-modules, and <m>x</m> projective resolutions <m>P</m> of <m>M</m> and <m>Q</m> of <m>N</m>. 
                  For all <m>n \geqslant 0</m>, there is an isomorphism
                  <me>L_{n}\left(M \otimes_{R} \quad\right)(N)=\mathrm{H}_{n}\left(M \otimes_{R} Q\right) \cong \mathrm{H}_{n}\left(P \otimes_{R} N\right)=L_{n}\left(\otimes_{R} N\right)(M)</me>
                </p>
              </statement>
  
              <proof>
                <p>
                  Consider <m>\pi: P_{0} \quad M</m> and <m>\varepsilon: Q_{0} \quad N</m> and the first quadrant double complex
                </p>
          
                <image source="2023_11_27_3974d73438430121205eg-16.jpg"/>
                  
                <p>
                  Each <m>P_{i}</m> and <m>Q_{i}</m> is projective and thus flat, by Theorem 4.37, so <m>P_{i} \otimes_{R}</m> and <m>\otimes_{R} Q_{i}</m> are both exact functors. 
                  The rows and columns of our double complex are thus exact everywhere except for the 0th row and column. 
                  We can complete our double complex to make a double complex <m>C</m> with both exact rows if we add in a column induced by the surjection <m>\pi</m> :
                </p>
         
                <image source="2023_11_27_3974d73438430121205eg-17(1).jpg"/>
          
                <p>
                  We can also make a double complex <m>D</m> with exact columns by adding in a row induced by <m>\varepsilon</m> :
                </p>
          
                <image source="2023_11_27_3974d73438430121205eg-17.jpg"/>
          
                <p>
                  By Lemma 6.22, <m>\operatorname{Tot}^{\oplus}(C)</m> and <m>\operatorname{Tot}^{\oplus}(D)</m> are both exact. 
                  Notice that <m>\pi \otimes Q</m> is a map of complexes <m>\operatorname{Tot}^{\oplus}(P \otimes Q) \rightarrow M \otimes Q</m>, and <m>P \otimes \varepsilon</m> is a map of <m>\operatorname{complexes} \operatorname{Tot}^{\oplus}(P \otimes Q) \rightarrow P \otimes N</m>. 
                  By Exercise 71,
                  <me>\operatorname{cone}(\pi \otimes Q)=\Sigma \operatorname{Tot}^{\oplus}(C) \quad \text { and } \quad \operatorname{cone}(P \otimes \varepsilon)=\Sigma \operatorname{Tot}^{\oplus}(D)</me>
                </p>
          
                <p>
                  Since <m>\Sigma \operatorname{Tot}^{\oplus}(C)</m> and <m>\Sigma \operatorname{Tot}^{\oplus}(D)</m> are both exact, by Remark 6.20 both
                  <me>\operatorname{Tot}^{\oplus}(P \otimes Q) \quad \stackrel{\pi \otimes Q}{\rightarrow} M \otimes Q \quad \text { and } \quad \operatorname{Tot}^{\oplus}(P \otimes Q) \stackrel{P \otimes \varepsilon}{\rightarrow} P \otimes N</me>
                  are quasi-isomorphisms, so that
                  <me>L_{n}\left(M \otimes_{R} \quad\right)(N)=\mathrm{H}_{n}\left(M \otimes_{R} Q\right) \cong \mathrm{H}_{n}\left(P \otimes_{R} N\right)=L_{n}\left(\otimes_{R} N\right)(M)</me>
                </p>
              </proof>
            </theorem>
  
            <theorem xml:id="thm-6.24">
              <statement>
                <p>
                  Theorem 6.24 (Balancing Ext). 
                  Let <m>M</m> and <m>N</m> be <m>R</m>-modules, and <m>x</m> a projective resolution <m>P</m> of <m>M</m> and an injective resolution <m>E</m> of <m>N</m>. 
                  For all <m>n</m>, there is an isomorphism
                  <me>R^{n} \operatorname{Hom}_{R}(M, \quad)(N)=\mathrm{H}^{n}\left(\operatorname{Hom}_{R}(M, E)\right) \cong \mathrm{H}^{n}\left(\operatorname{Hom}_{R}(P, N)\right)=R^{n} \operatorname{Hom}_{R}(, N)(M) \text {. }</me>
                </p>
              </statement>
  
              <proof>
                <p>
                  We have a surjection <m>\pi: P_{0} \rightarrow M</m> and an inclusion <m>\varepsilon: M \rightarrow E_{0}</m>. 
                  The double cocomplex <m>\operatorname{Hom}_{R}(P, E)</m> with <m>\operatorname{Hom}_{R}(P, E)_{p, q}=\operatorname{Hom}_{R}\left(P_{p}, E^{q}\right)</m> and
                  <me>\begin{array}{cc}
                    \operatorname{Hom}_{R}\left(P_{p}, E^{q}\right) \stackrel{d^{h}}{\longrightarrow} \operatorname{Hom}_{R}\left(P_{p+1}, E^{q}\right) &amp; \text { and } \operatorname{Hom}_{R}\left(P_{p}, E^{q}\right) \stackrel{d^{v}}{\longrightarrow} \operatorname{Hom}_{R}\left(P_{p}, D_{q+1}\right) . \\
                    f \longrightarrow f \circ \partial^{P} &amp; f \longrightarrow(1)^{p+q+1} \partial^{E} \circ f
                    \end{array}
                  </me>
                  is a cohomological first quadrant double complex:
                </p>
        
                <image source="2023_11_27_3974d73438430121205eg-18(1).jpg"/>
          
                <p>
                  We proceed just like in Theorem 6.23, now considering two cohomological double complexes:
                </p>
          
                <image source="2023_11_27_3974d73438430121205eg-18(2).jpg"/>
          
                <p>
                  and
                </p>
         
                <image source="2023_11_27_3974d73438430121205eg-18.jpg"/>
                  
                <p>
                  We obtained <m>C</m> from <m>\operatorname{Hom}(P, E)</m> by adding in a column induced by <m>\pi</m>, and <m>D</m> by adding in a row induced by <m>\varepsilon</m>. 
                  Now we notice that
                  <me>\operatorname{cone}\left(\operatorname{Hom}_{R}(P, N) \rightarrow \operatorname{Tot}^{\oplus}(\operatorname{Hom}(P, E))\right)=\operatorname{Tot}^{\oplus}(C)</me>
                  and
                  <me>\operatorname{cone}\left(\operatorname{Hom}_{R}(M, E) \rightarrow \operatorname{Tot}^{\oplus}(\operatorname{Hom}(P, E))\right)=\operatorname{Tot}^{\oplus}(D)</me>
                </p>
          
                <p>
                  The dual of Lemma 6.22 says that <m>\operatorname{Tot}^{\oplus}(C)</m> and <m>\operatorname{Tot}^{\oplus}(D)</m> are both exact, and thus <m>\operatorname{Hom}_{R}(P, N) \rightarrow \operatorname{Tot}^{\oplus}(\operatorname{Hom}(P, E))</m> and <m>\operatorname{Hom}_{R}(M, E) \rightarrow \operatorname{Tot}^{\oplus}(\operatorname{Hom}(P, E))</m> are both quasiisomorphisms. 
                  We conclude that
                  <me>R^{n} \operatorname{Hom}_{R}(M, \quad)(N)=\mathrm{H}^{n}\left(\operatorname{Hom}_{R}(P, N)\right) \cong \mathrm{H}^{n}\left(\operatorname{Hom}_{R}(M, E)\right)=R^{n} \operatorname{Hom}_{R}(, N)(M) \text {. }</me>
                </p>
              </proof>
            </theorem>
            
            <definition xml:id="def-6.25">
              <statement>
                <p>
                  Definition 6.25. 
                  Let <m>R</m> be a ring and <m>M</m> and <m>N</m> be <m>R</m>-modules. 
                  The <m>i</m> th Tor module from <m>M</m> to <m>N</m> is
                  <me>\operatorname{Tor}_{i}^{R}(M, N):=L_{i}\left(M \otimes_{R} \quad\right)(N) \cong L_{i}\left(\otimes_{R} N\right)(M)</me>
                </p>
              </statement>
            </definition>
            
            <p>
              Notice in particular that the <m>R</m>-module <m>\operatorname{Tor}_{i}^{R}(M, N)</m> is defined only up to isomorphism.
            </p>
  
            <definition xml:id="def-6.26">
              <statement>
                <p>
                  Definition 6.26. 
                  Let <m>R</m> be a ring and <m>M</m> and <m>N</m> be <m>R</m>-modules. 
                  The <m>i</m> th Ext module from <m>M</m> to <m>N</m> is
                  <me>\operatorname{Ext}_{R}^{i}(M, N):=R^{i} \operatorname{Hom}_{R}(M, \quad)(N) \cong R^{i} \operatorname{Hom}_{R}(, N)(M)</me>
                </p>
              </statement>
            </definition>
      
            <p>
              Notice in particular that the <m>R</m>-module <m>\operatorname{Ext}_{R}^{i}(M, N)</m> is only defined up to isomorphism.
            </p>
      
            <p>
              Theorem 6.5 immediately gives us long exact sequences for Ext and Tor.
            </p>
  
            <theorem xml:id="thm-6.27">
              <statement>
                <p>
                  Let <m>R</m> be a ring and <m>M</m> an <m>R</m>-module. 
                  Every short exact sequence of <m>R</m> modules
                  <me>0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0</me>
                  induces a long exact sequence
                  <me>
                    \begin{aligned}
                      \cdots \longrightarrow \operatorname{Tor}_{n+1}^{R}(M, C) \longrightarrow &amp; \operatorname{Tor}_{n}^{R}(M, A) \longrightarrow \operatorname{Tor}_{n}^{R}(M, B) \longrightarrow \operatorname{Tor}_{n}^{R}(M, A) \longrightarrow \cdots \\
                      \cdots &amp; \longrightarrow \operatorname{Tor}_{1}^{R}(M, C) \longrightarrow A \otimes_{R} M \longrightarrow \otimes_{R} M \longrightarrow C \otimes_{R} M \longrightarrow 0
                    \end{aligned}
                  </me>
                </p>
              </statement>
            </theorem>
  
            <theorem xml:id="thm-6.28">
              <statement>
                <p>
                  For every <m>R</m>-module <m>M</m>, every short exact sequence of <m>R</m>-modules
                  <me>0 \longrightarrow A \stackrel{f}{\longrightarrow} B \stackrel{g}{\longrightarrow} C \longrightarrow 0</me>
                  induces a natural long exact sequence
                  <me>
                    \begin{array}{r}
                      0 \longrightarrow \operatorname{Hom}_{R}(M, A) \longrightarrow \operatorname{Hom}_{R}(M, B) \longrightarrow \operatorname{Hom}_{R}(M, C) \longrightarrow \operatorname{Ext}_{R}^{n}(M, B) \longrightarrow \operatorname{Ext}_{R}^{1}(M, A) \longrightarrow \cdots \\
                      \cdots
                    \end{array}
                  </me>
                  and
                  <me>
                    \begin{array}{r}
                      0 \longrightarrow \operatorname{Hom}_{R}(C, M) \longrightarrow \operatorname{Hom}_{R}(B, M) \longrightarrow \operatorname{Hom}_{R}(A, M) \longrightarrow \operatorname{Ext}_{R}^{1}(C, M) \longrightarrow \cdots \\
                      \cdots \\
                      \cdots \operatorname{Ext}_{R}^{n}(B, M) \longrightarrow \operatorname{Ext}_{R}^{n}(A, M) \longrightarrow \operatorname{Ext}_{R}^{n+1}(C, M) \longrightarrow \cdots
                    \end{array}
                  </me>
                </p>
              </statement>
            </theorem>
  
            <theorem xml:id="thm-6.29">
              <statement>
                <p>
                  Let <m>M</m> and <m>N</m> be <m>R</m>-modules. 
                  For all <m>i</m>, there are natural isomorphisms
                  <me>\operatorname{Tor}_{i}^{R}(M, N) \cong \operatorname{Tor}_{i}^{R}(N, M)</me>
                </p>
              </statement>
  
              <proof>
                <p>
                  Let <m>P</m> be a projective resolution of <m>M</m>. 
                  By Theorem 6.23, <m>\operatorname{Tor}_{i}^{R}(M, N)=\mathrm{H}_{i}\left(P \otimes_{R} N\right)</m> and <m>\operatorname{Tor}_{i}^{R}(N, M)=\mathrm{H}_{i}\left(N \otimes_{R} P\right)</m>. 
                  By Lemma 3.38, <m>M \otimes_{R} N</m> and <m>N \otimes_{R} M</m> are naturally isomorphic. 
                  In fact, <m>m \otimes n \mapsto n \otimes m</m> determines an isomorphism. 
                  So consider the map
                  <me>
                    \begin{array}{cc}
                      P_{n} \otimes_{R} N \stackrel{f_{n}}{\longrightarrow} N \otimes_{R} P_{n} &amp; N \otimes_{R} M \stackrel{g_{n}}{\longrightarrow} P_{n} \otimes_{R} N \\
                      m \otimes n \longrightarrow m \otimes m &amp; n \otimes m \longrightarrow n
                    \end{array}
                  </me>
                  which again are isomorphisms for all <m>n</m>.
                  Notice that these <m>f_{n}</m> assemble into a map of complexes <m>P \otimes_{R} N \stackrel{f}{\rightarrow} N \otimes_{R} P</m>, since
                  <me>f_{n}(\partial(m \otimes n))=f_{n}(\partial(m) \otimes n)=n \otimes \partial(m)=\partial(n \otimes m)=\partial f_{n+1}(m \otimes n)</me>
                </p>
          
                <p>
                  Since all the <m>f_{n}</m> are isomorphisms, <m>f</m> is an isomorphism of complexes, and must then induce isomorphisms in homology. 
                  We conclude that
                  <me>\operatorname{Tor}_{i}^{R}(M, N)=\mathrm{H}_{i}\left(P \otimes_{R} N\right) \cong \mathrm{H}_{i}\left(N \otimes_{R} P\right)=\operatorname{Tor}_{i}^{R}(N, M)</me>
                </p>
              </proof>
            </theorem>
  
            <p>
              However, <m>\operatorname{Ext}_{R}^{i}(M, N)</m> and <m>\operatorname{Ext}_{R}^{i}(N, M)</m> can be dramatically different.
            </p>
  
            <example>
              <p>
                Let <m>k</m> be a field and <m>R=k[x]</m>. 
                The following is a minimal free resolution for <m>k=R /(x)</m> :
                <me>0 \longrightarrow R \stackrel{x}{\longrightarrow} R \longrightarrow k \longrightarrow 0</me>
              </p>
        
              <p>
                To compute <m>\operatorname{Ext}_{R}^{i}(k, R)</m>, we need only to apply <m>\operatorname{Hom}_{R}(, R)</m> to this resolution; 
                one needs to be careful, though, as this is a contravariant functor. 
                We obtain the following complex:
                <me>0 \longleftarrow \operatorname{Hom}_{R}(R, R) \stackrel{x^{*}}{\longleftarrow} \operatorname{Hom}_{R}(R, R) \longleftarrow 0</me>
              </p>
        
              <p>
                One can show that <m>\operatorname{Hom}_{R}(x, R)</m> is multiplication by <m>x</m> on <m>\operatorname{Hom}_{R}(R, R)</m>; 
                moreover, we have a natural isomorphism <m>\operatorname{Hom}_{R}(R, R) \cong R</m>, giving us
                <me>C=\quad 0 \longleftarrow \underset{1}{2 \longleftarrow} R \underset{0}{\longleftarrow} R \longleftarrow 0</me>
              </p>
        
              <p>
                In particular,
                <me>\operatorname{Ext}^{1}(k, R)=\mathrm{H}^{1}(C)=R /(x) .</me>
              </p>
        
              <p>
                In contrast,
                <me>\operatorname{Ext}^{1}(R, k)=0</me>
                since <m>R</m> is free. 
                Thus <m>\operatorname{Ext}^{1}(R, k) \neq \operatorname{Ext}^{1}(k, R)</m>.
              </p>
        
              <p>
                There is an alternative description of Ext. 
                It turns out that <m>\operatorname{Ext}_{R}^{1}(M, N)</m> measures the extensions of <m>M</m> by <m>N</m> modulo split extensions. 
                More precisely, an extension of <m>M</m> by <m>N</m> is a short exact sequence
                <me>0 \longrightarrow N \longrightarrow B \longrightarrow M \longrightarrow 0</me>
              </p>
        
              <p>
                We can put an abelian group structure on the set of isomorphism classes of extensions of <m>M</m> by <m>N</m>, using an operation called the Baer sum, and one can show that the resulting abelian group is isomorphic to <m>\operatorname{Ext}_{R}^{1}(M, N)</m>. 
                Via this description, the zero in <m>\operatorname{Ext}_{R}^{1}(M, N)</m> corresponds to the split short exact sequence
                <me>0 \longrightarrow N \longrightarrow N \oplus M \longrightarrow M \longrightarrow 0</me>
              </p>
        
              <p>
                The higher Ext modules can also be described in a similar fashion. 
                First, we consider the set of <m>n</m>-fold extensions of <m>N</m> by <m>M</m>, meaning short exact sequences of the form
                <me>0 \longrightarrow N \longrightarrow B_{1} \longrightarrow B_{2} \longrightarrow \cdots \longrightarrow B_{n} \longrightarrow M \longrightarrow 0</me>
                and the equivalence relation on this set given by the existence of a map of complexes
              </p>
        
              <image source="2023_11_27_3974d73438430121205eg-21.jpg"/>
                
              <p>
                where the maps between the <m>B_{i}</m> are not necessarily isomorphisms. 
                We then define an operation on the set of equivalence classes of <m>n</m>-fold extensions of <m>N</m> by <m>M</m> that is also called the Baer sum, and one shows that the resulting abelian group is isomorphic to <m>\operatorname{Ext}_{R}^{n}(M, n)</m>.
              </p>
        
              <p>
                Via this description, <m>\operatorname{Ext}_{R}^{1}(M, N)=0</m> if and only if every short exact sequence
                <me>0 \longrightarrow N \longrightarrow B \longrightarrow M \longrightarrow 0</me>
                splits.
              </p>
            </example>
      
            <p>
              Finally, here are some nice facts about Ext and Tor we leave as exercises.
            </p>
  
            <exercise>
              <p>
                Exercise 72. 
                If <m>M</m> and <m>N</m> are finitely generated <m>R</m>-modules and <m>R</m> is a noetherian ring, then <m>\operatorname{Ext}_{R}^{i}(M, N)</m> and <m>\operatorname{Tor}_{i}^{R}(M, N)</m> are both finitely generated <m>R</m>-modules for all <m>i</m>.
              </p>
            </exercise>
  
            <exercise>
              <p>
                Exercise 73.
                Let <m>R</m> be a commutative ring and <m>M</m> and <m>N</m> be <m>R</m>-modules. 
                Consider the <m>R</m>-module homomorphism <m>f: M \rightarrow M</m> given by multiplication by a fixed element <m>r \in R</m>.
                <ol>
                  <li>
                    <p>
                      Show that the map <m>\operatorname{Tor}_{i}^{R}(f, M): \operatorname{Tor}_{i}^{R}(M, N) \rightarrow \operatorname{Tor}_{i}^{R}(M, N)</m> induced by <m>f</m> is multiplication by <m>r</m> on <m>\operatorname{Tor}_{i}^{R}(M, N)</m>.
                    </p>
                  </li>
  
                  <li>
                    <p>
                      Show that <m>\operatorname{Ext}^{i}(f, M): \operatorname{Ext}_{R}^{i}(M, N) \rightarrow \operatorname{Ext}_{R}^{i}(M, N)</m> is multiplication by <m>r</m> on <m>\operatorname{Ext}_{R}^{i}(M, N)</m>.
                    </p>
                  </li>
  
                  <li>
                    <p>
                      Show that the map <m>\operatorname{Ext}^{i}(M, f): \operatorname{Ext}_{R}^{i}(N, M) \rightarrow \operatorname{Ext}_{R}^{i}(N, M)</m> induced by <m>f</m> is multiplication by <m>r</m> on <m>\operatorname{Ext}_{R}^{i}(N, M)</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </exercise>
  
            <exercise>
              <p>
                Exercise 74 . 
                Let <m>M</m> be an <m>R</m>-module.
                <ol>
                  <li>
                    <p>
                      Show that <m>M</m> is flat if and only if <m>\operatorname{Tor}_{1}^{R}(M, N)=0</m> for every <m>R</m>-module <m>N</m>.
                    </p>
                  </li>
  
                  <li>
                    <p>
                      Show that <m>M</m> is projective if and only if <m>\operatorname{Ext}_{R}^{1}(M, N)=0</m> for every <m>R</m>-module <m>N</m>.
                    </p>
                  </li>
  
                  <li>
                    <p>
                      Show that <m>M</m> is injective if and only if <m>\operatorname{Ext}_{R}^{1}(N, M)=0</m> for every <m>R</m>-module <m>N</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </exercise>
            
          </subsection>

          <outcomes>
            <ul>
              <li>
                <p>

                </p>
              </li>
            </ul>
          </outcomes>
          
        </section>

        <section xml:id="sec-comp-ext-tor"><title>Computing Ext and Tor</title>

          <objectives>
            <ul>
              <li>
                
              </li>
            </ul>
          </objectives>

          <subsection xml:id="subsec-constructions"><title>The Constructions</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>

            <p>
              Given <m>R</m>-modules <m>M</m> and <m>N</m>, we have two possible ways to compute <m>\operatorname{Tor}_{i}^{R}(M, N)</m> from the definition.
            </p>
      
            <p>
              Construction 6.31. 
              Find a projective resolution
              <me>\cdots \longrightarrow P_{2} \longrightarrow P_{1} \longrightarrow P_{0} \longrightarrow M \longrightarrow 0</me>
              of <m>M</m>. Applying <m>\otimes_{R} N</m> to the resolution (not counting <m>M</m> ), we get a complex
              <me>\cdots \longrightarrow P_{2} \otimes_{R} N \longrightarrow P_{1} \otimes_{R} N \longrightarrow P_{0} \otimes_{R} N \longrightarrow 0</me>
              Its homology is <m>\operatorname{Tor}_{*}^{R}(M, N)</m> :
              <me>\operatorname{Tor}_{i}^{R}(M, N)=\mathrm{H}_{i}\left(\cdots \longrightarrow P_{2} \otimes_{R} N \longrightarrow P_{1} \otimes_{R} N \longrightarrow P_{0} \otimes_{R} N \longrightarrow 0\right)</me>
            </p>
      
            <p>
              Alternatively, we can find a free resolution of <m>N</m>, say
              <me>\cdots \longrightarrow Q_{2} \longrightarrow Q_{1} \longrightarrow Q_{0} \longrightarrow N \longrightarrow 0</me>
              apply <m>M \otimes_{R} \quad</m>,
              <me>\cdots \longrightarrow M \otimes_{R} Q_{2} \longrightarrow M \otimes_{R} Q_{1} \longrightarrow M \otimes_{R} Q_{0} \longrightarrow 0</me>
              and compute the homology of the resulting complex:
              <me>\operatorname{Tor}_{i}^{R}(M, N)=\mathrm{H}_{i}\left(\cdots \longrightarrow M \otimes_{R} Q_{2} \longrightarrow M \otimes_{R} Q_{1} \longrightarrow M \otimes_{R} Q_{0} \longrightarrow 0\right)</me>
            </p>
      
            <p>
              Similarly, we have two possible ways to compute <m>\operatorname{Ext}_{R}^{i}(M, N)</m>.
            </p>
      
            <p>
              Construction 6.32.
              Find a projective resolution
              <me>\cdots \longrightarrow P_{2} \longrightarrow P_{1} \longrightarrow P_{0} \longrightarrow M \longrightarrow 0</me>
              of <m>M</m>. Applying the contravariant functor <m>\operatorname{Hom}_{R}(, N)</m> to the resolution gives us a cocomplex rather than a complex:
              <me>0 \longrightarrow \operatorname{Hom}_{R}\left(P_{0}, N\right) \longrightarrow \operatorname{Hom}_{R}\left(P_{1}, N\right) \longrightarrow \operatorname{Hom}_{R}\left(P_{2}, N\right) \longrightarrow \cdots</me>
              Its homology is <m>\operatorname{Ext}_{R}^{*}(M, N)</m> :
              <me>\operatorname{Ext}_{R}^{i}(M, N)=\mathrm{H}^{i}\left(0 \longrightarrow \operatorname{Hom}_{R}\left(P_{0}, N\right) \longrightarrow \operatorname{Hom}_{R}\left(P_{1}, N\right) \longrightarrow \operatorname{Hom}_{R}\left(P_{2}, N\right) \longrightarrow \cdots\right)</me>
            </p>
      
            <p>
              Alternatively, we can find an injective resolution of <m>N</m>, say
              <me>0 \longrightarrow N \longrightarrow E^{0} \longrightarrow E^{1} \longrightarrow E^{2} \longrightarrow \cdots</me>
              apply the covariant functor <m>\operatorname{Hom}_{R}(M, \quad)</m>, which yields the cocomplex
              <me>0 \longrightarrow \operatorname{Hom}_{R}\left(M, E^{0}\right) \longrightarrow \operatorname{Hom}_{R}\left(M, E^{1}\right) \longrightarrow \operatorname{Hom}_{R}\left(M, E^{2}\right) \longrightarrow \cdots</me>
              and compute the cohomology of the resulting cocomplex:
              <m>\operatorname{Ext}_{R}^{i}(M, N)=\mathrm{H}^{i}\left(0 \longrightarrow \operatorname{Hom}_{R}\left(M, E^{0}\right) \longrightarrow \operatorname{Hom}_{R}\left(M, E^{1}\right) \longrightarrow \operatorname{Hom}_{R}\left(M, E^{2}\right) \longrightarrow \cdots\right)</m>.
            </p>
      
            <p>
              It helps to keep a few simple ideas in mind:
            </p>
      
            <p>
              If <m>P</m> is a projective <m>R</m>-module, then
              <me>\operatorname{Tor}_{i}^{R}(M, P)=\operatorname{Tor}_{i}^{R}(P, M)=0</me>
              and
              <me>\operatorname{Ext}_{R}^{i}(P, M)=0</me>
              for all <m>i&gt;0</m> and all <m>R</m>-modules <m>M</m>, since <m>0 \rightarrow P \rightarrow 0</m> is a projective resolution for <m>M</m>. 
              This is a special case of Remark 6.3.
            </p>
      
            <p>
              If <m>E</m> is an injective <m>R</m>-module,
              <me>\operatorname{Ext}_{R}^{i}(M, E)=0</me>
              for all <m>i&gt;0</m> and all <m>R</m>-modules <m>M</m>.
              Free resolutions are often easier to compute explicitly, and the best path towards finding <m>\operatorname{Ext}_{R}^{n}(M, N)</m>.
            </p>
      
            <p>
              Relating one of our modules to other, easier modules via a short exact sequence can often simplify complicated computations.
            </p>
            
          </subsection>

          <subsection xml:id="subsec-examples"><title>Examples</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>

            <p>
              Let's compute some examples.
            </p>
  
            <example>
              <p>
                Example 6.33. 
                Let's compute <m>\operatorname{Ext}_{\mathbb{Z}}^{i}(\mathbb{Z} /(2), \mathbb{Z} /(3))</m>. 
                Injective resolutions are not so easy to find, so we start from a projective resolution for <m>\mathbb{Z} /(2)</m> :
              </p>
        
              <p>
                <me>0 \longrightarrow \mathbb{Z} \stackrel{2}{\longrightarrow} \mathbb{Z} \longrightarrow \mathbb{Z} /(2) \longrightarrow 0</me>
              </p>
        
              <p>
                Notice that <m>\operatorname{pdim}_{\mathbb{Z}}(\mathbb{Z} /(2)) \neq 0</m>, since <m>\mathbb{Z} /(2)</m> is not a projective <m>\mathbb{Z}</m>-module. 
                We found a free resolution of length 1 for <m>\mathbb{Z} /(2)</m>, so it must be that <m>\operatorname{pdim}_{\mathbb{Z}}(\mathbb{Z} /(2))=1</m>. 
                This immediately tells us that <m>\operatorname{Ext}_{\mathbb{Z}}^{i}(\mathbb{Z} /(2), \mathbb{Z} /(3))=0</m> for all <m>i \leqslant 2</m>.
                Now we apply <m>\operatorname{Hom}_{\mathbb{Z}}(, \mathbb{Z} /(3))</m> to our free resolutions for <m>\mathbb{Z} /(2)</m>, and obtain
                <me>0 \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}, \mathbb{Z} /(3)) \stackrel{2^{*}}{\longrightarrow} \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}, \mathbb{Z} /(3)) \longrightarrow 0</me>
              </p>
        
              <p>
                By Exercise <m>38, \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}, \mathbb{Z} /(3)) \cong \mathbb{Z} /(3)</m>, via the isomorphism <m>f \mapsto f(1)</m>. 
                Since <m>2^{*}</m> was the map <m>f \mapsto(2 \cdot \quad) \circ f=2 f()</m>, we can simplify our complex to
                <me>0 \longrightarrow \mathbb{Z} /(3) \stackrel{2}{\longrightarrow} \mathbb{Z} /(3) \longrightarrow 0</me>
              </p>
        
              <p>
                Notice that multiplication by 2 is an isomorphism on <m>\mathbb{Z} /(3)</m>, so the complex above is exact, and <m>\operatorname{Ext}_{\mathbb{Z}}^{i}(\mathbb{Z} /(2), \mathbb{Z} /(3))=0</m> for all <m>i</m>.
              </p>
            </example>
  
            <example>
              <p>
                Example 6.34. 
                Given an integer <m>n&gt;1</m>,
                <me>0 \longrightarrow \mathbb{Z} \stackrel{n}{\longrightarrow} \mathbb{Z} \stackrel{\pi}{\longrightarrow} \mathbb{Z} /(n) \longrightarrow 0</me>
                with <m>\pi</m> the canonical projection is a free resolution for <m>\mathbb{Z} /(n)</m> over <m>\mathbb{Z}</m>. 
                Notice that since <m>\mathbb{Z} /(n)</m> is not a free <m>\mathbb{Z}</m>-module, there is no shorter free resolution for <m>\mathbb{Z} / \mathfrak{n}</m>. 
                Now we can use this resolution to compute <m>\operatorname{Tor}_{i}^{\mathbb{Z}}(\mathbb{Z} /(n), M)</m> and <m>\operatorname{Ext}_{\mathbb{Z}}^{i}(\mathbb{Z} /(n), M)</m> for any <m>\mathbb{Z}</m>-module <m>M</m>. 
                For Tor,
                <me>\operatorname{Tor}_{i}^{\mathbb{Z}}(\mathbb{Z} /(n), M)=\mathrm{H}_{i}\left(0 \longrightarrow \mathbb{Z} \otimes_{\mathbb{Z}} M \stackrel{n \otimes 1}{\longrightarrow} \mathbb{Z} \otimes_{\mathbb{Z}} M \longrightarrow 0\right)</me>
              </p>
        
              <p>
                By Lemma 3.40, <m>\mathbb{Z} \otimes_{\mathbb{Z}} M \cong M</m>, via the map <m>k \otimes m \mapsto k m</m>, and the map <m>n \otimes 1_{M}</m> corresponds to multiplication by <m>n</m> on <m>M</m>. 
                Therefore,
                <me>\operatorname{Tor}_{i}^{\mathbb{Z}}(\mathbb{Z} /(n), M)=\mathrm{H}_{i}(0 \longrightarrow M \stackrel{n}{\longrightarrow} M \longrightarrow 0),</me>
              </p>
        
              <p>
                So
                <me>\operatorname{Tor}_{i}^{\mathbb{Z}}(\mathbb{Z} /(n), M)= \begin{cases}M / n M &amp; \text { for } i=0 \\ \left(0:_{M} n\right) &amp; \text { for } i=1 \\ 0 &amp; \text { otherwise }\end{cases}</me>
                Notice that <m>\operatorname{Tor}_{0}^{\mathbb{Z}}(\mathbb{Z} /(n), M)=M / n M=\mathbb{Z} / n \mathbb{Z} \otimes_{\mathbb{Z}} M</m>, as we already knew from Proposition 6.4.
              </p>
        
              <p>
                Similarly, we can compute all the Ext modules from <m>\mathbb{Z} /(n)</m> :
                <me>\operatorname{Ext}_{i}^{\mathbb{Z}}(\mathbb{Z} /(n), M)=\mathrm{H}_{i}\left(0 \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}, M) \stackrel{n^{*}}{\longrightarrow} \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}, M) \longrightarrow 0\right)</me>
              </p>
        
              <p>
                By Exercise <m>38, \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}, M) \cong M</m>, via the map <m>f \mapsto f(1)</m>, and <m>n^{*}=\operatorname{Hom}_{\mathbb{Z}}(n, M)</m> corresponds to multiplication by <m>n</m> on <m>M</m>. 
                So
                <me>\operatorname{Ext}_{\mathbb{Z}}^{i}(\mathbb{Z} /(n), M)=\mathrm{H}^{i}(0 \longrightarrow M \stackrel{n}{\longrightarrow} M \longrightarrow 0)</me>
              </p>
        
              <p>
                We conclude that
                <me>\operatorname{Ext}_{\mathbb{Z}}^{i}(\mathbb{Z} /(n), M)= \begin{cases}M / n M &amp; \text { for } i=1 \\ \left(0:_{M} n\right) &amp; \text { for } i=0 \\ 0 &amp; \text { otherwise }\end{cases}</me>
              </p>
        
              <p>
                Notice that <m>\operatorname{Ext}_{\mathbb{Z}}^{1}(\mathbb{Z} /(n), M)=\left(0:_{M} n\right)=\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} /(n), M)</m>, as we already knew from Proposition 6.4.
              </p>
            </example>
  
            <example>
              <p>
                Alternatively, we can compute <m>\operatorname{Ext}_{\mathbb{Z}}^{i}(\mathbb{Z} /(n), M)</m> and <m>\operatorname{Tor}_{i}^{\mathbb{Z}}(\mathbb{Z} /(n), M)</m> by looking at some long exact sequences. 
                The long exact sequence for Tor induced by the short exact sequence
                <me>0 \longrightarrow \mathbb{Z} \stackrel{n}{\longrightarrow} \mathbb{Z} \longrightarrow \mathbb{Z} /(n) \longrightarrow 0</me>
                is
                <me>\begin{aligned}
                &amp; \cdots \longrightarrow \operatorname{Tor}_{n+1}^{\mathbb{Z}}(\mathbb{Z} /(n), M) \longrightarrow \operatorname{Tor}_{n}^{\mathbb{Z}}(\mathbb{Z}, M) \longrightarrow \operatorname{Tor}_{n}^{\mathbb{Z}}(\mathbb{Z}, M) \longrightarrow \operatorname{Tor}_{n}^{\mathbb{Z}}(\mathbb{Z} /(n), M) \longrightarrow \cdots \\
                &amp; \cdots \longrightarrow \operatorname{Tor}_{1}^{\mathbb{Z}}(\mathbb{Z} /(n), M) \longrightarrow \mathbb{Z} \otimes_{\mathbb{Z}} M \longrightarrow \mathbb{Z} \otimes_{\mathbb{Z}} M \longrightarrow
                \end{aligned}</me>
              </p>
        
              <p>
                Since <m>\mathbb{Z}</m> is a projective <m>\mathbb{Z}</m>-module and thus flat, <m>\operatorname{Tor}_{i}^{\mathbb{Z}}(\mathbb{Z}, M)=0</m> for all <m>i&gt;0</m>. 
                As a consequence, the long exact sequence above forces <m>\operatorname{Tor}_{2}^{\mathbb{Z}}(\mathbb{Z} /(n), M)=0</m>. 
                So our long exact sequence really gets reduced to
                <me>0 \longrightarrow \operatorname{Tor}_{1}^{\mathbb{Z}}(\mathbb{Z} /(n), M) \longrightarrow \mathbb{Z} \otimes_{\mathbb{Z}} M \longrightarrow \mathbb{Z} \otimes_{\mathbb{Z}} M \longrightarrow \mathbb{Z} /(n) \otimes_{\mathbb{Z}} M \longrightarrow 0</me>
              </p>
        
              <p>
                Now <m>\mathbb{Z} \otimes_{\mathbb{Z}} M \cong M</m> via <m>k \otimes m \mapsto k m</m>, and this isomorphism turns <m>n \otimes 1_{M}</m> into multiplication by <m>n</m> on <m>M</m>, same as above. 
                So <m>\operatorname{Tor}_{1}^{\mathbb{Z}}(\mathbb{Z} /(n), M)</m> is the kernel of multiplication by <m>n</m> on <m>M</m>, or <m>\left(0:_{M} n\right)</m>.
                If we want to compute <m>\operatorname{Ext}_{\mathbb{Z}}^{i}(\mathbb{Z} /(n), M)</m>, we should now look at the long exact sequence
                <me>
                  \begin{array}{r}
                    0 \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} /(n), M) \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}, M) \stackrel{n^{*}}{\longrightarrow} \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}, M) \longrightarrow \operatorname{Ext}_{\mathbb{Z}}^{n}(\mathbb{Z}, M) \longrightarrow \operatorname{Ext}_{\mathbb{Z}}^{1}(\mathbb{Z} /(n), M) \longrightarrow \\
                    \cdots \operatorname{Ext}_{\mathbb{Z}}^{n}(\mathbb{Z}, M) \longrightarrow \operatorname{Ext}_{\mathbb{Z}}^{n+1}(\mathbb{Z} /(n), M) \longrightarrow \cdots
                  \end{array}
                </me>
              </p>
        
              <p>
                Again, <m>\mathbb{Z}</m> is a free <m>\mathbb{Z}</m>-module, so <m>\operatorname{Ext}_{\mathbb{Z}}^{i}(\mathbb{Z}, M)=0</m> for all <m>i&gt;0</m>. 
                Then <m>\operatorname{Ext}_{\mathbb{Z}}^{i}(\mathbb{Z} /(n), M)=0</m> for all <m>i&gt;1</m>, and our long exact sequence is actually just
                <me>0 \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z} /(n), M) \longrightarrow \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}, M) \stackrel{n^{*}}{\longrightarrow} \operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}, M) \longrightarrow \operatorname{Ext}_{\mathbb{Z}}^{1}(\mathbb{Z} /(n), M) \longrightarrow 0</me>
              </p>
        
              <p>
                So <m>\operatorname{Ext}_{\mathbb{Z}}^{1}(\mathbb{Z} /(n), M)</m> is the cokernel of <m>n^{*}</m>. 
                As before, notice that <m>\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Z}, M) \cong M</m> via the map <m>f \mapsto f(1)</m>, and <m>n^{*}</m> corresponds to multiplication by <m>n</m> on <m>M</m>. 
                We conclude that <m>\operatorname{Ext}_{\mathbb{Z}}^{1}(\mathbb{Z} /(n), M) \cong M / n M</m>.
              </p>
            </example>
  
            <exercise>
              <p>
                Exercise 75. 
                Let <m>k</m> be a field and <m>R=k[x] /\left(x^{3}\right)</m>.
                <ol>
                  <li>
                    <p>
                      Compute <m>\operatorname{Tor}_{i}^{R}(k, k)</m> for all <m>i</m>.
                    </p>
                  </li>
  
                  <li>
                    <p>
                      Show that <m>\operatorname{Ext}_{R}^{i}(k, k) \neq 0</m> for all <m>i</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </exercise>
  
            <exercise>
              <p>
                Exercise 76. 
                Let <m>k</m> be a field, <m>R=k[x, y]</m>, and <m>\quad=(x, y)</m>.
                <ol>
                  <li>
                    <p>
                      Show that
                      <me>
                        0 \longrightarrow R \stackrel{\left(\begin{array}{c}
                      y \\
                      x
                      \end{array}\right)}{\longrightarrow} R^{2} \stackrel{x \quad y)}{\longrightarrow} R \longrightarrow 0</me>
                      is a free resolution for <m>k=R /</m>.
                    </p>
                  </li>
  
                  <li>
                    <p>
                      Compute <m>\operatorname{Tor}_{i}^{R}(k, k)</m> for all <m>i</m>.
                    </p>
                  </li>
  
                  <li>
                    <p>
                      Show that
                      <me>\operatorname{Tor}_{1}(, k) \cong \operatorname{Tor}_{2}(k, k)</me>
                    </p>
                  </li>
                </ol>
              </p>
            </exercise>
            
          </subsection>

          <outcomes>
            <ul>
              <li>
                <p>

                </p>
              </li>
            </ul>
          </outcomes>
          
        </section>

        <section xml:id="sec-other-derived-functors"><title>Other Derived Functors</title> 

          <subsection xml:id="subsec-group-homology"><title>Group Homology</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>

            <p>
              Here are some other examples of derived functors you may encounter.
            </p>

            <p>
              Definition 6.35. category of <m>G</m>-modules Let <m>G</m> be a group. A (left) <m>G</m>-module is an abelian group <m>A</m> with an action of <m>G</m> by additive maps on the left, meaning that
            </p>
        
            <p>
              <me>g(a+b)=g a+g b</me>
            </p>
        
            <p>
              for all <m>a, b \in A</m> and all <m>g \in G</m>, where we write <m>g a</m> for the action of <m>g \in G</m> on <m>a \in A</m>. Given two <m>G</m>-modules <m>A</m> and <m>B</m>, a morphism of <m>G</m>-modules <m>f: A \rightarrow B</m> is a group homomorphism that is also <m>G</m>-equivariant, meaning <m>f(g a)=g f(a)</m> for all <m>g \in G</m> and <m>a \in A</m>.
            </p>
        
            <p>
              The category of <m>G</m>-modules, which we write as <m>G</m>-mod, has objects all <m>G</m>-modules and arrows all <m>G</m>-module morphisms. We write <m>\operatorname{Hom}_{G}(A, B)</m> instead of <m>\operatorname{Hom}_{G} \bmod (A, B)</m>.
            </p>
        
            <p>
              This category <m>G</m>-mod can be identified with the category of <m>\mathbb{Z}[G]</m>-modules, of modules over the (noncommutative) ring <m>\mathbb{Z} G</m>, the group ring of <m>G</m>. It can also be identified with the functor category <m>\mathbf{A b}^{G}</m> of functors from the category <m>G</m> to the category <m>\mathbf{A b}</m> of abelian groups. As a reminder, <m>G</m> gives a category with one object <m>G</m> and arrows the elements of <m>G</m>.
            </p>
        
            <p>
              Definition 6.36. The invariant subgroup <m>A^{G}</m> of a <m>G</m>-module <m>A</m> is
            </p>
        
            <p>
              <me>A^{G}:=\{a \in A \mid g a=a \text { for all } g \in G\}</me>
            </p>
        
            <p>
              The coinvariant subgroup <m>A^{G}</m> of a <m>G</m>-module <m>A</m> is
            </p>
        
            <p>
              <me>A_{G}:=A / G \text {-submodule generated by }\{g a \quad a \in A \mid g \in G, a \in A\} \text {. }</me>
            </p>
        
            <p>
              Exercise 77. Given any <m>G</m>-module <m>A, A_{G} \cong \mathbb{Z} \otimes_{\mathbb{Z} G} A</m> and <m>A^{G} \cong \operatorname{Hom}_{G}(\mathbb{Z}, A)</m>, where <m>\mathbb{Z}</m> denotes the trivial <m>G</m>-module. In fact, there are natural isomorphisms ()<m>_{G} \cong \mathbb{Z} \otimes_{\mathbb{Z} G} A</m> and ()<m>^{G} \cong \operatorname{Hom}_{G}(\mathbb{Z}, \quad)</m>.
            </p>
        
            <p>
              Thus taking coinvariants is right exact, and taking invariants is left exact.
            </p>
        
            <p>
              Definition 6.37. Let <m>G</m> be a group and <m>A</m> a <m>G</m>-module. The homology groups of <m>G</m> with coefficients in <m>A</m> are the <m>G</m>-modules <m>\mathrm{H}_{i}(G, A)</m> obtained via the left derived functors of the coinvariants functor:
            </p>
        
            <p>
              <me>\mathrm{H}_{i}(G ; A):=L_{i}\left(\quad{ }_{G}\right)(A)</me>
            </p>
        
            <p>
              Similarly, the cohomology groups of <m>G</m> with coefficients in <m>A</m> are the <m>G</m>-modules <m>\mathrm{H}^{i}(G, A)</m> obtained via the right derived functors of the invariants functor:
            </p>
        
            <p>
              <me>\mathrm{H}^{i}(G ; A):=R^{i}\left({ }^{G}\right)(A) .</me>
            </p>
        
            <p>
              By Exercise 77,
            </p>
        
            <p>
              <me>\mathrm{H}_{i}(G ; A) \cong \operatorname{Tor}_{i}^{\mathbb{Z}[G]}(\mathbb{Z}, A) \text { and } \mathrm{H}^{i}(G ; A) \cong \operatorname{Ext}_{\mathbb{Z}[G]}^{i}(\mathbb{Z}, A)</me>
            </p>
        
            <p>
              Thus to compute group (co)homology we need a projective resolution for the trivial <m>\mathbb{Z}[G]</m>-module <m>\mathbb{Z}</m>. Note also that by Proposition <m>6.4, \mathrm{H}_{0}(G ; A)=A_{G}</m> and <m>\mathrm{H}^{0}(G ; A)=A^{G}</m>.
            </p>
        
            <p>
              Group (co)homology is a rich subject. For a detailed treatment of group (co)homology, see Weibel's Homological Algebra [Wei94].
            </p>
            
          </subsection>

          <subsection xml:id="subsec-local-cohomology"><title>Local Cohomology</title>

            <blockquote>
              <p>
                <q>
                  
                </q>
              </p>
              <attribution></attribution>
            </blockquote>

            <p>
              Let <m>I</m> be an ideal in a ring <m>R</m>. The <m>I</m>-torsion functor <m>\quad{ }_{I}: R</m>-Mod <m>\rightarrow R</m>-Mod is defined by
            </p>
        
            <p>
              <me>{ }_{I}(M):=\left\{m \in M \mid I^{n} m=0 \text { for some } n\right\}</me>
            </p>
        
            <p>
              which acts on maps by restriction.
            </p>
        
            <p>
              Exercise 78. The <m>I</m>-torsion functor is a left exact covariant additive functor.
            </p>
        
            <p>
              The <m>I</m>-torsion functor gives rise to local cohomology, the right derived functors <m>\mathrm{H}_{I}^{i}</m> of <m>{ }_{I}</m>. The <m>i</m> th local cohomology of <m>M</m> with support on <m>I</m> is then given by
            </p>
        
            <p>
              <me>\mathrm{H}_{I}^{i}(M):=R_{I}^{i}{ }_{I}(M)</me>
            </p>
        
            <p>
              Local cohomology was introduced by Grothendieck in a series of seminars at Harvard in 1961, which are now of course very famous. Grothendieck himself never published any notes on the subject, but Robin Hartshorne's notes of those lectures have been published.
            </p>
        
            <p>
              Local cohomology is a rich subject, and we could easily spend an entire semester on it. For a modern treatment of the local cohomology and its connections, the book 24 hours of local cohomology [?] and the very nice notes by Craig Huneke, Mel Hochster, and Jack Jeffries are all excellent resources.
            </p>
        
            <p>
              It turns out that local cohomology modules can be defined in a few different ways, which are in no way obviously equivalent, and those different points of view are quite helpful. For example, we can define local cohomology via the Čech complex.
            </p>
        
            <p>
              Definition 6.38 (Čech complex). Let <m>M</m> be an <m>R</m>-module and <m>x \in R</m>. The Čech complex of <m>x</m> on <m>R</m> is given by
            </p>
        
            <p>
              <me>\check{C}^{\bullet}(x):=\left(\begin{array}{c}
                0 \longrightarrow \\
                0
                \end{array} \underset{x}{R} \begin{array}{c}
                \longrightarrow \\
                1
                \end{array}\right)</me>
            </p>
        
            <p>
              The Čech complex of <m>f_{1}, \ldots, f_{t} \in R</m> on <m>M</m> is given by
            </p>
        
            <p>
              <me>\check{C}^{\bullet}\left(f_{1}^{n}, \ldots, f_{t}^{n} ; M\right):=\check{C}^{\bullet}\left(f_{1}\right) \otimes \cdots \otimes \check{C}^{\bullet}\left(f_{t}\right) \otimes M .</me>
            </p>
        
            <p>
              Example 6.39. Let's compute the Čech complex on <m>f</m> and <m>g</m> and an <m>R</m>-module <m>M</m>.
            </p>
        
       
            <image source="2023_11_27_3974d73438430121205eg-27.jpg"/>

            <exercise>
              <p>Exercise 79.</p>
                
              <p>
                a) <m>\check{C} \bullet\left(f_{1}, \ldots, f_{t} ; M\right) \cong \bigoplus_{\left\{j_{1}, \ldots, j_{i}\right\} \subseteq[t]} M_{f_{j_{1}} \cdots f_{j_{i}}}</m>
              </p>
          
              <p>
                b) The maps between components corresponding to subsets <m>I, J</m> are zero if <m>I \nsubseteq J</m>, and \pm 1 if <m>J=I \cup\{k\}</m>.
              </p>
            </exercise>
        
            <p>
              It turns out that the cohomology of the Čech complex gives us local cohomology. For an ideal <m>I=\left(f_{1}, \ldots, f_{n}\right)</m>,
            </p>
        
            <p>
              <me>\begin{aligned}
              \mathrm{H}_{I}^{i}(M) &amp; =\mathrm{H}^{i}\left(\check{C}^{\bullet}\left(f_{1}, \ldots, f_{n} ; M\right)\right) \\
              &amp; =\mathrm{H}^{i}\left(0 \rightarrow M \rightarrow \cdots \rightarrow \bigoplus_{i} M_{f_{i}} \rightarrow \cdots \bigoplus_{i=1}^{n} M_{f_{1} \cdots \widehat{f}_{i} \cdots f_{n}} \rightarrow M_{f_{1} \cdots f_{n}} \rightarrow 0\right)
              \end{aligned}</me>
            </p>
        
            <p>
              so elements in the <m>i</m> th local cohomology can be realized as equivalence classes of fractions.
            </p>
        
            <p>
              Local cohomology modules also arise as a direct limit of Ext modules:
            </p>
        
            <p>
              <me>\underset{n}{\lim _{\rightarrow}} \operatorname{Ext}_{R}^{i}\left(R / I^{n}, M\right)</me>
            </p>
        
            <p>
              The equivalence between all these different definitions is a fundamental result in the theory of local cohomology.
            </p>
        
            <p>
              Local cohomology modules play a crucial, ubiquitous role in commutative algebra. They measure many important invariants, such as dimension and depth, and are extremely useful tools for studying all sorts of topics; for example, they can be used to detect if a ring is Gorenstein (if it has finite injective dimension as a module over itself) or Cohen-Macaulay (a nice class of rings that is both very large but also very well behaved). However, local cohomology modules are typically not finitely generated. One reason for this is that injective modules are also often not finitely generated. Local cohomology is also a major reason why commutative algebraists are interested in studying injective modules.
            </p>
        
            <p>
              In fact, local cohomology is almost never finitely generated. Here's a very simple example.
            </p>
        
            <p>
              Example 6.40. Let <m>R=k\left[x_{1}, \ldots, x_{n}\right], k</m> be a field, and <m>\quad=\left(x_{1}, \ldots, x_{n}\right)</m>. Then <m>\mathrm{H}^{n}(R)</m> has the <m>k</m>-vector space structure
            </p>
        
            <p>
              <me>\bigoplus_{\text {all } a_{i}&gt;0} k \cdot \frac{1}{x_{1}^{a_{1}} \cdots x_{n}^{a_{n}}}</me>
            </p>
        
            <p>
              with <m>R</m>-module structure given by
            </p>
        
            <p>
              <me>x_{1}^{b_{1}} \cdots x_{n}^{b_{n}} \cdot \frac{z}{x_{1}^{a_{1}} \cdots x_{n}^{a_{n}}}= \begin{cases}\frac{z}{x_{1}^{a_{1} b_{1} \ldots x_{n}^{a_{n} b_{n}}}} &amp; \text { if all } b_{i}&lt;a_{i} \\ 0 &amp; \text { otherwise }\end{cases}</me>
            </p>
        
            <p>
              This is not a finitely generated module! Note also that every finitely generated submodule only has terms with bounded negative degree. But this is still a very nice module: it looks like <m>R</m> upside down. 
              
            </p>

            <image source="2023_11_27_3974d73438430121205eg-29(1).jpg"/>
        
            <p>
              <me>\mathrm{H}_{(x, y)}^{2}(k[x, y])</me>
            </p>
       
            <image source="2023_11_27_3974d73438430121205eg-29.jpg"/>
             
            <p>
              Despite being infinitely generated, local cohomology modules enjoy many finiteness properties we have gotten used to expecting from finitely generated modules. For example, over a local ring <m>(R, \quad)</m>, the local cohomology modules <m>\mathrm{H}^{i}(M)</m> of a finitely generated module <m>M</m> are Artinian - but not Noetherian!
            </p>
        
            <p>
              Huneke raised the question of whether local cohomology modules of noetherian rings always have finitely many associated primes, a problem which has been a very active research are in commutative algebra in the last few decades. While the answer to Huneke's question is no - as famous examples by Katzmann, Singh, and Singh and Swanson show - the local cohomology modules of finitely generated <m>R</m>-modules over a regular ring do have finitely many associated primes.
            </p>
        
            <p>
              One very important invariant we can study with local cohomology is the arithmetic rank.
            </p>
        
            <p>
              Definition 6.41. Let <m>I</m> be an ideal in a Noetherian <m>\operatorname{ring} R</m>. The arithmetic rank of <m>I</m> is defined by
            </p>
        
            <p>
              <me>\operatorname{ara}(I):=\min \left\{s \mid \text { there exist some } x_{1}, \ldots, x_{s} \text { such that } \sqrt{\left(x_{1}, \ldots, x_{s}\right)}=\sqrt{I}\right\}</me>
            </p>
        
            <p>
              Given a variety <m>X=V(I) \subseteq \mathbb{A}_{k}^{n}</m>, the arithmetic rank of its defining ideal <m>I(X)</m> is the minimum number of equations needed to define <m>X</m>. It turns out that this number is difficult to study, and it is best understood via local cohomology, a thought best described by Lyubeznik:
            </p>
        
            <p>
              Part of what makes the problem about the number of defining equations so interesting is that it can be very easily stated, yet a solution, in those rare cases when it is known, usually is highly nontrivial and involves a fascinating interplay of Algebra and Geometry.
            </p>
        
            <p>
              The connection to local cohomology begins with the following two elementary facts about local cohomology:
            </p>
        
            <p>
              <me>\text { If } \sqrt{I}=\sqrt{J} \text {, then } \mathrm{H}_{I}^{i}(\quad)=\mathrm{H}_{J}^{i}(\quad) \text {. }</me>
            </p>
        
            <p>
              Given any ideal <m>I, \operatorname{ara}(I) \geqslant \min \left\{i \mid \mathrm{H}_{I}^{i}(M) \neq 0\right.</m> for some <m>R</m>-module <m>\left.M\right\}</m>.
            </p>
        
            <p>
              So computing local cohomology modules, or deciding when they vanish, can help us find bounds on the arithmetic rank of a variety.
            </p>
        
            <p>
              We close this chapter with yet another example of a derived functor of an interesting functor.
            </p>
        
            <p>
              Exercise 80. Let <m>R</m> be a domain and <m>Q</m> be its fraction field. Let <m>T</m> denote the torsion functor.
            </p>
        
            <p>
              a) Show that <m>T(M)=\operatorname{Tor}_{1}^{R}(M, Q / R)</m>.
            </p>
        
            <p>
              b) Show that for every short exact sequence
            </p>
        
            <p>
              <me>0 \longrightarrow A \longrightarrow B \longrightarrow C</me>
            </p>
        
            <p>
              of <m>R</m>-modules gives rise to an exact sequence
            </p>
        
            <p>
              <me>0 \longrightarrow T(A) \longrightarrow T(B) \longrightarrow T(C) \longrightarrow(Q / R) \otimes_{R} A \longrightarrow(Q / R) \otimes_{R} B \longrightarrow(Q / R) \otimes_{R} C \longrightarrow 0</me>
            </p>
        
            <p>
              c) Show that the right derived functors of <m>T</m> are <m>R^{1} T=(Q / R) \otimes_{R} \quad</m> and <m>R^{i} T=0</m> for all <m>i \geqslant 2</m>.
            </p>
            
          </subsection>

          <outcomes>
            <ul>
              <li>
                <p>

                </p>
              </li>
            </ul>
          </outcomes>
          
        </section>
        
      </chapter>

      <chapter xml:id="ch-abelian-categories"><title>Abelian Categories</title>

        <definition xml:id="def-mono-epi"><title>Monic and Epic</title>
          <statement>
            <p>
              <ul>
                <li>
                  <p>
                    An arrow <m>f \in \operatorname{Hom}(B, C)</m> is <em>monic</em>, a <em>monomorphism</em>, or a <em>mono</em> if for all arrows
                  </p>

                  <p>
                    <me>A \stackrel{g_{1}}{\underset{g_{2}}{\longrightarrow}} B \stackrel{f}{\longrightarrow} C</me>
                  </p>
              
                  <p>
                    if <m>f g_{1}=f g_{2}</m> then <m>g_{1}=g_{2}</m>.
                  </p>
                </li>
        
                <li>
                  <p>
                    Similarly, an arrow <m>f \in \operatorname{Hom}(A, B)</m> is an <em>epi</em> or an <em>epimorphism</em> if for all arrows
                    <me>
                      A \stackrel{f}{\longrightarrow} B \underset{g_{2}}{\stackrel{g_{1}}{\longrightarrow}} C
                    </me>
                    if <m>g_{1} f=g_{2} f</m> then <m>g_{1}=g_{2}</m>.
                  </p>
                </li>
              </ul>
            </p>
          </statement>
        </definition>
    
        <p>
          Here are some examples:
        </p>

        <exercise xml:id="exp-mono-epi-set"><title>Monos and Epis in Set</title>
          <p>
            Show that in <m>\Set</m>, the monos coincide with the injective functions and the epis coincide with the surjective functions.
          </p>
        </exercise>

        <exercise xml:id="exp-iso-mono-epi"><title>Isomorphisms Mono and Epi</title>
          <p>
            Show that in any category, every isomorphism is both epi and mono.
          </p>
        </exercise>

        <exercise xml:id="exp-epi-not-surj"><title>Epi and Surjective not the Same</title>
          <p>
            Show that the usual inclusion <m>\mathbb{Z} \longrightarrow \mathbb{Q}</m> is an epi in the category <m>\Ring</m>.
          </p>
        </exercise>
    
        <p>
          This should feel weird: it says being epi and being surjective are not the same thing. 
          Similarly, being monic and being injective are not the same thing.
        </p>

        <exercise xml:id="exp-mono-not-inj"><title>Mono and Injective not the Same</title>
          <p>
            Show that the canonical projection <m>\mathbb{Q} \longrightarrow \mathbb{Q} / \mathbb{Z}</m> is a mono in the category of divisible abelian groups.
            <fn>An abelian group <m>A</m> is divisible if for every <m>a \in A</m> and every positive integer <m>n</m> there exists <m>b \in A</m> such that <m>n b=a</m>.</fn>
          </p>
        </exercise>

        <exercise xml:id="exp-mono-epi-poset"><title>Monic and Epic in Poset Category</title>
          <p>
            Show that given any poset <m>P</m>, in the poset category of <m>P</m> every morphism is both monic and epic, but no nonidentity morphism has a left or right inverse.
          </p>
        </exercise>

        <p>
          There are some special types of objects we will want to consider.
        </p>

        <definition xml:id="def-initial-terminal"><title>Initial and Terminal Objects</title>
          <statement>
            <p>
              Let <m>\mathscr{C}</m> be a category. 
              An <em>initial object</em> in <m>\mathscr{C}</m> is an object <m>i</m> such that for every object <m>x</m> in <m>\mathscr{C}, \operatorname{Hom}_{\mathscr{C}}(i, x)</m> is a singleton, meaning there exists a unique arrow <m>i \longrightarrow x</m>. 
              A <em>terminal object</em> in <m>\mathscr{C}</m> is an object <m>t</m> such that for every object <m>x</m> in <m>\mathscr{C}, \operatorname{Hom}_{\mathscr{C}}(x, t)</m> is a singleton, meaning there exists a unique arrow <m>x \longrightarrow t</m>. 
              A <em>zero object</em> in <m>\mathscr{C}</m> is an object that is both initial and terminal.
            </p>
          </statement>
        </definition>

        <exercise xml:id="exp-unique-initial-terminal"><title>Uniqueness of Initial and Terminal Objects</title>
          <p>
            Initial objects are unique up to unique isomorphism. 
            Terminal objects are unique up to unique isomorphism.
          </p>
        </exercise>

        <p>
          So we can talk about the initial object, the terminal object, and the zero object, if they exist.
        </p>

        <example xml:id="ex-initial-terminal"><title>Initial and Terminal Objects</title>
          <p>
            <ol>
              <li>
                <p>
                  The empty set is initial in Set. 
                  Any singleton is terminal. 
                  Since the empty set and a singleton are not isomorphic in Set, there is no zero object in Set.
                </p>
              </li>

              <li>
                <p>
                  The <m>0</m> module is the zero object in <m>R</m><m>\Mod</m>.
                </p>
              </li>

              <li>
                <p>
                  The trivial group <m>\{e\}</m> is the zero object in <m>\Grp</m>.
                </p>
              </li>

              <li>
                <p>
                  In the category of rings, <m>\mathbb{Z}</m> is the initial object, but there is no terminal object unless we allow the <m>0</m> ring.
                </p>
              </li>

              <li>
                <p>
                  There are neither initial nor terminal objects in the category of fields.
                </p>
              </li>
            </ol>
          </p>
        </example>
        
      </chapter>

    </part>

    <backmatter xml:id="backmatter"><title>Backmatter</title>

      <appendix><title>Rings and Modules</title>

        <section xml:id="sec-rings"><title>Rings</title>

          <p>
            In this class, all rings have a multiplicative identity, written as 1 or <m>1_{R}</m> is we want to emphasize that we are referring to the ring <m>R</m>. 
            This is what some authors call unital rings; since for us all rings are unital, we will omit the adjective. 
            Moreover, we will think of 1 as part of the structure of the ring, and thus require it be preserved by all natural constructions. 
            As such, a subring <m>S</m> of <m>R</m> must share the same multiplicative identity with <m>R</m>, meaning <m>1_{R}=1_{S}</m>. 
            Moreover, any ring homomorphism must preserve the multiplicative identity. 
            To clear any possible confusion, we include below the relevant definitions.
          </p>

          <definition xml:id="def-A1"><title>Ring</title>
            <statement>
              <p>
                A <em>ring</em> is a set <m>R</m> equipped with two binary operations, + and <m>\cdot</m>, satisfying:
                <ol>
                  <li>
                    <p>
                      <m>(R,+)</m> is an abelian group with identity element denoted 0 or <m>0_{R}</m>.
                    </p>
                  </li>
          
                  <li>
                    <p>
                      The operation <m>\cdot</m> is associative, so that <m>(R, \cdot)</m> is a semigroup.
                    </p>
                  </li>
            
                  <li>
                    <p>
                      For all <m>a, b, c \in R</m>, we have
                      <me>a \cdot(b+c)=a \cdot b+a \cdot c \quad \text { and } \quad(a+b) \cdot c=a \cdot c+b \cdot c</me>
                    </p>
                  </li>

                  <li>
                    <p>
                      there is a multiplicative identity, written as 1 or <m>1_{R}</m>, such that <m>1 \neq 0</m> and <m>1 \cdot a=a=a \cdot 1</m> for all <m>a \in R</m>.
                    </p>
                  </li>
                </ol>
              </p>
            </statement>
          </definition>

          <p>
            To simplify notation, we will often drop the <m>\cdot</m> when writing the multiplication of two elements, so that <m>a b</m> will mean <m>a \cdot b</m>.
          </p>
      
          <p>
            Note that the requirement that <m>1 \neq 0</m> makes it so that the zero ring is not a ring.
          </p>

          <definition xml:id="def-A2">
            <statement>
              <p>
                Definition A.2. A ring <m>R</m> is a commutative ring if for all <m>a, b \in R</m> we have <m>a \cdot b=b \cdot a</m>.
              </p>
            </statement>
          </definition>

          <definition xml:id="def-A3">
            <statement>
              <p>
                Definition A.3. A ring <m>R</m> is a division ring if <m>1 \neq 0</m> and <m>R \backslash\{0\}</m> is a group under <m>\cdot</m>, so every nonzero <m>r \in R</m> has a multiplicative inverse. A field is a commutative division ring.
              </p>
            </statement>
          </definition>

          <definition xml:id="def-A4">
            <statement>
              <p>
                Definition A.4. A commutative ring <m>R</m> is a domain, sometimes called an integral domain, if it has no zerodivisors: <m>a b=0 \Rightarrow a=0</m> or <m>b=0</m>. Note that in particular we reserve the word domain for commutative rings.
              </p>
            </statement>
          </definition>
      
          <p>
            For some familiar examples, <m>\mathrm{M}_{n}(R)</m> (the set of <m>n \times n</m> matrices) is a ring with the usual addition and multiplication of matrices, <m>\mathbb{Z}</m> and <m>\mathbb{Z} / n</m> are commutative rings, <m>\mathbb{C}</m> and <m>\mathbb{Q}</m> are fields, and the real Hamiltonian quaternion ring <m>\mathbb{H}</m> is a division ring.
          </p>

          <definition xml:id="def-A5">
            <statement>
              <p>
                Definition A.5. A ring homomorphism is a function <m>f: R \rightarrow S</m> satisfying the following:
              </p>
              <p><ul>
                <li>
                    <p>
                <m>f(a+b)=f(a)+f(b)</m> for all <m>a, b \in R</m>.
              </p>
                </li>
          
                <li>
                    <p>
                <m>f(a b)=f(a) f(b)</m> for all <m>a, b \in R</m>.
              </p>
                </li>
          
                <li>
                    <p>
                <m>f\left(1_{R}\right)=1_{S}</m>.
              </p>
                </li>
          
              </ul></p>
            </statement>
          </definition>
      
          <p>
            Under this definition, the map <m>f: \mathbb{R} \rightarrow \mathrm{M}_{2}(\mathbb{R})</m> sending <m>a \mapsto\left[\begin{array}{ll}a &amp; 0 \\ 0 &amp; 0\end{array}\right]</m> preserves addition and multiplication but not the multiplicative identities, and thus it is not a ring homomorphism.
          </p>

          <exercise>
            <p>
              Exercise 65. For any ring <m>R</m>, there exists a unique homomorphism <m>\mathbb{Z} \rightarrow R</m>.
            </p>
          </exercise>

          <definition xml:id="def-A6">
            <statement>
              <p>
                Definition A.6. A subset <m>S</m> of a ring <m>R</m> is a subring of <m>R</m> if it is a ring under the same addition and multiplication operations and <m>1_{R}=1_{S}</m>.
              </p>
            </statement>
          </definition>
      
          <p>
            So under this definition, <m>2 \mathbb{Z}</m>, the set of even integers, is not a subring of <m>\mathbb{Z}</m>; in fact, it is not even a ring, since it does not have a multiplicative identity!
          </p>

          <definition xml:id="def-A7">
            <statement>
              <p>
                Definition A.7. 
                Let <m>R</m> be a ring. A subset <m>I</m> of <m>R</m> is an ideal if:
              </p>
          
              <p><ul>
                <li>
                    <p>
                <m>I</m> is nonempty.
              </p>
                </li>
          
                <li>
                    <p>
                <m>(I,+)</m> is a subgroup of <m>(R,+)</m>.
              </p>
                </li>
          
                <li>
                    <p>
                For every <m>a \in I</m> and every <m>r \in R</m>, we have <m>r a \in I</m> and <m>a r \in I</m>.
              </p>
                </li>
          
              </ul></p>
            </statement>
          </definition>

          <p>
            The final property is often called absorption. 
            A left ideal satisfies only absorption on the left, meaning that we require only that <m>r a \in I</m> for all <m>r \in R</m> and <m>a \in I</m>. 
            Similarly, a right ideal satisfies only absorption on the right, meaning that <m>a r \in I</m> for all <m>r \in R</m> and <m>a \in I</m>.
          </p>
      
          <p>
            When <m>R</m> is a commutative ring, the left ideals, right ideals, and ideals over <m>R</m> are all the same. 
            However, if <m>R</m> is not commutative, then these can be very different classes.
          </p>
      
          <p>
            One key distinction between unital rings and nonunital rings is that if one requires every ring to have a 1 , as we do, then the ideals and subrings of a ring <m>R</m> are very different creatures. 
            In fact, the only subring of <m>R</m> that is also an ideal is <m>R</m> itself. 
            The change lies in what constitutes a subring; notice that nothing has changed in the definition of ideal.
          </p>

          <remark>
            <p>
              Remark A.8. 
              Every ring <m>R</m> has two trivial ideals: <m>R</m> itself and the zero ideal <m>(0)=\{0\}</m>.
            </p>
          </remark>
      
          <p>
            A nontrivial ideal <m>I</m> of <m>R</m> is an ideal that <m>I \neq R</m> and <m>I \neq(0)</m>. 
            An ideal <m>I</m> of <m>R</m> is a proper ideal if <m>I \neq R</m>.
          </p>
          
        </section>

        <section xml:id="sec-modules"><title>Modules</title>
          <p>
            You can learn more about the basic theory of (commutative) rings and <m>R</m>-modules in any introductory algebra book, such as [DF04].
          </p>

          <definition xml:id="def-A9">
            <statement>
              <p>
                Definition A.9. Let <m>R</m> be a ring with <m>1 \neq 0</m>. A left <m>R</m>-module is an abelian group <m>(M,+)</m> together with an action <m>R \times M \rightarrow M</m> of <m>R</m> on <m>M</m>, written as <m>(r, m) \mapsto r m</m>, such that for all <m>r, s \in R</m> and <m>m, n \in M</m> we have the following:
              </p>
          
              <p><ul>
                <li>
                    <p>
                <m>(r+s) m=r m+s m</m>,
              </p>
                </li>
          
                <li>
                    <p>
                <m>(r s) m=r(s m)</m>,
              </p>
                </li>
          
                <li>
                    <p>
                <m>r(m+n)=r m+r n</m>, and
              </p>
                </li>
          
                <li>
                    <p>
                <m>1 m=m</m>.
              </p>
                </li>
          
              </ul></p>
          
              <p>
                A right <m>R</m>-module is an abelian group <m>(M,+)</m> together with an action of <m>R</m> on <m>M</m>, written as <m>M \times R \rightarrow M,(m, r) \mapsto m r</m>, such that for all <m>r, s \in R</m> and <m>m, n \in M</m> we have
              </p>
          
              <p><ul>
                <li>
                    <p>
                <m>m(r+s)=m r+m s</m>,
              </p>
                </li>
          
                <li>
                    <p>
                <m>m(r s)=(m r) s</m>,
              </p>
                </li>
          
                <li>
                    <p>
                <m>(m+n) r=m r+n r</m>, and
              </p>
                </li>
          
                <li>
                    <p>
                <m>m 1=m</m>.
              </p>
                </li>
          
              </ul></p>
            </statement>
          </definition>
      
          <p>
            By default, we will be studying left <m>R</m>-modules. 
            To make the writing less heavy, we will sometimes say <m>R</m>-module rather than left <m>R</m>-module whenever there is no ambiguity.
          </p>

          <remark>
            <p>
              Remark A.10. 
              If <m>R</m> is a commutative ring, then any left <m>R</m>-module <m>M</m> may be regarded as a right <m>R</m>-module by setting <m>m r:=r m</m>. 
              Likewise, any right <m>R</m>-module may be regarded as a left <m>R</m>-module. 
              Thus for commutative rings, we just refer to modules, and not left or right modules.
            </p>
          </remark>
      
          <p>
            The definitions of submodule, quotient of modules, and homomorphism of modules are very natural and easy to guess, but here they are.
          </p>

          <definition xml:id="def-A11">
            <statement>
              <p>
                If <m>N \subseteq M</m> are <m>R</m>-modules with compatible structures, we say that <m>N</m> is a submodule of <m>M</m>.
              </p>
          
              <p>
                A map <m>M \stackrel{f}{\longrightarrow} N</m> between <m>R</m>-modules is a homomorphism of <m>R</m>-modules if it is a homomorphism of abelian groups that preserves the <m>R</m>-action, meaning <m>f(r a)=r f(a)</m> for all <m>r \in R</m> and all <m>a \in M</m>. 
                We sometimes refer to <m>R</m>-module homomorphisms as <m>R</m>-module maps, or maps of <m>R</m>-modules. 
                An isomorphism of <m>R</m>-modules is a bijective homomorphism, which we really should think about as a relabeling of the elements in our module. 
                If two modules <m>M</m> and <m>N</m> are isomorphic, we write <m>M \cong N</m>.
              </p>
          
              <p>
                Given an <m>R</m>-module <m>M</m> and a submodule <m>N \subseteq M</m>, the quotient <m>M / N</m> is an <m>R</m>-module whose elements are the equivalence classes determined by the relation on <m>M</m> given by <m>a \sim</m> <m>b \Leftrightarrow a-b \in N</m>. 
                One can check that this set naturally inherits an <m>R</m>-module structure from the <m>R</m>-module structure on <m>M</m>, and it comes equipped with a natural canonical map <m>M \longrightarrow M / N</m> induced by sending <m>1</m> to its equivalence class.
              </p>
            </statement>
          </definition>

          <example>
            <p>
              Example A.12. 
              The modules over a field <m>k</m> are precisely all the <m>k</m>-vector spaces. 
              Linear transformations are precisely all the <m>k</m>-module maps.
            </p>
          </example>
      
          <p>
            While vector spaces make for a great first example, be warned that many of the basic facts we are used to from linear algebra are often a little more subtle in commutative algebra. 
            These differences are features, not bugs.
          </p>

          <example>
            <p>
              Example A.13. 
              The <m>\mathbb{Z}</m>-modules are precisely all the abelian groups.
            </p>
          </example>

          <example>
            <p>
              Example A.14. 
              When we think of the ring <m>R</m> as a module over itself, the submodules of <m>R</m> are precisely the ideals of <m>R</m>.
            </p>
          </example>

          <theorem xml:id="thm-A15"><title>First Isomorphism Theorem</title>
            <statement>
              <p>
                Any <m>R</m>-module homomorphism <m>M \stackrel{f}{\longrightarrow} N</m> satisfies <m>M / \operatorname{ker} f \cong \operatorname{im} f</m>.
              </p>
            </statement>
          </theorem>
      
          <p>
            The first big noticeable difference between vector spaces and more general <m>R</m>-modules is that while every vector space has a basis, most <m>R</m>-modules do not.
          </p>

          <definition xml:id="def-A16">
            <statement>
              <p>
                A subset <m>\Gamma \subseteq M</m> of an <m>R</m>-module <m>M</m> is a generating set, or a set of generators, if every element in <m>M</m> can be written as a finite linear combination of elements in <m>M</m> with coefficients in <m>R</m>. 
                A basis for an <m>R</m>-module <m>M</m> is a generating set <m>\Gamma</m> for <m>M</m> such that <m>\sum_{i} a_{i} \gamma_{i}=0</m> implies <m>a_{i}=0</m> for all <m>i</m>. 
                An <m>R</m>-module is free if it has a basis.
              </p>
            </statement>
          </definition>

          <remark>
            <p>
              Remark A.17. 
              Every vector space is a free module.
            </p>
          </remark>

          <remark>
            <p>
              Remark A.18. 
              Every free <m>R</m>-module is isomorphic to a direct sum of copies of <m>R</m>. 
              Indeed, let's construct such an isomorphism for a given free <m>R</m>-module <m>M</m>. 
              Given a basis <m>\Gamma=\left\{\gamma_{i}\right\}_{i \in I}</m> for <m>M</m>, let
              <me>
                \begin{aligned}
                &amp; \bigoplus_{i \in I} R \stackrel{\pi}{\longrightarrow} M \\
                &amp; \left(r_{i}\right)_{i \in I} \longrightarrow \sum_{i} r_{i} \gamma_{i}
                \end{aligned}
              </me>
            </p>
        
            <p>
              The condition that <m>\Gamma</m> is a basis for <m>M</m> can be restated into the statement that <m>\pi</m> is an isomorphism of <m>R</m>-modules.
            </p>
          </remark>
      
          <p>
            One of the key things that makes commutative algebra so rich and beautiful is that most modules are in fact not free. 
            In general, every <m>R</m>-module has a generating set - for example, <m>M</m> itself. 
            Given some generating set <m>\Gamma</m> for <m>M</m>, we can always repeat the idea above and write a presentation <m>\oplus_{i \in I} R \stackrel{\pi}{\longrightarrow} M</m> for <m>M</m>, but in general the resulting map <m>\pi</m> will have a nontrivial kernel. 
            A nonzero kernel element <m>\left(r_{i}\right)_{i \in I} \in \operatorname{ker} \pi</m> corresponds to a relation between the generators of <m>M</m>.
          </p>

          <remark>
            <p>
              Remark A.19. 
              Given a set of generators for an <m>R</m>-module <m>M</m>, any homomorphism of <m>R</m> modules <m>M \longrightarrow N</m> is determined by the images of the generators.
            </p>
          </remark>
      
          <p>
            We say that a module is finitely generated if we can find a finite generating set for <m>M</m>. 
            The simplest finitely generated modules are the cyclic modules.
          </p>

          <example>
            <p>
              Example A.20. 
              An <m>R</m>-module is cyclic if it can be generated by one element. 
              Equivalently, we can write <m>M</m> as a quotient of <m>R</m> by some ideal <m>I</m>. 
              Indeed, given a generator <m>m</m> for <m>M</m>, the kernel of the map <m>R \stackrel{\pi}{\longrightarrow} M</m> induced by <m>1 \mapsto m</m> is some ideal <m>I</m>. 
              Since we assumed that <m>m</m> generates <m>M, \pi</m> is automatically surjective, and thus induces an isomorphism <m>R / I \cong M</m>.
            </p>
          </example>

          <p>
            Similarly, if an <m>R</m>-module has <m>n</m> generators, we can naturally think about it as a quotient of <m>R^{n}</m> by the submodule of relations among those <m>n</m> generators.
          </p>
        </section>

      </appendix>

      <colophon>
        <p> This book was authored in <pretext />. </p>
      </colophon>

    </backmatter>

  </book>
</pretext>
